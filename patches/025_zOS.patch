diff --git a/Configurations/00-base-templates.conf b/Configurations/00-base-templates.conf
index 9add1cd..4bcbd15 100644
--- a/Configurations/00-base-templates.conf
+++ b/Configurations/00-base-templates.conf
@@ -288,17 +288,43 @@ my %targets=(
     s390x_asm => {
 	template	=> 1,
 	cpuid_asm_src   => "s390xcap.c s390xcpuid.S",
-	bn_asm_src      => "asm/s390x.S s390x-mont.S s390x-gf2m.s",
+	bn_asm_src      => "s390x.S s390x-mont.S s390x-gf2m.s",
 	ec_asm_src      => "ecp_s390x_nistp.c",
 	aes_asm_src     => "aes-s390x.S aes-ctr.fake aes-xts.fake",
 	sha1_asm_src    => "sha1-s390x.S sha256-s390x.S sha512-s390x.S",
 	rc4_asm_src     => "rc4-s390x.s",
 	modes_asm_src   => "ghash-s390x.S",
 	chacha_asm_src  => "chacha-s390x.S",
-	poly1305_asm_src=> "poly1305-s390x.S",
+	poly1305_asm_src => "poly1305-s390x.S",
 	keccak1600_asm_src	=> "keccak1600-s390x.S",
     },
-    armv4_asm => {
+    zos_asm => {
+	template	=> 1,
+	cpuid_asm_src   => "s390xcap.c s390xcpuid.s",
+	bn_asm_src      => "s390x.s s390x-mont.s s390x-gf2m.s",
+	ec_asm_src      => "ecp_s390x_nistp.c",
+	aes_asm_src     => "aes-s390x.s aes-ctr.fake aes-xts.fake",
+	sha1_asm_src    => "sha1-s390x.s sha256-s390x.s sha512-s390x.s",
+	rc4_asm_src     => "rc4-s390x.s",
+	modes_asm_src   => "ghash-s390x.s",
+	chacha_asm_src  => "chacha-s390x.s",
+	poly1305_asm_src => "poly1305-s390x.s",
+	keccak1600_asm_src	=> "keccak1600-s390x.s",
+    },
+   zos32_asm => {
+	template	=> 1,
+	cpuid_asm_src   => "s390xcap.c s390xcpuid.s",
+	bn_asm_src      => "s390x.s s390x-mont.s s390x-gf2m.s",
+	ec_asm_src      => "ecp_s390x_nistp.c",
+	aes_asm_src     => "aes-s390x.s aes-ctr.fake aes-xts.fake",
+	sha1_asm_src    => "sha1-s390x.s sha256-s390x.s sha512-s390x.s",
+	rc4_asm_src     => "rc4-s390x.s",
+	modes_asm_src   => "ghash-s390x.s",
+	chacha_asm_src  => "chacha-s390x.s",
+	poly1305_asm_src => "poly1305-s390x.s",
+	keccak1600_asm_src	=> "keccak1600-s390x.s",
+    },
+   armv4_asm => {
 	template	=> 1,
 	cpuid_asm_src   => "armcap.c armv4cpuid.S",
 	bn_asm_src      => "bn_asm.c armv4-mont.S armv4-gf2m.S",
diff --git a/Configurations/10-main.conf b/Configurations/10-main.conf
index 4d461e8..e059470 100644
--- a/Configurations/10-main.conf
+++ b/Configurations/10-main.conf
@@ -829,11 +829,12 @@ my %targets = (

     "linux64-s390x" => {
         inherit_from     => [ "linux-generic64", asm("s390x_asm") ],
-        cflags           => add("-m64"),
+        cflags           => add("-g3 -m64"),
         cxxflags         => add("-m64"),
         lib_cppflags     => add("-DB_ENDIAN"),
         perlasm_scheme   => "64",
         multilib         => "64",
+	perlasm_scheme   => "linux64",
     },
     "linux32-s390x" => {
         #### So called "highgprs" target for z/Architecture CPUs
@@ -856,8 +857,8 @@ my %targets = (
         cflags           => add("-m31 -Wa,-mzarch"),
         cxxflags         => add("-m31 -Wa,-mzarch"),
         lib_cppflags     => add("-DB_ENDIAN"),
-        bn_asm_src       => sub { my $r=join(" ",@_); $r=~s|asm/s390x\.S|bn_asm.c|; $r; },
-        perlasm_scheme   => "31",
+        bn_asm_src       => sub { my $r=join(" ",@_); $r=~s|s390x\.S|bn_asm.c|; $r; },
+        perlasm_scheme   => "linux31",
         multilib         => "/highgprs",
     },

@@ -1207,7 +1208,27 @@ my %targets = (
         bn_ops           => "THIRTY_TWO_BIT RC4_CHAR",
         thread_scheme    => "(unknown)",
     },
-
+# IBM zOS, 64 and 31 bit
+     "OS390-Unix" => {
+         inherit_from     => [ "BASE_unix", asm("zos_asm") ],
+         cc               => "./tools/c99.sh",
+         cflags           => "-O -Wc,dll,XPLINK,exportall,hgpr,lp64  -Wa,'GOFF,SYSPARM(USE_XPLINK)' -qlongname -qlanglvl=extc99 -DB_ENDIAN -DCHARSET_EBCDIC -DNO_SYS_PARAM_H -D_ALL_SOURCE -D_OPEN_THREADS=2 -D_POSIX_SOURCE  -D_OPEN_MSGQ_EXT",
+	 module_ldflags   => "-Wl,XPLINK,LP64",
+	 shared_ldflags   => "-Wl,dll,XPLINK,LP64",
+         bn_ops           => "SIXTY_FOUR_BIT_LONG RC4_CHAR",
+         thread_scheme    => "(unknown)",
+	 perlasm_scheme   => "zOS64",
+     },
+     "OS390-Unix31" => {
+         inherit_from     => [ "BASE_unix", asm("zos32_asm") ],
+         cc               => "./tools/c99.sh",
+         cflags           => "-O -Wc,'ARCH(9),dll,XPLINK,exportall,hgpr'  -Wa,'GOFF,SYSPARM(USE_XPLINK)' -qlongname -qlanglvl=extc99 -DB_ENDIAN -DCHARSET_EBCDIC -DNO_SYS_PARAM_H -D_ALL_SOURCE -D_OPEN_THREADS=2 -D_POSIX_SOURCE  -D_OPEN_MSGQ_EXT",
+         module_ldflags   => "-Wl,XPLINK",
+         shared_ldflags   => "-Wl,dll,XPLINK",
+         bn_ops           => "SIXTY_FOUR_BIT RC4_CHAR",
+         thread_scheme    => "(unknown)",
+         perlasm_scheme   => "zOS31",
+    },
 #### Visual C targets
 #
 # Win64 targets, WIN64I denotes IA-64/Itanium and WIN64A - AMD64
diff --git a/crypto/aes/asm/aes-s390x.pl b/crypto/aes/asm/aes-s390x.pl
index 4cb8f43..8a1e07a 100644
--- a/crypto/aes/asm/aes-s390x.pl
+++ b/crypto/aes/asm/aes-s390x.pl
@@ -1,5 +1,5 @@
 #! /usr/bin/env perl
-# Copyright 2007-2020 The OpenSSL Project Authors. All Rights Reserved.
+# Copyright 2007-2018 The OpenSSL Project Authors. All Rights Reserved.
 #
 # Licensed under the OpenSSL license (the "License").  You may not use
 # this file except in compliance with the License.  You can obtain a copy
@@ -38,14 +38,14 @@
 # Implement AES_set_[en|de]crypt_key. Key schedule setup is avoided
 # for 128-bit keys, if hardware support is detected.

-# January 2009.
+# Januray 2009.
 #
 # Add support for hardware AES192/256 and reschedule instructions to
 # minimize/avoid Address Generation Interlock hazard and to favour
 # dual-issue z10 pipeline. This gave ~25% improvement on z10 and
 # almost 50% on z9. The gain is smaller on z10, because being dual-
 # issue z10 makes it impossible to eliminate the interlock condition:
-# critical path is not long enough. Yet it spends ~24 cycles per byte
+# critial path is not long enough. Yet it spends ~24 cycles per byte
 # processed with 128-bit key.
 #
 # Unlike previous version hardware support detection takes place only
@@ -89,2194 +89,2583 @@
 # instructions, which deliver ~70% improvement at 8KB block size over
 # vanilla km-based code, 37% - at most like 512-bytes block size.

-$flavour = shift;
+use strict;
+use FindBin qw($Bin);
+use lib "$Bin/../..";
+use perlasm::s390x qw(:DEFAULT :VX :LD :MSA :MSA4 :MSA8 AUTOLOAD LABEL INCLUDE FUNCTION_BEGIN LOCAL_FUNCTION FUNCTION_END LOCAL_FUNCTION_END OBJECT_BEGIN OBJECT_END BYTE LONG ALIGN ASCIZ TEXT GET_EXTERN GET_OBJECT LOCAL_VARS_BEGIN LOCAL_VARS_END BR_EXIT ds);

+my $flavour = shift;
+
+my ($z,$DSA_OFF,$PARMS_OFF,$SIZE_T);
+my ($inp,$outp,$bits,$key);
+
+my ($ip,$ra,$rv,$sp,$wr0,$wr1,$wr2,$wr3,$wr5,$wr6,$inp,$tbl,$mask,$rounds);
+my ($i1,$i2,$i3,$temp);
+my ($s0,$s1,$s2,$s3);
+my ($t0,$t1,$t2,$t3);
+
+$DSA_OFF=2048;
 if ($flavour =~ /3[12]/) {
-	$SIZE_T=4;
-	$g="";
+    $z=0;    # S/390 ABI
+    $SIZE_T=4;
+    $PARMS_OFF=2112;
+} else {
+    $z=1;    # zSeries/zOS  ABI
+    $SIZE_T=8;
+    $PARMS_OFF=2176;
+}
+
+if ($flavour =~/linux/) {
+        $wr0="%r0";
+        $wr1="%r1";
+        $wr2="%r2";
+        $wr3="%r3";
+        $wr5="%r5";
+        $wr6="%r6";
+
+        $i1="%r5";
+        $i2="%r6";
+        $i3="%r7";
+        $temp="%r14";
+
+        $s0="%r8";  $t0="%r0";
+        $s1="%r9";  $t1="%r1";
+        $s2="%r10"; $t2="%r2";
+        $s3="%r11"; $t3="%r3";
+
+        $inp="%r2";
+        $outp="%r3";
+	$bits="%r3";
+        $key="%r4";
+        $sp="%r15";
+        $rv="%r2";
+        $ra="%r14";
+        $tbl="%r12";
+        $mask="%r0";
+        $rounds="%r13";
+
+        $ip=".";
 } else {
-	$SIZE_T=8;
-	$g="g";
+        $wr0="R0";
+        $wr1="R1";
+        $wr2="R2";
+        $wr3="R3";
+        $wr5="R5";
+        $wr6="R6";
+
+        $i1="R5";
+        $i2="R6";
+        $i3="R7";
+        $temp="R4"; # we can use r4 in _s390x_AES_encrypt as it gets restored upon return
+
+        $s0="R8";  $t0="R0";
+        $s1="R9";  $t1="R1";
+        $s2="R10"; $t2="R2";
+        $s3="R11"; $t3="R3";
+
+        $inp="R1";
+        $outp="R2";
+        $bits="R2";
+        $key="R3";
+        $sp="R15";
+        $ra="R7";
+        $rv="R3";
+        $tbl="R13";
+        $mask="R0";
+        $rounds="R12"; # we can use r12 in _s390x_AES_encrypt as it gets restored upon return and a base register is not used
+
+        $ip="*";
 }

+my $output;
 while (($output=shift) && ($output!~/\w[\w\-]*\.\w+$/)) {}
 open STDOUT,">$output";

-$softonly=0;	# allow hardware support
-
-$t0="%r0";	$mask="%r0";
-$t1="%r1";
-$t2="%r2";	$inp="%r2";
-$t3="%r3";	$out="%r3";	$bits="%r3";
-$key="%r4";
-$i1="%r5";
-$i2="%r6";
-$i3="%r7";
-$s0="%r8";
-$s1="%r9";
-$s2="%r10";
-$s3="%r11";
-$tbl="%r12";
-$rounds="%r13";
-$ra="%r14";
-$sp="%r15";
-
-$stdframe=16*$SIZE_T+4*8;
-
-sub _data_word()
-{ my $i;
-    while(defined($i=shift)) { $code.=sprintf".long\t0x%08x,0x%08x\n",$i,$i; }
+my $softonly=0;    # allow hardware support
+
+
+my $stdframe=16*$SIZE_T+4*8;
+
+sub _data_word() {
+    my $i;
+    while(defined($i=shift)) { &LONG($i,$i); }
 }

-$code=<<___;
-#include "s390x_arch.h"
+PERLASM_BEGIN($flavour,$output);

-.text
+INCLUDE    ("s390x_arch.h", "crypto/");
+TEXT    ();
+
+{
+
+OBJECT_BEGIN("AES_Te",256);
+#AES_Te:

-.type	AES_Te,\@object
-.align	256
-AES_Te:
-___
 &_data_word(
-	0xc66363a5, 0xf87c7c84, 0xee777799, 0xf67b7b8d,
-	0xfff2f20d, 0xd66b6bbd, 0xde6f6fb1, 0x91c5c554,
-	0x60303050, 0x02010103, 0xce6767a9, 0x562b2b7d,
-	0xe7fefe19, 0xb5d7d762, 0x4dababe6, 0xec76769a,
-	0x8fcaca45, 0x1f82829d, 0x89c9c940, 0xfa7d7d87,
-	0xeffafa15, 0xb25959eb, 0x8e4747c9, 0xfbf0f00b,
-	0x41adadec, 0xb3d4d467, 0x5fa2a2fd, 0x45afafea,
-	0x239c9cbf, 0x53a4a4f7, 0xe4727296, 0x9bc0c05b,
-	0x75b7b7c2, 0xe1fdfd1c, 0x3d9393ae, 0x4c26266a,
-	0x6c36365a, 0x7e3f3f41, 0xf5f7f702, 0x83cccc4f,
-	0x6834345c, 0x51a5a5f4, 0xd1e5e534, 0xf9f1f108,
-	0xe2717193, 0xabd8d873, 0x62313153, 0x2a15153f,
-	0x0804040c, 0x95c7c752, 0x46232365, 0x9dc3c35e,
-	0x30181828, 0x379696a1, 0x0a05050f, 0x2f9a9ab5,
-	0x0e070709, 0x24121236, 0x1b80809b, 0xdfe2e23d,
-	0xcdebeb26, 0x4e272769, 0x7fb2b2cd, 0xea75759f,
-	0x1209091b, 0x1d83839e, 0x582c2c74, 0x341a1a2e,
-	0x361b1b2d, 0xdc6e6eb2, 0xb45a5aee, 0x5ba0a0fb,
-	0xa45252f6, 0x763b3b4d, 0xb7d6d661, 0x7db3b3ce,
-	0x5229297b, 0xdde3e33e, 0x5e2f2f71, 0x13848497,
-	0xa65353f5, 0xb9d1d168, 0x00000000, 0xc1eded2c,
-	0x40202060, 0xe3fcfc1f, 0x79b1b1c8, 0xb65b5bed,
-	0xd46a6abe, 0x8dcbcb46, 0x67bebed9, 0x7239394b,
-	0x944a4ade, 0x984c4cd4, 0xb05858e8, 0x85cfcf4a,
-	0xbbd0d06b, 0xc5efef2a, 0x4faaaae5, 0xedfbfb16,
-	0x864343c5, 0x9a4d4dd7, 0x66333355, 0x11858594,
-	0x8a4545cf, 0xe9f9f910, 0x04020206, 0xfe7f7f81,
-	0xa05050f0, 0x783c3c44, 0x259f9fba, 0x4ba8a8e3,
-	0xa25151f3, 0x5da3a3fe, 0x804040c0, 0x058f8f8a,
-	0x3f9292ad, 0x219d9dbc, 0x70383848, 0xf1f5f504,
-	0x63bcbcdf, 0x77b6b6c1, 0xafdada75, 0x42212163,
-	0x20101030, 0xe5ffff1a, 0xfdf3f30e, 0xbfd2d26d,
-	0x81cdcd4c, 0x180c0c14, 0x26131335, 0xc3ecec2f,
-	0xbe5f5fe1, 0x359797a2, 0x884444cc, 0x2e171739,
-	0x93c4c457, 0x55a7a7f2, 0xfc7e7e82, 0x7a3d3d47,
-	0xc86464ac, 0xba5d5de7, 0x3219192b, 0xe6737395,
-	0xc06060a0, 0x19818198, 0x9e4f4fd1, 0xa3dcdc7f,
-	0x44222266, 0x542a2a7e, 0x3b9090ab, 0x0b888883,
-	0x8c4646ca, 0xc7eeee29, 0x6bb8b8d3, 0x2814143c,
-	0xa7dede79, 0xbc5e5ee2, 0x160b0b1d, 0xaddbdb76,
-	0xdbe0e03b, 0x64323256, 0x743a3a4e, 0x140a0a1e,
-	0x924949db, 0x0c06060a, 0x4824246c, 0xb85c5ce4,
-	0x9fc2c25d, 0xbdd3d36e, 0x43acacef, 0xc46262a6,
-	0x399191a8, 0x319595a4, 0xd3e4e437, 0xf279798b,
-	0xd5e7e732, 0x8bc8c843, 0x6e373759, 0xda6d6db7,
-	0x018d8d8c, 0xb1d5d564, 0x9c4e4ed2, 0x49a9a9e0,
-	0xd86c6cb4, 0xac5656fa, 0xf3f4f407, 0xcfeaea25,
-	0xca6565af, 0xf47a7a8e, 0x47aeaee9, 0x10080818,
-	0x6fbabad5, 0xf0787888, 0x4a25256f, 0x5c2e2e72,
-	0x381c1c24, 0x57a6a6f1, 0x73b4b4c7, 0x97c6c651,
-	0xcbe8e823, 0xa1dddd7c, 0xe874749c, 0x3e1f1f21,
-	0x964b4bdd, 0x61bdbddc, 0x0d8b8b86, 0x0f8a8a85,
-	0xe0707090, 0x7c3e3e42, 0x71b5b5c4, 0xcc6666aa,
-	0x904848d8, 0x06030305, 0xf7f6f601, 0x1c0e0e12,
-	0xc26161a3, 0x6a35355f, 0xae5757f9, 0x69b9b9d0,
-	0x17868691, 0x99c1c158, 0x3a1d1d27, 0x279e9eb9,
-	0xd9e1e138, 0xebf8f813, 0x2b9898b3, 0x22111133,
-	0xd26969bb, 0xa9d9d970, 0x078e8e89, 0x339494a7,
-	0x2d9b9bb6, 0x3c1e1e22, 0x15878792, 0xc9e9e920,
-	0x87cece49, 0xaa5555ff, 0x50282878, 0xa5dfdf7a,
-	0x038c8c8f, 0x59a1a1f8, 0x09898980, 0x1a0d0d17,
-	0x65bfbfda, 0xd7e6e631, 0x844242c6, 0xd06868b8,
-	0x824141c3, 0x299999b0, 0x5a2d2d77, 0x1e0f0f11,
-	0x7bb0b0cb, 0xa85454fc, 0x6dbbbbd6, 0x2c16163a);
-$code.=<<___;
+    0xc66363a5, 0xf87c7c84, 0xee777799, 0xf67b7b8d,
+    0xfff2f20d, 0xd66b6bbd, 0xde6f6fb1, 0x91c5c554,
+    0x60303050, 0x02010103, 0xce6767a9, 0x562b2b7d,
+    0xe7fefe19, 0xb5d7d762, 0x4dababe6, 0xec76769a,
+    0x8fcaca45, 0x1f82829d, 0x89c9c940, 0xfa7d7d87,
+    0xeffafa15, 0xb25959eb, 0x8e4747c9, 0xfbf0f00b,
+    0x41adadec, 0xb3d4d467, 0x5fa2a2fd, 0x45afafea,
+    0x239c9cbf, 0x53a4a4f7, 0xe4727296, 0x9bc0c05b,
+    0x75b7b7c2, 0xe1fdfd1c, 0x3d9393ae, 0x4c26266a,
+    0x6c36365a, 0x7e3f3f41, 0xf5f7f702, 0x83cccc4f,
+    0x6834345c, 0x51a5a5f4, 0xd1e5e534, 0xf9f1f108,
+    0xe2717193, 0xabd8d873, 0x62313153, 0x2a15153f,
+    0x0804040c, 0x95c7c752, 0x46232365, 0x9dc3c35e,
+    0x30181828, 0x379696a1, 0x0a05050f, 0x2f9a9ab5,
+    0x0e070709, 0x24121236, 0x1b80809b, 0xdfe2e23d,
+    0xcdebeb26, 0x4e272769, 0x7fb2b2cd, 0xea75759f,
+    0x1209091b, 0x1d83839e, 0x582c2c74, 0x341a1a2e,
+    0x361b1b2d, 0xdc6e6eb2, 0xb45a5aee, 0x5ba0a0fb,
+    0xa45252f6, 0x763b3b4d, 0xb7d6d661, 0x7db3b3ce,
+    0x5229297b, 0xdde3e33e, 0x5e2f2f71, 0x13848497,
+    0xa65353f5, 0xb9d1d168, 0x00000000, 0xc1eded2c,
+    0x40202060, 0xe3fcfc1f, 0x79b1b1c8, 0xb65b5bed,
+    0xd46a6abe, 0x8dcbcb46, 0x67bebed9, 0x7239394b,
+    0x944a4ade, 0x984c4cd4, 0xb05858e8, 0x85cfcf4a,
+    0xbbd0d06b, 0xc5efef2a, 0x4faaaae5, 0xedfbfb16,
+    0x864343c5, 0x9a4d4dd7, 0x66333355, 0x11858594,
+    0x8a4545cf, 0xe9f9f910, 0x04020206, 0xfe7f7f81,
+    0xa05050f0, 0x783c3c44, 0x259f9fba, 0x4ba8a8e3,
+    0xa25151f3, 0x5da3a3fe, 0x804040c0, 0x058f8f8a,
+    0x3f9292ad, 0x219d9dbc, 0x70383848, 0xf1f5f504,
+    0x63bcbcdf, 0x77b6b6c1, 0xafdada75, 0x42212163,
+    0x20101030, 0xe5ffff1a, 0xfdf3f30e, 0xbfd2d26d,
+    0x81cdcd4c, 0x180c0c14, 0x26131335, 0xc3ecec2f,
+    0xbe5f5fe1, 0x359797a2, 0x884444cc, 0x2e171739,
+    0x93c4c457, 0x55a7a7f2, 0xfc7e7e82, 0x7a3d3d47,
+    0xc86464ac, 0xba5d5de7, 0x3219192b, 0xe6737395,
+    0xc06060a0, 0x19818198, 0x9e4f4fd1, 0xa3dcdc7f,
+    0x44222266, 0x542a2a7e, 0x3b9090ab, 0x0b888883,
+    0x8c4646ca, 0xc7eeee29, 0x6bb8b8d3, 0x2814143c,
+    0xa7dede79, 0xbc5e5ee2, 0x160b0b1d, 0xaddbdb76,
+    0xdbe0e03b, 0x64323256, 0x743a3a4e, 0x140a0a1e,
+    0x924949db, 0x0c06060a, 0x4824246c, 0xb85c5ce4,
+    0x9fc2c25d, 0xbdd3d36e, 0x43acacef, 0xc46262a6,
+    0x399191a8, 0x319595a4, 0xd3e4e437, 0xf279798b,
+    0xd5e7e732, 0x8bc8c843, 0x6e373759, 0xda6d6db7,
+    0x018d8d8c, 0xb1d5d564, 0x9c4e4ed2, 0x49a9a9e0,
+    0xd86c6cb4, 0xac5656fa, 0xf3f4f407, 0xcfeaea25,
+    0xca6565af, 0xf47a7a8e, 0x47aeaee9, 0x10080818,
+    0x6fbabad5, 0xf0787888, 0x4a25256f, 0x5c2e2e72,
+    0x381c1c24, 0x57a6a6f1, 0x73b4b4c7, 0x97c6c651,
+    0xcbe8e823, 0xa1dddd7c, 0xe874749c, 0x3e1f1f21,
+    0x964b4bdd, 0x61bdbddc, 0x0d8b8b86, 0x0f8a8a85,
+    0xe0707090, 0x7c3e3e42, 0x71b5b5c4, 0xcc6666aa,
+    0x904848d8, 0x06030305, 0xf7f6f601, 0x1c0e0e12,
+    0xc26161a3, 0x6a35355f, 0xae5757f9, 0x69b9b9d0,
+    0x17868691, 0x99c1c158, 0x3a1d1d27, 0x279e9eb9,
+    0xd9e1e138, 0xebf8f813, 0x2b9898b3, 0x22111133,
+    0xd26969bb, 0xa9d9d970, 0x078e8e89, 0x339494a7,
+    0x2d9b9bb6, 0x3c1e1e22, 0x15878792, 0xc9e9e920,
+    0x87cece49, 0xaa5555ff, 0x50282878, 0xa5dfdf7a,
+    0x038c8c8f, 0x59a1a1f8, 0x09898980, 0x1a0d0d17,
+    0x65bfbfda, 0xd7e6e631, 0x844242c6, 0xd06868b8,
+    0x824141c3, 0x299999b0, 0x5a2d2d77, 0x1e0f0f11,
+    0x7bb0b0cb, 0xa85454fc, 0x6dbbbbd6, 0x2c16163a);
 # Te4[256]
-.byte	0x63, 0x7c, 0x77, 0x7b, 0xf2, 0x6b, 0x6f, 0xc5
-.byte	0x30, 0x01, 0x67, 0x2b, 0xfe, 0xd7, 0xab, 0x76
-.byte	0xca, 0x82, 0xc9, 0x7d, 0xfa, 0x59, 0x47, 0xf0
-.byte	0xad, 0xd4, 0xa2, 0xaf, 0x9c, 0xa4, 0x72, 0xc0
-.byte	0xb7, 0xfd, 0x93, 0x26, 0x36, 0x3f, 0xf7, 0xcc
-.byte	0x34, 0xa5, 0xe5, 0xf1, 0x71, 0xd8, 0x31, 0x15
-.byte	0x04, 0xc7, 0x23, 0xc3, 0x18, 0x96, 0x05, 0x9a
-.byte	0x07, 0x12, 0x80, 0xe2, 0xeb, 0x27, 0xb2, 0x75
-.byte	0x09, 0x83, 0x2c, 0x1a, 0x1b, 0x6e, 0x5a, 0xa0
-.byte	0x52, 0x3b, 0xd6, 0xb3, 0x29, 0xe3, 0x2f, 0x84
-.byte	0x53, 0xd1, 0x00, 0xed, 0x20, 0xfc, 0xb1, 0x5b
-.byte	0x6a, 0xcb, 0xbe, 0x39, 0x4a, 0x4c, 0x58, 0xcf
-.byte	0xd0, 0xef, 0xaa, 0xfb, 0x43, 0x4d, 0x33, 0x85
-.byte	0x45, 0xf9, 0x02, 0x7f, 0x50, 0x3c, 0x9f, 0xa8
-.byte	0x51, 0xa3, 0x40, 0x8f, 0x92, 0x9d, 0x38, 0xf5
-.byte	0xbc, 0xb6, 0xda, 0x21, 0x10, 0xff, 0xf3, 0xd2
-.byte	0xcd, 0x0c, 0x13, 0xec, 0x5f, 0x97, 0x44, 0x17
-.byte	0xc4, 0xa7, 0x7e, 0x3d, 0x64, 0x5d, 0x19, 0x73
-.byte	0x60, 0x81, 0x4f, 0xdc, 0x22, 0x2a, 0x90, 0x88
-.byte	0x46, 0xee, 0xb8, 0x14, 0xde, 0x5e, 0x0b, 0xdb
-.byte	0xe0, 0x32, 0x3a, 0x0a, 0x49, 0x06, 0x24, 0x5c
-.byte	0xc2, 0xd3, 0xac, 0x62, 0x91, 0x95, 0xe4, 0x79
-.byte	0xe7, 0xc8, 0x37, 0x6d, 0x8d, 0xd5, 0x4e, 0xa9
-.byte	0x6c, 0x56, 0xf4, 0xea, 0x65, 0x7a, 0xae, 0x08
-.byte	0xba, 0x78, 0x25, 0x2e, 0x1c, 0xa6, 0xb4, 0xc6
-.byte	0xe8, 0xdd, 0x74, 0x1f, 0x4b, 0xbd, 0x8b, 0x8a
-.byte	0x70, 0x3e, 0xb5, 0x66, 0x48, 0x03, 0xf6, 0x0e
-.byte	0x61, 0x35, 0x57, 0xb9, 0x86, 0xc1, 0x1d, 0x9e
-.byte	0xe1, 0xf8, 0x98, 0x11, 0x69, 0xd9, 0x8e, 0x94
-.byte	0x9b, 0x1e, 0x87, 0xe9, 0xce, 0x55, 0x28, 0xdf
-.byte	0x8c, 0xa1, 0x89, 0x0d, 0xbf, 0xe6, 0x42, 0x68
-.byte	0x41, 0x99, 0x2d, 0x0f, 0xb0, 0x54, 0xbb, 0x16
+BYTE (0x63, 0x7c, 0x77, 0x7b, 0xf2, 0x6b, 0x6f, 0xc5);
+BYTE (0x30, 0x01, 0x67, 0x2b, 0xfe, 0xd7, 0xab, 0x76);
+BYTE (0xca, 0x82, 0xc9, 0x7d, 0xfa, 0x59, 0x47, 0xf0);
+BYTE (0xad, 0xd4, 0xa2, 0xaf, 0x9c, 0xa4, 0x72, 0xc0);
+BYTE (0xb7, 0xfd, 0x93, 0x26, 0x36, 0x3f, 0xf7, 0xcc);
+BYTE (0x34, 0xa5, 0xe5, 0xf1, 0x71, 0xd8, 0x31, 0x15);
+BYTE (0x04, 0xc7, 0x23, 0xc3, 0x18, 0x96, 0x05, 0x9a);
+BYTE (0x07, 0x12, 0x80, 0xe2, 0xeb, 0x27, 0xb2, 0x75);
+BYTE (0x09, 0x83, 0x2c, 0x1a, 0x1b, 0x6e, 0x5a, 0xa0);
+BYTE (0x52, 0x3b, 0xd6, 0xb3, 0x29, 0xe3, 0x2f, 0x84);
+BYTE (0x53, 0xd1, 0x00, 0xed, 0x20, 0xfc, 0xb1, 0x5b);
+BYTE (0x6a, 0xcb, 0xbe, 0x39, 0x4a, 0x4c, 0x58, 0xcf);
+BYTE (0xd0, 0xef, 0xaa, 0xfb, 0x43, 0x4d, 0x33, 0x85);
+BYTE (0x45, 0xf9, 0x02, 0x7f, 0x50, 0x3c, 0x9f, 0xa8);
+BYTE (0x51, 0xa3, 0x40, 0x8f, 0x92, 0x9d, 0x38, 0xf5);
+BYTE (0xbc, 0xb6, 0xda, 0x21, 0x10, 0xff, 0xf3, 0xd2);
+BYTE (0xcd, 0x0c, 0x13, 0xec, 0x5f, 0x97, 0x44, 0x17);
+BYTE (0xc4, 0xa7, 0x7e, 0x3d, 0x64, 0x5d, 0x19, 0x73);
+BYTE (0x60, 0x81, 0x4f, 0xdc, 0x22, 0x2a, 0x90, 0x88);
+BYTE (0x46, 0xee, 0xb8, 0x14, 0xde, 0x5e, 0x0b, 0xdb);
+BYTE (0xe0, 0x32, 0x3a, 0x0a, 0x49, 0x06, 0x24, 0x5c);
+BYTE (0xc2, 0xd3, 0xac, 0x62, 0x91, 0x95, 0xe4, 0x79);
+BYTE (0xe7, 0xc8, 0x37, 0x6d, 0x8d, 0xd5, 0x4e, 0xa9);
+BYTE (0x6c, 0x56, 0xf4, 0xea, 0x65, 0x7a, 0xae, 0x08);
+BYTE (0xba, 0x78, 0x25, 0x2e, 0x1c, 0xa6, 0xb4, 0xc6);
+BYTE (0xe8, 0xdd, 0x74, 0x1f, 0x4b, 0xbd, 0x8b, 0x8a);
+BYTE (0x70, 0x3e, 0xb5, 0x66, 0x48, 0x03, 0xf6, 0x0e);
+BYTE (0x61, 0x35, 0x57, 0xb9, 0x86, 0xc1, 0x1d, 0x9e);
+BYTE (0xe1, 0xf8, 0x98, 0x11, 0x69, 0xd9, 0x8e, 0x94);
+BYTE (0x9b, 0x1e, 0x87, 0xe9, 0xce, 0x55, 0x28, 0xdf);
+BYTE (0x8c, 0xa1, 0x89, 0x0d, 0xbf, 0xe6, 0x42, 0x68);
+BYTE (0x41, 0x99, 0x2d, 0x0f, 0xb0, 0x54, 0xbb, 0x16);
 # rcon[]
-.long	0x01000000, 0x02000000, 0x04000000, 0x08000000
-.long	0x10000000, 0x20000000, 0x40000000, 0x80000000
-.long	0x1B000000, 0x36000000, 0, 0, 0, 0, 0, 0
-.align	256
-.size	AES_Te,.-AES_Te
+LONG(0x01000000, 0x02000000, 0x04000000, 0x08000000);
+LONG(0x10000000, 0x20000000, 0x40000000, 0x80000000);
+LONG(0x1B000000, 0x36000000, 0x0, 0x0);
+LONG(0x0, 0x0, 0x0, 0x0);
+ALIGN(256);

+OBJECT_END("AES_Te");
+}
+
+{
 # void AES_encrypt(const unsigned char *inp, unsigned char *out,
-#		 const AES_KEY *key) {
-.globl	AES_encrypt
-.type	AES_encrypt,\@function
-AES_encrypt:
-___
-$code.=<<___ if (!$softonly);
-	l	%r0,240($key)
-	lhi	%r1,16
-	clr	%r0,%r1
-	jl	.Lesoft
-
-	la	%r1,0($key)
-	#la	%r2,0($inp)
-	la	%r4,0($out)
-	lghi	%r3,16		# single block length
-	.long	0xb92e0042	# km %r4,%r2
-	brc	1,.-4		# can this happen?
-	br	%r14
-.align	64
-.Lesoft:
-___
-$code.=<<___;
-	stm${g}	%r3,$ra,3*$SIZE_T($sp)
-
-	llgf	$s0,0($inp)
-	llgf	$s1,4($inp)
-	llgf	$s2,8($inp)
-	llgf	$s3,12($inp)
-
-	larl	$tbl,AES_Te
-	bras	$ra,_s390x_AES_encrypt
-
-	l${g}	$out,3*$SIZE_T($sp)
-	st	$s0,0($out)
-	st	$s1,4($out)
-	st	$s2,8($out)
-	st	$s3,12($out)
-
-	lm${g}	%r6,$ra,6*$SIZE_T($sp)
-	br	$ra
-.size	AES_encrypt,.-AES_encrypt
-
-.type   _s390x_AES_encrypt,\@function
-.align	16
-_s390x_AES_encrypt:
-	st${g}	$ra,15*$SIZE_T($sp)
-	x	$s0,0($key)
-	x	$s1,4($key)
-	x	$s2,8($key)
-	x	$s3,12($key)
-	l	$rounds,240($key)
-	llill	$mask,`0xff<<3`
-	aghi	$rounds,-1
-	j	.Lenc_loop
-.align	16
-.Lenc_loop:
-	sllg	$t1,$s0,`0+3`
-	srlg	$t2,$s0,`8-3`
-	srlg	$t3,$s0,`16-3`
-	srl	$s0,`24-3`
-	nr	$s0,$mask
-	ngr	$t1,$mask
-	nr	$t2,$mask
-	nr	$t3,$mask
-
-	srlg	$i1,$s1,`16-3`	# i0
-	sllg	$i2,$s1,`0+3`
-	srlg	$i3,$s1,`8-3`
-	srl	$s1,`24-3`
-	nr	$i1,$mask
-	nr	$s1,$mask
-	ngr	$i2,$mask
-	nr	$i3,$mask
-
-	l	$s0,0($s0,$tbl)	# Te0[s0>>24]
-	l	$t1,1($t1,$tbl)	# Te3[s0>>0]
-	l	$t2,2($t2,$tbl) # Te2[s0>>8]
-	l	$t3,3($t3,$tbl)	# Te1[s0>>16]
-
-	x	$s0,3($i1,$tbl)	# Te1[s1>>16]
-	l	$s1,0($s1,$tbl)	# Te0[s1>>24]
-	x	$t2,1($i2,$tbl)	# Te3[s1>>0]
-	x	$t3,2($i3,$tbl)	# Te2[s1>>8]
-
-	srlg	$i1,$s2,`8-3`	# i0
-	srlg	$i2,$s2,`16-3`	# i1
-	nr	$i1,$mask
-	nr	$i2,$mask
-	sllg	$i3,$s2,`0+3`
-	srl	$s2,`24-3`
-	nr	$s2,$mask
-	ngr	$i3,$mask
-
-	xr	$s1,$t1
-	srlg	$ra,$s3,`8-3`	# i1
-	sllg	$t1,$s3,`0+3`	# i0
-	nr	$ra,$mask
-	la	$key,16($key)
-	ngr	$t1,$mask
-
-	x	$s0,2($i1,$tbl)	# Te2[s2>>8]
-	x	$s1,3($i2,$tbl)	# Te1[s2>>16]
-	l	$s2,0($s2,$tbl)	# Te0[s2>>24]
-	x	$t3,1($i3,$tbl)	# Te3[s2>>0]
-
-	srlg	$i3,$s3,`16-3`	# i2
-	xr	$s2,$t2
-	srl	$s3,`24-3`
-	nr	$i3,$mask
-	nr	$s3,$mask
-
-	x	$s0,0($key)
-	x	$s1,4($key)
-	x	$s2,8($key)
-	x	$t3,12($key)
-
-	x	$s0,1($t1,$tbl)	# Te3[s3>>0]
-	x	$s1,2($ra,$tbl)	# Te2[s3>>8]
-	x	$s2,3($i3,$tbl)	# Te1[s3>>16]
-	l	$s3,0($s3,$tbl)	# Te0[s3>>24]
-	xr	$s3,$t3
-
-	brct	$rounds,.Lenc_loop
-	.align	16
-
-	sllg	$t1,$s0,`0+3`
-	srlg	$t2,$s0,`8-3`
-	ngr	$t1,$mask
-	srlg	$t3,$s0,`16-3`
-	srl	$s0,`24-3`
-	nr	$s0,$mask
-	nr	$t2,$mask
-	nr	$t3,$mask
-
-	srlg	$i1,$s1,`16-3`	# i0
-	sllg	$i2,$s1,`0+3`
-	ngr	$i2,$mask
-	srlg	$i3,$s1,`8-3`
-	srl	$s1,`24-3`
-	nr	$i1,$mask
-	nr	$s1,$mask
-	nr	$i3,$mask
-
-	llgc	$s0,2($s0,$tbl)	# Te4[s0>>24]
-	llgc	$t1,2($t1,$tbl)	# Te4[s0>>0]
-	sll	$s0,24
-	llgc	$t2,2($t2,$tbl)	# Te4[s0>>8]
-	llgc	$t3,2($t3,$tbl)	# Te4[s0>>16]
-	sll	$t2,8
-	sll	$t3,16
-
-	llgc	$i1,2($i1,$tbl)	# Te4[s1>>16]
-	llgc	$s1,2($s1,$tbl)	# Te4[s1>>24]
-	llgc	$i2,2($i2,$tbl)	# Te4[s1>>0]
-	llgc	$i3,2($i3,$tbl)	# Te4[s1>>8]
-	sll	$i1,16
-	sll	$s1,24
-	sll	$i3,8
-	or	$s0,$i1
-	or	$s1,$t1
-	or	$t2,$i2
-	or	$t3,$i3
-
-	srlg	$i1,$s2,`8-3`	# i0
-	srlg	$i2,$s2,`16-3`	# i1
-	nr	$i1,$mask
-	nr	$i2,$mask
-	sllg	$i3,$s2,`0+3`
-	srl	$s2,`24-3`
-	ngr	$i3,$mask
-	nr	$s2,$mask
-
-	sllg	$t1,$s3,`0+3`	# i0
-	srlg	$ra,$s3,`8-3`	# i1
-	ngr	$t1,$mask
-
-	llgc	$i1,2($i1,$tbl)	# Te4[s2>>8]
-	llgc	$i2,2($i2,$tbl)	# Te4[s2>>16]
-	sll	$i1,8
-	llgc	$s2,2($s2,$tbl)	# Te4[s2>>24]
-	llgc	$i3,2($i3,$tbl)	# Te4[s2>>0]
-	sll	$i2,16
-	nr	$ra,$mask
-	sll	$s2,24
-	or	$s0,$i1
-	or	$s1,$i2
-	or	$s2,$t2
-	or	$t3,$i3
-
-	srlg	$i3,$s3,`16-3`	# i2
-	srl	$s3,`24-3`
-	nr	$i3,$mask
-	nr	$s3,$mask
-
-	l	$t0,16($key)
-	l	$t2,20($key)
-
-	llgc	$i1,2($t1,$tbl)	# Te4[s3>>0]
-	llgc	$i2,2($ra,$tbl)	# Te4[s3>>8]
-	llgc	$i3,2($i3,$tbl)	# Te4[s3>>16]
-	llgc	$s3,2($s3,$tbl)	# Te4[s3>>24]
-	sll	$i2,8
-	sll	$i3,16
-	sll	$s3,24
-	or	$s0,$i1
-	or	$s1,$i2
-	or	$s2,$i3
-	or	$s3,$t3
-
-	l${g}	$ra,15*$SIZE_T($sp)
-	xr	$s0,$t0
-	xr	$s1,$t2
-	x	$s2,24($key)
-	x	$s3,28($key)
-
-	br	$ra
-.size	_s390x_AES_encrypt,.-_s390x_AES_encrypt
-___
-
-$code.=<<___;
-.type	AES_Td,\@object
-.align	256
-AES_Td:
-___
+#          const AES_KEY *key) {
+#.globl    AES_encrypt
+#.type    AES_encrypt,\@function
+FUNCTION_BEGIN("AES_encrypt",3,"true","","true");
+
+LABEL("AES_encrypt_A");
+if ($flavour =~ /linux/) {
+    l      ($wr0,"240($key)");
+    lhi    ($wr1,16);
+    clr    ($wr0,$wr1);
+    jl  (LABEL("Lesoft"));
+    la    ($wr1,"0($key)");
+    la    ("%r4","0($outp)");
+    lghi  ($wr3,16);        # single block length
+    km    ("%r4",$wr2);
+  } else {
+    l    ($wr0,"240($key)");
+    lhi    ($wr5,16);
+    clr    ($wr0,$wr5);
+    jl  (LABEL("Lesoft"));
+
+    la    ($wr6,"0($outp)");
+    la    ($wr2,"0($inp)");
+    la    ($wr1,"0($key)");
+    lghi    ($wr3,16);        # single block length
+    km ($wr6,$wr2);
+  }
+    brc    (1,"$ip-4");        # can this happen?
+
+    BR_EXIT ();
+
+ALIGN(64);
+LABEL("Lesoft:");
+
+if ($flavour =~ /linux/) {
+    &{$z? \&stmg:\&stm}    ("%r3",$ra,"3*$SIZE_T($sp)");
+} else {
+    lay     ($sp,"STACK");
+    &{$z? \&stmg:\&stm}    ("R2","R14","2*$SIZE_T($sp)");
+}
+    llgf    ($s0,"0($inp)");
+    llgf    ($s1,"4($inp)");
+    llgf    ($s2,"8($inp)");
+    llgf    ($s3,"12($inp)");
+
+    larl    ($tbl,LABEL("AES_Te"));
+if ($flavour =~ /linux/) {
+    bras    ($ra,"_s390x_AES_encrypt");
+    &{$z? \&lg:\&l}    ($outp,"3*$SIZE_T($sp)");
+} else {
+    bras    ($ra,"_s390x_AES_encrypt");
+    &{$z? \&lg:\&l}    ($outp,"2*$SIZE_T($sp)");
+}
+    st      ($s0,"0($outp)");
+    st      ($s1,"4($outp)");
+    st      ($s2,"8($outp)");
+    st      ($s3,"12($outp)");
+
+if ($flavour =~ /linux/) {
+    &{$z? \&lmg:\&lm}    ("%r6",$ra,"6*$SIZE_T($sp)");
+} else {
+    &{$z? \&lg:\&l}    ("R4","4*$SIZE_T($sp)");
+}
+    BR_EXIT    ();
+
+FUNCTION_END("AES_encrypt",$rv);
+}
+
+{
+#.type   _s390x_AES_encrypt,\@function
+# inputs: $key in r3, $s0 in r8, $s1 in $r9, $s2 in r10, $s3 in r11, $tbl in r13
+# outputs: $s0, $s1, $s2, $s3
+LOCAL_FUNCTION("_s390x_AES_encrypt");
+my $key;
+&{$z? \&stg:\&st}    ($ra,"15*$SIZE_T($sp)");
+
+if ($flavour =~ /linux/) {
+    $key = "%r4";
+} else {
+    $key = "R14";
+    &{$z? \&lgr:\&lr} ($key,"R3");
+}
+    x       ($s0,"0($key)");
+    x       ($s1,"4($key)");
+    x       ($s2,"8($key)");
+    x       ($s3,"12($key)");
+    l       ($rounds,"240($key)");
+    llill   ($mask,0xff<<3);
+    aghi    ($rounds,-1);
+    j       (LABEL("Lenc_loop"));
+ALIGN(16);
+LABEL("Lenc_loop:");
+    sllg    ($t1,$s0,"0+3");
+    srlg    ($t2,$s0,"8-3");
+    srlg    ($t3,$s0,"16-3");
+    srl     ($s0,"24-3");
+    nr      ($s0,$mask);
+    ngr     ($t1,$mask);
+    nr      ($t2,$mask);
+    nr      ($t3,$mask);
+
+    srlg    ($i1,$s1,"16-3");    # i0
+    sllg    ($i2,$s1,"0+3");
+    srlg    ($i3,$s1,"8-3");
+    srl     ($s1,"24-3");
+    nr      ($i1,$mask);
+    nr      ($s1,$mask);
+    ngr     ($i2,$mask);
+    nr      ($i3,$mask);
+
+    l       ($s0,"0($s0,$tbl)");    # Te0[s0>>24]
+    l       ($t1,"1($t1,$tbl)");    # Te3[s0>>0]
+    l       ($t2,"2($t2,$tbl)");    # Te2[s0>>8]
+    l       ($t3,"3($t3,$tbl)");    # Te1[s0>>16]
+
+    x       ($s0,"3($i1,$tbl)");    # Te1[s1>>16]
+    l       ($s1,"0($s1,$tbl)");    # Te0[s1>>24]
+    x       ($t2,"1($i2,$tbl)");    # Te3[s1>>0]
+    x       ($t3,"2($i3,$tbl)");    # Te2[s1>>8]
+
+    srlg    ($i1,$s2,"8-3");    # i0
+    srlg    ($i2,$s2,"16-3");    # i1
+    nr      ($i1,$mask);
+    nr      ($i2,$mask);
+    sllg    ($i3,$s2,"0+3");
+    srl     ($s2,"24-3");
+    nr      ($s2,$mask);
+    ngr     ($i3,$mask);
+
+    xr      ($s1,$t1);
+    srlg    ($temp,$s3,"8-3");    # i1
+    sllg    ($t1,$s3,"0+3");    # i0
+    nr      ($temp,$mask);
+    la      ($key,"16($key)");
+    ngr     ($t1,$mask);
+
+    x       ($s0,"2($i1,$tbl)");    # Te2[s2>>8]
+    x       ($s1,"3($i2,$tbl)");    # Te1[s2>>16]
+    l       ($s2,"0($s2,$tbl)");    # Te0[s2>>24]
+    x       ($t3,"1($i3,$tbl)");    # Te3[s2>>0]
+
+    srlg    ($i3,$s3,"16-3");    # i2
+    xr      ($s2,$t2);
+    srl     ($s3,"24-3");
+    nr      ($i3,$mask);
+    nr      ($s3,$mask);
+
+    x       ($s0,"0($key)");
+    x       ($s1,"4($key)");
+    x       ($s2,"8($key)");
+    x       ($t3,"12($key)");
+
+    x       ($s0,"1($t1,$tbl)");    # Te3[s3>>0]
+    x       ($s1,"2($temp,$tbl)");    # Te2[s3>>8]
+    x       ($s2,"3($i3,$tbl)");    # Te1[s3>>16]
+    l       ($s3,"0($s3,$tbl)");    # Te0[s3>>24]
+    xr      ($s3,$t3);
+
+    brct    ($rounds,LABEL("Lenc_loop"));
+    ALIGN(16) if ($flavour =~ /linux/);
+
+    sllg    ($t1,$s0,"0+3");
+    srlg    ($t2,$s0,"8-3");
+    ngr     ($t1,$mask);
+    srlg    ($t3,$s0,"16-3");
+    srl     ($s0,"24-3");
+    nr      ($s0,$mask);
+    nr      ($t2,$mask);
+    nr      ($t3,$mask);
+
+    srlg    ($i1,$s1,"16-3");    # i0
+    sllg    ($i2,$s1,"0+3");
+    ngr     ($i2,$mask);
+    srlg    ($i3,$s1,"8-3");
+    srl     ($s1,"24-3");
+    nr      ($i1,$mask);
+    nr      ($s1,$mask);
+    nr      ($i3,$mask);
+
+    llgc    ($s0,"2($s0,$tbl)");    # Te4[s0>>24]
+    llgc    ($t1,"2($t1,$tbl)");    # Te4[s0>>0]
+    sll     ($s0,24);
+    llgc    ($t2,"2($t2,$tbl)");    # Te4[s0>>8]
+    llgc    ($t3,"2($t3,$tbl)");    # Te4[s0>>16]
+    sll     ($t2,8);
+    sll     ($t3,16);
+
+    llgc    ($i1,"2($i1,$tbl)");    # Te4[s1>>16]
+    llgc    ($s1,"2($s1,$tbl)");    # Te4[s1>>24]
+    llgc    ($i2,"2($i2,$tbl)");    # Te4[s1>>0]
+    llgc    ($i3,"2($i3,$tbl)");    # Te4[s1>>8]
+    sll     ($i1,16);
+    sll     ($s1,24);
+    sll     ($i3,8);
+    &or     ($s0,$i1);
+    &or     ($s1,$t1);
+    &or     ($t2,$i2);
+    &or     ($t3,$i3);
+
+    srlg    ($i1,$s2,"8-3");    # i0
+    srlg    ($i2,$s2,"16-3");    # i1
+    nr      ($i1,$mask);
+    nr      ($i2,$mask);
+    sllg    ($i3,$s2,"0+3");
+    srl     ($s2,"24-3");
+    ngr     ($i3,$mask);
+    nr      ($s2,$mask);
+
+    sllg    ($t1,$s3,"0+3");    # i0
+    srlg    ($temp,$s3,"8-3");    # i1
+    ngr     ($t1,$mask);
+
+    llgc    ($i1,"2($i1,$tbl)");    # Te4[s2>>8]
+    llgc    ($i2,"2($i2,$tbl)");    # Te4[s2>>16]
+    sll     ($i1,8);
+    llgc    ($s2,"2($s2,$tbl)");    # Te4[s2>>24]
+    llgc    ($i3,"2($i3,$tbl)");    # Te4[s2>>0]
+    sll     ($i2,16);
+    nr      ($temp,$mask);
+    sll     ($s2,24);
+    &or     ($s0,$i1);
+    &or     ($s1,$i2);
+    &or     ($s2,$t2);
+    &or     ($t3,$i3);
+
+    srlg    ($i3,$s3,"16-3");    # i2
+    srl     ($s3,"24-3");
+    nr      ($i3,$mask);
+    nr      ($s3,$mask);
+
+    l       ($t0,"16($key)");
+    l       ($t2,"20($key)");
+
+    llgc    ($i1,"2($t1,$tbl)");    # Te4[s3>>0]
+    llgc    ($i2,"2($temp,$tbl)");    # Te4[s3>>8]
+    llgc    ($i3,"2($i3,$tbl)");    # Te4[s3>>16]
+    llgc    ($s3,"2($s3,$tbl)");    # Te4[s3>>24]
+    sll     ($i2,8);
+    sll     ($i3,16);
+    sll     ($s3,24);
+    &or     ($s0,$i1);
+    &or     ($s1,$i2);
+    &or     ($s2,$i3);
+    &or     ($s3,$t3);
+
+&{$z? \&lg:\&l}    ($ra,"15*$SIZE_T($sp)");
+    xr      ($s0,$t0);
+    xr      ($s1,$t2);
+    x       ($s2,"24($key)");
+    x       ($s3,"28($key)");
+
+    br      ($ra);
+
+LOCAL_FUNCTION_END("_s390x_AES_encrypt");
+}
+
+{
+
+OBJECT_BEGIN("AES_Td",256);
+
 &_data_word(
-	0x51f4a750, 0x7e416553, 0x1a17a4c3, 0x3a275e96,
-	0x3bab6bcb, 0x1f9d45f1, 0xacfa58ab, 0x4be30393,
-	0x2030fa55, 0xad766df6, 0x88cc7691, 0xf5024c25,
-	0x4fe5d7fc, 0xc52acbd7, 0x26354480, 0xb562a38f,
-	0xdeb15a49, 0x25ba1b67, 0x45ea0e98, 0x5dfec0e1,
-	0xc32f7502, 0x814cf012, 0x8d4697a3, 0x6bd3f9c6,
-	0x038f5fe7, 0x15929c95, 0xbf6d7aeb, 0x955259da,
-	0xd4be832d, 0x587421d3, 0x49e06929, 0x8ec9c844,
-	0x75c2896a, 0xf48e7978, 0x99583e6b, 0x27b971dd,
-	0xbee14fb6, 0xf088ad17, 0xc920ac66, 0x7dce3ab4,
-	0x63df4a18, 0xe51a3182, 0x97513360, 0x62537f45,
-	0xb16477e0, 0xbb6bae84, 0xfe81a01c, 0xf9082b94,
-	0x70486858, 0x8f45fd19, 0x94de6c87, 0x527bf8b7,
-	0xab73d323, 0x724b02e2, 0xe31f8f57, 0x6655ab2a,
-	0xb2eb2807, 0x2fb5c203, 0x86c57b9a, 0xd33708a5,
-	0x302887f2, 0x23bfa5b2, 0x02036aba, 0xed16825c,
-	0x8acf1c2b, 0xa779b492, 0xf307f2f0, 0x4e69e2a1,
-	0x65daf4cd, 0x0605bed5, 0xd134621f, 0xc4a6fe8a,
-	0x342e539d, 0xa2f355a0, 0x058ae132, 0xa4f6eb75,
-	0x0b83ec39, 0x4060efaa, 0x5e719f06, 0xbd6e1051,
-	0x3e218af9, 0x96dd063d, 0xdd3e05ae, 0x4de6bd46,
-	0x91548db5, 0x71c45d05, 0x0406d46f, 0x605015ff,
-	0x1998fb24, 0xd6bde997, 0x894043cc, 0x67d99e77,
-	0xb0e842bd, 0x07898b88, 0xe7195b38, 0x79c8eedb,
-	0xa17c0a47, 0x7c420fe9, 0xf8841ec9, 0x00000000,
-	0x09808683, 0x322bed48, 0x1e1170ac, 0x6c5a724e,
-	0xfd0efffb, 0x0f853856, 0x3daed51e, 0x362d3927,
-	0x0a0fd964, 0x685ca621, 0x9b5b54d1, 0x24362e3a,
-	0x0c0a67b1, 0x9357e70f, 0xb4ee96d2, 0x1b9b919e,
-	0x80c0c54f, 0x61dc20a2, 0x5a774b69, 0x1c121a16,
-	0xe293ba0a, 0xc0a02ae5, 0x3c22e043, 0x121b171d,
-	0x0e090d0b, 0xf28bc7ad, 0x2db6a8b9, 0x141ea9c8,
-	0x57f11985, 0xaf75074c, 0xee99ddbb, 0xa37f60fd,
-	0xf701269f, 0x5c72f5bc, 0x44663bc5, 0x5bfb7e34,
-	0x8b432976, 0xcb23c6dc, 0xb6edfc68, 0xb8e4f163,
-	0xd731dcca, 0x42638510, 0x13972240, 0x84c61120,
-	0x854a247d, 0xd2bb3df8, 0xaef93211, 0xc729a16d,
-	0x1d9e2f4b, 0xdcb230f3, 0x0d8652ec, 0x77c1e3d0,
-	0x2bb3166c, 0xa970b999, 0x119448fa, 0x47e96422,
-	0xa8fc8cc4, 0xa0f03f1a, 0x567d2cd8, 0x223390ef,
-	0x87494ec7, 0xd938d1c1, 0x8ccaa2fe, 0x98d40b36,
-	0xa6f581cf, 0xa57ade28, 0xdab78e26, 0x3fadbfa4,
-	0x2c3a9de4, 0x5078920d, 0x6a5fcc9b, 0x547e4662,
-	0xf68d13c2, 0x90d8b8e8, 0x2e39f75e, 0x82c3aff5,
-	0x9f5d80be, 0x69d0937c, 0x6fd52da9, 0xcf2512b3,
-	0xc8ac993b, 0x10187da7, 0xe89c636e, 0xdb3bbb7b,
-	0xcd267809, 0x6e5918f4, 0xec9ab701, 0x834f9aa8,
-	0xe6956e65, 0xaaffe67e, 0x21bccf08, 0xef15e8e6,
-	0xbae79bd9, 0x4a6f36ce, 0xea9f09d4, 0x29b07cd6,
-	0x31a4b2af, 0x2a3f2331, 0xc6a59430, 0x35a266c0,
-	0x744ebc37, 0xfc82caa6, 0xe090d0b0, 0x33a7d815,
-	0xf104984a, 0x41ecdaf7, 0x7fcd500e, 0x1791f62f,
-	0x764dd68d, 0x43efb04d, 0xccaa4d54, 0xe49604df,
-	0x9ed1b5e3, 0x4c6a881b, 0xc12c1fb8, 0x4665517f,
-	0x9d5eea04, 0x018c355d, 0xfa877473, 0xfb0b412e,
-	0xb3671d5a, 0x92dbd252, 0xe9105633, 0x6dd64713,
-	0x9ad7618c, 0x37a10c7a, 0x59f8148e, 0xeb133c89,
-	0xcea927ee, 0xb761c935, 0xe11ce5ed, 0x7a47b13c,
-	0x9cd2df59, 0x55f2733f, 0x1814ce79, 0x73c737bf,
-	0x53f7cdea, 0x5ffdaa5b, 0xdf3d6f14, 0x7844db86,
-	0xcaaff381, 0xb968c43e, 0x3824342c, 0xc2a3405f,
-	0x161dc372, 0xbce2250c, 0x283c498b, 0xff0d9541,
-	0x39a80171, 0x080cb3de, 0xd8b4e49c, 0x6456c190,
-	0x7bcb8461, 0xd532b670, 0x486c5c74, 0xd0b85742);
-$code.=<<___;
+    0x51f4a750, 0x7e416553, 0x1a17a4c3, 0x3a275e96,
+    0x3bab6bcb, 0x1f9d45f1, 0xacfa58ab, 0x4be30393,
+    0x2030fa55, 0xad766df6, 0x88cc7691, 0xf5024c25,
+    0x4fe5d7fc, 0xc52acbd7, 0x26354480, 0xb562a38f,
+    0xdeb15a49, 0x25ba1b67, 0x45ea0e98, 0x5dfec0e1,
+    0xc32f7502, 0x814cf012, 0x8d4697a3, 0x6bd3f9c6,
+    0x038f5fe7, 0x15929c95, 0xbf6d7aeb, 0x955259da,
+    0xd4be832d, 0x587421d3, 0x49e06929, 0x8ec9c844,
+    0x75c2896a, 0xf48e7978, 0x99583e6b, 0x27b971dd,
+    0xbee14fb6, 0xf088ad17, 0xc920ac66, 0x7dce3ab4,
+    0x63df4a18, 0xe51a3182, 0x97513360, 0x62537f45,
+    0xb16477e0, 0xbb6bae84, 0xfe81a01c, 0xf9082b94,
+    0x70486858, 0x8f45fd19, 0x94de6c87, 0x527bf8b7,
+    0xab73d323, 0x724b02e2, 0xe31f8f57, 0x6655ab2a,
+    0xb2eb2807, 0x2fb5c203, 0x86c57b9a, 0xd33708a5,
+    0x302887f2, 0x23bfa5b2, 0x02036aba, 0xed16825c,
+    0x8acf1c2b, 0xa779b492, 0xf307f2f0, 0x4e69e2a1,
+    0x65daf4cd, 0x0605bed5, 0xd134621f, 0xc4a6fe8a,
+    0x342e539d, 0xa2f355a0, 0x058ae132, 0xa4f6eb75,
+    0x0b83ec39, 0x4060efaa, 0x5e719f06, 0xbd6e1051,
+    0x3e218af9, 0x96dd063d, 0xdd3e05ae, 0x4de6bd46,
+    0x91548db5, 0x71c45d05, 0x0406d46f, 0x605015ff,
+    0x1998fb24, 0xd6bde997, 0x894043cc, 0x67d99e77,
+    0xb0e842bd, 0x07898b88, 0xe7195b38, 0x79c8eedb,
+    0xa17c0a47, 0x7c420fe9, 0xf8841ec9, 0x00000000,
+    0x09808683, 0x322bed48, 0x1e1170ac, 0x6c5a724e,
+    0xfd0efffb, 0x0f853856, 0x3daed51e, 0x362d3927,
+    0x0a0fd964, 0x685ca621, 0x9b5b54d1, 0x24362e3a,
+    0x0c0a67b1, 0x9357e70f, 0xb4ee96d2, 0x1b9b919e,
+    0x80c0c54f, 0x61dc20a2, 0x5a774b69, 0x1c121a16,
+    0xe293ba0a, 0xc0a02ae5, 0x3c22e043, 0x121b171d,
+    0x0e090d0b, 0xf28bc7ad, 0x2db6a8b9, 0x141ea9c8,
+    0x57f11985, 0xaf75074c, 0xee99ddbb, 0xa37f60fd,
+    0xf701269f, 0x5c72f5bc, 0x44663bc5, 0x5bfb7e34,
+    0x8b432976, 0xcb23c6dc, 0xb6edfc68, 0xb8e4f163,
+    0xd731dcca, 0x42638510, 0x13972240, 0x84c61120,
+    0x854a247d, 0xd2bb3df8, 0xaef93211, 0xc729a16d,
+    0x1d9e2f4b, 0xdcb230f3, 0x0d8652ec, 0x77c1e3d0,
+    0x2bb3166c, 0xa970b999, 0x119448fa, 0x47e96422,
+    0xa8fc8cc4, 0xa0f03f1a, 0x567d2cd8, 0x223390ef,
+    0x87494ec7, 0xd938d1c1, 0x8ccaa2fe, 0x98d40b36,
+    0xa6f581cf, 0xa57ade28, 0xdab78e26, 0x3fadbfa4,
+    0x2c3a9de4, 0x5078920d, 0x6a5fcc9b, 0x547e4662,
+    0xf68d13c2, 0x90d8b8e8, 0x2e39f75e, 0x82c3aff5,
+    0x9f5d80be, 0x69d0937c, 0x6fd52da9, 0xcf2512b3,
+    0xc8ac993b, 0x10187da7, 0xe89c636e, 0xdb3bbb7b,
+    0xcd267809, 0x6e5918f4, 0xec9ab701, 0x834f9aa8,
+    0xe6956e65, 0xaaffe67e, 0x21bccf08, 0xef15e8e6,
+    0xbae79bd9, 0x4a6f36ce, 0xea9f09d4, 0x29b07cd6,
+    0x31a4b2af, 0x2a3f2331, 0xc6a59430, 0x35a266c0,
+    0x744ebc37, 0xfc82caa6, 0xe090d0b0, 0x33a7d815,
+    0xf104984a, 0x41ecdaf7, 0x7fcd500e, 0x1791f62f,
+    0x764dd68d, 0x43efb04d, 0xccaa4d54, 0xe49604df,
+    0x9ed1b5e3, 0x4c6a881b, 0xc12c1fb8, 0x4665517f,
+    0x9d5eea04, 0x018c355d, 0xfa877473, 0xfb0b412e,
+    0xb3671d5a, 0x92dbd252, 0xe9105633, 0x6dd64713,
+    0x9ad7618c, 0x37a10c7a, 0x59f8148e, 0xeb133c89,
+    0xcea927ee, 0xb761c935, 0xe11ce5ed, 0x7a47b13c,
+    0x9cd2df59, 0x55f2733f, 0x1814ce79, 0x73c737bf,
+    0x53f7cdea, 0x5ffdaa5b, 0xdf3d6f14, 0x7844db86,
+    0xcaaff381, 0xb968c43e, 0x3824342c, 0xc2a3405f,
+    0x161dc372, 0xbce2250c, 0x283c498b, 0xff0d9541,
+    0x39a80171, 0x080cb3de, 0xd8b4e49c, 0x6456c190,
+    0x7bcb8461, 0xd532b670, 0x486c5c74, 0xd0b85742);
+#$code.=<<___;
 # Td4[256]
-.byte	0x52, 0x09, 0x6a, 0xd5, 0x30, 0x36, 0xa5, 0x38
-.byte	0xbf, 0x40, 0xa3, 0x9e, 0x81, 0xf3, 0xd7, 0xfb
-.byte	0x7c, 0xe3, 0x39, 0x82, 0x9b, 0x2f, 0xff, 0x87
-.byte	0x34, 0x8e, 0x43, 0x44, 0xc4, 0xde, 0xe9, 0xcb
-.byte	0x54, 0x7b, 0x94, 0x32, 0xa6, 0xc2, 0x23, 0x3d
-.byte	0xee, 0x4c, 0x95, 0x0b, 0x42, 0xfa, 0xc3, 0x4e
-.byte	0x08, 0x2e, 0xa1, 0x66, 0x28, 0xd9, 0x24, 0xb2
-.byte	0x76, 0x5b, 0xa2, 0x49, 0x6d, 0x8b, 0xd1, 0x25
-.byte	0x72, 0xf8, 0xf6, 0x64, 0x86, 0x68, 0x98, 0x16
-.byte	0xd4, 0xa4, 0x5c, 0xcc, 0x5d, 0x65, 0xb6, 0x92
-.byte	0x6c, 0x70, 0x48, 0x50, 0xfd, 0xed, 0xb9, 0xda
-.byte	0x5e, 0x15, 0x46, 0x57, 0xa7, 0x8d, 0x9d, 0x84
-.byte	0x90, 0xd8, 0xab, 0x00, 0x8c, 0xbc, 0xd3, 0x0a
-.byte	0xf7, 0xe4, 0x58, 0x05, 0xb8, 0xb3, 0x45, 0x06
-.byte	0xd0, 0x2c, 0x1e, 0x8f, 0xca, 0x3f, 0x0f, 0x02
-.byte	0xc1, 0xaf, 0xbd, 0x03, 0x01, 0x13, 0x8a, 0x6b
-.byte	0x3a, 0x91, 0x11, 0x41, 0x4f, 0x67, 0xdc, 0xea
-.byte	0x97, 0xf2, 0xcf, 0xce, 0xf0, 0xb4, 0xe6, 0x73
-.byte	0x96, 0xac, 0x74, 0x22, 0xe7, 0xad, 0x35, 0x85
-.byte	0xe2, 0xf9, 0x37, 0xe8, 0x1c, 0x75, 0xdf, 0x6e
-.byte	0x47, 0xf1, 0x1a, 0x71, 0x1d, 0x29, 0xc5, 0x89
-.byte	0x6f, 0xb7, 0x62, 0x0e, 0xaa, 0x18, 0xbe, 0x1b
-.byte	0xfc, 0x56, 0x3e, 0x4b, 0xc6, 0xd2, 0x79, 0x20
-.byte	0x9a, 0xdb, 0xc0, 0xfe, 0x78, 0xcd, 0x5a, 0xf4
-.byte	0x1f, 0xdd, 0xa8, 0x33, 0x88, 0x07, 0xc7, 0x31
-.byte	0xb1, 0x12, 0x10, 0x59, 0x27, 0x80, 0xec, 0x5f
-.byte	0x60, 0x51, 0x7f, 0xa9, 0x19, 0xb5, 0x4a, 0x0d
-.byte	0x2d, 0xe5, 0x7a, 0x9f, 0x93, 0xc9, 0x9c, 0xef
-.byte	0xa0, 0xe0, 0x3b, 0x4d, 0xae, 0x2a, 0xf5, 0xb0
-.byte	0xc8, 0xeb, 0xbb, 0x3c, 0x83, 0x53, 0x99, 0x61
-.byte	0x17, 0x2b, 0x04, 0x7e, 0xba, 0x77, 0xd6, 0x26
-.byte	0xe1, 0x69, 0x14, 0x63, 0x55, 0x21, 0x0c, 0x7d
-.size	AES_Td,.-AES_Td
+BYTE    (0x52, 0x09, 0x6a, 0xd5, 0x30, 0x36, 0xa5, 0x38);
+BYTE    (0xbf, 0x40, 0xa3, 0x9e, 0x81, 0xf3, 0xd7, 0xfb);
+BYTE    (0x7c, 0xe3, 0x39, 0x82, 0x9b, 0x2f, 0xff, 0x87);
+BYTE    (0x34, 0x8e, 0x43, 0x44, 0xc4, 0xde, 0xe9, 0xcb);
+BYTE    (0x54, 0x7b, 0x94, 0x32, 0xa6, 0xc2, 0x23, 0x3d);
+BYTE    (0xee, 0x4c, 0x95, 0x0b, 0x42, 0xfa, 0xc3, 0x4e);
+BYTE    (0x08, 0x2e, 0xa1, 0x66, 0x28, 0xd9, 0x24, 0xb2);
+BYTE    (0x76, 0x5b, 0xa2, 0x49, 0x6d, 0x8b, 0xd1, 0x25);
+BYTE    (0x72, 0xf8, 0xf6, 0x64, 0x86, 0x68, 0x98, 0x16);
+BYTE    (0xd4, 0xa4, 0x5c, 0xcc, 0x5d, 0x65, 0xb6, 0x92);
+BYTE    (0x6c, 0x70, 0x48, 0x50, 0xfd, 0xed, 0xb9, 0xda);
+BYTE    (0x5e, 0x15, 0x46, 0x57, 0xa7, 0x8d, 0x9d, 0x84);
+BYTE    (0x90, 0xd8, 0xab, 0x00, 0x8c, 0xbc, 0xd3, 0x0a);
+BYTE    (0xf7, 0xe4, 0x58, 0x05, 0xb8, 0xb3, 0x45, 0x06);
+BYTE    (0xd0, 0x2c, 0x1e, 0x8f, 0xca, 0x3f, 0x0f, 0x02);
+BYTE    (0xc1, 0xaf, 0xbd, 0x03, 0x01, 0x13, 0x8a, 0x6b);
+BYTE    (0x3a, 0x91, 0x11, 0x41, 0x4f, 0x67, 0xdc, 0xea);
+BYTE    (0x97, 0xf2, 0xcf, 0xce, 0xf0, 0xb4, 0xe6, 0x73);
+BYTE    (0x96, 0xac, 0x74, 0x22, 0xe7, 0xad, 0x35, 0x85);
+BYTE    (0xe2, 0xf9, 0x37, 0xe8, 0x1c, 0x75, 0xdf, 0x6e);
+BYTE    (0x47, 0xf1, 0x1a, 0x71, 0x1d, 0x29, 0xc5, 0x89);
+BYTE    (0x6f, 0xb7, 0x62, 0x0e, 0xaa, 0x18, 0xbe, 0x1b);
+BYTE    (0xfc, 0x56, 0x3e, 0x4b, 0xc6, 0xd2, 0x79, 0x20);
+BYTE    (0x9a, 0xdb, 0xc0, 0xfe, 0x78, 0xcd, 0x5a, 0xf4);
+BYTE    (0x1f, 0xdd, 0xa8, 0x33, 0x88, 0x07, 0xc7, 0x31);
+BYTE    (0xb1, 0x12, 0x10, 0x59, 0x27, 0x80, 0xec, 0x5f);
+BYTE    (0x60, 0x51, 0x7f, 0xa9, 0x19, 0xb5, 0x4a, 0x0d);
+BYTE    (0x2d, 0xe5, 0x7a, 0x9f, 0x93, 0xc9, 0x9c, 0xef);
+BYTE    (0xa0, 0xe0, 0x3b, 0x4d, 0xae, 0x2a, 0xf5, 0xb0);
+BYTE    (0xc8, 0xeb, 0xbb, 0x3c, 0x83, 0x53, 0x99, 0x61);
+BYTE    (0x17, 0x2b, 0x04, 0x7e, 0xba, 0x77, 0xd6, 0x26);
+BYTE    (0xe1, 0x69, 0x14, 0x63, 0x55, 0x21, 0x0c, 0x7d);
+
+OBJECT_END("AES_Td");
+}

+{
 # void AES_decrypt(const unsigned char *inp, unsigned char *out,
-#		 const AES_KEY *key) {
-.globl	AES_decrypt
-.type	AES_decrypt,\@function
-AES_decrypt:
-___
-$code.=<<___ if (!$softonly);
-	l	%r0,240($key)
-	lhi	%r1,16
-	clr	%r0,%r1
-	jl	.Ldsoft
-
-	la	%r1,0($key)
-	#la	%r2,0($inp)
-	la	%r4,0($out)
-	lghi	%r3,16		# single block length
-	.long	0xb92e0042	# km %r4,%r2
-	brc	1,.-4		# can this happen?
-	br	%r14
-.align	64
-.Ldsoft:
-___
-$code.=<<___;
-	stm${g}	%r3,$ra,3*$SIZE_T($sp)
-
-	llgf	$s0,0($inp)
-	llgf	$s1,4($inp)
-	llgf	$s2,8($inp)
-	llgf	$s3,12($inp)
-
-	larl	$tbl,AES_Td
-	bras	$ra,_s390x_AES_decrypt
-
-	l${g}	$out,3*$SIZE_T($sp)
-	st	$s0,0($out)
-	st	$s1,4($out)
-	st	$s2,8($out)
-	st	$s3,12($out)
-
-	lm${g}	%r6,$ra,6*$SIZE_T($sp)
-	br	$ra
-.size	AES_decrypt,.-AES_decrypt
-
-.type   _s390x_AES_decrypt,\@function
-.align	16
-_s390x_AES_decrypt:
-	st${g}	$ra,15*$SIZE_T($sp)
-	x	$s0,0($key)
-	x	$s1,4($key)
-	x	$s2,8($key)
-	x	$s3,12($key)
-	l	$rounds,240($key)
-	llill	$mask,`0xff<<3`
-	aghi	$rounds,-1
-	j	.Ldec_loop
-.align	16
-.Ldec_loop:
-	srlg	$t1,$s0,`16-3`
-	srlg	$t2,$s0,`8-3`
-	sllg	$t3,$s0,`0+3`
-	srl	$s0,`24-3`
-	nr	$s0,$mask
-	nr	$t1,$mask
-	nr	$t2,$mask
-	ngr	$t3,$mask
-
-	sllg	$i1,$s1,`0+3`	# i0
-	srlg	$i2,$s1,`16-3`
-	srlg	$i3,$s1,`8-3`
-	srl	$s1,`24-3`
-	ngr	$i1,$mask
-	nr	$s1,$mask
-	nr	$i2,$mask
-	nr	$i3,$mask
-
-	l	$s0,0($s0,$tbl)	# Td0[s0>>24]
-	l	$t1,3($t1,$tbl)	# Td1[s0>>16]
-	l	$t2,2($t2,$tbl)	# Td2[s0>>8]
-	l	$t3,1($t3,$tbl)	# Td3[s0>>0]
-
-	x	$s0,1($i1,$tbl)	# Td3[s1>>0]
-	l	$s1,0($s1,$tbl)	# Td0[s1>>24]
-	x	$t2,3($i2,$tbl)	# Td1[s1>>16]
-	x	$t3,2($i3,$tbl)	# Td2[s1>>8]
-
-	srlg	$i1,$s2,`8-3`	# i0
-	sllg	$i2,$s2,`0+3`	# i1
-	srlg	$i3,$s2,`16-3`
-	srl	$s2,`24-3`
-	nr	$i1,$mask
-	ngr	$i2,$mask
-	nr	$s2,$mask
-	nr	$i3,$mask
-
-	xr	$s1,$t1
-	srlg	$ra,$s3,`8-3`	# i1
-	srlg	$t1,$s3,`16-3`	# i0
-	nr	$ra,$mask
-	la	$key,16($key)
-	nr	$t1,$mask
-
-	x	$s0,2($i1,$tbl)	# Td2[s2>>8]
-	x	$s1,1($i2,$tbl)	# Td3[s2>>0]
-	l	$s2,0($s2,$tbl)	# Td0[s2>>24]
-	x	$t3,3($i3,$tbl)	# Td1[s2>>16]
-
-	sllg	$i3,$s3,`0+3`	# i2
-	srl	$s3,`24-3`
-	ngr	$i3,$mask
-	nr	$s3,$mask
-
-	xr	$s2,$t2
-	x	$s0,0($key)
-	x	$s1,4($key)
-	x	$s2,8($key)
-	x	$t3,12($key)
-
-	x	$s0,3($t1,$tbl)	# Td1[s3>>16]
-	x	$s1,2($ra,$tbl)	# Td2[s3>>8]
-	x	$s2,1($i3,$tbl)	# Td3[s3>>0]
-	l	$s3,0($s3,$tbl)	# Td0[s3>>24]
-	xr	$s3,$t3
-
-	brct	$rounds,.Ldec_loop
-	.align	16
-
-	l	$t1,`2048+0`($tbl)	# prefetch Td4
-	l	$t2,`2048+64`($tbl)
-	l	$t3,`2048+128`($tbl)
-	l	$i1,`2048+192`($tbl)
-	llill	$mask,0xff
-
-	srlg	$i3,$s0,24	# i0
-	srlg	$t1,$s0,16
-	srlg	$t2,$s0,8
-	nr	$s0,$mask	# i3
-	nr	$t1,$mask
-
-	srlg	$i1,$s1,24
-	nr	$t2,$mask
-	srlg	$i2,$s1,16
-	srlg	$ra,$s1,8
-	nr	$s1,$mask	# i0
-	nr	$i2,$mask
-	nr	$ra,$mask
-
-	llgc	$i3,2048($i3,$tbl)	# Td4[s0>>24]
-	llgc	$t1,2048($t1,$tbl)	# Td4[s0>>16]
-	llgc	$t2,2048($t2,$tbl)	# Td4[s0>>8]
-	sll	$t1,16
-	llgc	$t3,2048($s0,$tbl)	# Td4[s0>>0]
-	sllg	$s0,$i3,24
-	sll	$t2,8
-
-	llgc	$s1,2048($s1,$tbl)	# Td4[s1>>0]
-	llgc	$i1,2048($i1,$tbl)	# Td4[s1>>24]
-	llgc	$i2,2048($i2,$tbl)	# Td4[s1>>16]
-	sll	$i1,24
-	llgc	$i3,2048($ra,$tbl)	# Td4[s1>>8]
-	sll	$i2,16
-	sll	$i3,8
-	or	$s0,$s1
-	or	$t1,$i1
-	or	$t2,$i2
-	or	$t3,$i3
-
-	srlg	$i1,$s2,8	# i0
-	srlg	$i2,$s2,24
-	srlg	$i3,$s2,16
-	nr	$s2,$mask	# i1
-	nr	$i1,$mask
-	nr	$i3,$mask
-	llgc	$i1,2048($i1,$tbl)	# Td4[s2>>8]
-	llgc	$s1,2048($s2,$tbl)	# Td4[s2>>0]
-	llgc	$i2,2048($i2,$tbl)	# Td4[s2>>24]
-	llgc	$i3,2048($i3,$tbl)	# Td4[s2>>16]
-	sll	$i1,8
-	sll	$i2,24
-	or	$s0,$i1
-	sll	$i3,16
-	or	$t2,$i2
-	or	$t3,$i3
-
-	srlg	$i1,$s3,16	# i0
-	srlg	$i2,$s3,8	# i1
-	srlg	$i3,$s3,24
-	nr	$s3,$mask	# i2
-	nr	$i1,$mask
-	nr	$i2,$mask
-
-	l${g}	$ra,15*$SIZE_T($sp)
-	or	$s1,$t1
-	l	$t0,16($key)
-	l	$t1,20($key)
-
-	llgc	$i1,2048($i1,$tbl)	# Td4[s3>>16]
-	llgc	$i2,2048($i2,$tbl)	# Td4[s3>>8]
-	sll	$i1,16
-	llgc	$s2,2048($s3,$tbl)	# Td4[s3>>0]
-	llgc	$s3,2048($i3,$tbl)	# Td4[s3>>24]
-	sll	$i2,8
-	sll	$s3,24
-	or	$s0,$i1
-	or	$s1,$i2
-	or	$s2,$t2
-	or	$s3,$t3
-
-	xr	$s0,$t0
-	xr	$s1,$t1
-	x	$s2,24($key)
-	x	$s3,28($key)
-
-	br	$ra
-.size	_s390x_AES_decrypt,.-_s390x_AES_decrypt
-___
-
-$code.=<<___;
-# void AES_set_encrypt_key(const unsigned char *in, int bits,
-#		 AES_KEY *key) {
-.globl	AES_set_encrypt_key
-.type	AES_set_encrypt_key,\@function
-.align	16
-AES_set_encrypt_key:
-_s390x_AES_set_encrypt_key:
-	lghi	$t0,0
-	cl${g}r	$inp,$t0
-	je	.Lminus1
-	cl${g}r	$key,$t0
-	je	.Lminus1
-
-	lghi	$t0,128
-	clr	$bits,$t0
-	je	.Lproceed
-	lghi	$t0,192
-	clr	$bits,$t0
-	je	.Lproceed
-	lghi	$t0,256
-	clr	$bits,$t0
-	je	.Lproceed
-	lghi	%r2,-2
-	br	%r14
-
-.align	16
-.Lproceed:
-___
-$code.=<<___ if (!$softonly);
-	# convert bits to km(c) code, [128,192,256]->[18,19,20]
-	lhi	%r5,-128
-	lhi	%r0,18
-	ar	%r5,$bits
-	srl	%r5,6
-	ar	%r5,%r0
-
-	larl	%r1,OPENSSL_s390xcap_P
-	llihh	%r0,0x8000
-	srlg	%r0,%r0,0(%r5)
-	ng	%r0,S390X_KM(%r1)  # check availability of both km...
-	ng	%r0,S390X_KMC(%r1) # ...and kmc support for given key length
-	jz	.Lekey_internal
-
-	lmg	%r0,%r1,0($inp)	# just copy 128 bits...
-	stmg	%r0,%r1,0($key)
-	lhi	%r0,192
-	cr	$bits,%r0
-	jl	1f
-	lg	%r1,16($inp)
-	stg	%r1,16($key)
-	je	1f
-	lg	%r1,24($inp)
-	stg	%r1,24($key)
-1:	st	$bits,236($key)	# save bits [for debugging purposes]
-	lgr	$t0,%r5
-	st	%r5,240($key)	# save km(c) code
-	lghi	%r2,0
-	br	%r14
-___
-$code.=<<___;
-.align	16
-.Lekey_internal:
-	stm${g}	%r4,%r13,4*$SIZE_T($sp)	# all non-volatile regs and $key
-
-	larl	$tbl,AES_Te+2048
-
-	llgf	$s0,0($inp)
-	llgf	$s1,4($inp)
-	llgf	$s2,8($inp)
-	llgf	$s3,12($inp)
-	st	$s0,0($key)
-	st	$s1,4($key)
-	st	$s2,8($key)
-	st	$s3,12($key)
-	lghi	$t0,128
-	cr	$bits,$t0
-	jne	.Lnot128
-
-	llill	$mask,0xff
-	lghi	$t3,0			# i=0
-	lghi	$rounds,10
-	st	$rounds,240($key)
-
-	llgfr	$t2,$s3			# temp=rk[3]
-	srlg	$i1,$s3,8
-	srlg	$i2,$s3,16
-	srlg	$i3,$s3,24
-	nr	$t2,$mask
-	nr	$i1,$mask
-	nr	$i2,$mask
-
-.align	16
-.L128_loop:
-	la	$t2,0($t2,$tbl)
-	la	$i1,0($i1,$tbl)
-	la	$i2,0($i2,$tbl)
-	la	$i3,0($i3,$tbl)
-	icm	$t2,2,0($t2)		# Te4[rk[3]>>0]<<8
-	icm	$t2,4,0($i1)		# Te4[rk[3]>>8]<<16
-	icm	$t2,8,0($i2)		# Te4[rk[3]>>16]<<24
-	icm	$t2,1,0($i3)		# Te4[rk[3]>>24]
-	x	$t2,256($t3,$tbl)	# rcon[i]
-	xr	$s0,$t2			# rk[4]=rk[0]^...
-	xr	$s1,$s0			# rk[5]=rk[1]^rk[4]
-	xr	$s2,$s1			# rk[6]=rk[2]^rk[5]
-	xr	$s3,$s2			# rk[7]=rk[3]^rk[6]
-
-	llgfr	$t2,$s3			# temp=rk[3]
-	srlg	$i1,$s3,8
-	srlg	$i2,$s3,16
-	nr	$t2,$mask
-	nr	$i1,$mask
-	srlg	$i3,$s3,24
-	nr	$i2,$mask
-
-	st	$s0,16($key)
-	st	$s1,20($key)
-	st	$s2,24($key)
-	st	$s3,28($key)
-	la	$key,16($key)		# key+=4
-	la	$t3,4($t3)		# i++
-	brct	$rounds,.L128_loop
-	lghi	$t0,10
-	lghi	%r2,0
-	lm${g}	%r4,%r13,4*$SIZE_T($sp)
-	br	$ra
-
-.align	16
-.Lnot128:
-	llgf	$t0,16($inp)
-	llgf	$t1,20($inp)
-	st	$t0,16($key)
-	st	$t1,20($key)
-	lghi	$t0,192
-	cr	$bits,$t0
-	jne	.Lnot192
-
-	llill	$mask,0xff
-	lghi	$t3,0			# i=0
-	lghi	$rounds,12
-	st	$rounds,240($key)
-	lghi	$rounds,8
-
-	srlg	$i1,$t1,8
-	srlg	$i2,$t1,16
-	srlg	$i3,$t1,24
-	nr	$t1,$mask
-	nr	$i1,$mask
-	nr	$i2,$mask
-
-.align	16
-.L192_loop:
-	la	$t1,0($t1,$tbl)
-	la	$i1,0($i1,$tbl)
-	la	$i2,0($i2,$tbl)
-	la	$i3,0($i3,$tbl)
-	icm	$t1,2,0($t1)		# Te4[rk[5]>>0]<<8
-	icm	$t1,4,0($i1)		# Te4[rk[5]>>8]<<16
-	icm	$t1,8,0($i2)		# Te4[rk[5]>>16]<<24
-	icm	$t1,1,0($i3)		# Te4[rk[5]>>24]
-	x	$t1,256($t3,$tbl)	# rcon[i]
-	xr	$s0,$t1			# rk[6]=rk[0]^...
-	xr	$s1,$s0			# rk[7]=rk[1]^rk[6]
-	xr	$s2,$s1			# rk[8]=rk[2]^rk[7]
-	xr	$s3,$s2			# rk[9]=rk[3]^rk[8]
-
-	st	$s0,24($key)
-	st	$s1,28($key)
-	st	$s2,32($key)
-	st	$s3,36($key)
-	brct	$rounds,.L192_continue
-	lghi	$t0,12
-	lghi	%r2,0
-	lm${g}	%r4,%r13,4*$SIZE_T($sp)
-	br	$ra
-
-.align	16
-.L192_continue:
-	lgr	$t1,$s3
-	x	$t1,16($key)		# rk[10]=rk[4]^rk[9]
-	st	$t1,40($key)
-	x	$t1,20($key)		# rk[11]=rk[5]^rk[10]
-	st	$t1,44($key)
-
-	srlg	$i1,$t1,8
-	srlg	$i2,$t1,16
-	srlg	$i3,$t1,24
-	nr	$t1,$mask
-	nr	$i1,$mask
-	nr	$i2,$mask
-
-	la	$key,24($key)		# key+=6
-	la	$t3,4($t3)		# i++
-	j	.L192_loop
-
-.align	16
-.Lnot192:
-	llgf	$t0,24($inp)
-	llgf	$t1,28($inp)
-	st	$t0,24($key)
-	st	$t1,28($key)
-	llill	$mask,0xff
-	lghi	$t3,0			# i=0
-	lghi	$rounds,14
-	st	$rounds,240($key)
-	lghi	$rounds,7
-
-	srlg	$i1,$t1,8
-	srlg	$i2,$t1,16
-	srlg	$i3,$t1,24
-	nr	$t1,$mask
-	nr	$i1,$mask
-	nr	$i2,$mask
-
-.align	16
-.L256_loop:
-	la	$t1,0($t1,$tbl)
-	la	$i1,0($i1,$tbl)
-	la	$i2,0($i2,$tbl)
-	la	$i3,0($i3,$tbl)
-	icm	$t1,2,0($t1)		# Te4[rk[7]>>0]<<8
-	icm	$t1,4,0($i1)		# Te4[rk[7]>>8]<<16
-	icm	$t1,8,0($i2)		# Te4[rk[7]>>16]<<24
-	icm	$t1,1,0($i3)		# Te4[rk[7]>>24]
-	x	$t1,256($t3,$tbl)	# rcon[i]
-	xr	$s0,$t1			# rk[8]=rk[0]^...
-	xr	$s1,$s0			# rk[9]=rk[1]^rk[8]
-	xr	$s2,$s1			# rk[10]=rk[2]^rk[9]
-	xr	$s3,$s2			# rk[11]=rk[3]^rk[10]
-	st	$s0,32($key)
-	st	$s1,36($key)
-	st	$s2,40($key)
-	st	$s3,44($key)
-	brct	$rounds,.L256_continue
-	lghi	$t0,14
-	lghi	%r2,0
-	lm${g}	%r4,%r13,4*$SIZE_T($sp)
-	br	$ra
-
-.align	16
-.L256_continue:
-	lgr	$t1,$s3			# temp=rk[11]
-	srlg	$i1,$s3,8
-	srlg	$i2,$s3,16
-	srlg	$i3,$s3,24
-	nr	$t1,$mask
-	nr	$i1,$mask
-	nr	$i2,$mask
-	la	$t1,0($t1,$tbl)
-	la	$i1,0($i1,$tbl)
-	la	$i2,0($i2,$tbl)
-	la	$i3,0($i3,$tbl)
-	llgc	$t1,0($t1)		# Te4[rk[11]>>0]
-	icm	$t1,2,0($i1)		# Te4[rk[11]>>8]<<8
-	icm	$t1,4,0($i2)		# Te4[rk[11]>>16]<<16
-	icm	$t1,8,0($i3)		# Te4[rk[11]>>24]<<24
-	x	$t1,16($key)		# rk[12]=rk[4]^...
-	st	$t1,48($key)
-	x	$t1,20($key)		# rk[13]=rk[5]^rk[12]
-	st	$t1,52($key)
-	x	$t1,24($key)		# rk[14]=rk[6]^rk[13]
-	st	$t1,56($key)
-	x	$t1,28($key)		# rk[15]=rk[7]^rk[14]
-	st	$t1,60($key)
-
-	srlg	$i1,$t1,8
-	srlg	$i2,$t1,16
-	srlg	$i3,$t1,24
-	nr	$t1,$mask
-	nr	$i1,$mask
-	nr	$i2,$mask
-
-	la	$key,32($key)		# key+=8
-	la	$t3,4($t3)		# i++
-	j	.L256_loop
-
-.Lminus1:
-	lghi	%r2,-1
-	br	$ra
-.size	AES_set_encrypt_key,.-AES_set_encrypt_key
+#          const AES_KEY *key) {
+
+FUNCTION_BEGIN("AES_decrypt",3,"true","","true");
+
+LABEL("AES_decrypt_A"); # for z/OS
+if($flavour =~/linux/ ) {
+    l       ($wr0,"240($key)");
+    lhi     ($wr1,16);
+    clr     ($wr0,$wr1);
+    jl      (LABEL("Ldsoft"));
+
+    la      ($wr1,"0($key)");
+    la      ("%r4","0($outp)");
+    lghi    ($wr3,16);        # single block length
+    km      ("%r4",$wr2);
+  } else {
+    l       ($wr0,"240($key)");
+    lhi     ($wr5,16);
+    clr     ($wr0,$wr5);
+    jl      (LABEL("Ldsoft"));
+
+    la      ($wr6,"0($outp)");
+    la      ($wr2,"0($inp)");
+    la      ($wr1,"0($key)");
+    lghi    ($wr3,16);        # single block length
+    km      ($wr6,$wr2);
+  }
+
+    brc     (1,"$ip-4");        # can this happen?
+
+    BR_EXIT ();
+
+ALIGN(64);
+LABEL("Ldsoft:");
+
+if ($flavour =~ /linux/) {
+    &{$z? \&stmg:\&stm}    ("%r3",$ra,"3*$SIZE_T($sp)");
+} else {
+    lay     ($sp,"STACK");
+    &{$z? \&stmg:\&stm}    ("R2","R14","2*$SIZE_T($sp)");
+}
+
+    llgf    ($s0,"0($inp)");
+    llgf    ($s1,"4($inp)");
+    llgf    ($s2,"8($inp)");
+    llgf    ($s3,"12($inp)");
+
+    larl    ($tbl,LABEL("AES_Td"));
+if ($flavour =~ /linux/) {
+    bras    ($ra,"_s390x_AES_decrypt");
+    &{$z? \&lg:\&l}    ($outp,"3*$SIZE_T($sp)");
+} else {
+    bas    ($ra,"_s390x_AES_decrypt");
+    &{$z? \&lg:\&l}    ($outp,"2*$SIZE_T($sp)");
+}
+    st      ($s0,"0($outp)");
+    st      ($s1,"4($outp)");
+    st      ($s2,"8($outp)");
+    st      ($s3,"12($outp)");
+
+if ($flavour =~ /linux/) {
+    &{$z? \&lmg:\&lm}    ("%r6",$ra,"6*$SIZE_T($sp)");
+} else {
+    &{$z? \&lg:\&l}    ("R4","4*$SIZE_T($sp)");
+}
+    BR_EXIT();
+
+FUNCTION_END("AES_decrypt",$rv);
+}
+
+{
+
+my $key;
+ALIGN(16);
+LOCAL_FUNCTION("_s390x_AES_decrypt");
+
+&{$z? \&stg:\&st}    ($ra,"15*$SIZE_T($sp)");
+if ($flavour !~ /linux/) {
+    $key = "R14";
+    &{$z? \&lgr:\&lr} ($key,"R3");
+} else {
+    $key="%r4";
+}
+    x       ($s0,"0($key)");
+    x       ($s1,"4($key)");
+    x       ($s2,"8($key)");
+    x       ($s3,"12($key)");
+    l       ($rounds,"240($key)");
+    llill   ($mask,0xff<<3);
+    aghi    ($rounds,-1);
+    j   (LABEL("Ldec_loop"));
+ALIGN(16);
+LABEL("Ldec_loop:");
+    srlg    ($t1,$s0,"16-3");
+    srlg    ($t2,$s0,"8-3");
+    sllg    ($t3,$s0,"0+3");
+    srl     ($s0,"24-3");
+    nr      ($s0,$mask);
+    nr      ($t1,$mask);
+    nr      ($t2,$mask);
+    ngr     ($t3,$mask);
+
+    sllg    ($i1,$s1,"0+3");    # i0
+    srlg    ($i2,$s1,"16-3");
+    srlg    ($i3,$s1,"8-3");
+    srl     ($s1,"24-3");
+    ngr     ($i1,$mask);
+    nr      ($s1,$mask);
+    nr      ($i2,$mask);
+    nr      ($i3,$mask);
+
+    l       ($s0,"0($s0,$tbl)");    # Td0[s0>>24]
+    l       ($t1,"3($t1,$tbl)");    # Td1[s0>>16]
+    l       ($t2,"2($t2,$tbl)");    # Td2[s0>>8]
+    l       ($t3,"1($t3,$tbl)");    # Td3[s0>>0]
+
+    x       ($s0,"1($i1,$tbl)");    # Td3[s1>>0]
+    l       ($s1,"0($s1,$tbl)");    # Td0[s1>>24]
+    x       ($t2,"3($i2,$tbl)");    # Td1[s1>>16]
+    x       ($t3,"2($i3,$tbl)");    # Td2[s1>>8]
+
+    srlg    ($i1,$s2,"8-3");    # i0
+    sllg    ($i2,$s2,"0+3");    # i1
+    srlg    ($i3,$s2,"16-3");
+    srl     ($s2,"24-3");
+    nr      ($i1,$mask);
+    ngr     ($i2,$mask);
+    nr      ($s2,$mask);
+    nr      ($i3,$mask);
+
+    xr      ($s1,$t1);
+    srlg    ($temp,$s3,"8-3");    # i1
+    srlg    ($t1,$s3,"16-3");    # i0
+    nr      ($temp,$mask);
+    la      ($key,"16($key)");
+    nr      ($t1,$mask);
+
+    x       ($s0,"2($i1,$tbl)");    # Td2[s2>>8]
+    x       ($s1,"1($i2,$tbl)");    # Td3[s2>>0]
+    l       ($s2,"0($s2,$tbl)");    # Td0[s2>>24]
+    x       ($t3,"3($i3,$tbl)");    # Td1[s2>>16]
+
+    sllg    ($i3,$s3,"0+3");    # i2
+    srl     ($s3,"24-3");
+    ngr     ($i3,$mask);
+    nr      ($s3,$mask);
+
+    xr      ($s2,$t2);
+    x       ($s0,"0($key)");
+    x       ($s1,"4($key)");
+    x       ($s2,"8($key)");
+    x       ($t3,"12($key)");
+
+    x       ($s0,"3($t1,$tbl)");    # Td1[s3>>16]
+    x       ($s1,"2($temp,$tbl)");    # Td2[s3>>8]
+    x       ($s2,"1($i3,$tbl)");    # Td3[s3>>0]
+    l       ($s3,"0($s3,$tbl)");    # Td0[s3>>24]
+    xr      ($s3,$t3);
+
+    brct    ($rounds,LABEL("Ldec_loop"));
+ALIGN(16) if ( $flavour =~ /linux/);
+
+    l       ($t1,"2048+0($tbl)");    # prefetch Td4
+    l       ($t2,"2048+64($tbl)");
+    l       ($t3,"2048+128($tbl)");
+    l       ($i1,"2048+192($tbl)");
+    llill   ($mask,0xff);
+
+    srlg    ($i3,$s0,24);    # i0
+    srlg    ($t1,$s0,16);
+    srlg    ($t2,$s0,8);
+    nr      ($s0,$mask);    # i3
+    nr      ($t1,$mask);
+
+    srlg    ($i1,$s1,24);
+    nr      ($t2,$mask);
+    srlg    ($i2,$s1,16);
+    srlg    ($temp,$s1,8);
+    nr      ($s1,$mask);    # i0
+    nr      ($i2,$mask);
+    nr      ($temp,$mask);
+
+    llgc    ($i3,"2048($i3,$tbl)");    # Td4[s0>>24]
+    llgc    ($t1,"2048($t1,$tbl)");    # Td4[s0>>16]
+    llgc    ($t2,"2048($t2,$tbl)");    # Td4[s0>>8]
+    sll     ($t1,16);
+    llgc    ($t3,"2048($s0,$tbl)");    # Td4[s0>>0]
+    sllg    ($s0,$i3,24);
+    sll     ($t2,8);
+
+    llgc    ($s1,"2048($s1,$tbl)");    # Td4[s1>>0]
+    llgc    ($i1,"2048($i1,$tbl)");    # Td4[s1>>24]
+    llgc    ($i2,"2048($i2,$tbl)");    # Td4[s1>>16]
+    sll     ($i1,24);
+    llgc    ($i3,"2048($temp,$tbl)");    # Td4[s1>>8]
+    sll     ($i2,16);
+    sll     ($i3,8);
+    &or     ($s0,$s1);
+    &or     ($t1,$i1);
+    &or     ($t2,$i2);
+    &or     ($t3,$i3);
+
+    srlg    ($i1,$s2,8);    # i0
+    srlg    ($i2,$s2,24);
+    srlg    ($i3,$s2,16);
+    nr      ($s2,$mask);    # i1
+    nr      ($i1,$mask);
+    nr      ($i3,$mask);
+    llgc    ($i1,"2048($i1,$tbl)");    # Td4[s2>>8]
+    llgc    ($s1,"2048($s2,$tbl)");    # Td4[s2>>0]
+    llgc    ($i2,"2048($i2,$tbl)");    # Td4[s2>>24]
+    llgc    ($i3,"2048($i3,$tbl)");    # Td4[s2>>16]
+    sll     ($i1,8);
+    sll     ($i2,24);
+    &or     ($s0,$i1);
+    sll     ($i3,16);
+    &or     ($t2,$i2);
+    &or     ($t3,$i3);
+
+    srlg    ($i1,$s3,16);    # i0
+    srlg    ($i2,$s3,8);    # i1
+    srlg    ($i3,$s3,24);
+    nr      ($s3,$mask);    # i2
+    nr      ($i1,$mask);
+    nr      ($i2,$mask);
+
+    &or     ($s1,$t1);
+    l       ($t0,"16($key)");
+    l       ($t1,"20($key)");
+
+    llgc    ($i1,"2048($i1,$tbl)");    # Td4[s3>>16]
+    llgc    ($i2,"2048($i2,$tbl)");    # Td4[s3>>8]
+    sll     ($i1,16);
+    llgc    ($s2,"2048($s3,$tbl)");    # Td4[s3>>0]
+    llgc    ($s3,"2048($i3,$tbl)");    # Td4[s3>>24]
+    sll     ($i2,8);
+    sll     ($s3,24);
+    &or     ($s0,$i1);
+    &or     ($s1,$i2);
+    &or     ($s2,$t2);
+    &or     ($s3,$t3);
+
+    xr      ($s0,$t0);
+    xr      ($s1,$t1);
+    x       ($s2,"24($key)");
+    x       ($s3,"28($key)");
+
+&{$z? \&lg:\&l}    ($ra,"15*$SIZE_T($sp)");
+    br      ($ra);
+
+LOCAL_FUNCTION_END("_s390x_AES_decrypt");
+}

+{
+
+# int AES_set_encrypt_key(const unsigned char *in, int bits,
+#          AES_KEY *key) {
+
+my ($wr0, $wr1, $key, $t1);
+if ($flavour =~ /linux/ ) {
+  $wr0="%r0";
+  $wr1="%r1";
+  $t1="%r1";
+  $key="%r4";
+  $rounds="%r13";
+  $rv = "%r2";
+} else {
+  $wr0="R9";
+  $wr1="R10";
+  $t1="R12";    # t1 is used in the software path and having it be r1 causes ABENDs because $inp is also r1
+  $key="R3";
+  $rounds="R14";
+  $rv = "R3";
+}
+FUNCTION_BEGIN("AES_set_encrypt_key",3,"","stor3","true");
+LABEL("_s390x_AES_set_encrypt_key:") if ($flavour =~ /linux/);
+    lghi   ($t0,0);
+&{$z? \&clgr:\&clr} ($inp,$t0);
+    je     (LABEL("Lminus1"));
+&{$z? \&clgr:\&clr} ($key,$t0);
+    je     (LABEL("Lminus1"));
+
+    lghi   ($t0,128);
+    clr    ($bits,$t0);
+    je     (LABEL("Lproceed"));
+    lghi   ($t0,192);
+    clr    ($bits,$t0);
+    je     (LABEL("Lproceed"));
+    lghi   ($t0,256);
+    clr    ($bits,$t0);
+    je     (LABEL("Lproceed"));
+    lghi   ($rv,-2);
+    BR_EXIT();
+
+    ALIGN(16);
+LABEL("Lproceed:");
+
+    GET_EXTERN($wr1,"OPENSSL_s390xcap_P"); # before r5 is corrupted
+#    # convert bits to km(c) code, [128,192,256]->[18,19,20]
+    lhi    ($wr5,-128);
+    lhi    ($wr0,18);
+    ar     ($wr5,$bits);
+    srl    ($wr5,6);
+    ar     ($wr5,$wr0);
+
+    llihh  ($wr0,0x8000);
+    srlg   ($wr0,$wr0,"0($wr5)");
+    ng     ($wr0,"CS390X_KM($wr1)");  # check availability of both km...
+    ng     ($wr0,"CS390X_KMC($wr1)"); # ...and kmc support for given key length
+    jz     (LABEL("Lekey_internal"));
+
+    lmg    ($wr0,$wr1,"0($inp)");  # just copy 128 bits...
+    stmg   ($wr0,$wr1,"0($key)");
+    lhi    ($wr0,192);
+    cr     ($bits,$wr0);
+    jl     (LABEL("ASEK1"));
+    lg     ($wr1,"16($inp)");
+    stg    ($wr1,"16($key)");
+    je     (LABEL("ASEK1"));
+    lg     ($wr1,"24($inp)");
+    stg    ($wr1,"24($key)");
+LABEL("ASEK1:");
+    st     ($bits,"236($key)");  # save bits [for debugging purposes]
+    lgr    ($t0,$wr5);
+    st     ($wr5,"240($key)");    # save km(c) code
+    lghi   ($rv,0);
+    BR_EXIT();
+
+    ALIGN(16);
+LABEL("Lekey_internal:");
+&{$z? \&stmg:\&stm}    ("%r4","%r13","4*$SIZE_T($sp)") if ($flavour =~ /linux/); # all non-volatile regs and $key
+
+    larl   ($tbl,LABEL("AES_Te+2048"));
+
+    llgf   ($s0,"0($inp)");
+    llgf   ($s1,"4($inp)");
+    llgf   ($s2,"8($inp)");
+    llgf   ($s3,"12($inp)");
+    st     ($s0,"0($key)");
+    st     ($s1,"4($key)");
+    st     ($s2,"8($key)");
+    st     ($s3,"12($key)");
+
+if ($flavour !~ /linux/) {
+  &{$z? \&lgr:\&lr} ("R15",$key); # preserve key address as $key and $t3 are the same reg
+    $key = "R15";				  # z/OS does not use r15 in this function
+}
+
+    lghi   ($t0,128);
+    cr     ($bits,$t0);
+    jne    (LABEL("Lnot128"));
+
+    llill  ($mask,0xff);
+    lghi   ($t3,0);               # i=0
+    lghi   ($rounds,10);
+    st     ($rounds,"240($key)");
+
+    llgfr  ($t2,$s3);             # temp=rk[3]
+    srlg   ($i1,$s3,8);
+    srlg   ($i2,$s3,16);
+    srlg   ($i3,$s3,24);
+    nr     ($t2,$mask);
+    nr     ($i1,$mask);
+    nr     ($i2,$mask);
+
+
+LABEL("L128_loop:");
+    la     ($t2,"0($t2,$tbl)");
+    la     ($i1,"0($i1,$tbl)");
+    la     ($i2,"0($i2,$tbl)");
+    la     ($i3,"0($i3,$tbl)");
+    icm    ($t2,2,"0($t2)");      # Te4[rk[3]>>0]<<8
+    icm    ($t2,4,"0($i1)");      # Te4[rk[3]>>8]<<16
+    icm    ($t2,8,"0($i2)");      # Te4[rk[3]>>16]<<24
+    icm    ($t2,1,"0($i3)");      # Te4[rk[3]>>24]
+    x      ($t2,"256($t3,$tbl)"); # rcon[i]
+    xr     ($s0,$t2);             # rk[4]=rk[0]^...
+    xr     ($s1,$s0);             # rk[5]=rk[1]^rk[4]
+    xr     ($s2,$s1);             # rk[6]=rk[2]^rk[5]
+    xr     ($s3,$s2);             # rk[7]=rk[3]^rk[6]
+
+    llgfr  ($t2,$s3);             # temp=rk[3]
+    srlg   ($i1,$s3,8);
+    srlg   ($i2,$s3,16);
+    nr     ($t2,$mask);
+    nr     ($i1,$mask);
+    srlg   ($i3,$s3,24);
+    nr     ($i2,$mask);
+
+    st     ($s0,"16($key)");
+    st     ($s1,"20($key)");
+    st     ($s2,"24($key)");
+    st     ($s3,"28($key)");
+    la     ($key,"16($key)");     # key+=4
+    la     ($t3,"4($t3)");        # i++
+    brct   ($rounds,LABEL("L128_loop"));
+    lghi   ($t0,10);
+    lghi   ($rv,0);
+&{$z? \&lmg:\&lm} ("%r4","%r13","4*$SIZE_T($sp)") if ($flavour =~ /linux/);
+    BR_EXIT();
+
+    ALIGN(16);
+LABEL("Lnot128:");
+    llgf   ($t0,"16($inp)");
+    llgf   ($t1,"20($inp)");
+    st     ($t0,"16($key)");
+    st     ($t1,"20($key)");
+    lghi   ($t0,192);
+    cr     ($bits,$t0);
+    jne    (LABEL("Lnot192"));
+
+    llill  ($mask,0xff);
+    lghi   ($t3,0);               # i=0
+    lghi   ($rounds,12);
+    st     ($rounds,"240($key)");
+    lghi   ($rounds,8);
+
+    srlg   ($i1,$t1,8);
+    srlg   ($i2,$t1,16);
+    srlg   ($i3,$t1,24);
+    nr     ($t1,$mask);
+    nr     ($i1,$mask);
+    nr     ($i2,$mask);
+
+
+LABEL("L192_loop:");
+    la     ($t1,"0($t1,$tbl)");
+    la     ($i1,"0($i1,$tbl)");
+    la     ($i2,"0($i2,$tbl)");
+    la     ($i3,"0($i3,$tbl)");
+    icm    ($t1,2,"0($t1)");      # Te4[rk[5]>>0]<<8
+    icm    ($t1,4,"0($i1)");      # Te4[rk[5]>>8]<<16
+    icm    ($t1,8,"0($i2)");      # Te4[rk[5]>>16]<<24
+    icm    ($t1,1,"0($i3)");      # Te4[rk[5]>>24]
+    x      ($t1,"256($t3,$tbl)"); # rcon[i]
+    xr     ($s0,$t1);             # rk[6]=rk[0]^...
+    xr     ($s1,$s0);             # rk[7]=rk[1]^rk[6]
+    xr     ($s2,$s1);             # rk[8]=rk[2]^rk[7]
+    xr     ($s3,$s2);             # rk[9]=rk[3]^rk[8]
+
+    st     ($s0,"24($key)");
+    st     ($s1,"28($key)");
+    st     ($s2,"32($key)");
+    st     ($s3,"36($key)");
+    brct   ($rounds,LABEL("L192_continue"));
+    lghi   ($t0,12);
+    lghi   ($rv,0);
+&{$z? \&lmg:\&lm} ("%r4","%r13","4*$SIZE_T($sp)") if ($flavour =~ /linux/);
+    BR_EXIT();
+
+
+LABEL("L192_continue:");
+    lgr    ($t1,$s3);
+    x      ($t1,"16($key)");      # rk[10]=rk[4]^rk[9]
+    st     ($t1,"40($key)");
+    x      ($t1,"20($key)");      # rk[11]=rk[5]^rk[10]
+    st     ($t1,"44($key)");
+
+    srlg   ($i1,$t1,8);
+    srlg   ($i2,$t1,16);
+    srlg   ($i3,$t1,24);
+    nr     ($t1,$mask);
+    nr     ($i1,$mask);
+    nr     ($i2,$mask);
+
+    la     ($key,"24($key)");     # key+=6
+    la     ($t3,"4($t3)");        # i++
+    j      (LABEL("L192_loop"));
+
+    ALIGN(16);
+LABEL("Lnot192:");
+    llgf   ($t0,"24($inp)");
+    llgf   ($t1,"28($inp)");
+    st     ($t0,"24($key)");
+    st     ($t1,"28($key)");
+    llill  ($mask,0xff);
+    lghi   ($t3,0);               # i=0
+    lghi   ($rounds,14);
+    st     ($rounds,"240($key)");
+    lghi   ($rounds,7);
+
+    srlg   ($i1,$t1,8);
+    srlg   ($i2,$t1,16);
+    srlg   ($i3,$t1,24);
+    nr     ($t1,$mask);
+    nr     ($i1,$mask);
+    nr     ($i2,$mask);
+
+
+LABEL("L256_loop:");
+    la     ($t1,"0($t1,$tbl)");
+    la     ($i1,"0($i1,$tbl)");
+    la     ($i2,"0($i2,$tbl)");
+    la     ($i3,"0($i3,$tbl)");
+    icm    ($t1,2,"0($t1)");      # Te4[rk[7]>>0]<<8
+    icm    ($t1,4,"0($i1)");      # Te4[rk[7]>>8]<<16
+    icm    ($t1,8,"0($i2)");      # Te4[rk[7]>>16]<<24
+    icm    ($t1,1,"0($i3)");      # Te4[rk[7]>>24]
+    x      ($t1,"256($t3,$tbl)"); # rcon[i]
+    xr     ($s0,$t1);            # rk[8]=rk[0]^...
+    xr     ($s1,$s0);            # rk[9]=rk[1]^rk[8]
+    xr     ($s2,$s1);            # rk[10]=rk[2]^rk[9]
+    xr     ($s3,$s2);            # rk[11]=rk[3]^rk[10]
+    st     ($s0,"32($key)");
+    st     ($s1,"36($key)");
+    st     ($s2,"40($key)");
+    st     ($s3,"44($key)");
+    brct   ($rounds,LABEL("L256_continue"));
+    lghi   ($t0,14);
+    lghi   ($rv,0);
+&{$z? \&lmg:\&lm} ("%r4","%r13","4*$SIZE_T($sp)") if ($flavour =~ /linux/);
+    BR_EXIT();
+
+    ALIGN(16);
+LABEL("L256_continue:");
+    lgr    ($t1,$s3);            # temp=rk[11]
+    srlg   ($i1,$s3,8);
+    srlg   ($i2,$s3,16);
+    srlg   ($i3,$s3,24);
+    nr     ($t1,$mask);
+    nr     ($i1,$mask);
+    nr     ($i2,$mask);
+    la     ($t1,"0($t1,$tbl)");
+    la     ($i1,"0($i1,$tbl)");
+    la     ($i2,"0($i2,$tbl)");
+    la     ($i3,"0($i3,$tbl)");
+    llgc   ($t1,"0($t1)");        # Te4[rk[11]>>0]
+    icm    ($t1,2,"0($i1)");      # Te4[rk[11]>>8]<<8
+    icm    ($t1,4,"0($i2)");      # Te4[rk[11]>>16]<<16
+    icm    ($t1,8,"0($i3)");      # Te4[rk[11]>>24]<<24
+    x      ($t1,"16($key)");      # rk[12]=rk[4]^...
+    st     ($t1,"48($key)");
+    x      ($t1,"20($key)");      # rk[13]=rk[5]^rk[12]
+    st     ($t1,"52($key)");
+    x      ($t1,"24($key)");      # rk[14]=rk[6]^rk[13]
+    st     ($t1,"56($key)");
+    x      ($t1,"28($key)");      # rk[15]=rk[7]^rk[14]
+    st     ($t1,"60($key)");
+
+    srlg   ($i1,$t1,8);
+    srlg   ($i2,$t1,16);
+    srlg   ($i3,$t1,24);
+    nr     ($t1,$mask);
+    nr     ($i1,$mask);
+    nr     ($i2,$mask);
+
+    la     ($key,"32($key)");     # key+=8
+    la     ($t3,"4($t3)");        # i++
+    j      (LABEL("L256_loop"));
+
+LABEL("Lminus1:");
+    lghi   ($rv,-1);
+    BR_EXIT();
+
+FUNCTION_END("AES_set_encrypt_key",$rv);
+}
+
+{
 # void AES_set_decrypt_key(const unsigned char *in, int bits,
-#		 AES_KEY *key) {
-.globl	AES_set_decrypt_key
-.type	AES_set_decrypt_key,\@function
-.align	16
-AES_set_decrypt_key:
-	#st${g}	$key,4*$SIZE_T($sp)	# I rely on AES_set_encrypt_key to
-	st${g}	$ra,14*$SIZE_T($sp)	# save non-volatile registers and $key!
-	bras	$ra,_s390x_AES_set_encrypt_key
-	#l${g}	$key,4*$SIZE_T($sp)
-	l${g}	$ra,14*$SIZE_T($sp)
-	ltgr	%r2,%r2
-	bnzr	$ra
-___
-$code.=<<___ if (!$softonly);
-	#l	$t0,240($key)
-	lhi	$t1,16
-	cr	$t0,$t1
-	jl	.Lgo
-	oill	$t0,S390X_DECRYPT	# set "decrypt" bit
-	st	$t0,240($key)
-	br	$ra
-___
-$code.=<<___;
-.align	16
-.Lgo:	lgr	$rounds,$t0	#llgf	$rounds,240($key)
-	la	$i1,0($key)
-	sllg	$i2,$rounds,4
-	la	$i2,0($i2,$key)
-	srl	$rounds,1
-	lghi	$t1,-16
-
-.align	16
-.Linv:	lmg	$s0,$s1,0($i1)
-	lmg	$s2,$s3,0($i2)
-	stmg	$s0,$s1,0($i2)
-	stmg	$s2,$s3,0($i1)
-	la	$i1,16($i1)
-	la	$i2,0($t1,$i2)
-	brct	$rounds,.Linv
-___
-$mask80=$i1;
-$mask1b=$i2;
-$maskfe=$i3;
-$code.=<<___;
-	llgf	$rounds,240($key)
-	aghi	$rounds,-1
-	sll	$rounds,2	# (rounds-1)*4
-	llilh	$mask80,0x8080
-	llilh	$mask1b,0x1b1b
-	llilh	$maskfe,0xfefe
-	oill	$mask80,0x8080
-	oill	$mask1b,0x1b1b
-	oill	$maskfe,0xfefe
-
-.align	16
-.Lmix:	l	$s0,16($key)	# tp1
-	lr	$s1,$s0
-	ngr	$s1,$mask80
-	srlg	$t1,$s1,7
-	slr	$s1,$t1
-	nr	$s1,$mask1b
-	sllg	$t1,$s0,1
-	nr	$t1,$maskfe
-	xr	$s1,$t1		# tp2
-
-	lr	$s2,$s1
-	ngr	$s2,$mask80
-	srlg	$t1,$s2,7
-	slr	$s2,$t1
-	nr	$s2,$mask1b
-	sllg	$t1,$s1,1
-	nr	$t1,$maskfe
-	xr	$s2,$t1		# tp4
-
-	lr	$s3,$s2
-	ngr	$s3,$mask80
-	srlg	$t1,$s3,7
-	slr	$s3,$t1
-	nr	$s3,$mask1b
-	sllg	$t1,$s2,1
-	nr	$t1,$maskfe
-	xr	$s3,$t1		# tp8
-
-	xr	$s1,$s0		# tp2^tp1
-	xr	$s2,$s0		# tp4^tp1
-	rll	$s0,$s0,24	# = ROTATE(tp1,8)
-	xr	$s2,$s3		# ^=tp8
-	xr	$s0,$s1		# ^=tp2^tp1
-	xr	$s1,$s3		# tp2^tp1^tp8
-	xr	$s0,$s2		# ^=tp4^tp1^tp8
-	rll	$s1,$s1,8
-	rll	$s2,$s2,16
-	xr	$s0,$s1		# ^= ROTATE(tp8^tp2^tp1,24)
-	rll	$s3,$s3,24
-	xr	$s0,$s2	# ^= ROTATE(tp8^tp4^tp1,16)
-	xr	$s0,$s3		# ^= ROTATE(tp8,8)
-
-	st	$s0,16($key)
-	la	$key,4($key)
-	brct	$rounds,.Lmix
-
-	lm${g}	%r6,%r13,6*$SIZE_T($sp)# as was saved by AES_set_encrypt_key!
-	lghi	%r2,0
-	br	$ra
-.size	AES_set_decrypt_key,.-AES_set_decrypt_key
-___
+#          AES_KEY *key) {
+
+FUNCTION_BEGIN("AES_set_decrypt_key",3,"","stor3","true");
+
+if ($flavour =~ /linux/) {
+    #st${g}    $key,4*$SIZE_T($sp)    # I rely on AES_set_encrypt_key to
+&{$z? \&stg:\&st} ($ra,"14*$SIZE_T($sp)");    # save non-volatile registers and $key!
+    bras    ($ra,LABEL("_s390x_AES_set_encrypt_key"));
+    #l${g}    $key,4*$SIZE_T($sp)
+&{$z? \&lg:\&l} ($ra,"14*$SIZE_T($sp)");
+
+} else {
+    lr      ($wr6,$ra);     # Save return address
+    &{$z? \&lgr:\&lr} ("R8",$key);    # Save key address
+    bras    ($ra,"AES_SET_ENCRYPT_KEY");
+    lr      ($ra,$wr6);     # Restore return address
+}
+    ltgr    ($rv,$rv);
+    BR_EXIT("nz");
+
+    #l       $t0,240($key)
+    &{$z? \&lgr:\&lr} ($key,"R8") if ($flavour !~ /linux/);
+    lhi    ($t1,16);
+    cr     ($t0,$t1);
+    jl     (LABEL("Lgo"));
+    oill   ($t0,"CS390X_DECRYPT");    # set "decrypt" bit
+    st     ($t0,"240($key)");
+    lghi   ($rv,0) if ($flavour !~ /linux/);
+    BR_EXIT();
+
+ALIGN(16);
+LABEL("Lgo:");
+    lgr    ($rounds,$t0);    #llgf    $rounds,240($key)
+    la     ($i1,"0($key)");
+    sllg   ($i2,$rounds,4);
+    la     ($i2,"0($i2,$key)");
+    srl    ($rounds,1);
+    lghi   ($t1,-16);
+
+ALIGN(16) if ($flavour =~ /linux/);
+LABEL("Linv:");
+    lmg    ($s0,$s1,"0($i1)");
+    lmg    ($s2,$s3,"0($i2)");
+    stmg   ($s0,$s1,"0($i2)");
+    stmg   ($s2,$s3,"0($i1)");
+    la     ($i1,"16($i1)");
+    la     ($i2,"0($t1,$i2)");
+    brct   ($rounds,LABEL("Linv"));
+
+my $mask80=$i1;
+my $mask1b=$i2;
+my $maskfe=$i3;
+
+    llgf   ($rounds,"240($key)");
+    aghi   ($rounds,-1);
+    sll    ($rounds,2);    # (rounds-1)*4
+    llilh  ($mask80,"0x8080");
+    llilh  ($mask1b,"0x1b1b");
+    llilh  ($maskfe,"0xfefe");
+    oill   ($mask80,"0x8080");
+    oill   ($mask1b,"0x1b1b");
+    oill   ($maskfe,"0xfefe");
+
+ALIGN(16)  if ($flavour =~ /linux/);
+LABEL("Lmix:");
+    l      ($s0,"16($key)");    # tp1
+    lr     ($s1,$s0);
+    ngr    ($s1,$mask80);
+    srlg   ($t1,$s1,7);
+    slr    ($s1,$t1);
+    nr     ($s1,$mask1b);
+    sllg   ($t1,$s0,1);
+    nr     ($t1,$maskfe);
+    xr     ($s1,$t1);        # tp2
+
+    lr     ($s2,$s1);
+    ngr    ($s2,$mask80);
+    srlg   ($t1,$s2,7);
+    slr    ($s2,$t1);
+    nr     ($s2,$mask1b);
+    sllg   ($t1,$s1,1);
+    nr     ($t1,$maskfe);
+    xr     ($s2,$t1);        # tp4
+
+    lr     ($s3,$s2);
+    ngr    ($s3,$mask80);
+    srlg   ($t1,$s3,7);
+    slr    ($s3,$t1);
+    nr     ($s3,$mask1b);
+    sllg   ($t1,$s2,1);
+    nr     ($t1,$maskfe);
+    xr     ($s3,$t1);        # tp8
+
+    xr     ($s1,$s0);        # tp2^tp1
+    xr     ($s2,$s0);        # tp4^tp1
+    rll    ($s0,$s0,24);    # = ROTATE(tp1,8)
+    xr     ($s2,$s3);        # ^=tp8
+    xr     ($s0,$s1);        # ^=tp2^tp1
+    xr     ($s1,$s3);        # tp2^tp1^tp8
+    xr     ($s0,$s2);        # ^=tp4^tp1^tp8
+    rll    ($s1,$s1,8);
+    rll    ($s2,$s2,16);
+    xr     ($s0,$s1);        # ^= ROTATE(tp8^tp2^tp1,24)
+    rll    ($s3,$s3,24);
+    xr     ($s0,$s2);        # ^= ROTATE(tp8^tp4^tp1,16)
+    xr     ($s0,$s3);        # ^= ROTATE(tp8,8)
+
+    st     ($s0,"16($key)");
+    la     ($key,"4($key)");
+    brct   ($rounds,LABEL("Lmix"));
+
+&{$z? \&lmg:\&lm} ("%r6","%r13","6*$SIZE_T($sp)") if ($flavour =~ /linux/); # as was saved by AES_set_encrypt_key!
+    lghi   ($rv,0);
+    BR_EXIT();
+FUNCTION_END("AES_set_decrypt_key",$rv);
+
+}

 ########################################################################
 # void AES_cbc_encrypt(const unsigned char *in, unsigned char *out,
 #                     size_t length, const AES_KEY *key,
 #                     unsigned char *ivec, const int enc)
 {
-my $inp="%r2";
-my $out="%r4";	# length and out are swapped
-my $len="%r3";
-my $key="%r5";
-my $ivp="%r6";
-
-$code.=<<___;
-.globl	AES_cbc_encrypt
-.type	AES_cbc_encrypt,\@function
-.align	16
-AES_cbc_encrypt:
-	xgr	%r3,%r4		# flip %r3 and %r4, out and len
-	xgr	%r4,%r3
-	xgr	%r3,%r4
-___
-$code.=<<___ if (!$softonly);
-	lhi	%r0,16
-	cl	%r0,240($key)
-	jh	.Lcbc_software
-
-	lg	%r0,0($ivp)	# copy ivec
-	lg	%r1,8($ivp)
-	stmg	%r0,%r1,16($sp)
-	lmg	%r0,%r1,0($key)	# copy key, cover 256 bit
-	stmg	%r0,%r1,32($sp)
-	lmg	%r0,%r1,16($key)
-	stmg	%r0,%r1,48($sp)
-	l	%r0,240($key)	# load kmc code
-	lghi	$key,15		# res=len%16, len-=res;
-	ngr	$key,$len
-	sl${g}r	$len,$key
-	la	%r1,16($sp)	# parameter block - ivec || key
-	jz	.Lkmc_truncated
-	.long	0xb92f0042	# kmc %r4,%r2
-	brc	1,.-4		# pay attention to "partial completion"
-	ltr	$key,$key
-	jnz	.Lkmc_truncated
-.Lkmc_done:
-	lmg	%r0,%r1,16($sp)	# copy ivec to caller
-	stg	%r0,0($ivp)
-	stg	%r1,8($ivp)
-	br	$ra
-.align	16
-.Lkmc_truncated:
-	ahi	$key,-1		# it's the way it's encoded in mvc
-	tmll	%r0,S390X_DECRYPT
-	jnz	.Lkmc_truncated_dec
-	lghi	%r1,0
-	stg	%r1,16*$SIZE_T($sp)
-	stg	%r1,16*$SIZE_T+8($sp)
-	bras	%r1,1f
-	mvc	16*$SIZE_T(1,$sp),0($inp)
-1:	ex	$key,0(%r1)
-	la	%r1,16($sp)	# restore parameter block
-	la	$inp,16*$SIZE_T($sp)
-	lghi	$len,16
-	.long	0xb92f0042	# kmc %r4,%r2
-	j	.Lkmc_done
-.align	16
-.Lkmc_truncated_dec:
-	st${g}	$out,4*$SIZE_T($sp)
-	la	$out,16*$SIZE_T($sp)
-	lghi	$len,16
-	.long	0xb92f0042	# kmc %r4,%r2
-	l${g}	$out,4*$SIZE_T($sp)
-	bras	%r1,2f
-	mvc	0(1,$out),16*$SIZE_T($sp)
-2:	ex	$key,0(%r1)
-	j	.Lkmc_done
-.align	16
-.Lcbc_software:
-___
-$code.=<<___;
-	stm${g}	$key,$ra,5*$SIZE_T($sp)
-	lhi	%r0,0
-	cl	%r0,`$stdframe+$SIZE_T-4`($sp)
-	je	.Lcbc_decrypt
-
-	larl	$tbl,AES_Te
-
-	llgf	$s0,0($ivp)
-	llgf	$s1,4($ivp)
-	llgf	$s2,8($ivp)
-	llgf	$s3,12($ivp)
-
-	lghi	$t0,16
-	sl${g}r	$len,$t0
-	brc	4,.Lcbc_enc_tail	# if borrow
-.Lcbc_enc_loop:
-	stm${g}	$inp,$out,2*$SIZE_T($sp)
-	x	$s0,0($inp)
-	x	$s1,4($inp)
-	x	$s2,8($inp)
-	x	$s3,12($inp)
-	lgr	%r4,$key
-
-	bras	$ra,_s390x_AES_encrypt
-
-	lm${g}	$inp,$key,2*$SIZE_T($sp)
-	st	$s0,0($out)
-	st	$s1,4($out)
-	st	$s2,8($out)
-	st	$s3,12($out)
-
-	la	$inp,16($inp)
-	la	$out,16($out)
-	lghi	$t0,16
-	lt${g}r	$len,$len
-	jz	.Lcbc_enc_done
-	sl${g}r	$len,$t0
-	brc	4,.Lcbc_enc_tail	# if borrow
-	j	.Lcbc_enc_loop
-.align	16
-.Lcbc_enc_done:
-	l${g}	$ivp,6*$SIZE_T($sp)
-	st	$s0,0($ivp)
-	st	$s1,4($ivp)
-	st	$s2,8($ivp)
-	st	$s3,12($ivp)
-
-	lm${g}	%r7,$ra,7*$SIZE_T($sp)
-	br	$ra
-
-.align	16
-.Lcbc_enc_tail:
-	aghi	$len,15
-	lghi	$t0,0
-	stg	$t0,16*$SIZE_T($sp)
-	stg	$t0,16*$SIZE_T+8($sp)
-	bras	$t1,3f
-	mvc	16*$SIZE_T(1,$sp),0($inp)
-3:	ex	$len,0($t1)
-	lghi	$len,0
-	la	$inp,16*$SIZE_T($sp)
-	j	.Lcbc_enc_loop
-
-.align	16
-.Lcbc_decrypt:
-	larl	$tbl,AES_Td
-
-	lg	$t0,0($ivp)
-	lg	$t1,8($ivp)
-	stmg	$t0,$t1,16*$SIZE_T($sp)
-
-.Lcbc_dec_loop:
-	stm${g}	$inp,$out,2*$SIZE_T($sp)
-	llgf	$s0,0($inp)
-	llgf	$s1,4($inp)
-	llgf	$s2,8($inp)
-	llgf	$s3,12($inp)
-	lgr	%r4,$key
-
-	bras	$ra,_s390x_AES_decrypt
-
-	lm${g}	$inp,$key,2*$SIZE_T($sp)
-	sllg	$s0,$s0,32
-	sllg	$s2,$s2,32
-	lr	$s0,$s1
-	lr	$s2,$s3
-
-	lg	$t0,0($inp)
-	lg	$t1,8($inp)
-	xg	$s0,16*$SIZE_T($sp)
-	xg	$s2,16*$SIZE_T+8($sp)
-	lghi	$s1,16
-	sl${g}r	$len,$s1
-	brc	4,.Lcbc_dec_tail	# if borrow
-	brc	2,.Lcbc_dec_done	# if zero
-	stg	$s0,0($out)
-	stg	$s2,8($out)
-	stmg	$t0,$t1,16*$SIZE_T($sp)
-
-	la	$inp,16($inp)
-	la	$out,16($out)
-	j	.Lcbc_dec_loop
-
-.Lcbc_dec_done:
-	stg	$s0,0($out)
-	stg	$s2,8($out)
-.Lcbc_dec_exit:
-	lm${g}	%r6,$ra,6*$SIZE_T($sp)
-	stmg	$t0,$t1,0($ivp)
-
-	br	$ra
-
-.align	16
-.Lcbc_dec_tail:
-	aghi	$len,15
-	stg	$s0,16*$SIZE_T($sp)
-	stg	$s2,16*$SIZE_T+8($sp)
-	bras	$s1,4f
-	mvc	0(1,$out),16*$SIZE_T($sp)
-4:	ex	$len,0($s1)
-	j	.Lcbc_dec_exit
-.size	AES_cbc_encrypt,.-AES_cbc_encrypt
-___
+my ($inp,$outp,$len,$key,$ivp);
+my ($AESE_key);
+
+if ($flavour =~ /linux/) {
+# upon entry $in is in r2, $out is in r3, $len is in r4, $key is in $r5 and $ivp is in r6
+# Before km c, $in needs to be in r8, $out can stay in r2 and $len can stay in r3
+    $inp="%r2";
+    $outp="%r4";    # length and out are swapped
+    $len="%r3";
+    $key="%r5";
+    $ivp="%r6";
+    $AESE_key="%r4";
+} else {
+# upon entry $in is in r1, $out is in r2, $len is in r3, $key and $ivp are in DSA
+# Before km c, $in needs to be in r8, $out can stay in r2 and $len can stay in r3
+    $inp="R1";
+    $outp="R2";
+    $len="R3";
+    $key="R5"; # in DSA - may need to move to a different reg as r5 contains environment,
+               # which is necessary to call other functions.
+    $ivp="R6"; # in DSA
+    $AESE_key="R3";
+}
+
+
+
+FUNCTION_BEGIN("AES_cbc_encrypt",6,"true","","true");
+if ($flavour =~ /linux/) {
+    xgr    ("%r3","%r4");        # flip %r3 and %r4, out and len
+    xgr    ("%r4","%r3");
+    xgr    ("%r3","%r4");
+} else {
+    lgr    ("R14",$outp);
+    lgr    ("R2",$inp);
+    $inp="R2";
+    $outp="R14";
+}
+
+if ($flavour !~ /linux/) {
+    lay    ($sp,"STACK"); # Set up stack for z/os
+    # Need to get ivp and key out of DSA
+  &{$z? \&lg:\&l} ("R9","$DSA_OFF(r4)");      # Get DSA address
+  &{$z? \&lg:\&l}    ($key,"$PARMS_OFF+$SIZE_T*3(r9)"); # Get key address
+  &{$z? \&lg:\&l}    ($ivp,"$PARMS_OFF+$SIZE_T*4(r9)"); # Get ivp
+}
+    lhi    ($wr0,16);
+    cl     ($wr0,"240($key)");
+    jh     (LABEL("Lcbc_software"));
+
+    lg     ($wr0,"0($ivp)");    # copy ivec
+    lg     ($wr1,"8($ivp)");
+    stmg   ($wr0,$wr1,"16($sp)");
+    lmg    ($wr0,$wr1,"0($key)");    # copy key, cover 256 bit
+    stmg   ($wr0,$wr1,"32($sp)");
+    lmg    ($wr0,$wr1,"16($key)");
+    stmg   ($wr0,$wr1,"48($sp)");
+    llgf   ($wr0,"240($key)");    # load kmc code
+    lghi   ($key,15);        # res=len%16, len-=res;
+    ngr    ($key,$len);
+&{$z? \&slgr:\&slr}  ($len,$key);
+    la     ($wr1,"16($sp)");    # parameter block - ivec || key
+    jz     (LABEL("Lkmc_truncated"));
+    kmc    ($outp,$inp);
+    brc    (1,"$ip-4");        # pay attention to "partial completion"
+    ltr    ($key,$key);
+    jnz    (LABEL("Lkmc_truncated"));
+LABEL("Lkmc_done:");
+    lmg    ($wr0,$wr1,"16($sp)");    # copy ivec to caller
+    stg    ($wr0,"0($ivp)");
+    stg    ($wr1,"8($ivp)");
+    BR_EXIT();
+ALIGN(16);
+LABEL("Lkmc_truncated:");
+    ahi    ($key,-1);        # it's the way it's encoded in mvc
+    tmll   ($wr0,"CS390X_DECRYPT");
+    jnz    (LABEL("Lkmc_truncated_dec"));
+    lghi   ($wr1,0);
+    stg    ($wr1,"16*$SIZE_T($sp)");
+    stg    ($wr1,"16*$SIZE_T+8($sp)");
+    bras   ($wr1,LABEL("AESCE1"));
+    mvc    ("16*$SIZE_T(1,$sp)","0($inp)");
+LABEL("AESCE1:");
+    ex     ($key,"0($wr1)");
+    la     ($wr1,"16($sp)");    # restore parameter block
+    la     ($inp,"16*$SIZE_T($sp)");
+    lghi   ($len,16);
+    kmc    ($outp,$inp);
+    j      (LABEL("Lkmc_done"));
+ALIGN(16);
+LABEL("Lkmc_truncated_dec:");
+&{$z? \&stg:\&st} ($outp,"4*$SIZE_T($sp)");
+    la     ($outp,"16*$SIZE_T($sp)");
+    lghi   ($len,16);
+    kmc    ($outp,$inp);
+&{$z? \&lg:\&l} ($outp,"4*$SIZE_T($sp)");
+    bras   ($wr1,LABEL("AESCE2"));
+    mvc    ("0(1,$outp)","16*$SIZE_T($sp)");
+LABEL("AESCE2:");
+    ex     ($key,"0($wr1)");
+    j      (LABEL("Lkmc_done"));
+ALIGN(16);
+LABEL("Lcbc_software:");
+
+&{$z? \&stmg:\&stm}  ($key,$ra,"5*$SIZE_T($sp)"); # this is 5-7 on z/OS or 5-14 on linux
+    xgr    ($wr0,$wr0);
+
+if ($flavour =~ /linux/) {
+    cl     ($wr0,"$stdframe+$SIZE_T-4($sp)");    # Check ENC parm
+} else {
+&{$z? \&clg:\&cl} ($wr0,"$PARMS_OFF+$SIZE_T*5(r9)");    # Check ENC parm
+}
+    je     (LABEL("Lcbc_decrypt"));
+
+    larl   ($tbl,LABEL("AES_Te"));
+
+    llgf   ($s0,"0($ivp)");
+    llgf   ($s1,"4($ivp)");
+    llgf   ($s2,"8($ivp)");
+    llgf   ($s3,"12($ivp)");
+
+    lghi   ($t0,16);
+&{$z? \&slgr:\&slr} ($len,$t0);
+    brc    (4,LABEL("Lcbc_enc_tail"));    # if borrow
+LABEL("Lcbc_enc_loop:");
+if ($flavour =~ /linux/) {
+  &{$z? \&stmg:\&stm}  ($inp,$outp,"2*$SIZE_T($sp)");      # this is 2->4
+} else {
+  &{$z? \&stmg:\&stm}  ($inp,$ra,"2*$SIZE_T($sp)");        # this is 2->7
+  &{$z? \&stmg:\&stm}  ("R12",$outp,"12*$SIZE_T($sp)");    # this is 12->14
+}
+    x      ($s0,"0($inp)");
+    x      ($s1,"4($inp)");
+    x      ($s2,"8($inp)");
+    x      ($s3,"12($inp)");
+    lgr    ($AESE_key,$key);
+if ($flavour !~ /linux/) {
+    lgr    ("R1",$inp);
+    lgr    ("R2",$outp);
+}
+    bras   ($ra,"_s390x_AES_encrypt");
+
+if ($flavour =~ /linux/) {
+  &{$z? \&lmg:\&lm} ($inp,$key,"2*$SIZE_T($sp)");         # this is 2->5
+} else {
+  &{$z? \&lmg:\&lm} ($inp,$ra,"2*$SIZE_T($sp)");          # this is 2->7
+  &{$z? \&lmg:\&lm} ("R12",$outp,"12*$SIZE_T($sp)");      # this is 12->14
+}
+    st     ($s0,"0($outp)");
+    st     ($s1,"4($outp)");
+    st     ($s2,"8($outp)");
+    st     ($s3,"12($outp)");
+
+    la     ($inp,"16($inp)");
+    la     ($outp,"16($outp)");
+    lghi   ($t0,16);
+&{$z? \&ltgr:\&ltr} ($len,$len);
+    jz     (LABEL("Lcbc_enc_done"));
+&{$z? \&slgr:\&slr} ($len,$t0);
+    brc    (4,LABEL("Lcbc_enc_tail"));    # if borrow
+    j      (LABEL("Lcbc_enc_loop"));
+ALIGN(16);
+LABEL("Lcbc_enc_done:");
+&{$z? \&lg:\&l} ($ivp,"6*$SIZE_T($sp)");
+    st     ($s0,"0($ivp)");
+    st     ($s1,"4($ivp)");
+    st     ($s2,"8($ivp)");
+    st     ($s3,"12($ivp)");
+
+&{$z? \&lmg:\&lm} ("%r7",$ra,"7*$SIZE_T($sp)") if ($flavour =~ /linux/);
+    BR_EXIT();
+
+ALIGN(16);
+LABEL("Lcbc_enc_tail:");
+    aghi   ($len,15);
+    lghi   ($t0,0);
+    stg    ($t0,"16*$SIZE_T($sp)");
+    stg    ($t0,"16*$SIZE_T+8($sp)");
+    bras   ($t1,LABEL("AESCE3"));
+    mvc    ("16*$SIZE_T(1,$sp)","0($inp)");
+LABEL("AESCE3:");
+    ex     ($len,"0($t1)");
+    lghi   ($len,0);
+    la     ($inp,"16*$SIZE_T($sp)");
+    j      (LABEL("Lcbc_enc_loop"));
+
+ALIGN(    16);
+LABEL("Lcbc_decrypt:");
+    larl   ($tbl,LABEL("AES_Td"));
+
+    lg     ($t0,"0($ivp)");
+    lg     ($t1,"8($ivp)");
+    stmg   ($t0,$t1,"16*$SIZE_T($sp)");
+
+LABEL("Lcbc_dec_loop:");
+if ($flavour =~ /linux/) {
+  &{$z? \&stmg:\&stm}  ($inp,$outp,"2*$SIZE_T($sp)");      # this is 2->4
+} else {
+  &{$z? \&stmg:\&stm}  ($inp,$ra,"2*$SIZE_T($sp)");       # this is 2->7
+  &{$z? \&stmg:\&stm}  ("R12",$outp,"12*$SIZE_T($sp)");   # this is 12->14
+}
+    llgf   ($s0,"0($inp)");
+    llgf   ($s1,"4($inp)");
+    llgf   ($s2,"8($inp)");
+    llgf   ($s3,"12($inp)");
+if ($flavour !~ /linux/) {
+    lgr    ("R1",$inp);
+    lgr    ("R2",$outp);
+}
+    lgr    ($AESE_key,$key);
+
+    bras   ($ra,"_s390x_AES_decrypt");
+if ($flavour =~ /linux/) {
+  &{$z? \&lmg:\&lm} ($inp,$key,"2*$SIZE_T($sp)");         # this is 2->5
+} else {
+  &{$z? \&lmg:\&lm} ($inp,$ra,"2*$SIZE_T($sp)");          # this is 2->7
+  &{$z? \&lmg:\&lm} ("R12",$outp,"12*$SIZE_T($sp)");      # this is 12->14
+}
+    sllg   ($s0,$s0,32);
+    sllg   ($s2,$s2,32);
+    lr     ($s0,$s1);
+    lr     ($s2,$s3);
+
+    lg     ($t0,"0($inp)");
+    lg     ($t1,"8($inp)");
+    xg     ($s0,"16*$SIZE_T($sp)");
+    xg     ($s2,"16*$SIZE_T+8($sp)");
+    lghi   ($s1,16);
+&{$z? \&slgr:\&slr} ($len,$s1);
+    brc    (4,LABEL("Lcbc_dec_tail"));    # if borrow
+    brc    (2,LABEL("Lcbc_dec_done"));    # if zero
+    stg    ($s0,"0($outp)");
+    stg    ($s2,"8($outp)");
+    stmg   ($t0,$t1,"16*$SIZE_T($sp)");
+
+    la     ($inp,"16($inp)");
+    la     ($outp,"16($outp)");
+    j      (LABEL("Lcbc_dec_loop"));
+
+LABEL("Lcbc_dec_done:");
+    stg    ($s0,"0($outp)");
+    stg    ($s2,"8($outp)");
+LABEL("Lcbc_dec_exit:");
+&{$z? \&lmg:\&lm} ("%r6",$ra,"6*$SIZE_T($sp)") if ($flavour =~ /linux/);
+    stmg   ($t0,$t1,"0($ivp)");
+
+    BR_EXIT();
+
+ALIGN(16);
+LABEL("Lcbc_dec_tail:");
+    aghi   ($len,15);
+    stg    ($s0,"16*$SIZE_T($sp)");
+    stg    ($s2,"16*$SIZE_T+8($sp)");
+    bras   ($s1,LABEL("AESCE4"));
+    mvc    ("0(1,$outp)","16*$SIZE_T($sp)");
+LABEL("AESCE4:");
+    ex     ($len,"0($s1)");
+    j      (LABEL("Lcbc_dec_exit"));
+
+FUNCTION_END("AES_cbc_encrypt",$rv);
 }
 ########################################################################
 # void AES_ctr32_encrypt(const unsigned char *in, unsigned char *out,
 #                     size_t blocks, const AES_KEY *key,
 #                     const unsigned char *ivec)
 {
-my $inp="%r2";
-my $out="%r4";	# blocks and out are swapped
-my $len="%r3";
-my $key="%r5";	my $iv0="%r5";
-my $ivp="%r6";
-my $fp ="%r7";
-
-$code.=<<___;
-.globl	AES_ctr32_encrypt
-.type	AES_ctr32_encrypt,\@function
-.align	16
-AES_ctr32_encrypt:
-	xgr	%r3,%r4		# flip %r3 and %r4, $out and $len
-	xgr	%r4,%r3
-	xgr	%r3,%r4
-	llgfr	$len,$len	# safe in ctr32 subroutine even in 64-bit case
-___
-$code.=<<___ if (!$softonly);
-	l	%r0,240($key)
-	lhi	%r1,16
-	clr	%r0,%r1
-	jl	.Lctr32_software
-
-	st${g}	$s2,10*$SIZE_T($sp)
-	st${g}	$s3,11*$SIZE_T($sp)
-
-	clr	$len,%r1		# does work even in 64-bit mode
-	jle	.Lctr32_nokma		# kma is slower for <= 16 blocks
-
-	larl	%r1,OPENSSL_s390xcap_P
-	lr	$s2,%r0
-	llihh	$s3,0x8000
-	srlg	$s3,$s3,0($s2)
-	ng	$s3,S390X_KMA(%r1)		# check kma capability vector
-	jz	.Lctr32_nokma
-
-	l${g}hi	%r1,-$stdframe-112
-	l${g}r	$s3,$sp
-	la	$sp,0(%r1,$sp)			# prepare parameter block
-
-	lhi	%r1,0x0600
-	sllg	$len,$len,4
-	or	%r0,%r1				# set HS and LAAD flags
-
-	st${g}	$s3,0($sp)			# backchain
-	la	%r1,$stdframe($sp)
-
-	lmg	$s2,$s3,0($key)			# copy key
-	stg	$s2,$stdframe+80($sp)
-	stg	$s3,$stdframe+88($sp)
-	lmg	$s2,$s3,16($key)
-	stg	$s2,$stdframe+96($sp)
-	stg	$s3,$stdframe+104($sp)
-
-	lmg	$s2,$s3,0($ivp)			# copy iv
-	stg	$s2,$stdframe+64($sp)
-	ahi	$s3,-1				# kma requires counter-1
-	stg	$s3,$stdframe+72($sp)
-	st	$s3,$stdframe+12($sp)		# copy counter
-
-	lghi	$s2,0				# no AAD
-	lghi	$s3,0
-
-	.long	0xb929a042	# kma $out,$s2,$inp
-	brc	1,.-4		# pay attention to "partial completion"
-
-	stg	%r0,$stdframe+80($sp)		# wipe key
-	stg	%r0,$stdframe+88($sp)
-	stg	%r0,$stdframe+96($sp)
-	stg	%r0,$stdframe+104($sp)
-	la	$sp,$stdframe+112($sp)
-
-	lm${g}	$s2,$s3,10*$SIZE_T($sp)
-	br	$ra
-
-.align	16
-.Lctr32_nokma:
-	stm${g}	%r6,$s1,6*$SIZE_T($sp)
-
-	slgr	$out,$inp
-	la	%r1,0($key)	# %r1 is permanent copy of $key
-	lg	$iv0,0($ivp)	# load ivec
-	lg	$ivp,8($ivp)
-
-	# prepare and allocate stack frame at the top of 4K page
-	# with 1K reserved for eventual signal handling
-	lghi	$s0,-1024-256-16# guarantee at least 256-bytes buffer
-	lghi	$s1,-4096
-	algr	$s0,$sp
-	lgr	$fp,$sp
-	ngr	$s0,$s1		# align at page boundary
-	slgr	$fp,$s0		# total buffer size
-	lgr	$s2,$sp
-	lghi	$s1,1024+16	# sl[g]fi is extended-immediate facility
-	slgr	$fp,$s1		# deduct reservation to get usable buffer size
-	# buffer size is at lest 256 and at most 3072+256-16
-
-	la	$sp,1024($s0)	# alloca
-	srlg	$fp,$fp,4	# convert bytes to blocks, minimum 16
-	st${g}	$s2,0($sp)	# back-chain
-	st${g}	$fp,$SIZE_T($sp)
-
-	slgr	$len,$fp
-	brc	1,.Lctr32_hw_switch	# not zero, no borrow
-	algr	$fp,$len	# input is shorter than allocated buffer
-	lghi	$len,0
-	st${g}	$fp,$SIZE_T($sp)
-
-.Lctr32_hw_switch:
-___
-$code.=<<___ if (!$softonly && 0);# kmctr code was measured to be ~12% slower
-	llgfr	$s0,%r0
-	lgr	$s1,%r1
-	larl	%r1,OPENSSL_s390xcap_P
-	llihh	%r0,0x8000	# check if kmctr supports the function code
-	srlg	%r0,%r0,0($s0)
-	ng	%r0,S390X_KMCTR(%r1)	# check kmctr capability vector
-	lgr	%r0,$s0
-	lgr	%r1,$s1
-	jz	.Lctr32_km_loop
+my ($inp,$outp,$len,$key,$iv0,$ivp,$fp);
+my ($AESE_key,$xcap);
+
+if ($flavour =~ /linux/) {
+# upon entry $in is in r2, $out is in r3, $blocks is in r4, $key is in $r5 and $ivec is in r6
+# Before kma, $in needs to be in r8, $out can stay in r2 and $len can stay in r3
+    $inp="%r2";
+    $outp="%r4";    # blocks and out are swapped
+    $len="%r3";
+    $key="%r5";    $iv0="%r5";
+    $ivp="%r6";
+    $fp ="%r7";
+    $AESE_key="%r4";
+} else {
+# upon entry $in is in r1, $outp is in r2, $blocks is in r3, $key and $ivec are in DSA
+# Before kma, $in needs to be in r8, $outp can stay in r2 and $len can stay in r3
+    $inp="R1";
+    $outp="R2";
+    $len="R3";
+    $key="R5"; # in DSA
+    $iv0="R5";
+    $ivp="R6"; # in DSA
+    $fp ="R7";
+    $xcap="R13";
+    $AESE_key="R3";
+}
+
+
+FUNCTION_BEGIN("AES_ctr32_encrypt",5,"true","stor3","true");
+if ($flavour =~ /linux/) {
+    xgr     ("%r3","%r4");                # flip %r3 and %r4, $outp and $len
+    xgr     ("%r4","%r3");
+    xgr     ("%r3","%r4");
+} else {
+    lgr    ("R14",$outp);
+    lgr    ("R2",$inp);
+    $inp="R2";
+    $outp="R14";
+}
+    llgfr   ($len,$len);                  # safe in ctr32 subroutine even in 64-bit case
+
+
+if (!$softonly) {
+
+# - need to get key out of dsa, which will corrupt the environment reg (r5), which will prevent us from getting OPENSSL_s390xcap_P, so get OPENSSL_s390xcap_P first.
+if ($flavour !~ /linux/) {
+    GET_EXTERN($xcap,"OPENSSL_s390xcap_P"); # get ptr to OPENSSL_s390xcap_P before r5 is corrupted
+    lay    ($sp,"STACK");                 # Set up stack for z/os
+    # Need to get ivp and key out of DSA
+  &{$z? \&lg:\&l} ("R9","$DSA_OFF(r4)");  # Get DSA address
+  &{$z? \&lg:\&l} ($key,"$PARMS_OFF+$SIZE_T*3(r9)"); # Get key address
+  &{$z? \&lg:\&l} ($ivp,"$PARMS_OFF+$SIZE_T*4(r9)"); # Get ivp
+}
+    l       ($wr0,"240($key)");
+    lhi     ($wr1,16);
+    clr     ($wr0,$wr1);
+    jl      (LABEL("Lctr32_software"));
+
+&{$z? \&stg:\&st} ($s2,"10*$SIZE_T($sp)");
+&{$z? \&stg:\&st} ($s3,"11*$SIZE_T($sp)");
+
+    clr     ($len,$wr1);                  # does work even in 64-bit mode
+    jle     (LABEL("Lctr32_nokma"));      # kma is slower for <= 16 blocks
+
+if ($flavour =~ /linux/) {
+    larl    ($wr1,"OPENSSL_s390xcap_P");
+} else {
+    lgr     ($wr1,$xcap);
+}
+    lr      ($s2,$wr0);
+    llihh   ($s3,"0x8000");
+    srlg    ($s3,$s3,"0($s2)");
+    ng      ($s3,"CS390X_KMA($wr1)");      # check kma capability vector
+    jz      (LABEL("Lctr32_nokma"));
+
+    &{$z? \&lghi:\&lhi} ($wr1,"-$stdframe-112");
+    &{$z? \&lgr:\&lr} ($s3,$sp);
+    la      ($sp,"0($wr1,$sp)");          # prepare parameter block
+
+    lhi     ($wr1,"0x0600");
+    sllg    ($len,$len,4);
+    &or     ($wr0,$wr1);                  # set HS and LAAD flags
+
+&{$z? \&stg:\&st} ($s3,"0($sp)");         # backchain
+    la      ($wr1,"$stdframe($sp)");
+
+    lmg     ($s2,$s3,"0($key)");          # copy key
+    stg     ($s2,"$stdframe+80($sp)");
+    stg     ($s3,"$stdframe+88($sp)");
+    lmg     ($s2,$s3,"16($key)");
+    stg     ($s2,"$stdframe+96($sp)");
+    stg     ($s3,"$stdframe+104($sp)");
+
+    lmg     ($s2,$s3,"0($ivp)");          # copy iv
+    stg     ($s2,"$stdframe+64($sp)");
+    ahi     ($s3,-1);                     # kma requires counter-1
+    stg     ($s3,"$stdframe+72($sp)");
+    st      ($s3,"$stdframe+12($sp)");    # copy counter
+
+    lghi    ($s2,0);                      # no AAD
+    lghi    ($s3,0);
+# kma needs $inp to be an even reg, $inp+1 is required, $s2 must be even, $s2+1 is required, outp must be even but no +1 reg required
+    kma     ($outp,$s2,$inp);             # long    0xb929a042    # kma     ("%r14","%r10","%r2");             # long    0xb929a042
+    brc     (1,"$ip-4");                  # pay attention to "partial completion"
+
+    stg     ($wr0,"$stdframe+80($sp)");   # wipe key
+    stg     ($wr0,"$stdframe+88($sp)");
+    stg     ($wr0,"$stdframe+96($sp)");
+    stg     ($wr0,"$stdframe+104($sp)");
+    la      ($sp,"$stdframe+112($sp)") if ($flavour =~ /linux/);
+
+&{$z? \&lmg:\&lm} ($s2,$s3,"10*$SIZE_T($sp)") if ($flavour =~ /linux/);
+    BR_EXIT();
+
+ALIGN(16);
+LABEL("Lctr32_nokma:");
+&{$z? \&stmg:\&stm} ($ivp,$s1,"6*$SIZE_T($sp)");
+
+    slgr    ($outp,$inp);
+    la      ($wr1,"0($key)");             # $wr1 is permanent copy of $key
+    lg      ($iv0,"0($ivp)");             # load ivec
+    lg      ($ivp,"8($ivp)");
+
+    # prepare and allocate stack frame at the top of 4K page
+    # with 1K reserved for eventual signal handling
+    lghi    ($s0,"-1024-256-16");         # guarantee at least 256-bytes buffer
+    lghi    ($s1,-4096);
+    algr    ($s0,$sp);
+    lgr     ($fp,$sp);
+    ngr     ($s0,$s1);                    # align at page boundary
+    slgr    ($fp,$s0);                    # total buffer size
+    lgr     ($s2,$sp);
+    lghi    ($s1,"1024+16");              # sl[g]fi is extended-immediate facility
+    slgr    ($fp,$s1);                    # deduct reservation to get usable buffer size
+    # buffer size is at lest 256 and at most 3072+256-16
+
+    la      ($sp,"1024($s0)");            # alloca
+    srlg    ($fp,$fp,4);                  # convert bytes to blocks, minimum 16
+&{$z? \&stg:\&st} ($s2,"0($sp)");         # back-chain
+&{$z? \&stg:\&st} ($fp,"$SIZE_T($sp)");
+
+    slgr    ($len,$fp);
+    brc     (1,LABEL("Lctr32_hw_switch")); # not zero, no borrow
+    algr    ($fp,$len);                   # input is shorter than allocated buffer
+    lghi    ($len,0);
+&{$z? \&stg:\&st} ($fp,"$SIZE_T($sp)");
+
+LABEL("Lctr32_hw_switch:");
+}
+
+
+
+if (!$softonly && 0) {                    # kmctr code was measured to be ~12% slower (This is now dead code)
+    llgfr   ($s0,$wr0);
+    lgr     ($s1,$wr1);
+if ($flavour =~ /linux/) {
+    larl    ($wr1,"OPENSSL_s390xcap_P");  # this might not work as r5 has been corrupted before getting here
+} else {
+    lgr     ($wr1,$xcap);
+}
+    llihh   ($wr0,"0x8000");              # check if kmctr supports the function code
+    srlg    ($wr0,$wr0,"0($s0)");
+    ng      ($wr0,"CS390X_KMCTR($wr1)");   # check kmctr capability vector
+    lgr     ($wr0,$s0);
+    lgr     ($wr1,$s1);
+    jz      (LABEL("Lctr32_km_loop"));

 ####### kmctr code
-	algr	$out,$inp	# restore $out
-	lgr	$s1,$len	# $s1 undertakes $len
-	j	.Lctr32_kmctr_loop
-.align	16
-.Lctr32_kmctr_loop:
-	la	$s2,16($sp)
-	lgr	$s3,$fp
-.Lctr32_kmctr_prepare:
-	stg	$iv0,0($s2)
-	stg	$ivp,8($s2)
-	la	$s2,16($s2)
-	ahi	$ivp,1		# 32-bit increment, preserves upper half
-	brct	$s3,.Lctr32_kmctr_prepare
-
-	#la	$inp,0($inp)	# inp
-	sllg	$len,$fp,4	# len
-	#la	$out,0($out)	# out
-	la	$s2,16($sp)	# iv
-	.long	0xb92da042	# kmctr $out,$s2,$inp
-	brc	1,.-4		# pay attention to "partial completion"
-
-	slgr	$s1,$fp
-	brc	1,.Lctr32_kmctr_loop	# not zero, no borrow
-	algr	$fp,$s1
-	lghi	$s1,0
-	brc	4+1,.Lctr32_kmctr_loop	# not zero
-
-	l${g}	$sp,0($sp)
-	lm${g}	%r6,$s3,6*$SIZE_T($sp)
-	br	$ra
-.align	16
-___
-$code.=<<___ if (!$softonly);
-.Lctr32_km_loop:
-	la	$s2,16($sp)
-	lgr	$s3,$fp
-.Lctr32_km_prepare:
-	stg	$iv0,0($s2)
-	stg	$ivp,8($s2)
-	la	$s2,16($s2)
-	ahi	$ivp,1		# 32-bit increment, preserves upper half
-	brct	$s3,.Lctr32_km_prepare
-
-	la	$s0,16($sp)	# inp
-	sllg	$s1,$fp,4	# len
-	la	$s2,16($sp)	# out
-	.long	0xb92e00a8	# km %r10,%r8
-	brc	1,.-4		# pay attention to "partial completion"
-
-	la	$s2,16($sp)
-	lgr	$s3,$fp
-	slgr	$s2,$inp
-.Lctr32_km_xor:
-	lg	$s0,0($inp)
-	lg	$s1,8($inp)
-	xg	$s0,0($s2,$inp)
-	xg	$s1,8($s2,$inp)
-	stg	$s0,0($out,$inp)
-	stg	$s1,8($out,$inp)
-	la	$inp,16($inp)
-	brct	$s3,.Lctr32_km_xor
-
-	slgr	$len,$fp
-	brc	1,.Lctr32_km_loop	# not zero, no borrow
-	algr	$fp,$len
-	lghi	$len,0
-	brc	4+1,.Lctr32_km_loop	# not zero
-
-	l${g}	$s0,0($sp)
-	l${g}	$s1,$SIZE_T($sp)
-	la	$s2,16($sp)
-.Lctr32_km_zap:
-	stg	$s0,0($s2)
-	stg	$s0,8($s2)
-	la	$s2,16($s2)
-	brct	$s1,.Lctr32_km_zap
-
-	la	$sp,0($s0)
-	lm${g}	%r6,$s3,6*$SIZE_T($sp)
-	br	$ra
-.align	16
-.Lctr32_software:
-___
-$code.=<<___;
-	stm${g}	$key,$ra,5*$SIZE_T($sp)
-	sl${g}r	$inp,$out
-	larl	$tbl,AES_Te
-	llgf	$t1,12($ivp)
-
-.Lctr32_loop:
-	stm${g}	$inp,$out,2*$SIZE_T($sp)
-	llgf	$s0,0($ivp)
-	llgf	$s1,4($ivp)
-	llgf	$s2,8($ivp)
-	lgr	$s3,$t1
-	st	$t1,16*$SIZE_T($sp)
-	lgr	%r4,$key
-
-	bras	$ra,_s390x_AES_encrypt
-
-	lm${g}	$inp,$ivp,2*$SIZE_T($sp)
-	llgf	$t1,16*$SIZE_T($sp)
-	x	$s0,0($inp,$out)
-	x	$s1,4($inp,$out)
-	x	$s2,8($inp,$out)
-	x	$s3,12($inp,$out)
-	stm	$s0,$s3,0($out)
-
-	la	$out,16($out)
-	ahi	$t1,1		# 32-bit increment
-	brct	$len,.Lctr32_loop
-
-	lm${g}	%r6,$ra,6*$SIZE_T($sp)
-	br	$ra
-.size	AES_ctr32_encrypt,.-AES_ctr32_encrypt
-___
+    algr    ($outp,$inp);                 # restore $outp
+    lgr     ($s1,$len);                   # $s1 undertakes $len
+    j       (LABEL("Lctr32_kmctr_loop"));
+ALIGN(16);
+LABEL("Lctr32_kmctr_loop:");
+    la      ($s2,"16($sp)");
+    lgr     ($s3,$fp);
+LABEL("Lctr32_kmctr_prepare:");
+    stg     ($iv0,"0($s2)");
+    stg     ($ivp,"8($s2)");
+    la      ($s2,"16($s2)");
+    ahi     ($ivp,1);                     # 32-bit increment, preserves upper half
+    brct    ($s3,LABEL("Lctr32_kmctr_prepare"));
+
+    #la     ($inp,"0($inp)");             # inp
+    sllg    ($len,$fp,4);                 # len
+    #la     ($outp,"0($outp)");           # out
+    la      ($s2,"16($sp)");              # iv
+    kmctr   ($outp,$s2,$inp);             #  .long    0xb92da042
+    brc     (1,"$ip-4");                  # pay attention to "partial completion"
+
+    slgr    ($s1,$fp);
+    brc     (1,LABEL("Lctr32_kmctr_loop")); # not zero, no borrow
+    algr    ($fp,$s1);
+    lghi    ($s1,0);
+    brc     (4+1,LABEL("Lctr32_kmctr_loop")); # not zero
+
+&{$z? \&lg:\&l} ($sp,"0($sp)");
+&{$z? \&lmg:\&lm} ($ivp,$s3,"6*$SIZE_T($sp)")  if ($flavour =~ /linux/);
+    BR_EXIT();
+ALIGN(16);
+}                                         # (!$softonly && 0) {  # kmctr code was measured to be ~12% slower
+
+if (!$softonly) {
+
+LABEL("Lctr32_km_loop:");
+    la      ($s2,"16($sp)");
+    lgr     ($s3,$fp);
+LABEL("Lctr32_km_prepare:");
+    stg     ($iv0,"0($s2)");
+    stg     ($ivp,"8($s2)");
+    la      ($s2,"16($s2)");
+    ahi     ($ivp,1);                     # 32-bit increment, preserves upper half
+    brct    ($s3,LABEL("Lctr32_km_prepare"));
+
+    la      ($s0,"16($sp)");              # inp
+    sllg    ($s1,$fp,4);                  # len
+    la      ($s2,"16($sp)");              # out
+    km      ($s2,$s0);                    # .long    0xb92e00a8
+    brc     (1,"$ip-4");                  # pay attention to "partial completion"
+
+    la      ($s2,"16($sp)");
+    lgr     ($s3,$fp);
+    slgr    ($s2,$inp);
+LABEL("Lctr32_km_xor:");
+    lg      ($s0,"0($inp)");
+    lg      ($s1,"8($inp)");
+    xg      ($s0,"0($s2,$inp)");
+    xg      ($s1,"8($s2,$inp)");
+    stg     ($s0,"0($outp,$inp)");
+    stg     ($s1,"8($outp,$inp)");
+    la      ($inp,"16($inp)");
+    brct    ($s3,LABEL("Lctr32_km_xor"));
+
+    slgr    ($len,$fp);
+    brc     (1,LABEL("Lctr32_km_loop"));  # not zero, no borrow
+    algr    ($fp,$len);
+    lghi    ($len,0);
+    brc     (4+1,LABEL("Lctr32_km_loop")); # not zero
+
+&{$z? \&lg:\&l} ($s0,"0($sp)");
+&{$z? \&lg:\&l} ($s1,"$SIZE_T($sp)");
+    la      ($s2,"16($sp)");
+LABEL("Lctr32_km_zap:");
+    stg     ($s0,"0($s2)");
+    stg     ($s0,"8($s2)");
+    la      ($s2,"16($s2)");
+    brct    ($s1,LABEL("Lctr32_km_zap"));
+
+    la      ($sp,"0($s0)");
+&{$z? \&lmg:\&lm} ($ivp,$s3,"6*$SIZE_T($sp)") if ($flavour =~ /linux/);
+    BR_EXIT();
+ALIGN(16);
+
+LABEL("Lctr32_software:");
+
+}
+
+&{$z? \&stmg:\&stm} ($key,$ra,"5*$SIZE_T($sp)");
+&{$z? \&slgr:\&slr} ($inp,$outp);
+    larl    ($tbl,LABEL("AES_Te"));
+    llgf    ($t1,"12($ivp)");
+
+LABEL("Lctr32_loop:");
+&{$z? \&stmg:\&stm} ($inp,$outp,"2*$SIZE_T($sp)");
+    llgf    ($s0,"0($ivp)");
+    llgf    ($s1,"4($ivp)");
+    llgf    ($s2,"8($ivp)");
+    lgr     ($s3,$t1);
+    st      ($t1,"16*$SIZE_T($sp)");
+    lgr     ($AESE_key,$key);
+
+    bras    ($ra,"_s390x_AES_encrypt");
+
+if ($flavour =~ /linux/) {
+  &{$z? \&lmg:\&lm} ($inp,$ivp,"2*$SIZE_T($sp)");         # this is 2->65
+} else {
+  &{$z? \&lmg:\&lm} ($inp,$ivp,"2*$SIZE_T($sp)");         # this is 2->6
+  &{$z? \&lmg:\&lm} ("R12",$outp,"12*$SIZE_T($sp)");      # this is 12->14
+}
+    llgf    ($t1,"16*$SIZE_T($sp)");
+    x       ($s0,"0($inp,$outp)");
+    x       ($s1,"4($inp,$outp)");
+    x       ($s2,"8($inp,$outp)");
+    x       ($s3,"12($inp,$outp)");
+    stm     ($s0,$s3,"0($outp)");
+
+    la      ($outp,"16($outp)");
+    ahi     ($t1,1);                      # 32-bit increment
+    brct    ($len,LABEL("Lctr32_loop"));
+
+&{$z? \&lmg:\&lm} ($ivp,$ra,"6*$SIZE_T($sp)") if ($flavour =~ /linux/);
+    BR_EXIT();
+
+FUNCTION_END("AES_ctr32_encrypt",$rv);
 }

 ########################################################################
 # void AES_xts_encrypt(const unsigned char *inp, unsigned char *out,
-#	size_t len, const AES_KEY *key1, const AES_KEY *key2,
-#	const unsigned char iv[16]);
+#    size_t len, const AES_KEY *key1, const AES_KEY *key2,
+#    const unsigned char iv[16]);
 #
 {
-my $inp="%r2";
-my $out="%r4";	# len and out are swapped
-my $len="%r3";
-my $key1="%r5";	# $i1
-my $key2="%r6";	# $i2
-my $fp="%r7";	# $i3
-my $tweak=16*$SIZE_T+16;	# or $stdframe-16, bottom of the frame...
-
-$code.=<<___;
-.type	_s390x_xts_km,\@function
-.align	16
-_s390x_xts_km:
-___
-$code.=<<___ if(1);
-	llgfr	$s0,%r0			# put aside the function code
-	lghi	$s1,0x7f
-	nr	$s1,%r0
-	larl	%r1,OPENSSL_s390xcap_P
-	llihh	%r0,0x8000
-	srlg	%r0,%r0,32($s1)		# check for 32+function code
-	ng	%r0,S390X_KM(%r1)	# check km capability vector
-	lgr	%r0,$s0			# restore the function code
-	la	%r1,0($key1)		# restore $key1
-	jz	.Lxts_km_vanilla
-
-	lmg	$i2,$i3,$tweak($sp)	# put aside the tweak value
-	algr	$out,$inp
-
-	oill	%r0,32			# switch to xts function code
-	aghi	$s1,-18			#
-	sllg	$s1,$s1,3		# (function code - 18)*8, 0 or 16
-	la	%r1,$tweak-16($sp)
-	slgr	%r1,$s1			# parameter block position
-	lmg	$s0,$s3,0($key1)	# load 256 bits of key material,
-	stmg	$s0,$s3,0(%r1)		# and copy it to parameter block.
-					# yes, it contains junk and overlaps
-					# with the tweak in 128-bit case.
-					# it's done to avoid conditional
-					# branch.
-	stmg	$i2,$i3,$tweak($sp)	# "re-seat" the tweak value
-
-	.long	0xb92e0042		# km %r4,%r2
-	brc	1,.-4			# pay attention to "partial completion"
-
-	lrvg	$s0,$tweak+0($sp)	# load the last tweak
-	lrvg	$s1,$tweak+8($sp)
-	stmg	%r0,%r3,$tweak-32($sp)	# wipe copy of the key
-
-	nill	%r0,0xffdf		# switch back to original function code
-	la	%r1,0($key1)		# restore pointer to $key1
-	slgr	$out,$inp
-
-	llgc	$len,2*$SIZE_T-1($sp)
-	nill	$len,0x0f		# $len%=16
-	br	$ra
-
-.align	16
-.Lxts_km_vanilla:
-___
-$code.=<<___;
-	# prepare and allocate stack frame at the top of 4K page
-	# with 1K reserved for eventual signal handling
-	lghi	$s0,-1024-256-16# guarantee at least 256-bytes buffer
-	lghi	$s1,-4096
-	algr	$s0,$sp
-	lgr	$fp,$sp
-	ngr	$s0,$s1		# align at page boundary
-	slgr	$fp,$s0		# total buffer size
-	lgr	$s2,$sp
-	lghi	$s1,1024+16	# sl[g]fi is extended-immediate facility
-	slgr	$fp,$s1		# deduct reservation to get usable buffer size
-	# buffer size is at lest 256 and at most 3072+256-16
-
-	la	$sp,1024($s0)	# alloca
-	nill	$fp,0xfff0	# round to 16*n
-	st${g}	$s2,0($sp)	# back-chain
-	nill	$len,0xfff0	# redundant
-	st${g}	$fp,$SIZE_T($sp)
-
-	slgr	$len,$fp
-	brc	1,.Lxts_km_go	# not zero, no borrow
-	algr	$fp,$len	# input is shorter than allocated buffer
-	lghi	$len,0
-	st${g}	$fp,$SIZE_T($sp)
-
-.Lxts_km_go:
-	lrvg	$s0,$tweak+0($s2)	# load the tweak value in little-endian
-	lrvg	$s1,$tweak+8($s2)
-
-	la	$s2,16($sp)		# vector of ascending tweak values
-	slgr	$s2,$inp
-	srlg	$s3,$fp,4
-	j	.Lxts_km_start
-
-.Lxts_km_loop:
-	la	$s2,16($sp)
-	slgr	$s2,$inp
-	srlg	$s3,$fp,4
-.Lxts_km_prepare:
-	lghi	$i1,0x87
-	srag	$i2,$s1,63		# broadcast upper bit
-	ngr	$i1,$i2			# rem
-	algr	$s0,$s0
-	alcgr	$s1,$s1
-	xgr	$s0,$i1
-.Lxts_km_start:
-	lrvgr	$i1,$s0			# flip byte order
-	lrvgr	$i2,$s1
-	stg	$i1,0($s2,$inp)
-	stg	$i2,8($s2,$inp)
-	xg	$i1,0($inp)
-	xg	$i2,8($inp)
-	stg	$i1,0($out,$inp)
-	stg	$i2,8($out,$inp)
-	la	$inp,16($inp)
-	brct	$s3,.Lxts_km_prepare
-
-	slgr	$inp,$fp		# rewind $inp
-	la	$s2,0($out,$inp)
-	lgr	$s3,$fp
-	.long	0xb92e00aa		# km $s2,$s2
-	brc	1,.-4			# pay attention to "partial completion"
-
-	la	$s2,16($sp)
-	slgr	$s2,$inp
-	srlg	$s3,$fp,4
-.Lxts_km_xor:
-	lg	$i1,0($out,$inp)
-	lg	$i2,8($out,$inp)
-	xg	$i1,0($s2,$inp)
-	xg	$i2,8($s2,$inp)
-	stg	$i1,0($out,$inp)
-	stg	$i2,8($out,$inp)
-	la	$inp,16($inp)
-	brct	$s3,.Lxts_km_xor
-
-	slgr	$len,$fp
-	brc	1,.Lxts_km_loop		# not zero, no borrow
-	algr	$fp,$len
-	lghi	$len,0
-	brc	4+1,.Lxts_km_loop	# not zero
-
-	l${g}	$i1,0($sp)		# back-chain
-	llgf	$fp,`2*$SIZE_T-4`($sp)	# bytes used
-	la	$i2,16($sp)
-	srlg	$fp,$fp,4
-.Lxts_km_zap:
-	stg	$i1,0($i2)
-	stg	$i1,8($i2)
-	la	$i2,16($i2)
-	brct	$fp,.Lxts_km_zap
-
-	la	$sp,0($i1)
-	llgc	$len,2*$SIZE_T-1($i1)
-	nill	$len,0x0f		# $len%=16
-	bzr	$ra
-
-	# generate one more tweak...
-	lghi	$i1,0x87
-	srag	$i2,$s1,63		# broadcast upper bit
-	ngr	$i1,$i2			# rem
-	algr	$s0,$s0
-	alcgr	$s1,$s1
-	xgr	$s0,$i1
-
-	ltr	$len,$len		# clear zero flag
-	br	$ra
-.size	_s390x_xts_km,.-_s390x_xts_km
-
-.globl	AES_xts_encrypt
-.type	AES_xts_encrypt,\@function
-.align	16
-AES_xts_encrypt:
-	xgr	%r3,%r4			# flip %r3 and %r4, $out and $len
-	xgr	%r4,%r3
-	xgr	%r3,%r4
-___
-$code.=<<___ if ($SIZE_T==4);
-	llgfr	$len,$len
-___
-$code.=<<___;
-	st${g}	$len,1*$SIZE_T($sp)	# save copy of $len
-	srag	$len,$len,4		# formally wrong, because it expands
-					# sign byte, but who can afford asking
-					# to process more than 2^63-1 bytes?
-					# I use it, because it sets condition
-					# code...
-	bcr	8,$ra			# abort if zero (i.e. less than 16)
-___
-$code.=<<___ if (!$softonly);
-	llgf	%r0,240($key2)
-	lhi	%r1,16
-	clr	%r0,%r1
-	jl	.Lxts_enc_software
-
-	st${g}	$ra,5*$SIZE_T($sp)
-	stm${g}	%r6,$s3,6*$SIZE_T($sp)
-
-	sllg	$len,$len,4		# $len&=~15
-	slgr	$out,$inp
-
-	# generate the tweak value
-	l${g}	$s3,$stdframe($sp)	# pointer to iv
-	la	$s2,$tweak($sp)
-	lmg	$s0,$s1,0($s3)
-	lghi	$s3,16
-	stmg	$s0,$s1,0($s2)
-	la	%r1,0($key2)		# $key2 is not needed anymore
-	.long	0xb92e00aa		# km $s2,$s2, generate the tweak
-	brc	1,.-4			# can this happen?
-
-	l	%r0,240($key1)
-	la	%r1,0($key1)		# $key1 is not needed anymore
-	bras	$ra,_s390x_xts_km
-	jz	.Lxts_enc_km_done
-
-	aghi	$inp,-16		# take one step back
-	la	$i3,0($out,$inp)	# put aside real $out
-.Lxts_enc_km_steal:
-	llgc	$i1,16($inp)
-	llgc	$i2,0($out,$inp)
-	stc	$i1,0($out,$inp)
-	stc	$i2,16($out,$inp)
-	la	$inp,1($inp)
-	brct	$len,.Lxts_enc_km_steal
-
-	la	$s2,0($i3)
-	lghi	$s3,16
-	lrvgr	$i1,$s0			# flip byte order
-	lrvgr	$i2,$s1
-	xg	$i1,0($s2)
-	xg	$i2,8($s2)
-	stg	$i1,0($s2)
-	stg	$i2,8($s2)
-	.long	0xb92e00aa		# km $s2,$s2
-	brc	1,.-4			# can this happen?
-	lrvgr	$i1,$s0			# flip byte order
-	lrvgr	$i2,$s1
-	xg	$i1,0($i3)
-	xg	$i2,8($i3)
-	stg	$i1,0($i3)
-	stg	$i2,8($i3)
-
-.Lxts_enc_km_done:
-	stg	$sp,$tweak+0($sp)	# wipe tweak
-	stg	$sp,$tweak+8($sp)
-	l${g}	$ra,5*$SIZE_T($sp)
-	lm${g}	%r6,$s3,6*$SIZE_T($sp)
-	br	$ra
-.align	16
-.Lxts_enc_software:
-___
-$code.=<<___;
-	stm${g}	%r6,$ra,6*$SIZE_T($sp)
-
-	slgr	$out,$inp
-
-	l${g}	$s3,$stdframe($sp)	# ivp
-	llgf	$s0,0($s3)		# load iv
-	llgf	$s1,4($s3)
-	llgf	$s2,8($s3)
-	llgf	$s3,12($s3)
-	stm${g}	%r2,%r5,2*$SIZE_T($sp)
-	la	$key,0($key2)
-	larl	$tbl,AES_Te
-	bras	$ra,_s390x_AES_encrypt	# generate the tweak
-	lm${g}	%r2,%r5,2*$SIZE_T($sp)
-	stm	$s0,$s3,$tweak($sp)	# save the tweak
-	j	.Lxts_enc_enter
-
-.align	16
-.Lxts_enc_loop:
-	lrvg	$s1,$tweak+0($sp)	# load the tweak in little-endian
-	lrvg	$s3,$tweak+8($sp)
-	lghi	%r1,0x87
-	srag	%r0,$s3,63		# broadcast upper bit
-	ngr	%r1,%r0			# rem
-	algr	$s1,$s1
-	alcgr	$s3,$s3
-	xgr	$s1,%r1
-	lrvgr	$s1,$s1			# flip byte order
-	lrvgr	$s3,$s3
-	srlg	$s0,$s1,32		# smash the tweak to 4x32-bits
-	stg	$s1,$tweak+0($sp)	# save the tweak
-	llgfr	$s1,$s1
-	srlg	$s2,$s3,32
-	stg	$s3,$tweak+8($sp)
-	llgfr	$s3,$s3
-	la	$inp,16($inp)		# $inp+=16
-.Lxts_enc_enter:
-	x	$s0,0($inp)		# ^=*($inp)
-	x	$s1,4($inp)
-	x	$s2,8($inp)
-	x	$s3,12($inp)
-	stm${g}	%r2,%r3,2*$SIZE_T($sp)	# only two registers are changing
-	la	$key,0($key1)
-	bras	$ra,_s390x_AES_encrypt
-	lm${g}	%r2,%r5,2*$SIZE_T($sp)
-	x	$s0,$tweak+0($sp)	# ^=tweak
-	x	$s1,$tweak+4($sp)
-	x	$s2,$tweak+8($sp)
-	x	$s3,$tweak+12($sp)
-	st	$s0,0($out,$inp)
-	st	$s1,4($out,$inp)
-	st	$s2,8($out,$inp)
-	st	$s3,12($out,$inp)
-	brct${g}	$len,.Lxts_enc_loop
-
-	llgc	$len,`2*$SIZE_T-1`($sp)
-	nill	$len,0x0f		# $len%16
-	jz	.Lxts_enc_done
-
-	la	$i3,0($inp,$out)	# put aside real $out
-.Lxts_enc_steal:
-	llgc	%r0,16($inp)
-	llgc	%r1,0($out,$inp)
-	stc	%r0,0($out,$inp)
-	stc	%r1,16($out,$inp)
-	la	$inp,1($inp)
-	brct	$len,.Lxts_enc_steal
-	la	$out,0($i3)		# restore real $out
-
-	# generate last tweak...
-	lrvg	$s1,$tweak+0($sp)	# load the tweak in little-endian
-	lrvg	$s3,$tweak+8($sp)
-	lghi	%r1,0x87
-	srag	%r0,$s3,63		# broadcast upper bit
-	ngr	%r1,%r0			# rem
-	algr	$s1,$s1
-	alcgr	$s3,$s3
-	xgr	$s1,%r1
-	lrvgr	$s1,$s1			# flip byte order
-	lrvgr	$s3,$s3
-	srlg	$s0,$s1,32		# smash the tweak to 4x32-bits
-	stg	$s1,$tweak+0($sp)	# save the tweak
-	llgfr	$s1,$s1
-	srlg	$s2,$s3,32
-	stg	$s3,$tweak+8($sp)
-	llgfr	$s3,$s3
-
-	x	$s0,0($out)		# ^=*(inp)|stolen cipther-text
-	x	$s1,4($out)
-	x	$s2,8($out)
-	x	$s3,12($out)
-	st${g}	$out,4*$SIZE_T($sp)
-	la	$key,0($key1)
-	bras	$ra,_s390x_AES_encrypt
-	l${g}	$out,4*$SIZE_T($sp)
-	x	$s0,`$tweak+0`($sp)	# ^=tweak
-	x	$s1,`$tweak+4`($sp)
-	x	$s2,`$tweak+8`($sp)
-	x	$s3,`$tweak+12`($sp)
-	st	$s0,0($out)
-	st	$s1,4($out)
-	st	$s2,8($out)
-	st	$s3,12($out)
-
-.Lxts_enc_done:
-	stg	$sp,$tweak+0($sp)	# wipe tweak
-	stg	$sp,$tweak+8($sp)
-	lm${g}	%r6,$ra,6*$SIZE_T($sp)
-	br	$ra
-.size	AES_xts_encrypt,.-AES_xts_encrypt
-___
-# void AES_xts_decrypt(const unsigned char *inp, unsigned char *out,
-#	size_t len, const AES_KEY *key1, const AES_KEY *key2,
-#	const unsigned char iv[16]);
+my ($inp,$outp,$len,$key1,$key2,$fp,$tweak);
+my ($AESE_key,$xcap);
+
+if ($flavour =~ /linux/) {
+# upon entry $inp is in r2, $outp is in r3, $blocks is in r4, $key1 is in $r5 and $key2 is in r6
+    $inp="%r2";
+    $outp="%r4";    # len and out are swapped
+    $len="%r3";
+    $key1="%r5";    # $i1
+    $key2="%r6";    # $i2
+    $fp="%r7";    # $i3
+    $AESE_key="%r4";
+    $tweak=16*$SIZE_T+16;    # or $stdframe-16, bottom of the frame...
+    $rv = "%r2";
+} else {
+# upon entry $inp is in r1, $outp is in r2, $blocks is in r3, $key1 and $key2 are in DSA
+# r2 needs to be moved to r14 and r1 needs to be moved to r2
+    $inp="R2";
+    $outp="R14";
+    $len="R3";
+    $key1="R5"; # in DSA # $i1
+    $key2="R6"; # in DSA # $i2
+    $fp ="R7";           # $i3
+    $xcap="R13";
+    $AESE_key="R3";
+    $tweak=16*$SIZE_T+16;    # or $stdframe-16, bottom of the frame...
+    $rv = "R3";
+}
+
+
+# z/OS: r1 will contain the OPENSSL_s390xcap_P pointer
 #
-$code.=<<___;
-.globl	AES_xts_decrypt
-.type	AES_xts_decrypt,\@function
-.align	16
-AES_xts_decrypt:
-	xgr	%r3,%r4			# flip %r3 and %r4, $out and $len
-	xgr	%r4,%r3
-	xgr	%r3,%r4
-___
-$code.=<<___ if ($SIZE_T==4);
-	llgfr	$len,$len
-___
-$code.=<<___;
-	st${g}	$len,1*$SIZE_T($sp)	# save copy of $len
-	aghi	$len,-16
-	bcr	4,$ra			# abort if less than zero. formally
-					# wrong, because $len is unsigned,
-					# but who can afford asking to
-					# process more than 2^63-1 bytes?
-	tmll	$len,0x0f
-	jnz	.Lxts_dec_proceed
-	aghi	$len,16
-.Lxts_dec_proceed:
-___
-$code.=<<___ if (!$softonly);
-	llgf	%r0,240($key2)
-	lhi	%r1,16
-	clr	%r0,%r1
-	jl	.Lxts_dec_software
-
-	st${g}	$ra,5*$SIZE_T($sp)
-	stm${g}	%r6,$s3,6*$SIZE_T($sp)
-
-	nill	$len,0xfff0		# $len&=~15
-	slgr	$out,$inp
-
-	# generate the tweak value
-	l${g}	$s3,$stdframe($sp)	# pointer to iv
-	la	$s2,$tweak($sp)
-	lmg	$s0,$s1,0($s3)
-	lghi	$s3,16
-	stmg	$s0,$s1,0($s2)
-	la	%r1,0($key2)		# $key2 is not needed past this point
-	.long	0xb92e00aa		# km $s2,$s2, generate the tweak
-	brc	1,.-4			# can this happen?
-
-	l	%r0,240($key1)
-	la	%r1,0($key1)		# $key1 is not needed anymore
-
-	ltgr	$len,$len
-	jz	.Lxts_dec_km_short
-	bras	$ra,_s390x_xts_km
-	jz	.Lxts_dec_km_done
-
-	lrvgr	$s2,$s0			# make copy in reverse byte order
-	lrvgr	$s3,$s1
-	j	.Lxts_dec_km_2ndtweak
-
-.Lxts_dec_km_short:
-	llgc	$len,`2*$SIZE_T-1`($sp)
-	nill	$len,0x0f		# $len%=16
-	lrvg	$s0,$tweak+0($sp)	# load the tweak
-	lrvg	$s1,$tweak+8($sp)
-	lrvgr	$s2,$s0			# make copy in reverse byte order
-	lrvgr	$s3,$s1
-
-.Lxts_dec_km_2ndtweak:
-	lghi	$i1,0x87
-	srag	$i2,$s1,63		# broadcast upper bit
-	ngr	$i1,$i2			# rem
-	algr	$s0,$s0
-	alcgr	$s1,$s1
-	xgr	$s0,$i1
-	lrvgr	$i1,$s0			# flip byte order
-	lrvgr	$i2,$s1
-
-	xg	$i1,0($inp)
-	xg	$i2,8($inp)
-	stg	$i1,0($out,$inp)
-	stg	$i2,8($out,$inp)
-	la	$i2,0($out,$inp)
-	lghi	$i3,16
-	.long	0xb92e0066		# km $i2,$i2
-	brc	1,.-4			# can this happen?
-	lrvgr	$i1,$s0
-	lrvgr	$i2,$s1
-	xg	$i1,0($out,$inp)
-	xg	$i2,8($out,$inp)
-	stg	$i1,0($out,$inp)
-	stg	$i2,8($out,$inp)
-
-	la	$i3,0($out,$inp)	# put aside real $out
-.Lxts_dec_km_steal:
-	llgc	$i1,16($inp)
-	llgc	$i2,0($out,$inp)
-	stc	$i1,0($out,$inp)
-	stc	$i2,16($out,$inp)
-	la	$inp,1($inp)
-	brct	$len,.Lxts_dec_km_steal
-
-	lgr	$s0,$s2
-	lgr	$s1,$s3
-	xg	$s0,0($i3)
-	xg	$s1,8($i3)
-	stg	$s0,0($i3)
-	stg	$s1,8($i3)
-	la	$s0,0($i3)
-	lghi	$s1,16
-	.long	0xb92e0088		# km $s0,$s0
-	brc	1,.-4			# can this happen?
-	xg	$s2,0($i3)
-	xg	$s3,8($i3)
-	stg	$s2,0($i3)
-	stg	$s3,8($i3)
-.Lxts_dec_km_done:
-	stg	$sp,$tweak+0($sp)	# wipe tweak
-	stg	$sp,$tweak+8($sp)
-	l${g}	$ra,5*$SIZE_T($sp)
-	lm${g}	%r6,$s3,6*$SIZE_T($sp)
-	br	$ra
-.align	16
-.Lxts_dec_software:
-___
-$code.=<<___;
-	stm${g}	%r6,$ra,6*$SIZE_T($sp)
-
-	srlg	$len,$len,4
-	slgr	$out,$inp
-
-	l${g}	$s3,$stdframe($sp)	# ivp
-	llgf	$s0,0($s3)		# load iv
-	llgf	$s1,4($s3)
-	llgf	$s2,8($s3)
-	llgf	$s3,12($s3)
-	stm${g}	%r2,%r5,2*$SIZE_T($sp)
-	la	$key,0($key2)
-	larl	$tbl,AES_Te
-	bras	$ra,_s390x_AES_encrypt	# generate the tweak
-	lm${g}	%r2,%r5,2*$SIZE_T($sp)
-	larl	$tbl,AES_Td
-	lt${g}r	$len,$len
-	stm	$s0,$s3,$tweak($sp)	# save the tweak
-	jz	.Lxts_dec_short
-	j	.Lxts_dec_enter
-
-.align	16
-.Lxts_dec_loop:
-	lrvg	$s1,$tweak+0($sp)	# load the tweak in little-endian
-	lrvg	$s3,$tweak+8($sp)
-	lghi	%r1,0x87
-	srag	%r0,$s3,63		# broadcast upper bit
-	ngr	%r1,%r0			# rem
-	algr	$s1,$s1
-	alcgr	$s3,$s3
-	xgr	$s1,%r1
-	lrvgr	$s1,$s1			# flip byte order
-	lrvgr	$s3,$s3
-	srlg	$s0,$s1,32		# smash the tweak to 4x32-bits
-	stg	$s1,$tweak+0($sp)	# save the tweak
-	llgfr	$s1,$s1
-	srlg	$s2,$s3,32
-	stg	$s3,$tweak+8($sp)
-	llgfr	$s3,$s3
-.Lxts_dec_enter:
-	x	$s0,0($inp)		# tweak^=*(inp)
-	x	$s1,4($inp)
-	x	$s2,8($inp)
-	x	$s3,12($inp)
-	stm${g}	%r2,%r3,2*$SIZE_T($sp)	# only two registers are changing
-	la	$key,0($key1)
-	bras	$ra,_s390x_AES_decrypt
-	lm${g}	%r2,%r5,2*$SIZE_T($sp)
-	x	$s0,$tweak+0($sp)	# ^=tweak
-	x	$s1,$tweak+4($sp)
-	x	$s2,$tweak+8($sp)
-	x	$s3,$tweak+12($sp)
-	st	$s0,0($out,$inp)
-	st	$s1,4($out,$inp)
-	st	$s2,8($out,$inp)
-	st	$s3,12($out,$inp)
-	la	$inp,16($inp)
-	brct${g}	$len,.Lxts_dec_loop
-
-	llgc	$len,`2*$SIZE_T-1`($sp)
-	nill	$len,0x0f		# $len%16
-	jz	.Lxts_dec_done
-
-	# generate pair of tweaks...
-	lrvg	$s1,$tweak+0($sp)	# load the tweak in little-endian
-	lrvg	$s3,$tweak+8($sp)
-	lghi	%r1,0x87
-	srag	%r0,$s3,63		# broadcast upper bit
-	ngr	%r1,%r0			# rem
-	algr	$s1,$s1
-	alcgr	$s3,$s3
-	xgr	$s1,%r1
-	lrvgr	$i2,$s1			# flip byte order
-	lrvgr	$i3,$s3
-	stmg	$i2,$i3,$tweak($sp)	# save the 1st tweak
-	j	.Lxts_dec_2ndtweak
-
-.align	16
-.Lxts_dec_short:
-	llgc	$len,`2*$SIZE_T-1`($sp)
-	nill	$len,0x0f		# $len%16
-	lrvg	$s1,$tweak+0($sp)	# load the tweak in little-endian
-	lrvg	$s3,$tweak+8($sp)
-.Lxts_dec_2ndtweak:
-	lghi	%r1,0x87
-	srag	%r0,$s3,63		# broadcast upper bit
-	ngr	%r1,%r0			# rem
-	algr	$s1,$s1
-	alcgr	$s3,$s3
-	xgr	$s1,%r1
-	lrvgr	$s1,$s1			# flip byte order
-	lrvgr	$s3,$s3
-	srlg	$s0,$s1,32		# smash the tweak to 4x32-bits
-	stg	$s1,$tweak-16+0($sp)	# save the 2nd tweak
-	llgfr	$s1,$s1
-	srlg	$s2,$s3,32
-	stg	$s3,$tweak-16+8($sp)
-	llgfr	$s3,$s3
-
-	x	$s0,0($inp)		# tweak_the_2nd^=*(inp)
-	x	$s1,4($inp)
-	x	$s2,8($inp)
-	x	$s3,12($inp)
-	stm${g}	%r2,%r3,2*$SIZE_T($sp)
-	la	$key,0($key1)
-	bras	$ra,_s390x_AES_decrypt
-	lm${g}	%r2,%r5,2*$SIZE_T($sp)
-	x	$s0,$tweak-16+0($sp)	# ^=tweak_the_2nd
-	x	$s1,$tweak-16+4($sp)
-	x	$s2,$tweak-16+8($sp)
-	x	$s3,$tweak-16+12($sp)
-	st	$s0,0($out,$inp)
-	st	$s1,4($out,$inp)
-	st	$s2,8($out,$inp)
-	st	$s3,12($out,$inp)
-
-	la	$i3,0($out,$inp)	# put aside real $out
-.Lxts_dec_steal:
-	llgc	%r0,16($inp)
-	llgc	%r1,0($out,$inp)
-	stc	%r0,0($out,$inp)
-	stc	%r1,16($out,$inp)
-	la	$inp,1($inp)
-	brct	$len,.Lxts_dec_steal
-	la	$out,0($i3)		# restore real $out
-
-	lm	$s0,$s3,$tweak($sp)	# load the 1st tweak
-	x	$s0,0($out)		# tweak^=*(inp)|stolen cipher-text
-	x	$s1,4($out)
-	x	$s2,8($out)
-	x	$s3,12($out)
-	st${g}	$out,4*$SIZE_T($sp)
-	la	$key,0($key1)
-	bras	$ra,_s390x_AES_decrypt
-	l${g}	$out,4*$SIZE_T($sp)
-	x	$s0,$tweak+0($sp)	# ^=tweak
-	x	$s1,$tweak+4($sp)
-	x	$s2,$tweak+8($sp)
-	x	$s3,$tweak+12($sp)
-	st	$s0,0($out)
-	st	$s1,4($out)
-	st	$s2,8($out)
-	st	$s3,12($out)
-	stg	$sp,$tweak-16+0($sp)	# wipe 2nd tweak
-	stg	$sp,$tweak-16+8($sp)
-.Lxts_dec_done:
-	stg	$sp,$tweak+0($sp)	# wipe tweak
-	stg	$sp,$tweak+8($sp)
-	lm${g}	%r6,$ra,6*$SIZE_T($sp)
-	br	$ra
-.size	AES_xts_decrypt,.-AES_xts_decrypt
-___
+LOCAL_FUNCTION("_s390x_xts_km");
+
+    llgfr   ($s0,$wr0);                   # put aside the function code
+    lghi    ($s1,"0x7f");
+    nr      ($s1,$wr0);
+    larl    ($wr1,"OPENSSL_s390xcap_P") if ($flavour =~ /linux/);
+    llihh   ($wr0,"0x8000");
+    srlg    ($wr0,$wr0,"32($s1)");        # check for 32+function code
+    ng      ($wr0,"CS390X_KM($wr1)");      # check km capability vector
+    lgr     ($wr0,$s0);                   # restore the function code
+    la      ($wr1,"0($key1)");            # restore $key1
+&{$z? \&lgr:\&lr} ("R13",$ra) if ($flavour !~ /linux/); # save return address
+    jz      (LABEL("Lxts_km_vanilla"));
+
+    lmg     ($i2,$i3,"$tweak($sp)");      # put aside the tweak value
+    algr    ($outp,$inp);
+
+    oill    ($wr0,32);                    # switch to xts function code
+    aghi    ($s1,-18);                    #
+    sllg    ($s1,$s1,3);                  # (function code - 18)*8, 0 or 16
+    la      ($wr1,"$tweak-16($sp)");
+    slgr    ($wr1,$s1);                   # parameter block position
+    lmg     ($s0,$s3,"0($key1)");         # load 256 bits of key material,
+    stmg    ($s0,$s3,"0($wr1)");          # and copy it to parameter block.
+                    # yes, it contains junk and overlaps
+                    # with the tweak in 128-bit case.
+                    # it's done to avoid conditional
+                    # branch.
+    stmg    ($i2,$i3,"$tweak($sp)");      # "Re-seat" the tweak value
+
+    km      ($outp,$inp);                 # .long    0xb92e0042
+    brc     (1,"$ip-4");                  # pay attention to "partial completion"
+
+    lrvg    ($s0,"$tweak+0($sp)");        # load the last tweak
+    lrvg    ($s1,"$tweak+8($sp)");
+    stmg    ($wr0,$wr3,"$tweak-32($sp)"); # wipe copy of the key
+
+    nill    ($wr0,"0xffdf");              # switch back to original function code
+    la      ($wr1,"0($key1)");            # restore pointer to $key1
+    slgr    ($outp,$inp);
+
+    llgc    ($len,"2*$SIZE_T-1($sp)");
+    nill    ($len,"0x0f");                # $len%=16
+&{$z? \&lgr:\&lr} ($ra,"R13") if ($flavour !~ /linux/); # restore return address
+    br      ($ra);
+
+ALIGN(16);
+LABEL("Lxts_km_vanilla:");
+
+    # prepare and allocate stack frame at the top of 4K page
+    # with 1K reserved for eventual signal handling
+    lghi    ($s0,"-1024-256-16"); # guarantee at least 256-bytes buffer
+    lghi    ($s1,-4096);
+    algr    ($s0,$sp);
+    lgr     ($fp,$sp);
+    ngr     ($s0,$s1);                    # align at page boundary
+    slgr    ($fp,$s0);                    # total buffer size
+    lgr     ($s2,$sp);
+    lghi    ($s1,"1024+16");              # sl[g]fi is extended-immediate facility
+    slgr    ($fp,$s1);                    # deduct reservation to get usable buffer size
+    # buffer size is at lest 256 and at most 3072+256-16
+
+    la      ($sp,"1024($s0)");            # alloca
+    nill    ($fp,"0xfff0");               # round to 16*n
+&{$z? \&stg:\&st} ($s2,"0($sp)");         # back-chain
+    nill    ($len,"0xfff0");              # redundant
+&{$z? \&stg:\&st} ($fp,"$SIZE_T($sp)");
+
+    slgr    ($len,$fp);
+    brc     (1,LABEL("Lxts_km_go"));      # not zero, no borrow
+    algr    ($fp,$len);                   # input is shorter than allocated buffer
+    lghi    ($len,0);
+&{$z? \&stg:\&st} ($fp,"$SIZE_T($sp)");
+
+LABEL("Lxts_km_go:");
+    lrvg    ($s0,"$tweak+0($s2)");        # load the tweak value in little-endian
+    lrvg    ($s1,"$tweak+8($s2)");
+
+    la      ($s2,"16($sp)");              # vector of ascending tweak values
+    slgr    ($s2,$inp);
+    srlg    ($s3,$fp,4);
+    j       (LABEL("Lxts_km_start"));
+
+LABEL("Lxts_km_loop:");
+    la      ($s2,"16($sp)");
+    slgr    ($s2,$inp);
+    srlg    ($s3,$fp,4);
+LABEL("Lxts_km_prepare:");
+    lghi    ($i1,"0x87");
+    srag    ($i2,$s1,63);                 # broadcast upper bit
+    ngr     ($i1,$i2);                    # rem
+    algr    ($s0,$s0);
+    alcgr   ($s1,$s1);
+    xgr     ($s0,$i1);
+LABEL("Lxts_km_start:");
+    lrvgr   ($i1,$s0);                    # flip byte order
+    lrvgr   ($i2,$s1);
+    stg     ($i1,"0($s2,$inp)");
+    stg     ($i2,"8($s2,$inp)");
+    xg      ($i1,"0($inp)");
+    xg      ($i2,"8($inp)");
+    stg     ($i1,"0($outp,$inp)");
+    stg     ($i2,"8($outp,$inp)");
+    la      ($inp,"16($inp)");
+    brct    ($s3,LABEL("Lxts_km_prepare"));
+
+    slgr    ($inp,$fp);                   # rewind $inp
+    la      ($s2,"0($outp,$inp)");
+    lgr     ($s3,$fp);
+    km      ($s2,$s2);                    # .long    0xb92e00aa
+    brc     (1,"$ip-4");                  # pay attention to "partial completion"
+
+    la      ($s2,"16($sp)");
+    slgr    ($s2,$inp);
+    srlg    ($s3,$fp,4);
+LABEL("Lxts_km_xor:");
+    lg      ($i1,"0($outp,$inp)");
+    lg      ($i2,"8($outp,$inp)");
+    xg      ($i1,"0($s2,$inp)");
+    xg      ($i2,"8($s2,$inp)");
+    stg     ($i1,"0($outp,$inp)");
+    stg     ($i2,"8($outp,$inp)");
+    la      ($inp,"16($inp)");
+    brct    ($s3,LABEL("Lxts_km_xor"));
+
+    slgr    ($len,$fp);
+    brc     (1,LABEL("Lxts_km_loop"));    # not zero, no borrow
+    algr    ($fp,$len);
+    lghi    ($len,0);
+    brc     ("4+1",LABEL("Lxts_km_loop")); # not zero
+
+&{$z? \&lg:\&l}    ($i1,"0($sp)");         # back-chain
+    llgf    ($fp,"2*$SIZE_T-4($sp)");      # bytes used
+    la      ($i2,"16($sp)");
+    srlg    ($fp,$fp,4);
+LABEL("Lxts_km_zap:");
+    stg     ($i1,"0($i2)");
+    stg     ($i1,"8($i2)");
+    la      ($i2,"16($i2)");
+    brct    ($fp,LABEL("Lxts_km_zap"));
+
+    la      ($sp,"0($i1)");
+    llgc    ($len,"2*$SIZE_T-1($i1)");
+    nill    ($len,"0x0f");                # $len%=16
+    &{$z? \&lgr:\&lr} ($ra,"R13") if ($flavour !~ /linux/); # restore return address
+    bzr     ($ra);
+
+    # generate one more tweak...
+    lghi    ($i1,"0x87");
+    srag    ($i2,$s1,63);                 # broadcast upper bit
+    ngr     ($i1,$i2);                    # rem
+    algr    ($s0,$s0);
+    alcgr   ($s1,$s1);
+    xgr     ($s0,$i1);
+
+    ltr     ($len,$len);                  # clear zero flag
+    &{$z? \&lgr:\&lr} ($ra,"R13") if ($flavour !~ /linux/); # restore return address
+    br      ($ra);
+
+LOCAL_FUNCTION_END("_s390x_xts_km");
+
+FUNCTION_BEGIN("AES_xts_encrypt",6,"true","stor3","true");
+if ($flavour =~ /linux/) {
+    xgr     ("%r3","%r4");                # flip %r3 and %r4, $outp and $len
+    xgr     ("%r4","%r3");
+    xgr     ("%r3","%r4");
+} else {
+    lgr    ($outp,"R2");
+    lgr    ($inp,"R1");
+    lay    ($sp,"STACK");                 # Set up stack for z/os
 }
-$code.=<<___;
-.string	"AES for s390x, CRYPTOGAMS by <appro\@openssl.org>"
-___

-$code =~ s/\`([^\`]*)\`/eval $1/gem;
-print $code;
-close STDOUT or die "error closing STDOUT: $!";	# force flush
+    llgfr   ($len,$len) if ($SIZE_T==4);
+
+&{$z? \&stg:\&st} ($len,"1*$SIZE_T($sp)");  # save copy of $len
+    srag    ($len,$len,4);                  # formally wrong, because it expands
+                    # sign byte, but who can afford asking
+                    # to process more than 2^63-1 bytes?
+                    # I use it, because it sets condition
+                    # code...
+    BR_EXIT("z");                           # abort if zero (i.e. less than 16)
+
+if ($flavour !~ /linux/) {    # get the parms out of the DSA
+  &{$z? \&lg:\&l} ("R9","$DSA_OFF(r4)");    # Get DSA address
+  GET_EXTERN ($xcap,"OPENSSL_s390xcap_P");    # must be done before r5 is corrupted
+  &{$z? \&lg:\&l} ($key1,"$PARMS_OFF+$SIZE_T*3(r9)"); # Get key1 address
+  &{$z? \&lg:\&l} ($key2,"$PARMS_OFF+$SIZE_T*4(r9)"); # Get key2 address
+}
+    llgf    ($wr0,"240($key2)");
+    lhi     ($wr1,16);
+    clr     ($wr0,$wr1);
+    jl      (LABEL("Lxts_enc_software"));
+
+&{$z? \&stg:\&st} ($ra,"5*$SIZE_T($sp)");
+&{$z? \&stmg:\&stm} ($key2,$s3,"6*$SIZE_T($sp)");  # reg 6->11
+
+    sllg    ($len,$len,4);                # $len&=~15
+    slgr    ($outp,$inp);
+
+    # generate the tweak value
+if ($flavour =~ /linux/) {
+  &{$z? \&lg:\&l} ($s3,"$stdframe($sp)"); # pointer to iv
+} else {
+  &{$z? \&lg:\&l} ($s3,"$PARMS_OFF+$SIZE_T*5(r9)"); # Get iv address
+}
+    la      ($s2,"$tweak($sp)");
+    lmg     ($s0,$s1,"0($s3)");
+    lghi    ($s3,16);
+    stmg    ($s0,$s1,"0($s2)");
+    la      ($wr1,"0($key2)");            # $key2 is not needed anymore
+    km      ($s2,$s2);                    #.long    0xb92e00aa, generate the tweak
+    brc     (1,"$ip-4");                  # can this happen?
+
+    l       ($wr0,"240($key1)");
+# _s390x_xts_km does not use the value in wr1
+#    la      ($wr1,"0($key1)");           # $key1 is not needed anymore
+    lgr     ($wr1,$xcap) if ($flavour !~ /linux/);
+    bras    ($ra,"_s390x_xts_km");
+    jz      (LABEL("Lxts_enc_km_done"));
+
+    aghi    ($inp,-16);                   # take one step back
+    la      ($i3,"0($outp,$inp)");        # put aside real $out
+LABEL("Lxts_enc_km_steal:");
+    llgc    ($i1,"16($inp)");
+    llgc    ($i2,"0($outp,$inp)");
+    stc     ($i1,"0($outp,$inp)");
+    stc     ($i2,"16($outp,$inp)");
+    la      ($inp,"1($inp)");
+    brct    ($len,LABEL("Lxts_enc_km_steal"));
+
+    la      ($s2,"0($i3)");
+    lghi    ($s3,16);
+    lrvgr   ($i1,$s0);                    # flip byte order
+    lrvgr   ($i2,$s1);
+    xg      ($i1,"0($s2)");
+    xg      ($i2,"8($s2)");
+    stg     ($i1,"0($s2)");
+    stg     ($i2,"8($s2)");
+    km      ($s2,$s2);                    #.long    0xb92e00aa
+    brc     (1,"$ip-4");                  # can this happen?
+    lrvgr   ($i1,$s0);                    # flip byte order
+    lrvgr   ($i2,$s1);
+    xg      ($i1,"0($i3)");
+    xg      ($i2,"8($i3)");
+    stg     ($i1,"0($i3)");
+    stg     ($i2,"8($i3)");
+
+LABEL("Lxts_enc_km_done:");
+    stg     ($sp,"$tweak+0($sp)");        # wipe tweak
+    stg     ($sp,"$tweak+8($sp)");
+&{$z? \&lg:\&l}  ($ra,"5*$SIZE_T($sp)");        # reg 7   probably not needed on z/os
+&{$z? \&lmg:\&lm} ($key2,$s3,"6*$SIZE_T($sp)") if ($flavour =~ /linux/); # regs 6-11
+    BR_EXIT();
+ALIGN(16);
+LABEL("Lxts_enc_software:");
+
+&{$z? \&stmg:\&stm} ($key2,$ra,"6*$SIZE_T($sp)");
+
+    slgr    ($outp,$inp);
+
+if ($flavour =~ /linux/) {
+	&{$z? \&lg:\&l} ($s3,"$stdframe($sp)");   # pointer to iv
+} else {
+	&{$z? \&lg:\&l} ($s3,"$PARMS_OFF+$SIZE_T*5(r9)"); # Get iv address
+}
+    llgf    ($s0,"0($s3)");               # load iv
+    llgf    ($s1,"4($s3)");
+    llgf    ($s2,"8($s3)");
+    llgf    ($s3,"12($s3)");
+&{$z? \&stmg:\&stm} ($inp,$key1,"2*$SIZE_T($sp)");
+&{$z? \&stg:\&st} ($outp,"14*$SIZE_T($sp)") if ($flavour !~ /linux/);  # z/OS needs outp preserved
+    la      ($AESE_key,"0($key2)");
+    larl    ($tbl,LABEL("AES_Te"));
+    bras    ($ra,"_s390x_AES_encrypt");   # generate the tweak
+&{$z? \&lmg:\&lm} ($inp,$key1,"2*$SIZE_T($sp)");
+&{$z? \&lg:\&l} ($outp,"14*$SIZE_T($sp)") if ($flavour !~ /linux/);  # z/OS needs outp preserved
+    stm     ($s0,$s3,"$tweak($sp)");      # save the tweak
+    j       (LABEL("Lxts_enc_enter"));
+
+ALIGN(16);
+LABEL("Lxts_enc_loop:");
+    lrvg    ($s1,"$tweak+0($sp)");        # load the tweak in little-endian
+    lrvg    ($s3,"$tweak+8($sp)");
+    lghi    ($wr1,"0x87");
+    srag    ($wr0,$s3,63);                # broadcast upper bit
+    ngr     ($wr1,$wr0);                  # rem
+    algr    ($s1,$s1);
+    alcgr   ($s3,$s3);
+    xgr     ($s1,$wr1);
+    lrvgr   ($s1,$s1);                    # flip byte order
+    lrvgr   ($s3,$s3);
+    srlg    ($s0,$s1,32);                 # smash the tweak to 4x32-bits
+    stg     ($s1,"$tweak+0($sp)");        # save the tweak
+    llgfr   ($s1,$s1);
+    srlg    ($s2,$s3,32);
+    stg     ($s3,"$tweak+8($sp)");
+    llgfr   ($s3,$s3);
+    la      ($inp,"16($inp)");            # $inp+=16
+LABEL("Lxts_enc_enter:");
+    x       ($s0,"0($inp)");              # ^=*($inp)
+    x       ($s1,"4($inp)");
+    x       ($s2,"8($inp)");
+    x       ($s3,"12($inp)");
+&{$z? \&stmg:\&stm} ($inp,$len,"2*$SIZE_T($sp)");    # only two registers are changing
+&{$z? \&stg:\&st} ($outp,"14*$SIZE_T($sp)") if ($flavour !~ /linux/);  # z/OS needs outp preserved
+    la      ($AESE_key,"0($key1)");
+    bras    ($ra,"_s390x_AES_encrypt");
+&{$z? \&lmg:\&lm} ($inp,$key1,"2*$SIZE_T($sp)");
+&{$z? \&lg:\&l} ($outp,"14*$SIZE_T($sp)") if ($flavour !~ /linux/);  # z/OS needs outp preserved
+    x       ($s0,"$tweak+0($sp)");        # ^=tweak
+    x       ($s1,"$tweak+4($sp)");
+    x       ($s2,"$tweak+8($sp)");
+    x       ($s3,"$tweak+12($sp)");
+    st      ($s0,"0($outp,$inp)");
+    st      ($s1,"4($outp,$inp)");
+    st      ($s2,"8($outp,$inp)");
+    st      ($s3,"12($outp,$inp)");
+&{$z? \&brctg:\&brct} ($len,LABEL("Lxts_enc_loop"));
+
+    llgc    ($len,"2*$SIZE_T-1($sp)");
+    nill    ($len,"0x0f");                # $len%16
+    jz      (LABEL("Lxts_enc_done"));
+
+    la      ($i3,"0($inp,$outp)");        # put aside real $out
+LABEL("Lxts_enc_steal:");
+    llgc    ($wr0,"16($inp)");
+    llgc    ($wr1,"0($outp,$inp)");
+    stc     ($wr0,"0($outp,$inp)");
+    stc     ($wr1,"16($outp,$inp)");
+    la      ($inp,"1($inp)");
+    brct    ($len,LABEL("Lxts_enc_steal"));
+    la      ($outp,"0($i3)");             # restore real $out
+
+    # generate last tweak...
+    lrvg    ($s1,"$tweak+0($sp)");        # load the tweak in little-endian
+    lrvg    ($s3,"$tweak+8($sp)");
+    lghi    ($wr1,"0x87");
+    srag    ($wr0,$s3,63);                # broadcast upper bit
+    ngr     ($wr1,$wr0);                  # rem
+    algr    ($s1,$s1);
+    alcgr   ($s3,$s3);
+    xgr     ($s1,$wr1);
+    lrvgr   ($s1,$s1);                    # flip byte order
+    lrvgr   ($s3,$s3);
+    srlg    ($s0,$s1,32);                 # smash the tweak to 4x32-bits
+    stg     ($s1,"$tweak+0($sp)");        # save the tweak
+    llgfr   ($s1,$s1);
+    srlg    ($s2,$s3,32);
+    stg     ($s3,"$tweak+8($sp)");
+    llgfr   ($s3,$s3);
+
+    x       ($s0,"0($outp)");             # ^=*(inp)|stolen cipther-text
+    x       ($s1,"4($outp)");
+    x       ($s2,"8($outp)");
+    x       ($s3,"12($outp)");
+&{$z? \&stg:\&st} ($outp,"4*$SIZE_T($sp)");
+    la      ($AESE_key,"0($key1)");
+    bras    ($ra,"_s390x_AES_encrypt");
+&{$z? \&lg:\&l}    ($outp,"4*$SIZE_T($sp)");
+    x       ($s0,"$tweak+0($sp)");        # ^=tweak
+    x       ($s1,"$tweak+4($sp)");
+    x       ($s2,"$tweak+8($sp)");
+    x       ($s3,"$tweak+12($sp)");
+    st      ($s0,"0($outp)");
+    st      ($s1,"4($outp)");
+    st      ($s2,"8($outp)");
+    st      ($s3,"12($outp)");
+
+LABEL("Lxts_enc_done:");
+    stg     ($sp,"$tweak+0($sp)");        # wipe tweak
+    stg     ($sp,"$tweak+8($sp)");
+&{$z? \&lmg:\&lm} ($key2,$ra,"6*$SIZE_T($sp)") if ($flavour =~ /linux/);
+    BR_EXIT();
+
+FUNCTION_END("AES_xts_encrypt",$rv);
+}
+
+
+{
+# void AES_xts_decrypt(const unsigned char *inp, unsigned char *outp,
+#    size_t len, const AES_KEY *key1, const AES_KEY *key2,
+#    const unsigned char iv[16]);
+#
+my ($inp,$outp,$len,$key1,$key2,$fp,$tweak);
+my ($AESE_key,$xcap);
+
+if ($flavour =~ /linux/) {
+# upon entry $inp is in r2, $outp is in r3, $blocks is in r4, $key1 is in $r5 and $key2 is in r6
+    $inp="%r2";
+    $outp="%r4";  # len and out are swapped
+    $len="%r3";
+    $key1="%r5";  # $i1
+    $key2="%r6";  # $i2
+    $fp ="%r7";   # $i3
+    $AESE_key="%r4";
+    $tweak=16*$SIZE_T+16;    # or $stdframe-16, bottom of the frame...
+} else {
+# upon entry $inp is in r1, $outp is in r2, $blocks is in r3, $key1 and $key2 are in DSA
+# r2 needs to be moved to r14 and r1 needs to be moved to r2
+    $inp="R2";
+    $outp="R14";
+    $len="R3";
+    $key1="R5"; # in DSA # $i1
+    $key2="R6"; # in DSA # $i2
+    $fp ="R7";           # $i3
+    $xcap="R13";
+    $AESE_key="R3";
+    $tweak=16*$SIZE_T+16;    # or $stdframe-16, bottom of the frame...
+}
+
+
+FUNCTION_BEGIN("AES_xts_decrypt",6,"true","stor3","true");
+if ($flavour =~ /linux/) {
+    xgr     ("%r3","%r4");                    # flip %r3 and %r4, $out and $len
+    xgr     ("%r4","%r3");
+    xgr     ("%r3","%r4");
+} else {
+    lgr    ($outp,"R2");
+    lgr    ($inp,"R1");
+    lay    ($sp,"STACK");                 # Set up stack for z/os
+}
+
+    llgfr    ($len,$len) if ($SIZE_T==4);
+
+&{$z? \&stg:\&st} ($len,"1*$SIZE_T($sp)");    # save copy of $len
+    aghi    ($len,-16);
+    BR_EXIT("m");                         # abort if less than zero. formally
+                    # wrong, because $len is unsigned,
+                    # but who can afford asking to
+                    # process more than 2^63-1 bytes?
+    tmll    ($len,"0x0f");
+    jnz     (LABEL("Lxts_dec_proceed"));
+    aghi    ($len,16);
+LABEL("Lxts_dec_proceed:");
+
+if ($flavour !~ /linux/) {                # get the parms out of the DSA
+  &{$z? \&lg:\&l} ("R9","$DSA_OFF(r4)");  # Get DSA address
+  GET_EXTERN ($xcap,"OPENSSL_s390xcap_P");    # must be done before r5 is corrupted
+  &{$z? \&lg:\&l} ($key1,"$PARMS_OFF+$SIZE_T*3(r9)"); # Get key1 address
+  &{$z? \&lg:\&l} ($key2,"$PARMS_OFF+$SIZE_T*4(r9)"); # Get key2 address
+}
+    llgf    ($wr0,"240($key2)");
+    lhi     ($wr1,16);
+    clr     ($wr0,$wr1);
+    jl      (LABEL("Lxts_dec_software"));
+
+&{$z? \&stg:\&st} ($ra,"5*$SIZE_T($sp)");    # reg on linux 14 on z/os 7
+&{$z? \&stmg:\&stm} ($key2,$s3,"6*$SIZE_T($sp)"); # regs 6->11
+
+    nill    ($len,"0xfff0");              # $len&=~15
+    slgr    ($outp,$inp);
+
+    # generate the tweak value
+if ($flavour =~ /linux/) {
+  &{$z? \&lg:\&l} ($s3,"$stdframe($sp)");   # pointer to iv
+} else {
+  &{$z? \&lg:\&l} ($s3,"$PARMS_OFF+$SIZE_T*5(r9)"); # Get iv address
+}
+    la      ($s2,"$tweak($sp)");
+    lmg     ($s0,$s1,"0($s3)");
+    lghi    ($s3,16);
+    stmg    ($s0,$s1,"0($s2)");
+    la      ($wr1,"0($key2)");            # $key2 is not needed past this point
+    km      ($s2,$s2);                    # .long    0xb92e00aa, generate the tweak
+    brc     (1,"$ip-4");                  # can this happen?
+
+    l       ($wr0,"240($key1)");
+    la      ($wr1,"0($key1)");            # $key1 is not needed anymore
+
+    ltgr    ($len,$len);
+    jz      (LABEL("Lxts_dec_km_short"));
+    lgr     ($wr1,$xcap) if ($flavour !~ /linux/);
+    bras    ($ra,"_s390x_xts_km");
+    jz      (LABEL("Lxts_dec_km_done"));
+
+    lrvgr   ($s2,$s0);                    # make copy in reverse byte order
+    lrvgr   ($s3,$s1);
+    j       (LABEL("Lxts_dec_km_2ndtweak"));
+
+LABEL("Lxts_dec_km_short:");
+    llgc    ($len,"2*$SIZE_T-1($sp)");
+    nill    ($len,"0x0f");                # $len%=16
+    lrvg    ($s0,"$tweak+0($sp)");        # load the tweak
+    lrvg    ($s1,"$tweak+8($sp)");
+    lrvgr   ($s2,$s0);                    # make copy in reverse byte order
+    lrvgr   ($s3,$s1);
+
+LABEL("Lxts_dec_km_2ndtweak:");
+    lghi    ($i1,"0x87");
+    srag    ($i2,$s1,63);                 # broadcast upper bit
+    ngr     ($i1,$i2);                    # rem
+    algr    ($s0,$s0);
+    alcgr   ($s1,$s1);
+    xgr     ($s0,$i1);
+    lrvgr   ($i1,$s0);                    # flip byte order
+    lrvgr   ($i2,$s1);
+
+    xg      ($i1,"0($inp)");
+    xg      ($i2,"8($inp)");
+    stg     ($i1,"0($outp,$inp)");
+    stg     ($i2,"8($outp,$inp)");
+    la      ($i2,"0($outp,$inp)");
+    lghi    ($i3,16);
+    km      ($i2,$i2);                    # .long    0xb92e0066
+    brc     (1,"$ip-4");                  # can this happen?
+    lrvgr   ($i1,$s0);
+    lrvgr   ($i2,$s1);
+    xg      ($i1,"0($outp,$inp)");
+    xg      ($i2,"8($outp,$inp)");
+    stg     ($i1,"0($outp,$inp)");
+    stg     ($i2,"8($outp,$inp)");
+
+    la      ($i3,"0($outp,$inp)");        # put aside real $out
+LABEL("Lxts_dec_km_steal:");
+    llgc    ($i1,"16($inp)");
+    llgc    ($i2,"0($outp,$inp)");
+    stc     ($i1,"0($outp,$inp)");
+    stc     ($i2,"16($outp,$inp)");
+    la      ($inp,"1($inp)");
+    brct    ($len,LABEL("Lxts_dec_km_steal"));
+
+    lgr     ($s0,$s2);
+    lgr     ($s1,$s3);
+    xg      ($s0,"0($i3)");
+    xg      ($s1,"8($i3)");
+    stg     ($s0,"0($i3)");
+    stg     ($s1,"8($i3)");
+    la      ($s0,"0($i3)");
+    lghi    ($s1,16);
+    km      ($s0,$s0);                    # .long    0xb92e0088
+    brc     (1,"$ip-4");                  # can this happen?
+    xg      ($s2,"0($i3)");
+    xg      ($s3,"8($i3)");
+    stg     ($s2,"0($i3)");
+    stg     ($s3,"8($i3)");
+LABEL("Lxts_dec_km_done:");
+    stg     ($sp,"$tweak+0($sp)");        # wipe tweak
+    stg     ($sp,"$tweak+8($sp)");
+&{$z? \&lg:\&l}   ($ra,"5*$SIZE_T($sp)");
+&{$z? \&lmg:\&lm} ($key2,$s3,"6*$SIZE_T($sp)") if ($flavour =~ /linux/);  # regs 6->11
+    BR_EXIT();
+ALIGN(16);
+LABEL("Lxts_dec_software:");
+
+&{$z? \&stmg:\&stm} ($key2,$ra,"6*$SIZE_T($sp)"); # regs on linux 6->14 on z/os 6->7
+
+    srlg    ($len,$len,4);
+    slgr    ($outp,$inp);
+
+if ($flavour =~ /linux/) {
+  &{$z? \&lg:\&l} ($s3,"$stdframe($sp)");   # pointer to iv
+} else {
+  &{$z? \&lg:\&l} ($s3,"$PARMS_OFF+$SIZE_T*5(r9)"); # Get iv address
+}
+    llgf    ($s0,"0($s3)");               # load iv
+    llgf    ($s1,"4($s3)");
+    llgf    ($s2,"8($s3)");
+    llgf    ($s3,"12($s3)");
+&{$z? \&stmg:\&stm} ($wr2,$key1,"2*$SIZE_T($sp)"); # regs on linux 2->5 on z/os 2->5
+&{$z? \&stg:\&st} ($outp,"14*$SIZE_T($sp)") if ($flavour !~ /linux/);  # z/OS needs outp preserved
+    la      ($AESE_key,"0($key2)");
+    larl    ($tbl,LABEL("AES_Te"));
+    bras    ($ra,"_s390x_AES_encrypt");   # generate the tweak
+&{$z? \&lmg:\&lm} ($wr2,$key1,"2*$SIZE_T($sp)"); # regs on linux 2->5 on z/os 2->5
+&{$z? \&lg:\&l} ($outp,"14*$SIZE_T($sp)") if ($flavour !~ /linux/);  # z/OS needs outp preserved
+    larl    ($tbl,LABEL("AES_Td"));
+&{$z? \&ltgr:\&ltr} ($len,$len);
+    stm     ($s0,$s3,"$tweak($sp)");      # save the tweak
+    jz      (LABEL("Lxts_dec_short"));
+    j       (LABEL("Lxts_dec_enter"));
+
+ALIGN(16);
+LABEL("Lxts_dec_loop:");
+    lrvg    ($s1,"$tweak+0($sp)");        # load the tweak in little-endian
+    lrvg    ($s3,"$tweak+8($sp)");
+    lghi    ($wr1,"0x87");
+    srag    ($wr0,$s3,63);                # broadcast upper bit
+    ngr     ($wr1,$wr0);                  # rem
+    algr    ($s1,$s1);
+    alcgr   ($s3,$s3);
+    xgr     ($s1,$wr1);
+    lrvgr   ($s1,$s1);                    # flip byte order
+    lrvgr   ($s3,$s3);
+    srlg    ($s0,$s1,32);                 # smash the tweak to 4x32-bits
+    stg     ($s1,"$tweak+0($sp)");        # save the tweak
+    llgfr   ($s1,$s1);
+    srlg    ($s2,$s3,32);
+    stg     ($s3,"$tweak+8($sp)");
+    llgfr   ($s3,$s3);
+LABEL("Lxts_dec_enter:");
+    x       ($s0,"0($inp)");              # tweak^=*(inp)
+    x       ($s1,"4($inp)");
+    x       ($s2,"8($inp)");
+    x       ($s3,"12($inp)");
+&{$z? \&stmg:\&stm} ($wr2,$wr3,"2*$SIZE_T($sp)");    # only two registers are changing
+&{$z? \&stg:\&st} ($outp,"14*$SIZE_T($sp)") if ($flavour !~ /linux/);  # z/OS needs outp preserved
+    la      ($AESE_key,"0($key1)");
+    bras    ($ra,"_s390x_AES_decrypt");
+&{$z? \&lmg:\&lm} ($wr2,$wr5,"2*$SIZE_T($sp)");      # regs 2->5
+&{$z? \&lg:\&l} ($outp,"14*$SIZE_T($sp)") if ($flavour !~ /linux/);    # z/OS needs outp preserved
+    x       ($s0,"$tweak+0($sp)");        # ^=tweak
+    x       ($s1,"$tweak+4($sp)");
+    x       ($s2,"$tweak+8($sp)");
+    x       ($s3,"$tweak+12($sp)");
+    st      ($s0,"0($outp,$inp)");
+    st      ($s1,"4($outp,$inp)");
+    st      ($s2,"8($outp,$inp)");
+    st      ($s3,"12($outp,$inp)");
+    la      ($inp,"16($inp)");
+&{$z? \&brctg:\&brct} ($len,LABEL("Lxts_dec_loop"));
+
+    llgc    ($len,"2*$SIZE_T-1($sp)");
+    nill    ($len,"0x0f");                # $len%16
+    jz      (LABEL("Lxts_dec_done"));
+
+    # generate pair of tweaks...
+    lrvg    ($s1,"$tweak+0($sp)");        # load the tweak in little-endian
+    lrvg    ($s3,"$tweak+8($sp)");
+    lghi    ($wr1,"0x87");
+    srag    ($wr0,$s3,63);                # broadcast upper bit
+    ngr     ($wr1,$wr0);                  # rem
+    algr    ($s1,$s1);
+    alcgr   ($s3,$s3);
+    xgr     ($s1,$wr1);
+    lrvgr   ($i2,$s1);                    # flip byte order
+    lrvgr   ($i3,$s3);
+    stmg    ($i2,$i3,"$tweak($sp)");      # save the 1st tweak
+    j       (LABEL("Lxts_dec_2ndtweak"));
+
+ALIGN(16);
+LABEL("Lxts_dec_short:");
+    llgc    ($len,"2*$SIZE_T-1($sp)");
+    nill    ($len,"0x0f");                # $len%16
+    lrvg    ($s1,"$tweak+0($sp)");        # load the tweak in little-endian
+    lrvg    ($s3,"$tweak+8($sp)");
+LABEL("Lxts_dec_2ndtweak:");
+    lghi    ($wr1,"0x87");
+    srag    ($wr0,$s3,63);                # broadcast upper bit
+    ngr     ($wr1,$wr0);                  # rem
+    algr    ($s1,$s1);
+    alcgr   ($s3,$s3);
+    xgr     ($s1,$wr1);
+    lrvgr   ($s1,$s1);                    # flip byte order
+    lrvgr   ($s3,$s3);
+    srlg    ($s0,$s1,32);                 # smash the tweak to 4x32-bits
+    stg     ($s1,"$tweak-16+0($sp)");     # save the 2nd tweak
+    llgfr   ($s1,$s1);
+    srlg    ($s2,$s3,32);
+    stg     ($s3,"$tweak-16+8($sp)");
+    llgfr   ($s3,$s3);
+
+    x       ($s0,"0($inp)");              # tweak_the_2nd^=*(inp)
+    x       ($s1,"4($inp)");
+    x       ($s2,"8($inp)");
+    x       ($s3,"12($inp)");
+&{$z? \&stmg:\&stm} ($wr2,$wr3,"2*$SIZE_T($sp)");  # regs 2->3
+    la      ($AESE_key,"0($key1)");
+    bras    ($ra,"_s390x_AES_decrypt");
+&{$z? \&lmg:\&lm} ($wr2,$wr5,"2*$SIZE_T($sp)");    # regs 2->5
+    x       ($s0,"$tweak-16+0($sp)");     # ^=tweak_the_2nd
+    x       ($s1,"$tweak-16+4($sp)");
+    x       ($s2,"$tweak-16+8($sp)");
+    x       ($s3,"$tweak-16+12($sp)");
+    st      ($s0,"0($outp,$inp)");
+    st      ($s1,"4($outp,$inp)");
+    st      ($s2,"8($outp,$inp)");
+    st      ($s3,"12($outp,$inp)");
+
+    la      ($i3,"0($outp,$inp)");        # put aside real $out
+LABEL("Lxts_dec_steal:");
+    llgc    ($wr0,"16($inp)");
+    llgc    ($wr1,"0($outp,$inp)");
+    stc     ($wr0,"0($outp,$inp)");
+    stc     ($wr1,"16($outp,$inp)");
+    la      ($inp,"1($inp)");
+    brct    ($len,LABEL("Lxts_dec_steal"));
+    la      ($outp,"0($i3)");             # restore real $out
+
+    lm      ($s0,$s3,"$tweak($sp)");      # load the 1st tweak
+    x       ($s0,"0($outp)");             # tweak^=*(inp)|stolen cipher-text
+    x       ($s1,"4($outp)");
+    x       ($s2,"8($outp)");
+    x       ($s3,"12($outp)");
+&{$z? \&stg:\&st} ($outp,"4*$SIZE_T($sp)");
+    la      ($AESE_key,"0($key1)");
+    bras    ($ra,"_s390x_AES_decrypt");
+&{$z? \&lg:\&l} ($outp,"4*$SIZE_T($sp)");
+    x       ($s0,"$tweak+0($sp)");        # ^=tweak
+    x       ($s1,"$tweak+4($sp)");
+    x       ($s2,"$tweak+8($sp)");
+    x       ($s3,"$tweak+12($sp)");
+    st      ($s0,"0($outp)");
+    st      ($s1,"4($outp)");
+    st      ($s2,"8($outp)");
+    st      ($s3,"12($outp)");
+    stg     ($sp,"$tweak-16+0($sp)");     # wipe 2nd tweak
+    stg     ($sp,"$tweak-16+8($sp)");
+LABEL("Lxts_dec_done:");
+    stg     ($sp,"$tweak+0($sp)");        # wipe tweak
+    stg     ($sp,"$tweak+8($sp)");        # twesk?
+&{$z? \&lmg:\&lm} ($key2,$ra,"6*$SIZE_T($sp)") if ($flavour =~ /linux/);  # regs on linux 5->14
+    BR_EXIT();
+
+FUNCTION_END("AES_xts_decrypt",$rv);
+}
+
+ASCIZ	("AES for s390x, CRYPTOGAMS by <appro\@openssl.org>");
+
+LOCAL_VARS_BEGIN();
+    ds    ("STCKSPCE", "2048F");
+    ds    ("STACK", "${stdframe}F");
+LOCAL_VARS_END();
+PERLASM_END();
diff --git a/crypto/aes/build.info b/crypto/aes/build.info
index 0f04863..80e046e 100644
--- a/crypto/aes/build.info
+++ b/crypto/aes/build.info
@@ -50,6 +50,7 @@ GENERATE[bsaes-armv7.S]=asm/bsaes-armv7.pl $(PERLASM_SCHEME)
 INCLUDE[bsaes-armv7.o]=..

 GENERATE[aes-s390x.S]=asm/aes-s390x.pl $(PERLASM_SCHEME)
+GENERATE[aes-s390x.s]=asm/aes-s390x.pl $(PERLASM_SCHEME)
 INCLUDE[aes-s390x.o]=..

 BEGINRAW[Makefile]
diff --git a/crypto/bn/asm/s390x-gf2m.pl b/crypto/bn/asm/s390x-gf2m.pl
index a7e4b8a..5c10c6d 100644
--- a/crypto/bn/asm/s390x-gf2m.pl
+++ b/crypto/bn/asm/s390x-gf2m.pl
@@ -1,5 +1,5 @@
 #! /usr/bin/env perl
-# Copyright 2011-2020 The OpenSSL Project Authors. All Rights Reserved.
+# Copyright 2011-2016 The OpenSSL Project Authors. All Rights Reserved.
 #
 # Licensed under the OpenSSL license (the "License").  You may not use
 # this file except in compliance with the License.  You can obtain a copy
@@ -31,198 +31,276 @@
 # (*)	gcc 4.1 was observed to deliver better results than gcc 4.3,
 #	so that improvement coefficients can vary from one specific
 #	setup to another.
+use strict;
+use FindBin qw($Bin);
+use lib "$Bin/../..";
+use perlasm::s390x qw(:MSA :DEFAULT :VX :LD AUTOLOAD LABEL INCLUDE FUNCTION_BEGIN FUNCTION_END LOCAL_FUNCTION LOCAL_FUNCTION_END OBJECT_BEGIN OBJECT_END BYTE LONG QUAD ALIGN ASCIZ TEXT GET_EXTERN LOCAL_VARS_BEGIN LOCAL_VARS_END ds);
+
+my ($flavour,$output,$DSA_OFF,$PARMS_OFF,$SIZE_T,$z);

 $flavour = shift;

+$DSA_OFF=2048;
+$SIZE_T = 8; # 64 bit, 31 bit zOS
 if ($flavour =~ /3[12]/) {
-        $SIZE_T=4;
-        $g="";
+   $z=0;	# 31/32 bit ABI
+   if($flavour =~ /linux/) {
+      $SIZE_T = 4;
+   }
+   $PARMS_OFF=2112
 } else {
-        $SIZE_T=8;
-        $g="g";
+   $z=1;	# 64 bit ABI
+   $PARMS_OFF=2176
 }

 while (($output=shift) && ($output!~/\w[\w\-]*\.\w+$/)) {}
 open STDOUT,">$output";

-$stdframe=16*$SIZE_T+4*8;
-
-$rp="%r2";
-$a1="%r3";
-$a0="%r4";
-$b1="%r5";
-$b0="%r6";
-
-$ra="%r14";
-$sp="%r15";
-
-@T=("%r0","%r1");
-@i=("%r12","%r13");
-
-($a1,$a2,$a4,$a8,$a12,$a48)=map("%r$_",(6..11));
-($lo,$hi,$b)=map("%r$_",(3..5)); $a=$lo; $mask=$a8;
-
-$code.=<<___;
-.text
-
-.type	_mul_1x1,\@function
-.align	16
-_mul_1x1:
-	lgr	$a1,$a
-	sllg	$a2,$a,1
-	sllg	$a4,$a,2
-	sllg	$a8,$a,3
-
-	srag	$lo,$a1,63			# broadcast 63rd bit
-	nihh	$a1,0x1fff
-	srag	@i[0],$a2,63			# broadcast 62nd bit
-	nihh	$a2,0x3fff
-	srag	@i[1],$a4,63			# broadcast 61st bit
-	nihh	$a4,0x7fff
-	ngr	$lo,$b
-	ngr	@i[0],$b
-	ngr	@i[1],$b
-
-	lghi	@T[0],0
-	lgr	$a12,$a1
-	stg	@T[0],`$stdframe+0*8`($sp)	# tab[0]=0
-	xgr	$a12,$a2
-	stg	$a1,`$stdframe+1*8`($sp)	# tab[1]=a1
-	 lgr	$a48,$a4
-	stg	$a2,`$stdframe+2*8`($sp)	# tab[2]=a2
-	 xgr	$a48,$a8
-	stg	$a12,`$stdframe+3*8`($sp)	# tab[3]=a1^a2
-	 xgr	$a1,$a4
-
-	stg	$a4,`$stdframe+4*8`($sp)	# tab[4]=a4
-	xgr	$a2,$a4
-	stg	$a1,`$stdframe+5*8`($sp)	# tab[5]=a1^a4
-	xgr	$a12,$a4
-	stg	$a2,`$stdframe+6*8`($sp)	# tab[6]=a2^a4
-	 xgr	$a1,$a48
-	stg	$a12,`$stdframe+7*8`($sp)	# tab[7]=a1^a2^a4
-	 xgr	$a2,$a48
-
-	stg	$a8,`$stdframe+8*8`($sp)	# tab[8]=a8
-	xgr	$a12,$a48
-	stg	$a1,`$stdframe+9*8`($sp)	# tab[9]=a1^a8
-	 xgr	$a1,$a4
-	stg	$a2,`$stdframe+10*8`($sp)	# tab[10]=a2^a8
-	 xgr	$a2,$a4
-	stg	$a12,`$stdframe+11*8`($sp)	# tab[11]=a1^a2^a8
-
-	xgr	$a12,$a4
-	stg	$a48,`$stdframe+12*8`($sp)	# tab[12]=a4^a8
-	 srlg	$hi,$lo,1
-	stg	$a1,`$stdframe+13*8`($sp)	# tab[13]=a1^a4^a8
-	 sllg	$lo,$lo,63
-	stg	$a2,`$stdframe+14*8`($sp)	# tab[14]=a2^a4^a8
-	 srlg	@T[0],@i[0],2
-	stg	$a12,`$stdframe+15*8`($sp)	# tab[15]=a1^a2^a4^a8
-
-	lghi	$mask,`0xf<<3`
-	sllg	$a1,@i[0],62
-	 sllg	@i[0],$b,3
-	srlg	@T[1],@i[1],3
-	 ngr	@i[0],$mask
-	sllg	$a2,@i[1],61
-	 srlg	@i[1],$b,4-3
-	xgr	$hi,@T[0]
-	 ngr	@i[1],$mask
-	xgr	$lo,$a1
-	xgr	$hi,@T[1]
-	xgr	$lo,$a2
-
-	xg	$lo,$stdframe(@i[0],$sp)
-	srlg	@i[0],$b,8-3
-	ngr	@i[0],$mask
-___
+PERLASM_BEGIN($flavour,$output);
+
+my ($stdframe,$rp,$b1,$b0,$ra,$sp,@T,@i);
+my ($a0,$a1,$a2,$a4,$a8,$a12,$a48);
+my ($lo,$hi,$b,$a,$mask);
+my ($n,@r);
+my ($wr0,$wr1);
+my $rv;
+
+if($flavour =~ /linux/) {
+	$stdframe=16*$SIZE_T+4*8;
+
+	$rp="%r2";
+	$a1="%r3";
+	$a0="%r4";
+	$b1="%r5";
+	$b0="%r6";
+
+	$wr0="%r0";
+	$wr1="%r1";
+
+	$ra="%r14";
+	$sp="%r15";
+
+	@T=("%r0","%r1");
+	@i=("%r12","%r13");
+
+	($a1,$a2,$a4,$a8,$a12,$a48)=map("%r$_",(6..11));  # a1 seems to be above also, so this is probably breaking the a1 parameter access.
+	($lo,$hi,$b)=map("%r$_",(3..5)); $a=$lo; $mask=$a8;
+	$rv = "%r2";
+} else {
+	$stdframe=16*$SIZE_T+4*8;
+
+	$rp="R2";	# passed in reg1
+	$a1="R3";	# passed in reg2
+	$a0="R4";	# passed in reg3
+	$b1="R5";	# passed in DSA
+	$b0="R6";	# passed in DSA
+
+	$wr0="R0";
+	$wr1="R1";
+
+	$ra="R14";
+	$sp="R15";
+
+	@T=("R0","R1");
+	@i=("R12","R13");
+
+	($a1,$a2,$a4,$a8,$a12,$a48)=map("R$_",(6..11));  # a1 seems to be above also, so this is probably breaking the a1 parameter access.
+	($lo,$hi,$b)=map("R$_",(3..5));
+	$a=$lo; $mask=$a8;
+	$rv = "R3";
+}
+
+
+
+	TEXT();
+LOCAL_FUNCTION("_mul_1x1");		# Not sure on parameters
+
+	lgr	($a1,$a);
+	sllg	($a2,$a,1);
+	sllg	($a4,$a,2);
+	sllg	($a8,$a,3);
+
+	srag	($lo,$a1,63);			# broadcast 63rd bit
+	nihh	($a1,0x1fff);
+	srag	(@i[0],$a2,63);			# broadcast 62nd bit
+	nihh	($a2,0x3fff);
+	srag	(@i[1],$a4,63);			# broadcast 61st bit
+	nihh	($a4,0x7fff);
+	ngr	($lo,$b);
+	ngr	(@i[0],$b);
+	ngr	(@i[1],$b);
+
+	lghi	(@T[0],0);
+	lgr	($a12,$a1);
+	stg	(@T[0],"$stdframe+0*8($sp)");	# tab[0]=0
+	xgr	($a12,$a2);
+	stg	($a1,"$stdframe+1*8($sp)");	# tab[1]=a1
+	lgr	($a48,$a4);
+	stg	($a2,"$stdframe+2*8($sp)");	# tab[2]=a2
+	xgr	($a48,$a8);
+	stg	($a12,"$stdframe+3*8($sp)");	# tab[3]=a1^a2
+	xgr	($a1,$a4);
+
+	stg	($a4,"$stdframe+4*8($sp)");	# tab[4]=a4
+	xgr	($a2,$a4);
+	stg	($a1,"$stdframe+5*8($sp)");	# tab[5]=a1^a4
+	xgr	($a12,$a4);
+	stg	($a2,"$stdframe+6*8($sp)");	# tab[6]=a2^a4
+	xgr	($a1,$a48);
+	stg	($a12,"$stdframe+7*8($sp)");	# tab[7]=a1^a2^a4
+	xgr	($a2,$a48);
+
+	stg	($a8,"$stdframe+8*8($sp)");	# tab[8]=a8
+	xgr	($a12,$a48);
+	stg	($a1,"$stdframe+9*8($sp)");	# tab[9]=a1^a8
+	xgr	($a1,$a4);
+	stg	($a2,"$stdframe+10*8($sp)");	# tab[10]=a2^a8
+	xgr	($a2,$a4);
+	stg	($a12,"$stdframe+11*8($sp)");	# tab[11]=a1^a2^a8
+
+	xgr	($a12,$a4);
+	stg	($a48,"$stdframe+12*8($sp)");	# tab[12]=a4^a8
+	srlg	($hi,$lo,1);
+	stg	($a1,"$stdframe+13*8($sp)");	# tab[13]=a1^a4^a8
+	sllg	($lo,$lo,63);
+	stg	($a2,"$stdframe+14*8($sp)");	# tab[14]=a2^a4^a8
+	srlg	(@T[0],@i[0],2);
+	stg	($a12,"$stdframe+15*8($sp)");	# tab[15]=a1^a2^a4^a8
+
+	lghi	($mask,0xf<<3);
+	sllg	($a1,@i[0],62);
+	sllg	(@i[0],$b,3);
+	srlg	(@T[1],@i[1],3);
+	ngr	(@i[0],$mask);
+	sllg	($a2,@i[1],61);
+	srlg	(@i[1],$b,4-3);
+	xgr	($hi,@T[0]);
+	ngr	(@i[1],$mask);
+	xgr	($lo,$a1);
+	xgr	($hi,@T[1]);
+	xgr	($lo,$a2);
+
+	xg		($lo,"$stdframe(@i[0],$sp)");
+	srlg	(@i[0],$b,8-3);
+	ngr	(@i[0],$mask);
+
 for($n=1;$n<14;$n++) {
-$code.=<<___;
-	lg	@T[1],$stdframe(@i[1],$sp)
-	srlg	@i[1],$b,`($n+2)*4`-3
-	sllg	@T[0],@T[1],`$n*4`
-	ngr	@i[1],$mask
-	srlg	@T[1],@T[1],`64-$n*4`
-	xgr	$lo,@T[0]
-	xgr	$hi,@T[1]
-___
+	lg		(@T[1],"$stdframe(@i[1],$sp)");
+	srlg	(@i[1],$b,"(($n+2)*4)-3");
+	sllg	(@T[0],@T[1],"$n*4");
+	ngr	(@i[1],$mask);
+	srlg	(@T[1],@T[1],64-$n*4);
+	xgr	($lo,@T[0]);
+	xgr	($hi,@T[1]);
+
 	push(@i,shift(@i)); push(@T,shift(@T));
 }
-$code.=<<___;
-	lg	@T[1],$stdframe(@i[1],$sp)
-	sllg	@T[0],@T[1],`$n*4`
-	srlg	@T[1],@T[1],`64-$n*4`
-	xgr	$lo,@T[0]
-	xgr	$hi,@T[1]
-
-	lg	@T[0],$stdframe(@i[0],$sp)
-	sllg	@T[1],@T[0],`($n+1)*4`
-	srlg	@T[0],@T[0],`64-($n+1)*4`
-	xgr	$lo,@T[1]
-	xgr	$hi,@T[0]
-
-	br	$ra
-.size	_mul_1x1,.-_mul_1x1
-
-.globl	bn_GF2m_mul_2x2
-.type	bn_GF2m_mul_2x2,\@function
-.align	16
-bn_GF2m_mul_2x2:
-	stm${g}	%r3,%r15,3*$SIZE_T($sp)
-
-	lghi	%r1,-$stdframe-128
-	la	%r0,0($sp)
-	la	$sp,0(%r1,$sp)			# alloca
-	st${g}	%r0,0($sp)			# back chain
-___
+
+	lg		(@T[1],"$stdframe(@i[1],$sp)");
+	sllg	(@T[0],@T[1],$n*4);
+	srlg	(@T[1],@T[1],64-$n*4);
+	xgr	($lo,@T[0]);
+	xgr	($hi,@T[1]);
+
+	lg		(@T[0],"$stdframe(@i[0],$sp)");
+	sllg	(@T[1],@T[0],($n+1)*4);
+	srlg	(@T[0],@T[0],64-($n+1)*4);
+	xgr	($lo,@T[1]);
+	xgr	($hi,@T[0]);
+	br	($ra);
+LOCAL_FUNCTION_END("_mul_1x1",$rv);
+
+#
+#void bn_GF2m_mul_2x2(BN_ULONG *r, BN_ULONG a1, BN_ULONG a0, BN_ULONG b1, BN_ULONG b0);
+#
+FUNCTION_BEGIN("bn_GF2m_mul_2x2",5,"true");
+  if ($flavour =~ /linux/) {
+	&{$z? \&stmg :\&stm}	("%r3","%r15","3*$SIZE_T($sp)");
+  } else {
+&{$z? \&lg:\&l} ("R9","$DSA_OFF(R4)");            # Get DSA address
+    if ($z == 0) {
+        # In 31 bit pointers are 4 bytes long, BN_ULONG are 8 bytes long
+        # *r takes up 4 bytes, we don't need to reload this parameter because z/OS got it right.
+        # But *r only takes up 4 bytes the other parameters take up 8 bytes. The 4 bytes at the front must be accounted for all the following parameters.
+        lg      ("R2","$PARMS_OFF+4+$SIZE_T*0(R9)"); # Get a1
+        lg      ("R3","$PARMS_OFF+4+$SIZE_T*1(R9)"); # Get a0
+        lg      ($b1,"$PARMS_OFF+4+$SIZE_T*2(R9)"); # Get b1
+        lg      ($b0,"$PARMS_OFF+4+$SIZE_T*3(R9)"); # Get b0
+    } else {
+        lg      ($b1,"$PARMS_OFF+$SIZE_T*3(R9)"); # Get b1
+        lg      ($b0,"$PARMS_OFF+$SIZE_T*4(R9)"); # Get b0
+    }
+
+    # Set the sp to the end of the STACK variable to allow it to go backwards. $sp = STACK+sizeof(STACK)-sizeof(savearea) or
+    # DC STACK 240F, DC SAVEAREA 16F
+    la      ($sp,"SAVEAREA");
+    &{$z? \&stg:\&st}	("R4","0($sp)");				# DSA pointer must be restored before returning - $a0 is R4 also
+    lgr     ($a0,"R3");
+    lgr     ("R3","R2");
+    lgr     ($rp,"R1");
+    stmg    ("R3","R6","3*$SIZE_T($sp)"); # Save parms
+  }
+
+    lghi	($wr1,-$stdframe-128);
+    la		($wr0,"0($sp)");
+	la		($sp,"0($wr1,$sp)");			# alloca
+	&{$z? \&stg : \&st}	($wr0,"0($sp)");			# back chain
+
+    if($flavour =~ /linux/) {
+	@r=map("%r$_",(6..9));
+	} else {
+	@r=map("R$_",(6..9));	# These regs aren't used for anything else after the last bras call
+	}
+
 if ($SIZE_T==8) {
-my @r=map("%r$_",(6..9));
-$code.=<<___;
-	bras	$ra,_mul_1x1			# a1Â·b1
-	stmg	$lo,$hi,16($rp)
-
-	lg	$a,`$stdframe+128+4*$SIZE_T`($sp)
-	lg	$b,`$stdframe+128+6*$SIZE_T`($sp)
-	bras	$ra,_mul_1x1			# a0Â·b0
-	stmg	$lo,$hi,0($rp)
-
-	lg	$a,`$stdframe+128+3*$SIZE_T`($sp)
-	lg	$b,`$stdframe+128+5*$SIZE_T`($sp)
-	xg	$a,`$stdframe+128+4*$SIZE_T`($sp)
-	xg	$b,`$stdframe+128+6*$SIZE_T`($sp)
-	bras	$ra,_mul_1x1			# (a0+a1)Â·(b0+b1)
-	lmg	@r[0],@r[3],0($rp)
-
-	xgr	$lo,$hi
-	xgr	$hi,@r[1]
-	xgr	$lo,@r[0]
-	xgr	$hi,@r[2]
-	xgr	$lo,@r[3]
-	xgr	$hi,@r[3]
-	xgr	$lo,$hi
-	stg	$hi,16($rp)
-	stg	$lo,8($rp)
-___
+	bras	($ra,"_mul_1x1");			# a1Â·b1
+	stmg	($lo,$hi,"16($rp)");
+
+	lg		($a,"$stdframe+128+4*$SIZE_T($sp)");
+	lg		($b,"$stdframe+128+6*$SIZE_T($sp)");
+	bras	($ra,"_mul_1x1");			# a0*b0
+	stmg	($lo,$hi,"0($rp)");
+
+	lg		($a,"$stdframe+128+3*$SIZE_T($sp)");
+	lg		($b,"$stdframe+128+5*$SIZE_T($sp)");
+	xg		($a,"$stdframe+128+4*$SIZE_T($sp)");
+	xg		($b,"$stdframe+128+6*$SIZE_T($sp)");
+	bras	($ra,"_mul_1x1");			# (a0+a1)*(b0+b1)
+	lmg	(@r[0],@r[3],"0($rp)");
+
+	xgr	($lo,$hi);
+	xgr	($hi,@r[1]);
+	xgr	($lo,@r[0]);
+	xgr	($hi,@r[2]);
+	xgr	($lo,@r[3]);
+	xgr	($hi,@r[3]);
+	xgr	($lo,$hi);
+	stg	($hi,"16($rp)");
+	stg	($lo,"8($rp)");
+} else {
+	sllg	($a,$a,32);
+	sllg	($b1,$b1,32);
+	&or	($a,$a0);
+	&or	($b1,$b0);
+	bras	($ra,"_mul_1x1");
+	rllg	($lo,$lo,32);
+	rllg	($hi,$hi,32);
+	stmg	($lo,$hi,"0($rp)");
+}
+
+if ($flavour =~ /linux/) {
+	&{$z?  \&lmg :\&lm}	("%r6","%r15","$stdframe+128+6*$SIZE_T($sp)");
 } else {
-$code.=<<___;
-	sllg	%r3,%r3,32
-	sllg	%r5,%r5,32
-	or	%r3,%r4
-	or	%r5,%r6
-	bras	$ra,_mul_1x1
-	rllg	$lo,$lo,32
-	rllg	$hi,$hi,32
-	stmg	$lo,$hi,0($rp)
-___
+	&{$z? \&lg:\&l} ("R4","$stdframe+128+0*$SIZE_T($sp)");
 }
-$code.=<<___;
-	lm${g}	%r6,%r15,`$stdframe+128+6*$SIZE_T`($sp)
-	br	$ra
-.size	bn_GF2m_mul_2x2,.-bn_GF2m_mul_2x2
-.string	"GF(2^m) Multiplication for s390x, CRYPTOGAMS by <appro\@openssl.org>"
-___
-
-$code =~ s/\`([^\`]*)\`/eval($1)/gem;
-print $code;
-close STDOUT or die "error closing STDOUT: $!";
+FUNCTION_END("bn_GF2m_mul_2x2",$rv);
+	ASCIZ	("GF(2^m) Multiplication for s390x, CRYPTOGAMS by <appro\@openssl.org>");
+
+
+#$code =~ s/\`([^\`]*)\`/eval($1)/gem; # Hopefully done inline now
+LOCAL_VARS_BEGIN();
+    ds    ("STACK", "240F");
+    ds    ("SAVEAREA", "16F");
+LOCAL_VARS_END();
+PERLASM_END();
+
diff --git a/crypto/bn/asm/s390x-mont.pl b/crypto/bn/asm/s390x-mont.pl
index bc8c895..00c51cd 100644
--- a/crypto/bn/asm/s390x-mont.pl
+++ b/crypto/bn/asm/s390x-mont.pl
@@ -1,5 +1,5 @@
 #! /usr/bin/env perl
-# Copyright 2007-2020 The OpenSSL Project Authors. All Rights Reserved.
+# Copyright 2007-2018 The OpenSSL Project Authors. All Rights Reserved.
 #
 # Licensed under the OpenSSL license (the "License").  You may not use
 # this file except in compliance with the License.  You can obtain a copy
@@ -51,234 +51,319 @@
 # On z990 it was measured to perform 2.6-2.2 times better than
 # compiler-generated code, less for longer keys...

+use strict;
+use FindBin qw($Bin);
+use lib "$Bin/../..";
+use perlasm::s390x qw(:MSA :DEFAULT :VX :LD AUTOLOAD LABEL INCLUDE FUNCTION_BEGIN FUNCTION_END OBJECT_BEGIN OBJECT_END BYTE LONG QUAD ALIGN ASCIZ TEXT GET_EXTERN LOCAL_VARS_BEGIN LOCAL_VARS_END BR_EXIT ds);
+
+my ($flavour,$output,$SIZE_T,$z,$stdframe,$sp);
+my ($mn0,$mn1,$rp,$ap,$bp,$np,$n0);
+my ($bi,$j,$ahi,$alo,$nhi,$nlo,$AHI,$NHI,$count,$num);
+my ($DSA_OFF,$PARMS_OFF);
+my ($wr0,$wr1,$wr8,$rv);
 $flavour = shift;

+$DSA_OFF=2048;
 if ($flavour =~ /3[12]/) {
 	$SIZE_T=4;
-	$g="";
+	$z = 0;  # 31/32 bit ABI
+	$PARMS_OFF=2112;
 } else {
 	$SIZE_T=8;
-	$g="g";
+	$z=1;    # 64 bit ABI
+	$PARMS_OFF=2176;
 }

 while (($output=shift) && ($output!~/\w[\w\-]*\.\w+$/)) {}
 open STDOUT,">$output";

-$stdframe=16*$SIZE_T+4*8;
+PERLASM_BEGIN($flavour,$output);
+
+if($flavour =~/linux/ ) {
+	$stdframe=16*$SIZE_T+4*8;

-$mn0="%r0";
-$num="%r1";
+	$mn0="%r0";	$wr0="%r0";
+	$num="%r1";

 # int bn_mul_mont(
-$rp="%r2";		# BN_ULONG *rp,
-$ap="%r3";		# const BN_ULONG *ap,
-$bp="%r4";		# const BN_ULONG *bp,
-$np="%r5";		# const BN_ULONG *np,
-$n0="%r6";		# const BN_ULONG *n0,
+	$rp="%r2";		# BN_ULONG *rp,
+	$ap="%r3";		# const BN_ULONG *ap,
+	$bp="%r4";		# const BN_ULONG *bp,
+	$np="%r5";		# const BN_ULONG *np,
+	$n0="%r6";		# const BN_ULONG *n0,
 #$num="160(%r15)"	# int num);
+
+	$rv="%r2";	$bi="%r2";	# zaps rp
+	$j="%r7";
+
+	$ahi="%r8";
+	$alo="%r9";
+	$nhi="%r10";
+	$nlo="%r11";
+	$AHI="%r12";
+	$NHI="%r13";
+	$count="%r14";
+	$sp="%r15";
+} else {
+	$stdframe=16*$SIZE_T+4*8;
+
+	$mn0="R0";	$wr0="R0";
+	$num="R1";
+
+# int bn_mul_mont(
+	$rp="R2";		# BN_ULONG *rp,
+	$ap="R3";		# const BN_ULONG *ap,
+	$bp="R4";		# const BN_ULONG *bp,
+	$np="R5";		# const BN_ULONG *np,	Passed in DSA
+	$n0="R6";		# const BN_ULONG *n0,	Passed in DSA
+#$num="160(%r15)"	# int num);				Passed in DSA
+
+	$bi="R2";	# zaps rp
+	$rv="R2";
+	$j="R7";
+
+	$ahi="R8";
+	$alo="R9";
+	$nhi="R10";
+	$nlo="R11";
+	$AHI="R12";
+	$NHI="R13";
+	$count="R14";
+	$sp="R15";
+}
+sub _dswap {
+	my $reg = shift;
+	if(($flavour =~ /linux/) && ($z == 0)) {
+		rllg ($reg,$reg,32);
+	}
+}
+# int bn_mul_mont(BN_ULONG *rp,const BN_ULONG *ap,const BN_ULONG *bp,const BN_ULONG *np,const BN_ULONG *n0,int num);
+	TEXT();
+	FUNCTION_BEGIN("bn_mul_mont",6,"true");
+
+# load parameters not passed in registers
+if ($flavour =~ /linux/) {
+	lgf		($num,"$stdframe+$SIZE_T-4($sp)");	# pull $num
+} else {
+   la      ($sp,"STACK");		# Setup stack for z/OS
+
+	&{$z? \&lg:\&l} ("R9","$DSA_OFF(R4)");			# Get callers DSA address
+
+	&{$z? \&stg:\&st} ("R4","0*$SIZE_T($sp)");			# save DSA on stack
+	&{$z? \&lgr:\&lr} ("R8","R3");						# Move bp into R8 and later into $bp which will corrupt the DSA (R4)
+	&{$z? \&lgr:\&lr} ($ap,"R2");						# Move ap into $ap
+	&{$z? \&lgr:\&lr} ($rp,"R1");						# Move rp into $rp
+
+	&{$z? \&lg:\&l} ($np,"$PARMS_OFF+$SIZE_T*3(R9)");	# Get np address
+	&{$z? \&lg:\&l} ($n0,"$PARMS_OFF+$SIZE_T*4(R9)");	# Get n0 address
+	&{$z? \&lg:\&l} ($num,"$PARMS_OFF+$SIZE_T*5(R9)");	# Get num
+}
+
+if ($flavour =~ /linux/) {
+	sla		($num,eval "log($SIZE_T)/log(2)");	# $num to enumerate bytes   jpf - change this to SIZE_T for 8 byte BN_ULONG
+	la		($bp,"0($num,$bp)");
+} else {
+	sla		($num,eval "log(8)/log(2)");	# $num to enumerate bytes   jpf - change this to SIZE_T for 8 byte BN_ULONG
+	la		("R8","0($num,R8)");	# Don't corrupt DSA pointer before branches below
+}
+
+	&{$z? \&stg:\&st}	($rp,"2*$SIZE_T($sp)");	# save rp
+
+	cghi	($num,16);		#
+	lghi	($rv,0);		# Set return code - linux shares r2 with $rp, zos shares r3 with $ap
+	BR_EXIT("l");			# if($num<16) return 0;

-$bi="%r2";	# zaps rp
-$j="%r7";
-
-$ahi="%r8";
-$alo="%r9";
-$nhi="%r10";
-$nlo="%r11";
-$AHI="%r12";
-$NHI="%r13";
-$count="%r14";
-$sp="%r15";
-
-$code.=<<___;
-.text
-.globl	bn_mul_mont
-.type	bn_mul_mont,\@function
-bn_mul_mont:
-	lgf	$num,`$stdframe+$SIZE_T-4`($sp)	# pull $num
-	sla	$num,`log($SIZE_T)/log(2)`	# $num to enumerate bytes
-	la	$bp,0($num,$bp)
-
-	st${g}	%r2,2*$SIZE_T($sp)
-
-	cghi	$num,16		#
-	lghi	%r2,0		#
-	blr	%r14		# if($num<16) return 0;
-___
-$code.=<<___ if ($flavour =~ /3[12]/);
-	tmll	$num,4
-	bnzr	%r14		# if ($num&1) return 0;
-___
-$code.=<<___ if ($flavour !~ /3[12]/);
-	cghi	$num,96		#
-	bhr	%r14		# if($num>96) return 0;
-___
-$code.=<<___;
-	stm${g}	%r3,%r15,3*$SIZE_T($sp)
-
-	lghi	$rp,-$stdframe-8	# leave room for carry bit
-	lcgr	$j,$num		# -$num
-	lgr	%r0,$sp
-	la	$rp,0($rp,$sp)
-	la	$sp,0($j,$rp)	# alloca
-	st${g}	%r0,0($sp)	# back chain
-
-	sra	$num,3		# restore $num
-	la	$bp,0($j,$bp)	# restore $bp
-	ahi	$num,-1		# adjust $num for inner loop
-	lg	$n0,0($n0)	# pull n0
-	_dswap	$n0
-
-	lg	$bi,0($bp)
-	_dswap	$bi
-	lg	$alo,0($ap)
-	_dswap	$alo
-	mlgr	$ahi,$bi	# ap[0]*bp[0]
-	lgr	$AHI,$ahi
-
-	lgr	$mn0,$alo	# "tp[0]"*n0
-	msgr	$mn0,$n0
-
-	lg	$nlo,0($np)	#
-	_dswap	$nlo
-	mlgr	$nhi,$mn0	# np[0]*m1
-	algr	$nlo,$alo	# +="tp[0]"
-	lghi	$NHI,0
-	alcgr	$NHI,$nhi
-
-	la	$j,8		# j=1
-	lr	$count,$num
-
-.align	16
-.L1st:
-	lg	$alo,0($j,$ap)
-	_dswap	$alo
-	mlgr	$ahi,$bi	# ap[j]*bp[0]
-	algr	$alo,$AHI
-	lghi	$AHI,0
-	alcgr	$AHI,$ahi
-
-	lg	$nlo,0($j,$np)
-	_dswap	$nlo
-	mlgr	$nhi,$mn0	# np[j]*m1
-	algr	$nlo,$NHI
-	lghi	$NHI,0
-	alcgr	$nhi,$NHI	# +="tp[j]"
-	algr	$nlo,$alo
-	alcgr	$NHI,$nhi
-
-	stg	$nlo,$stdframe-8($j,$sp)	# tp[j-1]=
-	la	$j,8($j)	# j++
-	brct	$count,.L1st
-
-	algr	$NHI,$AHI
-	lghi	$AHI,0
-	alcgr	$AHI,$AHI	# upmost overflow bit
-	stg	$NHI,$stdframe-8($j,$sp)
-	stg	$AHI,$stdframe($j,$sp)
-	la	$bp,8($bp)	# bp++
-
-.Louter:
-	lg	$bi,0($bp)	# bp[i]
-	_dswap	$bi
-	lg	$alo,0($ap)
-	_dswap	$alo
-	mlgr	$ahi,$bi	# ap[0]*bp[i]
-	alg	$alo,$stdframe($sp)	# +=tp[0]
-	lghi	$AHI,0
-	alcgr	$AHI,$ahi
-
-	lgr	$mn0,$alo
-	msgr	$mn0,$n0	# tp[0]*n0
-
-	lg	$nlo,0($np)	# np[0]
-	_dswap	$nlo
-	mlgr	$nhi,$mn0	# np[0]*m1
-	algr	$nlo,$alo	# +="tp[0]"
-	lghi	$NHI,0
-	alcgr	$NHI,$nhi
-
-	la	$j,8		# j=1
-	lr	$count,$num
-
-.align	16
-.Linner:
-	lg	$alo,0($j,$ap)
-	_dswap	$alo
-	mlgr	$ahi,$bi	# ap[j]*bp[i]
-	algr	$alo,$AHI
-	lghi	$AHI,0
-	alcgr	$ahi,$AHI
-	alg	$alo,$stdframe($j,$sp)# +=tp[j]
-	alcgr	$AHI,$ahi
-
-	lg	$nlo,0($j,$np)
-	_dswap	$nlo
-	mlgr	$nhi,$mn0	# np[j]*m1
-	algr	$nlo,$NHI
-	lghi	$NHI,0
-	alcgr	$nhi,$NHI
-	algr	$nlo,$alo	# +="tp[j]"
-	alcgr	$NHI,$nhi
-
-	stg	$nlo,$stdframe-8($j,$sp)	# tp[j-1]=
-	la	$j,8($j)	# j++
-	brct	$count,.Linner
-
-	algr	$NHI,$AHI
-	lghi	$AHI,0
-	alcgr	$AHI,$AHI
-	alg	$NHI,$stdframe($j,$sp)# accumulate previous upmost overflow bit
-	lghi	$ahi,0
-	alcgr	$AHI,$ahi	# new upmost overflow bit
-	stg	$NHI,$stdframe-8($j,$sp)
-	stg	$AHI,$stdframe($j,$sp)
-
-	la	$bp,8($bp)	# bp++
-	cl${g}	$bp,`$stdframe+8+4*$SIZE_T`($j,$sp)	# compare to &bp[num]
-	jne	.Louter
-
-	l${g}	$rp,`$stdframe+8+2*$SIZE_T`($j,$sp)	# reincarnate rp
-	la	$ap,$stdframe($sp)
-	ahi	$num,1		# restore $num, incidentally clears "borrow"
-
-	la	$j,0
-	lr	$count,$num
-.Lsub:	lg	$alo,0($j,$ap)
-	lg	$nlo,0($j,$np)
-	_dswap	$nlo
-	slbgr	$alo,$nlo
-	stg	$alo,0($j,$rp)
-	la	$j,8($j)
-	brct	$count,.Lsub
-	lghi	$ahi,0
-	slbgr	$AHI,$ahi	# handle upmost carry
-	lghi	$NHI,-1
-	xgr	$NHI,$AHI
-
-	la	$j,0
-	lgr	$count,$num
-.Lcopy:	lg	$ahi,$stdframe($j,$sp)	# conditional copy
-	lg	$alo,0($j,$rp)
-	ngr	$ahi,$AHI
-	ngr	$alo,$NHI
-	ogr	$alo,$ahi
-	_dswap	$alo
-	stg	$j,$stdframe($j,$sp)	# zap tp
-	stg	$alo,0($j,$rp)
-	la	$j,8($j)
-	brct	$count,.Lcopy
-
-	la	%r1,`$stdframe+8+6*$SIZE_T`($j,$sp)
-	lm${g}	%r6,%r15,0(%r1)
-	lghi	%r2,1		# signal "processed"
-	br	%r14
-.size	bn_mul_mont,.-bn_mul_mont
-.string	"Montgomery Multiplication for s390x, CRYPTOGAMS by <appro\@openssl.org>"
-___
-
-foreach (split("\n",$code)) {
-	s/\`([^\`]*)\`/eval $1/ge;
-	s/_dswap\s+(%r[0-9]+)/sprintf("rllg\t%s,%s,32",$1,$1) if($SIZE_T==4)/e;
-	print $_,"\n";
+if ($flavour =~ /3[12]/) {
+	tmll	($num,4);
+	BR_EXIT("nz");			# if ($num&1) return 0;
+} else {
+	cghi	($num,96);		#
+	BR_EXIT("h");			# if($num>96) return 0;
+}
+
+	lgr     ($bp,"R8") if ($flavour !~ /linux/);	# This corrupts DSA pointer (R4)
+if ($flavour =~ /linux/) {
+	&{$z? \&stmg:\&stm}	("%r3","%r15","3*$SIZE_T($sp)");
+} else {
+	&{$z? \&stmg:\&stm}	("R3","R4","3*$SIZE_T($sp)");
 }
-close STDOUT or die "error closing STDOUT: $!";
+
+	lghi	($rp,-$stdframe-8);	# leave room for carry bit
+	lcgr	($j,$num);		# -$num
+	lgr		($wr0,$sp);
+	la		($rp,"0($rp,$sp)");	# restore value overwritten by $rv
+	la		($sp,"0($j,$rp)");	# alloca
+	&{$z? \&stg:\&st }	($wr0,"0($sp)");	# back chain
+
+	sra		($num,3);		# restore $num      jpf - Above we sla of 2 for 32 bit and 3 for 64 bit...bug
+	la		($bp,"0($j,$bp)");	# restore $bp
+	ahi		($num,-1);		# adjust $num for inner loop
+	lg		($n0,"0($n0)");	# pull n0                                   jpf - need to clear high bits
+	_dswap	($n0);
+
+	lg		($bi,"0($bp)");
+	_dswap	($bi);
+	lg		($alo,"0($ap)");
+	_dswap	($alo);
+	mlgr	($ahi,$bi);		# ap[0]*bp[0]
+	lgr		($AHI,$ahi);
+
+	lgr		($mn0,$alo);	# "tp[0]"*n0
+	msgr	($mn0,$n0);
+
+	lg		($nlo,"0($np)");	#
+	_dswap	($nlo);
+	mlgr	($nhi,$mn0);	# np[0]*m1
+	algr	($nlo,$alo);	# +="tp[0]"
+	lghi	($NHI,0);
+	alcgr	($NHI,$nhi);
+
+	la		($j,"8($wr0)");	# j=1
+	lr		($count,$num);
+
+	ALIGN(16) if ($flavour =~ /linux/);
+LABEL("L1st:");
+	lg		($alo,"0($j,$ap)");
+	_dswap	($alo);
+	mlgr	($ahi,$bi);		# ap[j]*bp[0]
+	algr	($alo,$AHI);
+	lghi	($AHI,0);
+	alcgr	($AHI,$ahi);
+
+	lg		($nlo,"0($j,$np)");
+	_dswap	($nlo);
+	mlgr	($nhi,$mn0);	# np[j]*m1
+	algr	($nlo,$NHI);
+	lghi	($NHI,0);
+	alcgr	($nhi,$NHI);	# +="tp[j]"
+	algr	($nlo,$alo);
+	alcgr	($NHI,$nhi);
+
+	stg		($nlo,"$stdframe-8($j,$sp)");	# tp[j-1]=
+	la		($j,"8($j)");	# j++
+	brct	($count,LABEL("L1st"));
+
+	algr	($NHI,$AHI);
+	lghi	($AHI,0);
+	alcgr	($AHI,$AHI);	# upmost overflow bit
+	stg		($NHI,"$stdframe-8($j,$sp)");
+	stg		($AHI,"$stdframe($j,$sp)");
+	la		($bp,"8($bp)");	# bp++
+
+LABEL("Louter:");
+	lg		($bi,"0($bp)");		# bp[i]
+	_dswap	($bi);
+	lg		($alo,"0($ap)");
+	_dswap	($alo);
+	mlgr	($ahi,$bi);			# ap[0]*bp[i]
+	alg		($alo,"$stdframe($sp)");	# +=tp[0]
+	lghi	($AHI,0);
+	alcgr	($AHI,$ahi);
+
+	lgr		($mn0,$alo);
+	msgr	($mn0,$n0);			# tp[0]*n0
+
+	lg		($nlo,"0($np)");	# np[0]
+	_dswap	($nlo);
+	mlgr	($nhi,$mn0);		# np[0]*m1
+	algr	($nlo,$alo);		# +="tp[0]"
+	lghi	($NHI,0);
+	alcgr	($NHI,$nhi);
+
+	la		($j,"8($wr0)");		# j=1
+	lr		($count,$num);
+
+	ALIGN(16) if ($flavour =~ /linux/);
+LABEL("Linner:");
+	lg		($alo,"0($j,$ap)");
+	_dswap	($alo);
+	mlgr	($ahi,$bi);	# ap[j]*bp[i]
+	algr	($alo,$AHI);
+	lghi	($AHI,0);
+	alcgr	($ahi,$AHI);
+	alg		($alo,"$stdframe($j,$sp)"); # +=tp[j]
+	alcgr	($AHI,$ahi);
+
+	lg		($nlo,"0($j,$np)");
+	_dswap	($nlo);
+	mlgr	($nhi,$mn0);	# np[j]*m1
+	algr	($nlo,$NHI);
+	lghi	($NHI,0);
+	alcgr	($nhi,$NHI);
+	algr	($nlo,$alo);	# +="tp[j]"
+	alcgr	($NHI,$nhi);
+
+	stg		($nlo,"$stdframe-8($j,$sp)");	# tp[j-1]=
+	la		($j,"8($j)");	# j++
+	brct	($count,LABEL("Linner"));
+
+	algr	($NHI,$AHI);
+	lghi	($AHI,0);
+	alcgr	($AHI,$AHI);
+	alg		($NHI,"$stdframe($j,$sp)");# accumulate previous upmost overflow bit
+	lghi	($ahi,0);
+	alcgr	($AHI,$ahi);	# new upmost overflow bit
+	stg		($NHI,"$stdframe-8($j,$sp)");
+	stg		($AHI,"$stdframe($j,$sp)");
+
+	la		($bp,"8($bp)");	# bp++
+	&{$z? \&clg:\&cl}	($bp,"$stdframe+8+4*$SIZE_T($j,$sp)");	# compare to &bp[num]
+	jne	(LABEL("Louter"));
+
+	&{$z ? \&lg : \&l}	($rp,"$stdframe+8+2*$SIZE_T($j,$sp)");	# reincarnate rp
+	la		($ap,"$stdframe($sp)");
+	ahi	($num,1);		# restore $num, incidentally clears "borrow"
+
+	la		($j,"0($wr0)");
+	lr		($count,$num);
+LABEL("Lsub:");
+	lg		($alo,"0($j,$ap)");
+	lg		($nlo,"0($j,$np)");
+	_dswap($nlo);
+	slbgr	($alo,$nlo);
+	stg		($alo,"0($j,$rp)");
+	la		($j,"8($j)");
+	brct	($count,LABEL("Lsub"));
+	lghi	($ahi,0);
+	slbgr	($AHI,$ahi);	# handle upmost carry
+	lghi	($NHI,-1);
+	xgr		($NHI,$AHI);
+
+	la		($j,"0($wr0)");
+	lgr		($count,$num);
+LABEL("Lcopy:");
+	lg		($ahi,"$stdframe($j,$sp)");	# conditional copy
+	lg		($alo,"0($j,$rp)");
+	ngr		($ahi,$AHI);
+	ngr		($alo,$NHI);
+	ogr		($alo,$ahi);
+	_dswap($alo);
+	stg		($j,"$stdframe($j,$sp)");	# zap tp
+	stg		($alo,"0($j,$rp)");
+	la		($j,"8($j)");
+	brct	($count,LABEL("Lcopy"));
+
+if ($flavour =~ /linux/) {
+	la		("%r1","$stdframe+8+6*$SIZE_T($j,$sp)");
+	&{$z?\&lmg:\&lm}	("%r6","%r15","0(%r1)");
+} else {
+	&{$z ? \&lg : \&l}	("R4","$stdframe+8+0*$SIZE_T($j,$sp)");	 # reload DSA pointer, other regs will be restored by exit macro
+}
+	lghi	($rv,1);		# signal "processed"
+	FUNCTION_END("bn_mul_mont", $rv);
+
+	ASCIZ	("Montgomery Multiplication for s390x, CRYPTOGAMS by <appro\@openssl.org>");
+
+
+#foreach (split("\n",$code)) {
+#	s/\`([^\`]*)\`/eval $1/ge;
+#	s/_dswap\s+(%r[0-9]+)/sprintf("rllg\t%s,%s,32",$1,$1) if($SIZE_T==4)/e;
+#	print $_,"\n";
+#}
+
+LOCAL_VARS_BEGIN();
+	ds		("STACKSPACE","400F");
+    ds		("STACK", "0F");
+    ds      ("SAVEAREA","32F");
+LOCAL_VARS_END();
+PERLASM_END();
diff --git a/crypto/bn/build.info b/crypto/bn/build.info
index b9ed532..2dc7b0d 100644
--- a/crypto/bn/build.info
+++ b/crypto/bn/build.info
@@ -38,7 +38,10 @@ INCLUDE[bn-mips.o]=..
 GENERATE[mips-mont.S]=asm/mips-mont.pl $(PERLASM_SCHEME)
 INCLUDE[mips-mont.o]=..

+GENERATE[s390x.S]=asm/s390x.pl $(PERLASM_SCHEME)
 GENERATE[s390x-mont.S]=asm/s390x-mont.pl $(PERLASM_SCHEME)
+GENERATE[s390x.s]=asm/s390x.pl $(PERLASM_SCHEME)
+GENERATE[s390x-mont.s]=asm/s390x-mont.pl $(PERLASM_SCHEME)
 GENERATE[s390x-gf2m.s]=asm/s390x-gf2m.pl $(PERLASM_SCHEME)

 GENERATE[x86_64-mont.s]=asm/x86_64-mont.pl $(PERLASM_SCHEME)
diff --git a/crypto/build.info b/crypto/build.info
index 2c619c6..b772a17 100644
--- a/crypto/build.info
+++ b/crypto/build.info
@@ -32,6 +32,7 @@ INCLUDE[arm64cpuid.o]=.
 GENERATE[armv4cpuid.S]=armv4cpuid.pl $(PERLASM_SCHEME)
 INCLUDE[armv4cpuid.o]=.
 GENERATE[s390xcpuid.S]=s390xcpuid.pl $(PERLASM_SCHEME)
+GENERATE[s390xcpuid.s]=s390xcpuid.pl $(PERLASM_SCHEME)
 INCLUDE[s390xcpuid.o]=.

 IF[{- $config{target} =~ /^(?:Cygwin|mingw|VC-)/ -}]
diff --git a/crypto/chacha/asm/chacha-s390x.pl b/crypto/chacha/asm/chacha-s390x.pl
index dd66a9c..a780d31 100755
--- a/crypto/chacha/asm/chacha-s390x.pl
+++ b/crypto/chacha/asm/chacha-s390x.pl
@@ -1,7 +1,7 @@
 #! /usr/bin/env perl
-# Copyright 2016-2020 The OpenSSL Project Authors. All Rights Reserved.
+# Copyright 2016-2019 The OpenSSL Project Authors. All Rights Reserved.
 #
-# Licensed under the OpenSSL license (the "License").  You may not use
+# Licensed under the Apache License 2.0 (the "License").  You may not use
 # this file except in compliance with the License.  You can obtain a copy
 # in the file LICENSE in the source distribution or at
 # https://www.openssl.org/source/license.html
@@ -20,42 +20,92 @@
 #
 # 3 times faster than compiler-generated code.

-$flavour = shift;
+#
+# August 2018
+#
+# Add vx code path: 4x"vertical".
+#
+# Copyright IBM Corp. 2018
+# Author: Patrick Steuer <patrick.steuer@de.ibm.com>
+
+#
+# February 2019
+#
+# Add 6x"horizontal" VX implementation. It's ~25% faster than IBM's
+# 4x"vertical" submission [on z13] and >3 faster than scalar code.
+# But to harness overheads revert to transliteration of VSX code path
+# from chacha-ppc module, which is also 4x"vertical", to handle inputs
+# not longer than 256 bytes.
+
+#
+# July 2019
+# zOS support.
+# Peter Waltenberg <pwalten@au1.ibm.com>
+# Jon Furminger    <furming@us.ibm.com>
+#
+use strict;
+use FindBin qw($Bin);
+use lib "$Bin/../..";
+use perlasm::s390x qw(:DEFAULT :VX :LD AUTOLOAD LABEL INCLUDE FUNCTION_BEGIN LOCAL_FUNCTION FUNCTION_END LOCAL_FUNCTION_END OBJECT_BEGIN OBJECT_END LONG ALIGN ASCIZ TEXT GET_EXTERN LOCAL_VARS_BEGIN LOCAL_VARS_END BR_EXIT ds);
+
+my $flavour = shift;
+my $output;
+
+
+
+
+#print "ChaCha flavour = $flavour z=$z size_t = $SIZE_T\n";
+

+while (($output=shift) && ($output!~/\w[\w\-]*\.\w+$/)) {}
+
+PERLASM_BEGIN($flavour,$output);
+
+my ($sp,$frame,$stdframe);
+
+my (@x,@t,$a0,$b0,$a1,$a2,$a3,$b1,$b2,$b3,$c0,$c1,$c2,$c3,$d0,$d1,$d2,$d3,$xc,$xc_,$rv);
+my ($wr0,$wr1,$wr2,$wr3,$wr4,$wr5,$wr6,$wr7,$wr8,$wr9,$wr10,$wr11,$wr12,$wr13,$wr14);
+my ($z,$DSA_OFF,$PARMS_OFF,$SIZE_T);
+$DSA_OFF=2048;
 if ($flavour =~ /3[12]/) {
+	$z=0;	# 31/32 bit ABI
 	$SIZE_T=4;
-	$g="";
+	$PARMS_OFF=2112;
 } else {
+	$z=1;	# 64 bit ABI
 	$SIZE_T=8;
-	$g="g";
+	$PARMS_OFF=2176;
 }

-while (($output=shift) && ($output!~/\w[\w\-]*\.\w+$/)) {}
-open STDOUT,">$output";
-
-sub AUTOLOAD()		# thunk [simplified] x86-style perlasm
-{ my $opcode = $AUTOLOAD; $opcode =~ s/.*:://;
-    $code .= "\t$opcode\t".join(',',@_)."\n";
+$stdframe=16*$SIZE_T+4*8;
+if($flavour =~ /linux/) {
+    ($wr0,$wr1,$wr2,$wr3,$wr4,$wr5,$wr6,$wr7,$wr8,$wr9,$wr10,$wr11,$wr12,$wr13,$wr14)=map("%r$_",0..14);
+	$sp="%r15";
+	$rv = "%r2";
+} else {
+	($wr0,$wr1,$wr2,$wr3,$wr4,$wr5,$wr6,$wr7,$wr8,$wr9,$wr10,$wr11,$wr12,$wr13,$wr14)=map("R$_",0..14);
+	$sp="R15";
+	$rv = "R3";
 }

-my $sp="%r15";
-
-my $stdframe=16*$SIZE_T+4*8;
-my $frame=$stdframe+4*20;
-
-my ($out,$inp,$len,$key,$counter)=map("%r$_",(2..6));
-
-my @x=map("%r$_",(0..7,"x","x","x","x",(10..13)));
-my @t=map("%r$_",(8,9));
-
 sub ROUND {
-my ($a0,$b0,$c0,$d0)=@_;
-my ($a1,$b1,$c1,$d1)=map(($_&~3)+(($_+1)&3),($a0,$b0,$c0,$d0));
-my ($a2,$b2,$c2,$d2)=map(($_&~3)+(($_+1)&3),($a1,$b1,$c1,$d1));
-my ($a3,$b3,$c3,$d3)=map(($_&~3)+(($_+1)&3),($a2,$b2,$c2,$d2));
-my ($xc,$xc_)=map("\"$_\"",@t);
-my @x=map("\"$_\"",@x);
-
+	if($flavour =~ /linux/) {
+		@x=map("%r$_",(0..7,"x","x","x","x",(10..13)));
+		@t=map("%r$_",(8,9));
+		($a0,$b0,$c0,$d0)=@_;
+		($a1,$b1,$c1,$d1)=map(($_&~3)+(($_+1)&3),($a0,$b0,$c0,$d0));
+		($a2,$b2,$c2,$d2)=map(($_&~3)+(($_+1)&3),($a1,$b1,$c1,$d1));
+		($a3,$b3,$c3,$d3)=map(($_&~3)+(($_+1)&3),($a2,$b2,$c2,$d2));
+		($xc,$xc_)=map("$_",@t);
+	} else {
+		@x=map("R$_",(0..7,"x","x","x","x",(10..13)));
+		@t=map("R$_",(8,9));
+		($a0,$b0,$c0,$d0)=@_;
+		($a1,$b1,$c1,$d1)=map(($_&~3)+(($_+1)&3),($a0,$b0,$c0,$d0));
+		($a2,$b2,$c2,$d2)=map(($_&~3)+(($_+1)&3),($a1,$b1,$c1,$d1));
+		($a3,$b3,$c3,$d3)=map(($_&~3)+(($_+1)&3),($a2,$b2,$c2,$d2));
+		($xc,$xc_)=map("$_",@t);
+	}
 	# Consider order in which variables are addressed by their
 	# index:
 	#
@@ -78,249 +128,1073 @@ my @x=map("\"$_\"",@x);
 	# 'c' stores and loads in the middle, but none in the beginning
 	# or end.

-	(
-	"&alr	(@x[$a0],@x[$b0])",	# Q1
-	 "&alr	(@x[$a1],@x[$b1])",	# Q2
-	"&xr	(@x[$d0],@x[$a0])",
-	 "&xr	(@x[$d1],@x[$a1])",
-	"&rll	(@x[$d0],@x[$d0],16)",
-	 "&rll	(@x[$d1],@x[$d1],16)",
-
-	"&alr	($xc,@x[$d0])",
-	 "&alr	($xc_,@x[$d1])",
-	"&xr	(@x[$b0],$xc)",
-	 "&xr	(@x[$b1],$xc_)",
-	"&rll	(@x[$b0],@x[$b0],12)",
-	 "&rll	(@x[$b1],@x[$b1],12)",
-
-	"&alr	(@x[$a0],@x[$b0])",
-	 "&alr	(@x[$a1],@x[$b1])",
-	"&xr	(@x[$d0],@x[$a0])",
-	 "&xr	(@x[$d1],@x[$a1])",
-	"&rll	(@x[$d0],@x[$d0],8)",
-	 "&rll	(@x[$d1],@x[$d1],8)",
-
-	"&alr	($xc,@x[$d0])",
-	 "&alr	($xc_,@x[$d1])",
-	"&xr	(@x[$b0],$xc)",
-	 "&xr	(@x[$b1],$xc_)",
-	"&rll	(@x[$b0],@x[$b0],7)",
-	 "&rll	(@x[$b1],@x[$b1],7)",
-
-	"&stm	($xc,$xc_,'$stdframe+4*8+4*$c0($sp)')",	# reload pair of 'c's
-	"&lm	($xc,$xc_,'$stdframe+4*8+4*$c2($sp)')",
-
-	"&alr	(@x[$a2],@x[$b2])",	# Q3
-	 "&alr	(@x[$a3],@x[$b3])",	# Q4
-	"&xr	(@x[$d2],@x[$a2])",
-	 "&xr	(@x[$d3],@x[$a3])",
-	"&rll	(@x[$d2],@x[$d2],16)",
-	 "&rll	(@x[$d3],@x[$d3],16)",
-
-	"&alr	($xc,@x[$d2])",
-	 "&alr	($xc_,@x[$d3])",
-	"&xr	(@x[$b2],$xc)",
-	 "&xr	(@x[$b3],$xc_)",
-	"&rll	(@x[$b2],@x[$b2],12)",
-	 "&rll	(@x[$b3],@x[$b3],12)",
-
-	"&alr	(@x[$a2],@x[$b2])",
-	 "&alr	(@x[$a3],@x[$b3])",
-	"&xr	(@x[$d2],@x[$a2])",
-	 "&xr	(@x[$d3],@x[$a3])",
-	"&rll	(@x[$d2],@x[$d2],8)",
-	 "&rll	(@x[$d3],@x[$d3],8)",
-
-	"&alr	($xc,@x[$d2])",
-	 "&alr	($xc_,@x[$d3])",
-	"&xr	(@x[$b2],$xc)",
-	 "&xr	(@x[$b3],$xc_)",
-	"&rll	(@x[$b2],@x[$b2],7)",
-	 "&rll	(@x[$b3],@x[$b3],7)"
-	);
+	alr	(@x[$a0],@x[$b0]);	# Q1
+	alr	(@x[$a1],@x[$b1]);	# Q2
+	xr		(@x[$d0],@x[$a0]);
+	xr		(@x[$d1],@x[$a1]);
+	rll	(@x[$d0],@x[$d0],16);
+	rll	(@x[$d1],@x[$d1],16);
+
+	alr	($xc,@x[$d0]);
+	alr	($xc_,@x[$d1]);
+	xr		(@x[$b0],$xc);
+	xr		(@x[$b1],$xc_);
+	rll	(@x[$b0],@x[$b0],12);
+	rll	(@x[$b1],@x[$b1],12);
+
+	alr	(@x[$a0],@x[$b0]);
+	alr	(@x[$a1],@x[$b1]);
+	xr		(@x[$d0],@x[$a0]);
+	xr		(@x[$d1],@x[$a1]);
+	rll	(@x[$d0],@x[$d0],8);
+	rll	(@x[$d1],@x[$d1],8);
+
+	alr	($xc,@x[$d0]);
+	alr	($xc_,@x[$d1]);
+	xr		(@x[$b0],$xc);
+	xr		(@x[$b1],$xc_);
+	rll	(@x[$b0],@x[$b0],7);
+	rll	(@x[$b1],@x[$b1],7);
+
+	stm	($xc,$xc_,"$stdframe+4*8+4*$c0($sp)");	# reload pair of 'c's
+	lm		($xc,$xc_,"$stdframe+4*8+4*$c2($sp)");
+
+	alr	(@x[$a2],@x[$b2]);	# Q3
+	alr	(@x[$a3],@x[$b3]);	# Q4
+	xr		(@x[$d2],@x[$a2]);
+	xr		(@x[$d3],@x[$a3]);
+	rll	(@x[$d2],@x[$d2],16);
+	rll	(@x[$d3],@x[$d3],16);
+
+	alr	($xc,@x[$d2]);
+	alr	($xc_,@x[$d3]);
+	xr		(@x[$b2],$xc);
+	xr		(@x[$b3],$xc_);
+	rll	(@x[$b2],@x[$b2],12);
+	rll	(@x[$b3],@x[$b3],12);
+
+	alr	(@x[$a2],@x[$b2]);
+	alr	(@x[$a3],@x[$b3]);
+	xr		(@x[$d2],@x[$a2]);
+	xr		(@x[$d3],@x[$a3]);
+	rll	(@x[$d2],@x[$d2],8);
+	rll	(@x[$d3],@x[$d3],8);
+
+	alr	($xc,@x[$d2]);
+	alr	($xc_,@x[$d3]);
+	xr		(@x[$b2],$xc);
+	xr		(@x[$b3],$xc_);
+	rll	(@x[$b2],@x[$b2],7);
+	rll	(@x[$b3],@x[$b3],7);
+}
+
+sub VX_lane_ROUND {
+
+	my ($a0,$b0,$c0,$d0)=@_;
+	my ($a1,$b1,$c1,$d1)=map(($_&~3)+(($_+1)&3),($a0,$b0,$c0,$d0));
+	my ($a2,$b2,$c2,$d2)=map(($_&~3)+(($_+1)&3),($a1,$b1,$c1,$d1));
+	my ($a3,$b3,$c3,$d3)=map(($_&~3)+(($_+1)&3),($a2,$b2,$c2,$d2));
+	my @x;
+if ($flavour =~ /linux/) {
+	@x=map("%v$_",(0..15));
+} else {
+	@x=map("V$_",(0..15));
+}
+
+	vaf	(@x[$a0],@x[$a0],@x[$b0]);	# Q1
+	vx		(@x[$d0],@x[$d0],@x[$a0]);
+	verllf	(@x[$d0],@x[$d0],16);
+	vaf	(@x[$a1],@x[$a1],@x[$b1]);	# Q2
+	vx		(@x[$d1],@x[$d1],@x[$a1]);
+	verllf	(@x[$d1],@x[$d1],16);
+	vaf	(@x[$a2],@x[$a2],@x[$b2]);	# Q3
+	vx		(@x[$d2],@x[$d2],@x[$a2]);
+	verllf	(@x[$d2],@x[$d2],16);
+	vaf	(@x[$a3],@x[$a3],@x[$b3]);	# Q4
+	vx		(@x[$d3],@x[$d3],@x[$a3]);
+	verllf	(@x[$d3],@x[$d3],16);
+
+	vaf	(@x[$c0],@x[$c0],@x[$d0]);
+	vx		(@x[$b0],@x[$b0],@x[$c0]);
+	verllf	(@x[$b0],@x[$b0],12);
+	vaf	(@x[$c1],@x[$c1],@x[$d1]);
+	vx		(@x[$b1],@x[$b1],@x[$c1]);
+	verllf	(@x[$b1],@x[$b1],12);
+	vaf	(@x[$c2],@x[$c2],@x[$d2]);
+	vx		(@x[$b2],@x[$b2],@x[$c2]);
+	verllf	(@x[$b2],@x[$b2],12);
+	vaf	(@x[$c3],@x[$c3],@x[$d3]);
+	vx		(@x[$b3],@x[$b3],@x[$c3]);
+	verllf	(@x[$b3],@x[$b3],12);
+
+	vaf	(@x[$a0],@x[$a0],@x[$b0]);
+	vx		(@x[$d0],@x[$d0],@x[$a0]);
+	verllf	(@x[$d0],@x[$d0],8);
+	vaf	(@x[$a1],@x[$a1],@x[$b1]);
+	vx		(@x[$d1],@x[$d1],@x[$a1]);
+	verllf	(@x[$d1],@x[$d1],8);
+	vaf	(@x[$a2],@x[$a2],@x[$b2]);
+	vx		(@x[$d2],@x[$d2],@x[$a2]);
+	verllf	(@x[$d2],@x[$d2],8);
+	vaf	(@x[$a3],@x[$a3],@x[$b3]);
+	vx		(@x[$d3],@x[$d3],@x[$a3]);
+	verllf	(@x[$d3],@x[$d3],8);
+
+	vaf	(@x[$c0],@x[$c0],@x[$d0]);
+	vx		(@x[$b0],@x[$b0],@x[$c0]);
+	verllf	(@x[$b0],@x[$b0],7);
+	vaf	(@x[$c1],@x[$c1],@x[$d1]);
+	vx		(@x[$b1],@x[$b1],@x[$c1]);
+	verllf	(@x[$b1],@x[$b1],7);
+	vaf	(@x[$c2],@x[$c2],@x[$d2]);
+	vx		(@x[$b2],@x[$b2],@x[$c2]);
+	verllf	(@x[$b2],@x[$b2],7);
+	vaf	(@x[$c3],@x[$c3],@x[$d3]);
+	vx		(@x[$b3],@x[$b3],@x[$c3]);
+	verllf	(@x[$b3],@x[$b3],7);
+}
+
+sub VX_ROUND {
+
+	my @a=@_[0..5];
+	my @b=@_[6..11];
+	my @c=@_[12..17];
+	my @d=@_[18..23];
+	my $odd=@_[24];
+
+	vaf		(@a[$_],@a[$_],@b[$_]) for (0..5);
+	vx			(@d[$_],@d[$_],@a[$_]) for (0..5);
+	verllf	(@d[$_],@d[$_],16) for (0..5);
+
+	vaf		(@c[$_],@c[$_],@d[$_]) for (0..5);
+	vx			(@b[$_],@b[$_],@c[$_]) for (0..5);
+	verllf	(@b[$_],@b[$_],12) for (0..5);
+
+	vaf		(@a[$_],@a[$_],@b[$_]) for (0..5);
+	vx			(@d[$_],@d[$_],@a[$_]) for (0..5);
+	verllf	(@d[$_],@d[$_],8) for (0..5);
+
+	vaf		(@c[$_],@c[$_],@d[$_]) for (0..5);
+	vx			(@b[$_],@b[$_],@c[$_]) for (0..5);
+	verllf	(@b[$_],@b[$_],7) for (0..5);
+
+	vsldb		(@c[$_],@c[$_],@c[$_],8) for (0..5);
+	vsldb		(@b[$_],@b[$_],@b[$_],$odd?12:4) for (0..5);
+	vsldb		(@d[$_],@d[$_],@d[$_],$odd?4:12) for (0..5);
+}
+
+PERLASM_BEGIN($flavour,$output);
+
+INCLUDE	("s390x_arch.h","crypto/");
+TEXT	();
+
+################
+# void ChaCha20_ctr32(unsigned char *out, const unsigned char *inp, size_t len,
+#                     const unsigned int key[8], const unsigned int counter[4])
+my ($out,$inp,$len,$key,$counter);
+if ($flavour =~ /linux/) {
+	($out,$inp,$len,$key,$counter)=map("%r$_",(2..6));
+} else {
+	($out,$inp,$len,$key,$counter)=map("R$_",(2..6));
+}
+
+{
+	if ($flavour =~ /linux/) {
+		$frame=$stdframe+4*20;
+		@x=map("%r$_",(0..7,"x","x","x","x",(10..13)));
+		@t=map("%r$_",(8,9));
+	} else {
+		$frame=$stdframe+4*20;
+		@x=map("R$_",(0..7,"x","x","x","x",(10..13)));
+		@t=map("R$_",(8,9));
+	}
+
+FUNCTION_BEGIN("ChaCha20_ctr32",5,"true","stor8");
+if ($flavour =~ /linux/) {
+	larl	($wr1,"OPENSSL_s390xcap_P");
+} else {
+	la      ($sp,"STACK");		# setup stack
+	&{$z? \&stg:\&st} ("R4","15*$SIZE_T($sp)");	# Store R4 before it is corrupted (and in unused r15 slot so it won't get overwritten by saving $len)
+	&{$z? \&lg:\&l}	("R9","$DSA_OFF(R4)");      # Get DSA address, before corrupting R4
+
+	# move parms into appropriate regs
+	lgr		($len,"R3");						# R4 is now corrupted
+	lgr		($inp,"R2");
+	lgr		($out,"R1");
+	GET_EXTERN ($wr1,"OPENSSL_s390xcap_P");		# Get external before R5 is corrupted
+	&{$z? \&lg:\&l}	($key,"$PARMS_OFF+$SIZE_T*3(R9)");		# Get key from DSA - R5 is now corrupted
+	&{$z? \&lg:\&l}	($counter,"$PARMS_OFF+$SIZE_T*4(R9)");	# Get counter from DSA
+}
+
+	lghi	($wr0,64);
+&{$z? \&ltgr:\&ltr}	($len,$len);		# len==0?
+	BR_EXIT	("z");
+	lg		($wr1,"CS390X_STFLE+16($wr1)");
+&{$z? \&clgr:\&clr}	($len,$wr0);
+	jle		(LABEL("Lshort"));
+
+	tmhh	($wr1,0x4000);			# check for vx bit
+	jnz		(LABEL("LChaCha20_ctr32_vx"));
+
+
+LABEL	("Lshort:");
+	&{$z? \&aghi:\&ahi }	($len,-64);
+	&{$z? \&lghi:\&lhi }	($wr1,-$frame);
+	&{$z? \&stmg:\&stm }	("%r6","%r15","6*$SIZE_T($sp)") if ($flavour =~ /linux/);
+	&{$z? \&slgr:\&slr }	($out,$inp);	# difference
+	la		($len,"0($inp,$len)");	# end of input minus 64
+	larl	($wr7,LABEL("Lsigma"));
+	lgr		($wr0,$sp);
+	la		($sp,"0($wr1,$sp)");
+	&{$z? \&stg:\&st}	($wr0,"0($sp)");
+
+	lmg		($wr8,$wr11,"0($key)");	# load key
+	lmg		($wr12,$wr13,"0($counter)");	# load counter
+	lmg		($wr6,$wr7,"0($wr7)");		# load sigma constant
+
+	la		($wr14,"0($inp)");
+&{$z? \&stg:\&st}	($out,"$frame+3*$SIZE_T($sp)");
+&{$z? \&stg:\&st}	($len,"$frame+4*$SIZE_T($sp)");
+	stmg	($wr6,$wr13,"$stdframe($sp)");	# copy key schedule to stack
+	srlg	(@x[12],$wr12,32);	# 32-bit counter value
+	j		(LABEL("Loop_outer"));
+
+ALIGN(16);
+LABEL("Loop_outer:");
+	lm		(@x[0],@x[7],"$stdframe+4*0($sp)");		# load x[0]-x[7]
+	lm		(@t[0],@t[1],"$stdframe+4*10($sp)");	# load x[10]-x[11]
+	lm		(@x[13],@x[15],"$stdframe+4*13($sp)");	# load x[13]-x[15]
+	stm		(@t[0],@t[1],"$stdframe+4*8+4*10($sp)");# offload x[10]-x[11]
+	lm		(@t[0],@t[1],"$stdframe+4*8($sp)");	# load x[8]-x[9]
+	st		(@x[12],"$stdframe+4*12($sp)");	# save counter
+&{$z? \&stg:\&st}	($wr14,"$frame+2*$SIZE_T($sp)");# save input pointer
+	lhi		($wr14,10);
+	j		(LABEL("Loop"));
+
+ALIGN	(4);
+LABEL	("Loop:");
+	ROUND	(0, 4, 8,12);
+	ROUND	(0, 5,10,15);
+	brct	($wr14,LABEL("Loop")); # Needs changing for zOS - huh?
+
+&{$z? \&lg:\&l}	($wr14,"$frame+2*$SIZE_T($sp)");# pull input pointer
+	stm		(@t[0],@t[1],"$stdframe+4*8+4*8($sp)");	# offload x[8]-x[9]
+&{$z? \&lmg:\&lm}	(@t[0],@t[1],"$frame+3*$SIZE_T($sp)");
+
+	al		(@x[0],"$stdframe+4*0($sp)");	# accumulate key schedule
+	al		(@x[1],"$stdframe+4*1($sp)");
+	al		(@x[2],"$stdframe+4*2($sp)");
+	al		(@x[3],"$stdframe+4*3($sp)");
+	al		(@x[4],"$stdframe+4*4($sp)");
+	al		(@x[5],"$stdframe+4*5($sp)");
+	al		(@x[6],"$stdframe+4*6($sp)");
+	al		(@x[7],"$stdframe+4*7($sp)");
+	lrvr	(@x[0],@x[0]);
+	lrvr	(@x[1],@x[1]);
+	lrvr	(@x[2],@x[2]);
+	lrvr	(@x[3],@x[3]);
+	lrvr	(@x[4],@x[4]);
+	lrvr	(@x[5],@x[5]);
+	lrvr	(@x[6],@x[6]);
+	lrvr	(@x[7],@x[7]);
+	al		(@x[12],"$stdframe+4*12($sp)");
+	al		(@x[13],"$stdframe+4*13($sp)");
+	al		(@x[14],"$stdframe+4*14($sp)");
+	al		(@x[15],"$stdframe+4*15($sp)");
+	lrvr	(@x[12],@x[12]);
+	lrvr	(@x[13],@x[13]);
+	lrvr	(@x[14],@x[14]);
+	lrvr	(@x[15],@x[15]);
+
+	la		(@t[0],"0(@t[0],$wr14)");	# reconstruct output pointer
+&{$z? \&clgr:\&clr}	($wr14,@t[1]); # zoS - needs attention
+	jh		(LABEL("Ltail"));
+
+	x		(@x[0],"4*0($wr14)");	# xor with input
+	x		(@x[1],"4*1($wr14)");
+	st		(@x[0],"4*0(@t[0])");	# store output
+	x		(@x[2],"4*2($wr14)");
+	st		(@x[1],"4*1(@t[0])");
+	x		(@x[3],"4*3($wr14)");
+	st		(@x[2],"4*2(@t[0])");
+	x		(@x[4],"4*4($wr14)");
+	st		(@x[3],"4*3(@t[0])");
+	lm		(@x[0],@x[3],"$stdframe+4*8+4*8($sp)");	# load x[8]-x[11]
+	x		(@x[5],"4*5($wr14)");
+	st		(@x[4],"4*4(@t[0])");
+	x		(@x[6],"4*6($wr14)");
+	al		(@x[0],"$stdframe+4*8($sp)");
+	st		(@x[5],"4*5(@t[0])");
+	x		(@x[7],"4*7($wr14)");
+	al		(@x[1],"$stdframe+4*9($sp)");
+	st		(@x[6],"4*6(@t[0])");
+	x		(@x[12],"4*12($wr14)");
+	al		(@x[2],"$stdframe+4*10($sp)");
+	st		(@x[7],"4*7(@t[0])");
+	x		(@x[13],"4*13($wr14)");
+	al		(@x[3],"$stdframe+4*11($sp)");
+	st		(@x[12],"4*12(@t[0])");
+	x		(@x[14],"4*14($wr14)");
+	st		(@x[13],"4*13(@t[0])");
+	x		(@x[15],"4*15($wr14)");
+	st		(@x[14],"4*14(@t[0])");
+	lrvr	(@x[0],@x[0]);
+	st		(@x[15],"4*15(@t[0])");
+	lrvr	(@x[1],@x[1]);
+	lrvr	(@x[2],@x[2]);
+	lrvr	(@x[3],@x[3]);
+	lhi		(@x[12],1);
+	x		(@x[0],"4*8($wr14)");
+	al		(@x[12],"$stdframe+4*12($sp)");	# increment counter
+	x		(@x[1],"4*9($wr14)");
+	st		(@x[0],"4*8(@t[0])");
+	x		(@x[2],"4*10($wr14)");
+	st		(@x[1],"4*9(@t[0])");
+	x		(@x[3],"4*11($wr14)");
+	st		(@x[2],"4*10(@t[0])");
+	st		(@x[3],"4*11(@t[0])");
+
+&{$z?	\&clgr:\&clr}	($wr14,@t[1]);	# done yet?
+	la		($wr14,"64($wr14)");
+	jl		(LABEL("Loop_outer"));
+
+LABEL	("Ldone:");
+	xgr		($wr0,$wr0);
+	xgr		($wr1,$wr1);
+	xgr		($wr2,$wr2);
+	xgr		($wr3,$wr3);
+	stmg	($wr0,$wr3,"$stdframe+4*4($sp)");	# wipe key copy
+	stmg	($wr0,$wr3,"$stdframe+4*12($sp)");
+if ($flavour =~ /linux/) {
+	&{$z? \&lmg:\&lm}	("%r6","%r15","$frame+6*$SIZE_T($sp)");
+} else {
+	&{$z? \&lg:\&l}	("R4","$frame+15*$SIZE_T($sp)");
+}
+	BR_EXIT	();
+
+ALIGN(16);
+LABEL("Ltail:");
+	la		(@t[1],"64($t[1])");
+	stm		(@x[0],@x[7],"$stdframe+4*0($sp)");
+&{$z? \&slgr:\&slr}	(@t[1],$wr14);
+	lm		(@x[0],@x[3],"$stdframe+4*8+4*8($sp)");
+&{$z? \&lghi:\&lhi}	(@x[6],0);
+	stm		(@x[12],@x[15],"$stdframe+4*12($sp)");
+	al		(@x[0],"$stdframe+4*8($sp)");
+	al		(@x[1],"$stdframe+4*9($sp)");
+	al		(@x[2],"$stdframe+4*10($sp)");
+	al		(@x[3],"$stdframe+4*11($sp)");
+	lrvr	(@x[0],@x[0]);
+	lrvr	(@x[1],@x[1]);
+	lrvr	(@x[2],@x[2]);
+	lrvr	(@x[3],@x[3]);
+	stm		(@x[0],@x[3],"$stdframe+4*8($sp)");
+
+LABEL("Loop_tail:");
+	llgc	(@x[4],"0(@x[6],$wr14)");
+	llgc	(@x[5],"$stdframe(@x[6],$sp)");
+	xr		(@x[5],@x[4]);
+	stc		(@x[5],"0(@x[6],@t[0])");
+	la		(@x[6],"1(@x[6])");
+	brct	(@t[1],LABEL("Loop_tail"));
+
+	j		(LABEL("Ldone"));
+
+FUNCTION_END("ChaCha20_ctr32",$rv);
+#SIZE	("ChaCha20_ctr32",".-ChaCha20_ctr32");
+}
+
+########################################################################
+# 4x"vertical" layout minimizes amount of instructions, but pipeline
+# runs underutilized [because of vector instructions' high latency].
+# On the other hand minimum amount of data it takes to fully utilize
+# the pipeline is higher, so that effectively, short inputs would be
+# processed slower. Hence this code path targeting <=256 bytes lengths.
+#
+# Notes: This function is not called from outside the assembler module, well right now at least.
+# Originally it was a local function however on z/OS we have to make it a real function so that the
+# Exit macro is used to return to the caller, as this function returns directly back to the caller
+# of ChaCha20_ctr32 rather than returning to ChaCha20_ctr32. As the z/OS exit macro is used to handle
+# the DSA processing (don't try to do it yourself, if it ever changes you will get bitten) the entry
+# macro although it generates code that is not actually executed, is required by the assembler. So,
+# ChaCha20_ctr32_4x must be a function so that it can exit correctly.
+#
+{
+my ($xa0,$xa1,$xa2,$xa3, $xb0,$xb1,$xb2,$xb3, $xc0,$xc1,$xc2,$xc3, $xd0,$xd1,$xd2,$xd3);
+my @K;
+my $CTR;
+my ($xt0,$xt1,$xt2,$xt3);
+my $beperm;
+my $FRAME=$stdframe+4*16;
+if ($flavour =~ /linux/) {
+    ($xa0,$xa1,$xa2,$xa3, $xb0,$xb1,$xb2,$xb3,
+     $xc0,$xc1,$xc2,$xc3, $xd0,$xd1,$xd2,$xd3)=map("%v$_",(0..15));
+
+	@K=map("%v$_",(16..19));
+	$CTR="%v26";
+	($xt0,$xt1,$xt2,$xt3)=map("%v$_",(27..30));
+	$beperm="%v31";
+} else {
+    ($xa0,$xa1,$xa2,$xa3, $xb0,$xb1,$xb2,$xb3,
+     $xc0,$xc1,$xc2,$xc3, $xd0,$xd1,$xd2,$xd3)=map("V$_",(0..15));
+
+	@K=map("V$_",(16..19));
+	$CTR="V26";
+	($xt0,$xt1,$xt2,$xt3)=map("V$_",(27..30));
+	$beperm="V31";
+}
+
+ALIGN	(32);
+FUNCTION_BEGIN("ChaCha20_ctr32_4x",5);
+LABEL	("LChaCha20_ctr32_4x:");
+
+&{$z? \&stmg:\&stm}	("%r6","%r7","6*$SIZE_T($sp)") if ($flavour =~ /linux/);
+if (!$z) {
+	std		("%f4","16*$SIZE_T+2*8($sp)");
+	std		("%f6","16*$SIZE_T+3*8($sp)");
+}
+&{$z? \&lghi:\&lhi}	($wr1,-$FRAME);
+	lgr		($wr0,$sp);
+	la		($sp,"0($wr1,$sp)");
+&{$z? \&stg:\&st}	($wr0,"0($sp)");	# back-chain
+if ($z) {
+	std		("%f8","$stdframe+8*0($sp)");
+	std		("%f9","$stdframe+8*1($sp)");
+	std		("%f10","$stdframe+8*2($sp)");
+	std		("%f11","$stdframe+8*3($sp)");
+	std		("%f12","$stdframe+8*4($sp)");
+	std		("%f13","$stdframe+8*5($sp)");
+	std		("%f14","$stdframe+8*6($sp)");
+	std		("%f15","$stdframe+8*7($sp)");
+}
+	larl	($wr7,LABEL("Lsigma"));
+	lhi		($wr0,10);
+	lhi		($wr1,0);
+
+	vl		(@K[0],"0($wr7)");		# load sigma
+	vl		(@K[1],"0($key)");		# load key
+	vl		(@K[2],"16($key)");
+	vl		(@K[3],"0($counter)");		# load counter
+
+	vl		($beperm,"0x40($wr7)");
+	vl		($xt1,"0x50($wr7)");
+	vrepf	($CTR,@K[3],0);
+	vlvgf	(@K[3],$wr1,0);			# clear @K[3].word[0]
+	vaf		($CTR,$CTR,$xt1);
+
+#LABEL	("Loop_outer_4x");
+	vlm		($xa0,$xa3,"0x60($wr7)");	# load [smashed] sigma
+
+	vrepf	($xb0,@K[1],0);			# smash the key
+	vrepf	($xb1,@K[1],1);
+	vrepf	($xb2,@K[1],2);
+	vrepf	($xb3,@K[1],3);
+
+	vrepf	($xc0,@K[2],0);
+	vrepf	($xc1,@K[2],1);
+	vrepf	($xc2,@K[2],2);
+	vrepf	($xc3,@K[2],3);
+
+	vlr		($xd0,$CTR);
+	vrepf	($xd1,@K[3],1);
+	vrepf	($xd2,@K[3],2);
+	vrepf	($xd3,@K[3],3);
+
+LABEL("Loop_4x:");
+	VX_lane_ROUND(0, 4, 8,12);
+	VX_lane_ROUND(0, 5,10,15);
+	brct	($wr0,LABEL("Loop_4x"));
+
+	vaf		($xd0,$xd0,$CTR);
+
+	vmrhf	($xt0,$xa0,$xa1);		# transpose data
+	vmrhf	($xt1,$xa2,$xa3);
+	vmrlf	($xt2,$xa0,$xa1);
+	vmrlf	($xt3,$xa2,$xa3);
+	vpdi	($xa0,$xt0,$xt1,0b0000);
+	vpdi	($xa1,$xt0,$xt1,0b0101);
+	vpdi	($xa2,$xt2,$xt3,0b0000);
+	vpdi	($xa3,$xt2,$xt3,0b0101);
+
+	vmrhf	($xt0,$xb0,$xb1);
+	vmrhf	($xt1,$xb2,$xb3);
+	vmrlf	($xt2,$xb0,$xb1);
+	vmrlf	($xt3,$xb2,$xb3);
+	vpdi	($xb0,$xt0,$xt1,0b0000);
+	vpdi	($xb1,$xt0,$xt1,0b0101);
+	vpdi	($xb2,$xt2,$xt3,0b0000);
+	vpdi	($xb3,$xt2,$xt3,0b0101);
+
+	vmrhf	($xt0,$xc0,$xc1);
+	vmrhf	($xt1,$xc2,$xc3);
+	vmrlf	($xt2,$xc0,$xc1);
+	vmrlf	($xt3,$xc2,$xc3);
+	vpdi	($xc0,$xt0,$xt1,0b0000);
+	vpdi	($xc1,$xt0,$xt1,0b0101);
+	vpdi	($xc2,$xt2,$xt3,0b0000);
+	vpdi	($xc3,$xt2,$xt3,0b0101);
+
+	vmrhf	($xt0,$xd0,$xd1);
+	vmrhf	($xt1,$xd2,$xd3);
+	vmrlf	($xt2,$xd0,$xd1);
+	vmrlf	($xt3,$xd2,$xd3);
+	vpdi	($xd0,$xt0,$xt1,0b0000);
+	vpdi	($xd1,$xt0,$xt1,0b0101);
+	vpdi	($xd2,$xt2,$xt3,0b0000);
+	vpdi	($xd3,$xt2,$xt3,0b0101);
+
+	#vrepif	($xt0,4);
+	#vaf	($CTR,$CTR,$xt0);		# next counter value
+
+	vaf		($xa0,$xa0,@K[0]);
+	vaf		($xb0,$xb0,@K[1]);
+	vaf		($xc0,$xc0,@K[2]);
+	vaf		($xd0,$xd0,@K[3]);
+
+	vperm	($xa0,$xa0,$xa0,$beperm);
+	vperm	($xb0,$xb0,$xb0,$beperm);
+	vperm	($xc0,$xc0,$xc0,$beperm);
+	vperm	($xd0,$xd0,$xd0,$beperm);
+
+	#&{$z? \&clgfi:\&clfi} ($len,0x40);
+	#jl	("Ltail_4x");
+
+	vlm		($xt0,$xt3,"0($inp)");
+
+	vx		($xt0,$xt0,$xa0);
+	vx		($xt1,$xt1,$xb0);
+	vx		($xt2,$xt2,$xc0);
+	vx		($xt3,$xt3,$xd0);
+
+	vstm	($xt0,$xt3,"0($out)");
+
+	la		($inp,"0x40($inp)");
+	la		($out,"0x40($out)");
+	&{$z? \&aghi:\&ahi}	($len,-0x40);
+	#je		("Ldone_4x");
+
+	vaf		($xa0,$xa1,@K[0]);
+	vaf		($xb0,$xb1,@K[1]);
+	vaf		($xc0,$xc1,@K[2]);
+	vaf		($xd0,$xd1,@K[3]);
+
+	vperm	($xa0,$xa0,$xa0,$beperm);
+	vperm	($xb0,$xb0,$xb0,$beperm);
+	vperm	($xc0,$xc0,$xc0,$beperm);
+	vperm	($xd0,$xd0,$xd0,$beperm);
+
+	&{$z? \&clgfi:\&clfi} ($len,0x40);
+	jl		(LABEL("Ltail_4x"));
+
+	vlm		($xt0,$xt3,"0($inp)");
+
+	vx		($xt0,$xt0,$xa0);
+	vx		($xt1,$xt1,$xb0);
+	vx		($xt2,$xt2,$xc0);
+	vx		($xt3,$xt3,$xd0);
+
+	vstm	($xt0,$xt3,"0($out)");
+
+	la		($inp,"0x40($inp)");
+	la		($out,"0x40($out)");
+	&{$z? \&aghi:\&ahi}	($len,-0x40);
+	je		(LABEL("Ldone_4x"));
+
+	vaf		($xa0,$xa2,@K[0]);
+	vaf		($xb0,$xb2,@K[1]);
+	vaf		($xc0,$xc2,@K[2]);
+	vaf		($xd0,$xd2,@K[3]);
+
+	vperm	($xa0,$xa0,$xa0,$beperm);
+	vperm	($xb0,$xb0,$xb0,$beperm);
+	vperm	($xc0,$xc0,$xc0,$beperm);
+	vperm	($xd0,$xd0,$xd0,$beperm);
+
+	&{$z? \&clgfi:\&clfi} ($len,0x40);
+	jl		(LABEL("Ltail_4x"));
+
+	vlm		($xt0,$xt3,"0($inp)");
+
+	vx		($xt0,$xt0,$xa0);
+	vx		($xt1,$xt1,$xb0);
+	vx		($xt2,$xt2,$xc0);
+	vx		($xt3,$xt3,$xd0);
+
+	vstm	($xt0,$xt3,"0($out)");
+
+	la		($inp,"0x40($inp)");
+	la		($out,"0x40($out)");
+	&{$z? \&aghi:\&ahi}	($len,-0x40);
+	je		(LABEL("Ldone_4x"));
+
+	vaf		($xa0,$xa3,@K[0]);
+	vaf		($xb0,$xb3,@K[1]);
+	vaf		($xc0,$xc3,@K[2]);
+	vaf		($xd0,$xd3,@K[3]);
+
+	vperm	($xa0,$xa0,$xa0,$beperm);
+	vperm	($xb0,$xb0,$xb0,$beperm);
+	vperm	($xc0,$xc0,$xc0,$beperm);
+	vperm	($xd0,$xd0,$xd0,$beperm);
+
+	&{$z? \&clgfi:\&clfi} ($len,0x40);
+	jl		(LABEL("Ltail_4x"));
+
+	vlm		($xt0,$xt3,"0($inp)");
+
+	vx		($xt0,$xt0,$xa0);
+	vx		($xt1,$xt1,$xb0);
+	vx		($xt2,$xt2,$xc0);
+	vx		($xt3,$xt3,$xd0);
+
+	vstm	($xt0,$xt3,"0($out)");
+
+	#la	$inp,0x40($inp));
+	#la	$out,0x40($out));
+	#lhi	%r0,10);
+	#&{$z?	\&aghi:\&ahi}	$len,-0x40);
+	#jne	.Loop_outer_4x);
+
+LABEL("Ldone_4x:");
+if (!$z) {
+	ld		("%f4","$FRAME+16*$SIZE_T+2*8($sp)");
+	ld		("%f6","$FRAME+16*$SIZE_T+3*8($sp)");
+} else {
+	ld		("%f8","$stdframe+8*0($sp)");
+	ld		("%f9","$stdframe+8*1($sp)");
+	ld		("%f10","$stdframe+8*2($sp)");
+	ld		("%f11","$stdframe+8*3($sp)");
+	ld		("%f12","$stdframe+8*4($sp)");
+	ld		("%f13","$stdframe+8*5($sp)");
+	ld		("%f14","$stdframe+8*6($sp)");
+	ld		("%f15","$stdframe+8*7($sp)");
+}
+if ($flavour =~ /linux/) {
+	&{$z? \&lmg:\&lm} ("%r6","%r7","$FRAME+6*$SIZE_T($sp)");
+} else {
+	&{$z? \&lg:\&l}	("R4","$FRAME+15*$SIZE_T($sp)");
+}
+	la		($sp,"$FRAME($sp)");
+	BR_EXIT	();
+
+ALIGN(16);
+LABEL("Ltail_4x:");
+if (!$z) {
+	vlr		($xt0,$xb0);
+	ld		("%f4","$FRAME+16*$SIZE_T+2*8($sp)");
+	ld		("%f6","$FRAME+16*$SIZE_T+3*8($sp)");
+
+	vst		($xa0,"$stdframe+0x00($sp)");
+	vst		($xt0,"$stdframe+0x10($sp)");
+	vst		($xc0,"$stdframe+0x20($sp)");
+	vst		($xd0,"$stdframe+0x30($sp)");
+} else {
+	vlr		($xt0,$xc0);
+	ld		("%f8","$stdframe+8*0($sp)");
+	ld		("%f9","$stdframe+8*1($sp)");
+	ld		("%f10","$stdframe+8*2($sp)");
+	ld		("%f11","$stdframe+8*3($sp)");
+	vlr		($xt1,$xd0);
+	ld		("%f12","$stdframe+8*4($sp)");
+	ld		("%f13","$stdframe+8*5($sp)");
+	ld		("%f14","$stdframe+8*6($sp)");
+	ld		("%f15","$stdframe+8*7($sp)");
+
+	vst		($xa0,"$stdframe+0x00($sp)");
+	vst		($xb0,"$stdframe+0x10($sp)");
+	vst		($xt0,"$stdframe+0x20($sp)");
+	vst		($xt1,"$stdframe+0x30($sp)");
+}
+	lghi	($wr1,0);
+
+LABEL("Loop_tail_4x:");
+	llgc	($wr5,"0($wr1,$inp)");
+	llgc	($wr6,"$stdframe($wr1,$sp)");
+	xr		($wr6,"$wr5");
+	stc		($wr6,"0($wr1,$out)");
+	la		($wr1,"1($wr1)");
+	brct	($len,LABEL("Loop_tail_4x"));
+
+if ($flavour =~ /linux/) {
+	&{$z? \&lmg:\&lm} ("%r6","%r7","$FRAME+6*$SIZE_T($sp)");
+} else {
+	&{$z? \&lg:\&l}	("R4","$FRAME+15*$SIZE_T($sp)");
+}
+	la	($sp,"$FRAME($sp)");
+
+FUNCTION_END("ChaCha20_ctr32_4x",$rv);
+}
+
+########################################################################
+# 6x"horizontal" layout is optimal fit for the platform in its current
+# shape, more specifically for given vector instructions' latency. Well,
+# computational part of 8x"vertical" would be faster, but it consumes
+# all registers and dealing with that will diminish the return...
+#
+{
+my ($a0,$b0,$c0,$d0, $a1,$b1,$c1,$d1, $a2,$b2,$c2,$d2, $a3,$b3,$c3,$d3, $a4,$b4,$c4,$d4, $a5,$b5,$c5,$d5);
+my @K;
+my ($t0,$t1,$t2,$t3);
+my $beperm;
+my $FRAME=$stdframe + 4*16;
+if ($flavour =~ /linux/) {
+	($a0,$b0,$c0,$d0, $a1,$b1,$c1,$d1,
+    $a2,$b2,$c2,$d2, $a3,$b3,$c3,$d3,
+    $a4,$b4,$c4,$d4, $a5,$b5,$c5,$d5)=map("%v$_",(0..23));
+
+	@K=map("%v$_",(27,24..26));
+	($t0,$t1,$t2,$t3)=map("%v$_",27..30);
+	$beperm="%v31";
+} else {
+	($a0,$b0,$c0,$d0, $a1,$b1,$c1,$d1,
+    $a2,$b2,$c2,$d2, $a3,$b3,$c3,$d3,
+    $a4,$b4,$c4,$d4, $a5,$b5,$c5,$d5)=map("V$_",(0..23));
+
+	@K=map("V$_",(27,24..26));
+	($t0,$t1,$t2,$t3)=map("V$_",27..30);
+	$beperm="V31";
+}
+
+#
+# ChaCha20_ctr32_vx
+#
+# Notes: This function is not called from outside the assembler module, well right now at least.
+# Originally it was a local function however on z/OS we have to make it a real function so that the
+# Exit macro is used to return to the caller, as this function returns directly back to the caller
+# of ChaCha20_ctr32 rather than returning to ChaCha20_ctr32. As the z/OS exit macro is used to handle
+# the DSA processing (don't try to do it yourself, if it ever changes you will get bitten) the entry
+# macro although it generates code that is not actually executed, is required by the assembler. So,
+# ChaCha20_ctr32_vx must be a function so that it can exit correctly.
+#
+FUNCTION_BEGIN("ChaCha20_ctr32_vx",5);
+
+LABEL("LChaCha20_ctr32_vx:");
+&{$z? \&clgfi:\&clfi}	($len,256);
+	jle		(LABEL("LChaCha20_ctr32_4x"));
+&{$z? \&stmg:\&stm}	("%r6","%r7","6*$SIZE_T($sp)") if ($flavour =~ /linux/);
+if (!$z) {
+	std		("%f4","16*$SIZE_T+2*8($sp)");
+	std		("%f6","16*$SIZE_T+3*8($sp)");
+}
+&{$z? \&lghi:\&lhi}	($wr1,-$FRAME);
+	lgr		($wr0,$sp);
+	la		($sp,"0($wr1,$sp)");
+&{$z? \&stg:\&st}	($wr0,"0($sp)");	# back-chain
+if ($z) {
+	std		("%f8","$FRAME-8*8($sp)");
+	std		("%f9","$FRAME-8*7($sp)");
+	std		("%f10","$FRAME-8*6($sp)");
+	std		("%f11","$FRAME-8*5($sp)");
+	std		("%f12","$FRAME-8*4($sp)");
+	std		("%f13","$FRAME-8*3($sp)");
+	std		("%f14","$FRAME-8*2($sp)");
+	std		("%f15","$FRAME-8*1($sp)");
+}
+	larl	($wr7,LABEL("Lsigma"));
+	lhi		($wr0,10);
+
+	vlm	(@K[1],@K[2],"0($key)");	# load key
+	vl	(@K[3],"0($counter)");		# load counter
+
+	vlm	(@K[0],"$beperm","0($wr7)");	# load sigma, increments, ...
+
+LABEL("Loop_outer_vx:");
+	vlr		($a0,@K[0]);
+	vlr		($b0,@K[1]);
+	vlr		($a1,@K[0]);
+	vlr		($b1,@K[1]);
+	vlr		($a2,@K[0]);
+	vlr		($b2,@K[1]);
+	vlr		($a3,@K[0]);
+	vlr		($b3,@K[1]);
+	vlr		($a4,@K[0]);
+	vlr		($b4,@K[1]);
+	vlr		($a5,@K[0]);
+	vlr		($b5,@K[1]);
+
+	vlr		($d0,@K[3]);
+	vaf		($d1,@K[3],$t1);		# K[3]+1
+	vaf		($d2,@K[3],$t2);		# K[3]+2
+	vaf		($d3,@K[3],$t3);		# K[3]+3
+	vaf		($d4,$d2,$t2);			# K[3]+4
+	vaf		($d5,$d2,$t3);			# K[3]+5
+
+	vlr		($c0,@K[2]);
+	vlr		($c1,@K[2]);
+	vlr		($c2,@K[2]);
+	vlr		($c3,@K[2]);
+	vlr		($c4,@K[2]);
+	vlr		($c5,@K[2]);
+
+	vlr		($t1,$d1);
+	vlr		($t2,$d2);
+	vlr		($t3,$d3);
+
+ALIGN(4) if ($flavour =~ /linux/);
+LABEL("Loop_vx:");
+
+	VX_ROUND($a0,$a1,$a2,$a3,$a4,$a5,
+		 $b0,$b1,$b2,$b3,$b4,$b5,
+		 $c0,$c1,$c2,$c3,$c4,$c5,
+		 $d0,$d1,$d2,$d3,$d4,$d5,
+		 0);
+
+	VX_ROUND($a0,$a1,$a2,$a3,$a4,$a5,
+		 $b0,$b1,$b2,$b3,$b4,$b5,
+		 $c0,$c1,$c2,$c3,$c4,$c5,
+		 $d0,$d1,$d2,$d3,$d4,$d5,
+		 1);
+
+	brct	($wr0,LABEL("Loop_vx"));
+
+	vaf		($a0,$a0,@K[0]);
+	vaf		($b0,$b0,@K[1]);
+	vaf		($c0,$c0,@K[2]);
+	vaf		($d0,$d0,@K[3]);
+	vaf		($a1,$a1,@K[0]);
+	vaf		($d1,$d1,$t1);			# +K[3]+1
+
+	vperm	($a0,$a0,$a0,$beperm);
+	vperm	($b0,$b0,$b0,$beperm);
+	vperm	($c0,$c0,$c0,$beperm);
+	vperm	($d0,$d0,$d0,$beperm);
+
+&{$z? \&clgfi:\&clfi}	($len,0x40);
+	jl		(LABEL("Ltail_vx"));
+
+	vaf		($d2,$d2,$t2);			# +K[3]+2
+	vaf		($d3,$d3,$t3);			# +K[3]+3
+	vlm		($t0,$t3,"0($inp)");
+
+	vx		($a0,$a0,$t0);
+	vx		($b0,$b0,$t1);
+	vx		($c0,$c0,$t2);
+	vx		($d0,$d0,$t3);
+
+	vlm		(@K[0],$t3,"0($wr7)");		# re-load sigma and increments
+
+	vstm	($a0,$d0,"0($out)");
+
+	la		($inp,"0x40($inp)");
+	la		($out,"0x40($out)");
+&{$z? \&aghi:\&ahi}	($len,-0x40);
+	je		(LABEL("Ldone_vx"));
+
+	vaf		($b1,$b1,@K[1]);
+	vaf		($c1,$c1,@K[2]);
+
+	vperm	($a0,$a1,$a1,$beperm);
+	vperm	($b0,$b1,$b1,$beperm);
+	vperm	($c0,$c1,$c1,$beperm);
+	vperm	($d0,$d1,$d1,$beperm);
+
+&{$z? \&clgfi:\&clfi} ($len,0x40);
+	jl		(LABEL("Ltail_vx"));
+
+	vlm		($a1,$d1,"0($inp)");
+
+	vx		($a0,$a0,$a1);
+	vx		($b0,$b0,$b1);
+	vx		($c0,$c0,$c1);
+	vx		($d0,$d0,$d1);
+
+	vstm	($a0,$d0,"0($out)");
+
+	la		($inp,"0x40($inp)");
+	la		($out,"0x40($out)");
+&{$z? \&aghi:\&ahi}	($len,-0x40);
+	je		(LABEL("Ldone_vx"));
+
+	vaf		($a2,$a2,@K[0]);
+	vaf		($b2,$b2,@K[1]);
+	vaf		($c2,$c2,@K[2]);
+
+	vperm	($a0,$a2,$a2,$beperm);
+	vperm	($b0,$b2,$b2,$beperm);
+	vperm	($c0,$c2,$c2,$beperm);
+	vperm	($d0,$d2,$d2,$beperm);
+
+&{$z? \&clgfi:\&clfi}	($len,0x40);
+	jl		(LABEL("Ltail_vx"));
+
+	vlm		($a1,$d1,"0($inp)");
+
+	vx		($a0,$a0,$a1);
+	vx		($b0,$b0,$b1);
+	vx		($c0,$c0,$c1);
+	vx		($d0,$d0,$d1);
+
+	vstm	($a0,$d0,"0($out)");
+
+	la		($inp,"0x40($inp)");
+	la		($out,"0x40($out)");
+&{$z? \&aghi:\&ahi}	($len,-0x40);
+	je		(LABEL("Ldone_vx"));
+
+	vaf		($a3,$a3,@K[0]);
+	vaf		($b3,$b3,@K[1]);
+	vaf		($c3,$c3,@K[2]);
+	vaf		($d2,@K[3],$t3);		# K[3]+3
+
+	vperm	($a0,$a3,$a3,$beperm);
+	vperm	($b0,$b3,$b3,$beperm);
+	vperm	($c0,$c3,$c3,$beperm);
+	vperm	($d0,$d3,$d3,$beperm);
+
+&{$z? \&clgfi:\&clfi}	($len,0x40);
+	jl		(LABEL("Ltail_vx"));
+
+	vaf		($d3,$d2,$t1);			# K[3]+4
+	vlm		($a1,$d1,"0($inp)");
+
+	vx		($a0,$a0,$a1);
+	vx		($b0,$b0,$b1);
+	vx		($c0,$c0,$c1);
+	vx		($d0,$d0,$d1);
+
+	vstm	($a0,$d0,"0($out)");
+
+	la		($inp,"0x40($inp)");
+	la		($out,"0x40($out)");
+&{$z? \&aghi:\&ahi}	($len,-0x40);
+	je		(LABEL("Ldone_vx"));
+
+	vaf		($a4,$a4,@K[0]);
+	vaf		($b4,$b4,@K[1]);
+	vaf		($c4,$c4,@K[2]);
+	vaf		($d4,$d4,$d3);			# +K[3]+4
+	vaf		($d3,$d3,$t1);			# K[3]+5
+	vaf		(@K[3],$d2,$t3);		# K[3]+=6
+
+	vperm	($a0,$a4,$a4,$beperm);
+	vperm	($b0,$b4,$b4,$beperm);
+	vperm	($c0,$c4,$c4,$beperm);
+	vperm	($d0,$d4,$d4,$beperm);
+
+&{$z? \&clgfi:\&clfi}	($len,0x40);
+	jl		(LABEL("Ltail_vx"));
+
+	vlm		($a1,$d1,"0($inp)");
+
+	vx		($a0,$a0,$a1);
+	vx		($b0,$b0,$b1);
+	vx		($c0,$c0,$c1);
+	vx		($d0,$d0,$d1);
+
+	vstm	($a0,$d0,"0($out)");
+
+	la		($inp,"0x40($inp)");
+	la		($out,"0x40($out)");
+&{$z? \&aghi:\&ahi}	($len,-0x40);
+	je		(LABEL("Ldone_vx"));
+
+	vaf		($a5,$a5,@K[0]);
+	vaf		($b5,$b5,@K[1]);
+	vaf		($c5,$c5,@K[2]);
+	vaf		($d5,$d5,$d3);			# +K[3]+5
+
+	vperm	($a0,$a5,$a5,$beperm);
+	vperm	($b0,$b5,$b5,$beperm);
+	vperm	($c0,$c5,$c5,$beperm);
+	vperm	($d0,$d5,$d5,$beperm);
+
+&{$z? \&clgfi:\&clfi} ($len,0x40);
+	jl		(LABEL("Ltail_vx"));
+
+	vlm		($a1,$d1,"0($inp)");
+
+	vx		($a0,$a0,$a1);
+	vx		($b0,$b0,$b1);
+	vx		($c0,$c0,$c1);
+	vx		($d0,$d0,$d1);
+
+	vstm	($a0,$d0,"0($out)");
+
+	la		($inp,"0x40($inp)");
+	la		($out,"0x40($out)");
+	lhi		($wr0,10);
+&{$z? \&aghi:\&ahi}	($len,-0x40);
+	jne		(LABEL("Loop_outer_vx"));
+
+LABEL("Ldone_vx:");
+if (!$z) {
+	ld		("%f4","$FRAME+16*$SIZE_T+2*8($sp)");
+	ld		("%f6","$FRAME+16*$SIZE_T+3*8($sp)");
+} else {
+	ld		("%f8","$FRAME-8*8($sp)");
+	ld		("%f9","$FRAME-8*7($sp)");
+	ld		("%f10","$FRAME-8*6($sp)");
+	ld		("%f11","$FRAME-8*5($sp)");
+	ld		("%f12","$FRAME-8*4($sp)");
+	ld		("%f13","$FRAME-8*3($sp)");
+	ld		("%f14","$FRAME-8*2($sp)");
+	ld		("%f15","$FRAME-8*1($sp)");
 }
+if ($flavour =~ /linux/) {
+	&{$z? \&lmg:\&lm} ("%r6","%r7","$FRAME+6*$SIZE_T($sp)");
+} else {
+	&{$z? \&lg:\&l}	("R4","$FRAME+15*$SIZE_T($sp)");
+}
+	la		($sp,"$FRAME($sp)");
+	BR_EXIT	();
+
+ALIGN(16);
+LABEL("Ltail_vx:");
+if (!$z) {
+	ld		("%f4","$FRAME+16*$SIZE_T+2*8($sp)");
+	ld		("%f6","$FRAME+16*$SIZE_T+3*8($sp)");
+} else {
+	ld		("%f8","$FRAME-8*8($sp)");
+	ld		("%f9","$FRAME-8*7($sp)");
+	ld		("%f10","$FRAME-8*6($sp)");
+	ld		("%f11","$FRAME-8*5($sp)");
+	ld		("%f12","$FRAME-8*4($sp)");
+	ld		("%f13","$FRAME-8*3($sp)");
+	ld		("%f14","$FRAME-8*2($sp)");
+	ld		("%f15","$FRAME-8*1($sp)");
+}
+	vstm	($a0,$d0,"$stdframe($sp)");
+	lghi	($wr1,0);
+
+LABEL("Loop_tail_vx:");
+	llgc	($wr5,"0($wr1,$inp)");
+	llgc	($wr6,"$stdframe($wr1,$sp)");
+	xr		($wr6,$wr5);
+	stc		($wr6,"0($wr1,$out)");
+	la		($wr1,"1($wr1)");
+	brct	($len,LABEL("Loop_tail_vx"));
+
+if ($flavour =~ /linux/) {
+	&{$z? \&lmg:\&lm}	("%r6","%r7","$FRAME+6*$SIZE_T($sp)");
+} else {
+	&{$z? \&lg:\&l}	("R4","$FRAME+15*$SIZE_T($sp)");
+}
+	la		($sp,"$FRAME($sp)");

-$code.=<<___;
-.text
-
-.globl	ChaCha20_ctr32
-.type	ChaCha20_ctr32,\@function
-.align	32
-ChaCha20_ctr32:
-	lt${g}r	$len,$len			# $len==0?
-	bzr	%r14
-	a${g}hi	$len,-64
-	l${g}hi	%r1,-$frame
-	stm${g}	%r6,%r15,`6*$SIZE_T`($sp)
-	sl${g}r	$out,$inp			# difference
-	la	$len,0($inp,$len)		# end of input minus 64
-	larl	%r7,.Lsigma
-	lgr	%r0,$sp
-	la	$sp,0(%r1,$sp)
-	st${g}	%r0,0($sp)
-
-	lmg	%r8,%r11,0($key)		# load key
-	lmg	%r12,%r13,0($counter)		# load counter
-	lmg	%r6,%r7,0(%r7)			# load sigma constant
-
-	la	%r14,0($inp)
-	st${g}	$out,$frame+3*$SIZE_T($sp)
-	st${g}	$len,$frame+4*$SIZE_T($sp)
-	stmg	%r6,%r13,$stdframe($sp)		# copy key schedule to stack
-	srlg	@x[12],%r12,32			# 32-bit counter value
-	j	.Loop_outer
-
-.align	16
-.Loop_outer:
-	lm	@x[0],@x[7],$stdframe+4*0($sp)		# load x[0]-x[7]
-	lm	@t[0],@t[1],$stdframe+4*10($sp)		# load x[10]-x[11]
-	lm	@x[13],@x[15],$stdframe+4*13($sp)	# load x[13]-x[15]
-	stm	@t[0],@t[1],$stdframe+4*8+4*10($sp)	# offload x[10]-x[11]
-	lm	@t[0],@t[1],$stdframe+4*8($sp)		# load x[8]-x[9]
-	st	@x[12],$stdframe+4*12($sp)		# save counter
-	st${g}	%r14,$frame+2*$SIZE_T($sp)		# save input pointer
-	lhi	%r14,10
-	j	.Loop
-
-.align	4
-.Loop:
-___
-	foreach (&ROUND(0, 4, 8,12)) { eval; }
-	foreach (&ROUND(0, 5,10,15)) { eval; }
-$code.=<<___;
-	brct	%r14,.Loop
-
-	l${g}	%r14,$frame+2*$SIZE_T($sp)		# pull input pointer
-	stm	@t[0],@t[1],$stdframe+4*8+4*8($sp)	# offload x[8]-x[9]
-	lm${g}	@t[0],@t[1],$frame+3*$SIZE_T($sp)
-
-	al	@x[0],$stdframe+4*0($sp)	# accumulate key schedule
-	al	@x[1],$stdframe+4*1($sp)
-	al	@x[2],$stdframe+4*2($sp)
-	al	@x[3],$stdframe+4*3($sp)
-	al	@x[4],$stdframe+4*4($sp)
-	al	@x[5],$stdframe+4*5($sp)
-	al	@x[6],$stdframe+4*6($sp)
-	al	@x[7],$stdframe+4*7($sp)
-	lrvr	@x[0],@x[0]
-	lrvr	@x[1],@x[1]
-	lrvr	@x[2],@x[2]
-	lrvr	@x[3],@x[3]
-	lrvr	@x[4],@x[4]
-	lrvr	@x[5],@x[5]
-	lrvr	@x[6],@x[6]
-	lrvr	@x[7],@x[7]
-	al	@x[12],$stdframe+4*12($sp)
-	al	@x[13],$stdframe+4*13($sp)
-	al	@x[14],$stdframe+4*14($sp)
-	al	@x[15],$stdframe+4*15($sp)
-	lrvr	@x[12],@x[12]
-	lrvr	@x[13],@x[13]
-	lrvr	@x[14],@x[14]
-	lrvr	@x[15],@x[15]
-
-	la	@t[0],0(@t[0],%r14)		# reconstruct output pointer
-	cl${g}r	%r14,@t[1]
-	jh	.Ltail
-
-	x	@x[0],4*0(%r14)			# xor with input
-	x	@x[1],4*1(%r14)
-	st	@x[0],4*0(@t[0])		# store output
-	x	@x[2],4*2(%r14)
-	st	@x[1],4*1(@t[0])
-	x	@x[3],4*3(%r14)
-	st	@x[2],4*2(@t[0])
-	x	@x[4],4*4(%r14)
-	st	@x[3],4*3(@t[0])
-	 lm	@x[0],@x[3],$stdframe+4*8+4*8($sp)	# load x[8]-x[11]
-	x	@x[5],4*5(%r14)
-	st	@x[4],4*4(@t[0])
-	x	@x[6],4*6(%r14)
-	 al	@x[0],$stdframe+4*8($sp)
-	st	@x[5],4*5(@t[0])
-	x	@x[7],4*7(%r14)
-	 al	@x[1],$stdframe+4*9($sp)
-	st	@x[6],4*6(@t[0])
-	x	@x[12],4*12(%r14)
-	 al	@x[2],$stdframe+4*10($sp)
-	st	@x[7],4*7(@t[0])
-	x	@x[13],4*13(%r14)
-	 al	@x[3],$stdframe+4*11($sp)
-	st	@x[12],4*12(@t[0])
-	x	@x[14],4*14(%r14)
-	st	@x[13],4*13(@t[0])
-	x	@x[15],4*15(%r14)
-	st	@x[14],4*14(@t[0])
-	 lrvr	@x[0],@x[0]
-	st	@x[15],4*15(@t[0])
-	 lrvr	@x[1],@x[1]
-	 lrvr	@x[2],@x[2]
-	 lrvr	@x[3],@x[3]
-	lhi	@x[12],1
-	 x	@x[0],4*8(%r14)
-	al	@x[12],$stdframe+4*12($sp)	# increment counter
-	 x	@x[1],4*9(%r14)
-	 st	@x[0],4*8(@t[0])
-	 x	@x[2],4*10(%r14)
-	 st	@x[1],4*9(@t[0])
-	 x	@x[3],4*11(%r14)
-	 st	@x[2],4*10(@t[0])
-	 st	@x[3],4*11(@t[0])
-
-	cl${g}r	%r14,@t[1]			# done yet?
-	la	%r14,64(%r14)
-	jl	.Loop_outer
-
-.Ldone:
-	xgr	%r0,%r0
-	xgr	%r1,%r1
-	xgr	%r2,%r2
-	xgr	%r3,%r3
-	stmg	%r0,%r3,$stdframe+4*4($sp)	# wipe key copy
-	stmg	%r0,%r3,$stdframe+4*12($sp)
-
-	lm${g}	%r6,%r15,`$frame+6*$SIZE_T`($sp)
-	br	%r14
-
-.align	16
-.Ltail:
-	la	@t[1],64($t[1])
-	stm	@x[0],@x[7],$stdframe+4*0($sp)
-	sl${g}r	@t[1],%r14
-	lm	@x[0],@x[3],$stdframe+4*8+4*8($sp)
-	l${g}hi	@x[6],0
-	stm	@x[12],@x[15],$stdframe+4*12($sp)
-	al	@x[0],$stdframe+4*8($sp)
-	al	@x[1],$stdframe+4*9($sp)
-	al	@x[2],$stdframe+4*10($sp)
-	al	@x[3],$stdframe+4*11($sp)
-	lrvr	@x[0],@x[0]
-	lrvr	@x[1],@x[1]
-	lrvr	@x[2],@x[2]
-	lrvr	@x[3],@x[3]
-	stm	@x[0],@x[3],$stdframe+4*8($sp)
-
-.Loop_tail:
-	llgc	@x[4],0(@x[6],%r14)
-	llgc	@x[5],$stdframe(@x[6],$sp)
-	xr	@x[5],@x[4]
-	stc	@x[5],0(@x[6],@t[0])
-	la	@x[6],1(@x[6])
-	brct	@t[1],.Loop_tail
-
-	j	.Ldone
-.size	ChaCha20_ctr32,.-ChaCha20_ctr32
-
-.align	32
-.Lsigma:
-.long	0x61707865,0x3320646e,0x79622d32,0x6b206574	# endian-neutral
-.asciz	"ChaCha20 for s390x, CRYPTOGAMS by <appro\@openssl.org>"
-.align	4
-___
-
-foreach (split("\n",$code)) {
-	s/\`([^\`]*)\`/eval $1/ge;
-
-	print $_,"\n";
+FUNCTION_END("ChaCha20_ctr32_vx",$rv);
 }
-close STDOUT or die "error closing STDOUT: $!";
+################
+
+OBJECT_BEGIN("Lsigma",32);
+
+LONG	(0x61707865,0x3320646e,0x79622d32,0x6b206574);	# endian-neutral sigma
+LONG	(1,0,0,0);
+LONG	(2,0,0,0);
+LONG	(3,0,0,0);
+LONG	(0x03020100,0x07060504,0x0b0a0908,0x0f0e0d0c);	# byte swap
+
+LONG	(0,1,2,3);
+LONG	(0x61707865,0x61707865,0x61707865,0x61707865);	# smashed sigma
+LONG	(0x3320646e,0x3320646e,0x3320646e,0x3320646e);
+LONG	(0x79622d32,0x79622d32,0x79622d32,0x79622d32);
+LONG	(0x6b206574,0x6b206574,0x6b206574,0x6b206574);
+OBJECT_END("Lsigma");
+ASCIZ	("ChaCha20 for s390x, CRYPTOGAMS by <appro\@openssl.org>");
+
+LOCAL_VARS_BEGIN();
+	ds		("STACKSPACE","178F");
+    ds		("STACK", "0F");
+    ds      ("SAVEAREA","32F");
+LOCAL_VARS_END();
+
+PERLASM_END();
diff --git a/crypto/chacha/build.info b/crypto/chacha/build.info
index e75ca72..40f529c 100644
--- a/crypto/chacha/build.info
+++ b/crypto/chacha/build.info
@@ -10,6 +10,7 @@ INCLUDE[chacha-armv4.o]=..
 GENERATE[chacha-armv8.S]=asm/chacha-armv8.pl $(PERLASM_SCHEME)
 INCLUDE[chacha-armv8.o]=..
 GENERATE[chacha-s390x.S]=asm/chacha-s390x.pl $(PERLASM_SCHEME)
+GENERATE[chacha-s390x.s]=asm/chacha-s390x.pl $(PERLASM_SCHEME)
 INCLUDE[chacha-s390x.o]=..

 BEGINRAW[Makefile(unix)]
diff --git a/crypto/cryptlib.c b/crypto/cryptlib.c
index f0ecc0b..90712db 100644
--- a/crypto/cryptlib.c
+++ b/crypto/cryptlib.c
@@ -462,11 +462,13 @@ int CRYPTO_memcmp(const void * in_a, const void * in_b, size_t len)
 /*
  * For systems that don't provide an instruction counter register or equivalent.
  */
+
+#if !defined(__MVS__)
 uint32_t OPENSSL_rdtsc(void)
 {
     return 0;
 }
-
+#endif
 size_t OPENSSL_instrument_bus(unsigned int *out, size_t cnt)
 {
     return 0;
@@ -523,7 +525,7 @@ int OPENSSL_cpuid(long long *id)
   return 1;
 }

-#elif defined(__s390x__)  || defined(__s390__)
+#elif defined(__s390x__)  || defined(__s390__) || defined(__MVS__)
 /* S390x/S390 does have a minimal CPUID */
 /* Handled inside s390xcap.c */

@@ -592,7 +594,7 @@ int OPENSSL_HW_rand(unsigned char *buf)
   }
   return rv;
 }
-#elif defined(__s390__)
+#elif defined(__s390__) || defined(__MVS__)
 #include "s390x_arch.h"
 extern void s390x_trng(void *buff,size_t len);

@@ -600,7 +602,7 @@ int OPENSSL_HW_rand(unsigned char *buf)
 {
   unsigned long long x;

-  if(OPENSSL_s390xcap_P.prno[1] & S390X_CAPBIT(S390X_TRNG)) {
+  if(OPENSSL_s390xcap_P.prno[1] & S390X_CAPBIT(CS390X_TRNG)) {
     if(NULL != buf) {
       s390x_trng((void *)&x,sizeof(x));
       memcpy(buf,&x,sizeof(x));
@@ -609,7 +611,7 @@ int OPENSSL_HW_rand(unsigned char *buf)
   }
   return 0;
 }
-#elif defined(__MVS__)
+#if defined(__MVS__)
 #include <builtins.h>
 #include <stdio.h>

@@ -619,7 +621,7 @@ unsigned long OPENSSL_rdtsc()
   __stcke(&val);
   return val;
 }
-
+#endif
 #elif defined(__ppc__) || defined(__powerpc__) || defined(_AIX)
 #include "ppc_arch.h"
 extern uint64_t OPENSSL_HW_rand_raw(void);
diff --git a/crypto/ec/ecp_s390x_nistp.c b/crypto/ec/ecp_s390x_nistp.c
index 8194c0c..f395fc7 100644
--- a/crypto/ec/ecp_s390x_nistp.c
+++ b/crypto/ec/ecp_s390x_nistp.c
@@ -187,7 +187,7 @@ static ECDSA_SIG *ecdsa_s390x_nistp_sign_sig(const unsigned char *dgst,
             goto ret;
         }
         /* Turns KDSA internal nonce-generation off. */
-        fc |= S390X_KDSA_D;
+        fc |= CS390X_KDSA_D;
     }

     if (s390x_kdsa(fc, param, NULL, 0) != 0) {
@@ -285,7 +285,7 @@ static int ec_GFp_s390x_nistp##bits##_mul(const EC_GROUP *group,        \
 {                                                                       \
     return ec_GFp_s390x_nistp_mul(group, r, scalar, num, points,        \
                                   scalars, ctx,                         \
-                                  S390X_SCALAR_MULTIPLY_P##bits,        \
+                                  CS390X_SCALAR_MULTIPLY_P##bits,        \
                                   S390X_SIZE_P##bits);                  \
 }                                                                       \
                                                                         \
@@ -297,7 +297,7 @@ static ECDSA_SIG *ecdsa_s390x_nistp##bits##_sign_sig(const unsigned     \
                                                      EC_KEY *eckey)     \
 {                                                                       \
     return ecdsa_s390x_nistp_sign_sig(dgst, dgstlen, kinv, r, eckey,    \
-                                      S390X_ECDSA_SIGN_P##bits,         \
+                                      CS390X_ECDSA_SIGN_P##bits,         \
                                       S390X_SIZE_P##bits);              \
 }                                                                       \
                                                                         \
@@ -308,7 +308,7 @@ static int ecdsa_s390x_nistp##bits##_verify_sig(const                   \
                                                 EC_KEY *eckey)          \
 {                                                                       \
     return ecdsa_s390x_nistp_verify_sig(dgst, dgstlen, sig, eckey,      \
-                                        S390X_ECDSA_VERIFY_P##bits,     \
+                                        CS390X_ECDSA_VERIFY_P##bits,     \
                                         S390X_SIZE_P##bits);            \
 }                                                                       \
                                                                         \
@@ -377,11 +377,11 @@ const EC_METHOD *EC_GFp_s390x_nistp##bits##_method(void)                \
     static const EC_METHOD *ret;                                        \
                                                                         \
     if ((OPENSSL_s390xcap_P.pcc[1]                                      \
-         & S390X_CAPBIT(S390X_SCALAR_MULTIPLY_P##bits))                 \
+         & S390X_CAPBIT(CS390X_SCALAR_MULTIPLY_P##bits))                 \
         && (OPENSSL_s390xcap_P.kdsa[0]                                  \
-            & S390X_CAPBIT(S390X_ECDSA_VERIFY_P##bits))                 \
+            & S390X_CAPBIT(CS390X_ECDSA_VERIFY_P##bits))                 \
         && (OPENSSL_s390xcap_P.kdsa[0]                                  \
-            & S390X_CAPBIT(S390X_ECDSA_SIGN_P##bits)))                  \
+            & S390X_CAPBIT(CS390X_ECDSA_SIGN_P##bits)))                  \
         ret = &EC_GFp_s390x_nistp##bits##_meth;                         \
     else                                                                \
         ret = EC_GFp_mont_method();                                     \
diff --git a/crypto/err/openssl.txt b/crypto/err/openssl.txt
index 5c35989..101ff71 100644
--- a/crypto/err/openssl.txt
+++ b/crypto/err/openssl.txt
@@ -679,6 +679,12 @@ EC_F_PKEY_EC_KDF_DERIVE:283:pkey_ec_kdf_derive
 EC_F_PKEY_EC_KEYGEN:199:pkey_ec_keygen
 EC_F_PKEY_EC_PARAMGEN:219:pkey_ec_paramgen
 EC_F_PKEY_EC_SIGN:218:pkey_ec_sign
+EC_F_S390X_PKEY_ECD_DIGESTSIGN25519:303:s390x_pkey_ecd_digestsign25519
+EC_F_S390X_PKEY_ECD_DIGESTSIGN448:304:s390x_pkey_ecd_digestsign448
+EC_F_S390X_PKEY_ECD_KEYGEN25519:305:s390x_pkey_ecd_keygen25519
+EC_F_S390X_PKEY_ECD_KEYGEN448:306:s390x_pkey_ecd_keygen448
+EC_F_S390X_PKEY_ECX_KEYGEN25519:307:s390x_pkey_ecx_keygen25519
+EC_F_S390X_PKEY_ECX_KEYGEN448:308:s390x_pkey_ecx_keygen448
 EC_F_VALIDATE_ECX_DERIVE:278:validate_ecx_derive
 ENGINE_F_DIGEST_UPDATE:198:digest_update
 ENGINE_F_DYNAMIC_CTRL:180:dynamic_ctrl
diff --git a/crypto/evp/e_aes.c b/crypto/evp/e_aes.c
index aadb445..7db2d40 100644
--- a/crypto/evp/e_aes.c
+++ b/crypto/evp/e_aes.c
@@ -996,7 +996,7 @@ static const EVP_CIPHER aes_##keylen##_##mode = { \
 const EVP_CIPHER *EVP_aes_##keylen##_##mode(void) \
 { return SPARC_AES_CAPABLE?&aes_t4_##keylen##_##mode:&aes_##keylen##_##mode; }

-#elif defined(OPENSSL_CPUID_OBJ) && defined(__s390__)
+#elif defined(OPENSSL_CPUID_OBJ) && defined(AES_ASM) && (defined(__s390__) || defined(__MVS__))
 /*
  * IBM S390X support
  */
@@ -1154,15 +1154,15 @@ typedef struct {
 } S390X_AES_CCM_CTX;

 /* Convert key size to function code: [16,24,32] -> [18,19,20]. */
-# define S390X_AES_FC(keylen)  (S390X_AES_128 + ((((keylen) << 3) - 128) >> 6))
+# define S390X_AES_FC(keylen)  (CS390X_AES_128 + ((((keylen) << 3) - 128) >> 6))

 /* Most modes of operation need km for partial block processing. */
 # define S390X_aes_128_CAPABLE (OPENSSL_s390xcap_P.km[0] &	\
-                                S390X_CAPBIT(S390X_AES_128))
+                                S390X_CAPBIT(CS390X_AES_128))
 # define S390X_aes_192_CAPABLE (OPENSSL_s390xcap_P.km[0] &	\
-                                S390X_CAPBIT(S390X_AES_192))
+                                S390X_CAPBIT(CS390X_AES_192))
 # define S390X_aes_256_CAPABLE (OPENSSL_s390xcap_P.km[0] &	\
-                                S390X_CAPBIT(S390X_AES_256))
+                                S390X_CAPBIT(CS390X_AES_256))

 # define s390x_aes_init_key aes_init_key
 static int s390x_aes_init_key(EVP_CIPHER_CTX *ctx, const unsigned char *key,
@@ -1190,7 +1190,7 @@ static int s390x_aes_ecb_init_key(EVP_CIPHER_CTX *ctx,
     S390X_AES_ECB_CTX *cctx = EVP_C_DATA(S390X_AES_ECB_CTX, ctx);
     const int keylen = EVP_CIPHER_CTX_key_length(ctx);

-    cctx->fc = S390X_AES_FC(keylen) | (enc ? 0 : S390X_DECRYPT);
+    cctx->fc = S390X_AES_FC(keylen) | (enc ? 0 : CS390X_DECRYPT);

     if (key != NULL)
         memcpy(cctx->km.param.k, key, keylen);
@@ -1209,13 +1209,13 @@ static int s390x_aes_ecb_cipher(EVP_CIPHER_CTX *ctx, unsigned char *out,

 # define S390X_aes_128_ofb_CAPABLE (S390X_aes_128_CAPABLE &&		\
                                     (OPENSSL_s390xcap_P.kmo[0] &	\
-                                     S390X_CAPBIT(S390X_AES_128)))
+                                     S390X_CAPBIT(CS390X_AES_128)))
 # define S390X_aes_192_ofb_CAPABLE (S390X_aes_192_CAPABLE &&		\
                                     (OPENSSL_s390xcap_P.kmo[0] &	\
-                                     S390X_CAPBIT(S390X_AES_192)))
+                                     S390X_CAPBIT(CS390X_AES_192)))
 # define S390X_aes_256_ofb_CAPABLE (S390X_aes_256_CAPABLE &&		\
                                     (OPENSSL_s390xcap_P.kmo[0] &	\
-                                     S390X_CAPBIT(S390X_AES_256)))
+                                     S390X_CAPBIT(CS390X_AES_256)))

 static int s390x_aes_ofb_init_key(EVP_CIPHER_CTX *ctx,
                                   const unsigned char *key,
@@ -1281,13 +1281,13 @@ static int s390x_aes_ofb_cipher(EVP_CIPHER_CTX *ctx, unsigned char *out,

 # define S390X_aes_128_cfb_CAPABLE (S390X_aes_128_CAPABLE &&		\
                                     (OPENSSL_s390xcap_P.kmf[0] &	\
-                                     S390X_CAPBIT(S390X_AES_128)))
+                                     S390X_CAPBIT(CS390X_AES_128)))
 # define S390X_aes_192_cfb_CAPABLE (S390X_aes_192_CAPABLE &&		\
                                     (OPENSSL_s390xcap_P.kmf[0] &	\
-                                     S390X_CAPBIT(S390X_AES_192)))
+                                     S390X_CAPBIT(CS390X_AES_192)))
 # define S390X_aes_256_cfb_CAPABLE (S390X_aes_256_CAPABLE &&		\
                                     (OPENSSL_s390xcap_P.kmf[0] &	\
-                                     S390X_CAPBIT(S390X_AES_256)))
+                                     S390X_CAPBIT(CS390X_AES_256)))

 static int s390x_aes_cfb_init_key(EVP_CIPHER_CTX *ctx,
                                   const unsigned char *key,
@@ -1298,7 +1298,7 @@ static int s390x_aes_cfb_init_key(EVP_CIPHER_CTX *ctx,
     const int keylen = EVP_CIPHER_CTX_key_length(ctx);
     const int ivlen = EVP_CIPHER_CTX_iv_length(ctx);

-    cctx->fc = S390X_AES_FC(keylen) | (enc ? 0 : S390X_DECRYPT)
+    cctx->fc = S390X_AES_FC(keylen) | (enc ? 0 : CS390X_DECRYPT)
                | (16 << 24); /* 16 bytes cipher feedback */

     if (key != NULL)
@@ -1360,11 +1360,11 @@ static int s390x_aes_cfb_cipher(EVP_CIPHER_CTX *ctx, unsigned char *out,
 }

 # define S390X_aes_128_cfb8_CAPABLE (OPENSSL_s390xcap_P.kmf[0] &	\
-                                     S390X_CAPBIT(S390X_AES_128))
+                                     S390X_CAPBIT(CS390X_AES_128))
 # define S390X_aes_192_cfb8_CAPABLE (OPENSSL_s390xcap_P.kmf[0] &	\
-                                     S390X_CAPBIT(S390X_AES_192))
+                                     S390X_CAPBIT(CS390X_AES_192))
 # define S390X_aes_256_cfb8_CAPABLE (OPENSSL_s390xcap_P.kmf[0] &	\
-                                     S390X_CAPBIT(S390X_AES_256))
+                                     S390X_CAPBIT(CS390X_AES_256))

 static int s390x_aes_cfb8_init_key(EVP_CIPHER_CTX *ctx,
                                    const unsigned char *key,
@@ -1375,7 +1375,7 @@ static int s390x_aes_cfb8_init_key(EVP_CIPHER_CTX *ctx,
     const int keylen = EVP_CIPHER_CTX_key_length(ctx);
     const int ivlen = EVP_CIPHER_CTX_iv_length(ctx);

-    cctx->fc = S390X_AES_FC(keylen) | (enc ? 0 : S390X_DECRYPT)
+    cctx->fc = S390X_AES_FC(keylen) | (enc ? 0 : CS390X_DECRYPT)
                | (1 << 24); /* 1 byte cipher feedback flag */

     if (key != NULL)
@@ -1422,13 +1422,13 @@ static int s390x_aes_ctr_cipher(EVP_CIPHER_CTX *ctx, unsigned char *out,

 # define S390X_aes_128_gcm_CAPABLE (S390X_aes_128_CAPABLE &&		\
                                     (OPENSSL_s390xcap_P.kma[0] &	\
-                                     S390X_CAPBIT(S390X_AES_128)))
+                                     S390X_CAPBIT(CS390X_AES_128)))
 # define S390X_aes_192_gcm_CAPABLE (S390X_aes_192_CAPABLE &&		\
                                     (OPENSSL_s390xcap_P.kma[0] &	\
-                                     S390X_CAPBIT(S390X_AES_192)))
+                                     S390X_CAPBIT(CS390X_AES_192)))
 # define S390X_aes_256_gcm_CAPABLE (S390X_aes_256_CAPABLE &&		\
                                     (OPENSSL_s390xcap_P.kma[0] &	\
-                                     S390X_CAPBIT(S390X_AES_256)))
+                                     S390X_CAPBIT(CS390X_AES_256)))

 /* iv + padding length for iv lengths != 12 */
 # define S390X_gcm_ivpadlen(i)	((((i) + 15) >> 4 << 4) + 16)
@@ -1462,7 +1462,7 @@ static int s390x_aes_gcm_aad(S390X_AES_GCM_CTX *ctx, const unsigned char *aad,
         /* ctx->ares contains a complete block if offset has wrapped around */
         if (!n) {
             s390x_kma(ctx->ares, 16, NULL, 0, NULL, ctx->fc, &ctx->kma.param);
-            ctx->fc |= S390X_KMA_HS;
+            ctx->fc |= CS390X_KMA_HS;
         }
         ctx->areslen = n;
     }
@@ -1473,7 +1473,7 @@ static int s390x_aes_gcm_aad(S390X_AES_GCM_CTX *ctx, const unsigned char *aad,
     if (len) {
         s390x_kma(aad, len, NULL, 0, NULL, ctx->fc, &ctx->kma.param);
         aad += len;
-        ctx->fc |= S390X_KMA_HS;
+        ctx->fc |= CS390X_KMA_HS;
     }

     if (rem) {
@@ -1521,8 +1521,8 @@ static int s390x_aes_gcm(S390X_AES_GCM_CTX *ctx, const unsigned char *in,
         /* ctx->mres contains a complete block if offset has wrapped around */
         if (!n) {
             s390x_kma(ctx->ares, ctx->areslen, ctx->mres, 16, buf.b,
-                      ctx->fc | S390X_KMA_LAAD, &ctx->kma.param);
-            ctx->fc |= S390X_KMA_HS;
+                      ctx->fc | CS390X_KMA_LAAD, &ctx->kma.param);
+            ctx->fc |= CS390X_KMA_HS;
             ctx->areslen = 0;

             /* previous call already encrypted/decrypted its remainder,
@@ -1544,10 +1544,10 @@ static int s390x_aes_gcm(S390X_AES_GCM_CTX *ctx, const unsigned char *in,
     len &= ~(size_t)0xf;
     if (len) {
         s390x_kma(ctx->ares, ctx->areslen, in, len, out,
-                  ctx->fc | S390X_KMA_LAAD, &ctx->kma.param);
+                  ctx->fc | CS390X_KMA_LAAD, &ctx->kma.param);
         in += len;
         out += len;
-        ctx->fc |= S390X_KMA_HS;
+        ctx->fc |= CS390X_KMA_HS;
         ctx->areslen = 0;
     }

@@ -1597,7 +1597,7 @@ static void s390x_aes_gcm_setiv(S390X_AES_GCM_CTX *ctx)
         /* ctx->iv has the right size and is already padded. */
         s390x_kma(ctx->iv, S390X_gcm_ivpadlen(ctx->ivlen), NULL, 0, NULL,
                   ctx->fc, &ctx->kma.param);
-        ctx->fc |= S390X_KMA_HS;
+        ctx->fc |= CS390X_KMA_HS;

         ctx->kma.param.j0.g[0] = ctx->kma.param.t.g[0];
         ctx->kma.param.j0.g[1] = ctx->kma.param.t.g[1];
@@ -1793,10 +1793,10 @@ static int s390x_aes_gcm_init_key(EVP_CIPHER_CTX *ctx,
     S390X_AES_GCM_CTX *gctx = EVP_C_DATA(S390X_AES_GCM_CTX, ctx);
     const int keylen = EVP_CIPHER_CTX_key_length(ctx);

-    gctx->fc = S390X_AES_FC(keylen) | (enc ? 0 : S390X_DECRYPT);
+    gctx->fc = S390X_AES_FC(keylen) | (enc ? 0 : CS390X_DECRYPT);

     if (key != NULL) {
-        gctx->fc &= ~S390X_KMA_HS;
+        gctx->fc &= ~CS390X_KMA_HS;
         memcpy(&gctx->kma.param.k, key, keylen);
         gctx->key_set = 1;
     }
@@ -1810,7 +1810,7 @@ static int s390x_aes_gcm_init_key(EVP_CIPHER_CTX *ctx,
     if (gctx->key_set && gctx->iv_set)
             s390x_aes_gcm_setiv(gctx);

-    gctx->fc &= ~(S390X_KMA_LPC | S390X_KMA_LAAD);
+    gctx->fc &= ~(CS390X_KMA_LPC | CS390X_KMA_LAAD);
     gctx->areslen = 0;
     gctx->mreslen = 0;
     gctx->kreslen = 0;
@@ -1844,7 +1844,7 @@ static int s390x_aes_gcm_tls_cipher(EVP_CIPHER_CTX *ctx, unsigned char *out,
     gctx->kma.param.taadl = gctx->tls_aad_len << 3;
     gctx->kma.param.tpcl = len << 3;
     s390x_kma(buf, gctx->tls_aad_len, in, len, out,
-              gctx->fc | S390X_KMA_LAAD | S390X_KMA_LPC, &gctx->kma.param);
+              gctx->fc | CS390X_KMA_LAAD | CS390X_KMA_LPC, &gctx->kma.param);

     if (enc) {
         memcpy(out + len, gctx->kma.param.t.b, EVP_GCM_TLS_TAG_LEN);
@@ -1898,7 +1898,7 @@ int s390x_aes_gcm_cipher(EVP_CIPHER_CTX *ctx, unsigned char *out,
         gctx->kma.param.taadl <<= 3;
         gctx->kma.param.tpcl <<= 3;
         s390x_kma(gctx->ares, gctx->areslen, gctx->mres, gctx->mreslen, tmp,
-                  gctx->fc | S390X_KMA_LAAD | S390X_KMA_LPC, &gctx->kma.param);
+                  gctx->fc | CS390X_KMA_LAAD | CS390X_KMA_LPC, &gctx->kma.param);
         /* recall that we already did en-/decrypt gctx->mres
          * and returned it to caller... */
         OPENSSL_cleanse(tmp, gctx->mreslen);
@@ -1951,13 +1951,13 @@ static int s390x_aes_xts_ctrl(EVP_CIPHER_CTX *, int type, int arg, void *ptr);

 # define S390X_aes_128_ccm_CAPABLE (S390X_aes_128_CAPABLE &&		\
                                     (OPENSSL_s390xcap_P.kmac[0] &	\
-                                     S390X_CAPBIT(S390X_AES_128)))
+                                     S390X_CAPBIT(CS390X_AES_128)))
 # define S390X_aes_192_ccm_CAPABLE (S390X_aes_192_CAPABLE &&		\
                                     (OPENSSL_s390xcap_P.kmac[0] &	\
-                                     S390X_CAPBIT(S390X_AES_192)))
+                                     S390X_CAPBIT(CS390X_AES_192)))
 # define S390X_aes_256_ccm_CAPABLE (S390X_aes_256_CAPABLE &&		\
                                     (OPENSSL_s390xcap_P.kmac[0] &	\
-                                     S390X_CAPBIT(S390X_AES_256)))
+                                     S390X_CAPBIT(CS390X_AES_256)))

 # define S390X_CCM_AAD_FLAG	0x40

diff --git a/crypto/evp/m_sha3.c b/crypto/evp/m_sha3.c
index 54c592a..86ac793 100644
--- a/crypto/evp/m_sha3.c
+++ b/crypto/evp/m_sha3.c
@@ -140,7 +140,7 @@ static int shake_ctrl(EVP_MD_CTX *evp_ctx, int cmd, int p1, void *p2)
     }
 }

-#if defined(OPENSSL_CPUID_OBJ) && defined(__s390__) && defined(KECCAK1600_ASM)
+#if defined(OPENSSL_CPUID_OBJ) && (defined(__s390__) || defined(__MVS__)) && defined(KECCAK1600_ASM)
 /*
  * IBM S390X support
  */
@@ -149,29 +149,29 @@ static int shake_ctrl(EVP_MD_CTX *evp_ctx, int cmd, int p1, void *p2)
 # define S390X_SHA3_FC(ctx)     ((ctx)->pad)

 # define S390X_sha3_224_CAPABLE ((OPENSSL_s390xcap_P.kimd[0] &      \
-                                  S390X_CAPBIT(S390X_SHA3_224)) &&  \
+                                  S390X_CAPBIT(CS390X_SHA3_224)) &&  \
                                  (OPENSSL_s390xcap_P.klmd[0] &      \
-                                  S390X_CAPBIT(S390X_SHA3_224)))
+                                  S390X_CAPBIT(CS390X_SHA3_224)))
 # define S390X_sha3_256_CAPABLE ((OPENSSL_s390xcap_P.kimd[0] &      \
-                                  S390X_CAPBIT(S390X_SHA3_256)) &&  \
+                                  S390X_CAPBIT(CS390X_SHA3_256)) &&  \
                                  (OPENSSL_s390xcap_P.klmd[0] &      \
-                                  S390X_CAPBIT(S390X_SHA3_256)))
+                                  S390X_CAPBIT(CS390X_SHA3_256)))
 # define S390X_sha3_384_CAPABLE ((OPENSSL_s390xcap_P.kimd[0] &      \
-                                  S390X_CAPBIT(S390X_SHA3_384)) &&  \
+                                  S390X_CAPBIT(CS390X_SHA3_384)) &&  \
                                  (OPENSSL_s390xcap_P.klmd[0] &      \
-                                  S390X_CAPBIT(S390X_SHA3_384)))
+                                  S390X_CAPBIT(CS390X_SHA3_384)))
 # define S390X_sha3_512_CAPABLE ((OPENSSL_s390xcap_P.kimd[0] &      \
-                                  S390X_CAPBIT(S390X_SHA3_512)) &&  \
+                                  S390X_CAPBIT(CS390X_SHA3_512)) &&  \
                                  (OPENSSL_s390xcap_P.klmd[0] &      \
-                                  S390X_CAPBIT(S390X_SHA3_512)))
+                                  S390X_CAPBIT(CS390X_SHA3_512)))
 # define S390X_shake128_CAPABLE ((OPENSSL_s390xcap_P.kimd[0] &      \
-                                  S390X_CAPBIT(S390X_SHAKE_128)) && \
+                                  S390X_CAPBIT(CS390X_SHAKE_128)) && \
                                  (OPENSSL_s390xcap_P.klmd[0] &      \
-                                  S390X_CAPBIT(S390X_SHAKE_128)))
+                                  S390X_CAPBIT(CS390X_SHAKE_128)))
 # define S390X_shake256_CAPABLE ((OPENSSL_s390xcap_P.kimd[0] &      \
-                                  S390X_CAPBIT(S390X_SHAKE_256)) && \
+                                  S390X_CAPBIT(CS390X_SHAKE_256)) && \
                                  (OPENSSL_s390xcap_P.klmd[0] &      \
-                                  S390X_CAPBIT(S390X_SHAKE_256)))
+                                  S390X_CAPBIT(CS390X_SHAKE_256)))

 /* Convert md-size to block-size. */
 # define S390X_KECCAK1600_BSZ(n) ((KECCAK1600_WIDTH - ((n) << 1)) >> 3)
@@ -187,16 +187,16 @@ static int s390x_sha3_init(EVP_MD_CTX *evp_ctx)
      */
     switch (bsz) {
     case S390X_KECCAK1600_BSZ(224):
-        ctx->pad = S390X_SHA3_224;
+        ctx->pad = CS390X_SHA3_224;
         break;
     case S390X_KECCAK1600_BSZ(256):
-        ctx->pad = S390X_SHA3_256;
+        ctx->pad = CS390X_SHA3_256;
         break;
     case S390X_KECCAK1600_BSZ(384):
-        ctx->pad = S390X_SHA3_384;
+        ctx->pad = CS390X_SHA3_384;
         break;
     case S390X_KECCAK1600_BSZ(512):
-        ctx->pad = S390X_SHA3_512;
+        ctx->pad = CS390X_SHA3_512;
         break;
     default:
         return 0;
@@ -220,10 +220,10 @@ static int s390x_shake_init(EVP_MD_CTX *evp_ctx)
      */
     switch (bsz) {
     case S390X_KECCAK1600_BSZ(128):
-        ctx->pad = S390X_SHAKE_128;
+        ctx->pad = CS390X_SHAKE_128;
         break;
     case S390X_KECCAK1600_BSZ(256):
-        ctx->pad = S390X_SHAKE_256;
+        ctx->pad = CS390X_SHAKE_256;
         break;
     default:
         return 0;
diff --git a/crypto/modes/asm/ghash-s390x.pl b/crypto/modes/asm/ghash-s390x.pl
index 2f3ca29..eb2f257 100644
--- a/crypto/modes/asm/ghash-s390x.pl
+++ b/crypto/modes/asm/ghash-s390x.pl
@@ -1,5 +1,5 @@
 #! /usr/bin/env perl
-# Copyright 2010-2020 The OpenSSL Project Authors. All Rights Reserved.
+# Copyright 2010-2016 The OpenSSL Project Authors. All Rights Reserved.
 #
 # Licensed under the OpenSSL license (the "License").  You may not use
 # this file except in compliance with the License.  You can obtain a copy
@@ -43,220 +43,294 @@
 # impressive for smaller buffer sizes and for smallest 16-bytes buffer
 # it's actually almost 2 times slower. Which is the reason why
 # KIMD-GHASH is not used in gcm_gmult_4bit.
+#
+# 2019  Ported to support dual ABI (zLinux/zOS) conventions
+# Peter Waltenberg (pwalten@au1.ibm.com), Jon Furminger <furming@us.ibm.com>
+#
+#
+
+use strict;
+use FindBin qw($Bin);
+use lib "$Bin/../..";
+use perlasm::s390x qw(:MSA :DEFAULT :VX :LD AUTOLOAD LABEL INCLUDE FUNCTION_BEGIN FUNCTION_END OBJECT_BEGIN OBJECT_END BYTE LONG ALIGN ASCIZ TEXT GET_EXTERN LOCAL_VARS_BEGIN LOCAL_VARS_END ds);
+
+my ($flavour,$output);
+my ($SIZE_T,$g,$z,$DSA_OFF,$PARMS_OFF);
+my ($Zhi,$Zlo,$Xi,$Htbl,$inp,$len,$rem0,$rem1,$nlo,$nhi,$xi,$cnt,$tmp,$x78,$rem_4bit,$sp,$ip,$rv);
+my ($xcap,$wr0,$wr1,$wr8,@kimd_op2);
+my $softonly=0;

 $flavour = shift;

+$DSA_OFF=2048;
 if ($flavour =~ /3[12]/) {
+    $z=0;    # S/390 ABI
 	$SIZE_T=4;
 	$g="";
+    $PARMS_OFF=2112;
 } else {
+    $z=1;    # zSeries/zOS  ABI
 	$SIZE_T=8;
 	$g="g";
+    $PARMS_OFF=2176;
 }

 while (($output=shift) && ($output!~/\w[\w\-]*\.\w+$/)) {}
 open STDOUT,">$output";

-$softonly=0;
-
-$Zhi="%r0";
-$Zlo="%r1";
-
-$Xi="%r2";	# argument block
-$Htbl="%r3";
-$inp="%r4";
-$len="%r5";
-
-$rem0="%r6";	# variables
-$rem1="%r7";
-$nlo="%r8";
-$nhi="%r9";
-$xi="%r10";
-$cnt="%r11";
-$tmp="%r12";
-$x78="%r13";
-$rem_4bit="%r14";
-
-$sp="%r15";
-
-$code.=<<___;
-#include "s390x_arch.h"
-
-.text
-
-.globl	gcm_gmult_4bit
-.align	32
-gcm_gmult_4bit:
-___
-$code.=<<___ if(!$softonly && 0);	# hardware is slow for single block...
-	larl	%r1,OPENSSL_s390xcap_P
-	lghi	%r0,0
-	lg	%r1,S390X_KIMD+8(%r1)	# load second word of kimd capabilities
-					#  vector
-	tmhh	%r1,0x4000	# check for function 65
-	jz	.Lsoft_gmult
-	stg	%r0,16($sp)	# arrange 16 bytes of zero input
-	stg	%r0,24($sp)
-	lghi	%r0,S390X_GHASH	# function 65
-	la	%r1,0($Xi)	# H lies right after Xi in gcm128_context
-	la	$inp,16($sp)
-	lghi	$len,16
-	.long	0xb93e0004	# kimd %r0,$inp
-	brc	1,.-4		# pay attention to "partial completion"
-	br	%r14
-.align	32
-.Lsoft_gmult:
-___
-$code.=<<___;
-	stm${g}	%r6,%r14,6*$SIZE_T($sp)
-
-	aghi	$Xi,-1
-	lghi	$len,1
-	lghi	$x78,`0xf<<3`
-	larl	$rem_4bit,rem_4bit
-
-	lg	$Zlo,8+1($Xi)		# Xi
-	j	.Lgmult_shortcut
-.type	gcm_gmult_4bit,\@function
-.size	gcm_gmult_4bit,(.-gcm_gmult_4bit)
-
-.globl	gcm_ghash_4bit
-.align	32
-gcm_ghash_4bit:
-___
-$code.=<<___ if(!$softonly);
-	larl	%r1,OPENSSL_s390xcap_P
-	lg	%r0,S390X_KIMD+8(%r1)	# load second word of kimd capabilities
-					#  vector
-	tmhh	%r0,0x4000	# check for function 65
-	jz	.Lsoft_ghash
-	lghi	%r0,S390X_GHASH	# function 65
-	la	%r1,0($Xi)	# H lies right after Xi in gcm128_context
-	.long	0xb93e0004	# kimd %r0,$inp
-	brc	1,.-4		# pay attention to "partial completion"
-	br	%r14
-.align	32
-.Lsoft_ghash:
-___
-$code.=<<___ if ($flavour =~ /3[12]/);
-	llgfr	$len,$len
-___
-$code.=<<___;
-	stm${g}	%r6,%r14,6*$SIZE_T($sp)
-
-	aghi	$Xi,-1
-	srlg	$len,$len,4
-	lghi	$x78,`0xf<<3`
-	larl	$rem_4bit,rem_4bit
-
-	lg	$Zlo,8+1($Xi)		# Xi
-	lg	$Zhi,0+1($Xi)
-	lghi	$tmp,0
-.Louter:
-	xg	$Zhi,0($inp)		# Xi ^= inp
-	xg	$Zlo,8($inp)
-	xgr	$Zhi,$tmp
-	stg	$Zlo,8+1($Xi)
-	stg	$Zhi,0+1($Xi)
-
-.Lgmult_shortcut:
-	lghi	$tmp,0xf0
-	sllg	$nlo,$Zlo,4
-	srlg	$xi,$Zlo,8		# extract second byte
-	ngr	$nlo,$tmp
-	lgr	$nhi,$Zlo
-	lghi	$cnt,14
-	ngr	$nhi,$tmp
-
-	lg	$Zlo,8($nlo,$Htbl)
-	lg	$Zhi,0($nlo,$Htbl)
-
-	sllg	$nlo,$xi,4
-	sllg	$rem0,$Zlo,3
-	ngr	$nlo,$tmp
-	ngr	$rem0,$x78
-	ngr	$xi,$tmp
-
-	sllg	$tmp,$Zhi,60
-	srlg	$Zlo,$Zlo,4
-	srlg	$Zhi,$Zhi,4
-	xg	$Zlo,8($nhi,$Htbl)
-	xg	$Zhi,0($nhi,$Htbl)
-	lgr	$nhi,$xi
-	sllg	$rem1,$Zlo,3
-	xgr	$Zlo,$tmp
-	ngr	$rem1,$x78
-	sllg	$tmp,$Zhi,60
-	j	.Lghash_inner
-.align	16
-.Lghash_inner:
-	srlg	$Zlo,$Zlo,4
-	srlg	$Zhi,$Zhi,4
-	xg	$Zlo,8($nlo,$Htbl)
-	llgc	$xi,0($cnt,$Xi)
-	xg	$Zhi,0($nlo,$Htbl)
-	sllg	$nlo,$xi,4
-	xg	$Zhi,0($rem0,$rem_4bit)
-	nill	$nlo,0xf0
-	sllg	$rem0,$Zlo,3
-	xgr	$Zlo,$tmp
-	ngr	$rem0,$x78
-	nill	$xi,0xf0
-
-	sllg	$tmp,$Zhi,60
-	srlg	$Zlo,$Zlo,4
-	srlg	$Zhi,$Zhi,4
-	xg	$Zlo,8($nhi,$Htbl)
-	xg	$Zhi,0($nhi,$Htbl)
-	lgr	$nhi,$xi
-	xg	$Zhi,0($rem1,$rem_4bit)
-	sllg	$rem1,$Zlo,3
-	xgr	$Zlo,$tmp
-	ngr	$rem1,$x78
-	sllg	$tmp,$Zhi,60
-	brct	$cnt,.Lghash_inner
-
-	srlg	$Zlo,$Zlo,4
-	srlg	$Zhi,$Zhi,4
-	xg	$Zlo,8($nlo,$Htbl)
-	xg	$Zhi,0($nlo,$Htbl)
-	sllg	$xi,$Zlo,3
-	xg	$Zhi,0($rem0,$rem_4bit)
-	xgr	$Zlo,$tmp
-	ngr	$xi,$x78
-
-	sllg	$tmp,$Zhi,60
-	srlg	$Zlo,$Zlo,4
-	srlg	$Zhi,$Zhi,4
-	xg	$Zlo,8($nhi,$Htbl)
-	xg	$Zhi,0($nhi,$Htbl)
-	xgr	$Zlo,$tmp
-	xg	$Zhi,0($rem1,$rem_4bit)
-
-	lg	$tmp,0($xi,$rem_4bit)
-	la	$inp,16($inp)
-	sllg	$tmp,$tmp,4		# correct last rem_4bit[rem]
-	brctg	$len,.Louter
-
-	xgr	$Zhi,$tmp
-	stg	$Zlo,8+1($Xi)
-	stg	$Zhi,0+1($Xi)
-	lm${g}	%r6,%r14,6*$SIZE_T($sp)
-	br	%r14
-.type	gcm_ghash_4bit,\@function
-.size	gcm_ghash_4bit,(.-gcm_ghash_4bit)
-
-.align	64
-rem_4bit:
-	.long	`0x0000<<12`,0,`0x1C20<<12`,0,`0x3840<<12`,0,`0x2460<<12`,0
-	.long	`0x7080<<12`,0,`0x6CA0<<12`,0,`0x48C0<<12`,0,`0x54E0<<12`,0
-	.long	`0xE100<<12`,0,`0xFD20<<12`,0,`0xD940<<12`,0,`0xC560<<12`,0
-	.long	`0x9180<<12`,0,`0x8DA0<<12`,0,`0xA9C0<<12`,0,`0xB5E0<<12`,0
-.type	rem_4bit,\@object
-.size	rem_4bit,(.-rem_4bit)
-.string	"GHASH for s390x, CRYPTOGAMS by <appro\@openssl.org>"
-___
-
-$code =~ s/\`([^\`]*)\`/eval $1/gem;
-print $code;
-close STDOUT or die "error closing STDOUT: $!";
+PERLASM_BEGIN($flavour,$output);
+
+
+
+if($flavour =~ /linux/) {
+	$Zhi="%r0";
+	$Zlo="%r1";
+
+	$Xi="%r2";	# argument block
+	$Htbl="%r3";
+	$inp="%r4";		@kimd_op2=("%r4","%r5");
+	$len="%r5";
+
+	$rem0="%r6";	# variables
+	$rem1="%r7";
+	$nlo="%r8";
+	$nhi="%r9";
+	$xi="%r10";
+	$cnt="%r11";
+	$tmp="%r12";
+	$x78="%r13";
+	$rem_4bit="%r14";
+
+	$xcap="%r1";
+	$wr0="%r0";
+	$wr1="%r1";
+	$wr8="%r8";
+
+	$sp="%r15";
+	$ip=".";
+	$rv = "%r2";
+} else {
+	$Zhi="R0";
+	$Zlo="R15";		# reg shared with unused $sp
+
+	$Xi="R1";	# argument block
+	$Htbl="R2";
+	$inp="R3";
+	$len="R5";
+
+	@kimd_op2=("R6","R7");
+	$rem0="R6";	# variables
+	$rem1="R7";
+	$nlo="R8";
+	$nhi="R9";
+	$xi="R10";
+	$cnt="R11";
+	$tmp="R12";
+	$x78="R13";
+	$rem_4bit="R14";
+
+	$xcap="R13";
+	$wr0="R0";
+	$wr1="R1";
+	$wr8="R8";
+	$rv = "R3";
+
+	#$sp="R15"; # Not needed by z/OS unless disabled code in gcm_gmult_4bit is enabled
+	$ip="*";
+}
+
+INCLUDE("s390x_arch.h", "crypto/");
+
+TEXT();
+# void gcm_gmult (u64 Xi[2], const u128 Htable[16]);
+
+FUNCTION_BEGIN("gcm_gmult_4bit",2,"true","stor6");
+if (! $softonly && 0) {
+	GET_EXTERN($xcap,"OPENSSL_s390xcap_P");	# before r5 is corrupted
+	la      ($sp,"STACK") if ($flavour !~ /linux/);		# set up stack for zos
+
+	lghi	($wr0,0);
+	lg		($wr8,"CS390X_KIMD+8($xcap)");	# load second word of kimd capabilities
+											#  vector
+	tmhh	($wr8,0x4000);					# check for function 65
+	jz		(LABEL("Lsoft_gmult"));
+	stg		($wr0,"16($sp)");				# arrange 16 bytes of zero input
+	stg		($wr0,"24($sp)");
+	lghi	($wr0,"CS390X_GHASH");			# function 65
+	la		($wr1,"0($Xi)");				# H lies right after Xi in gcm128_context
+	la		(@kimd_op2[0],"16($sp)");
+	lghi	(@kimd_op2[1],16);
+	kimd	($wr0,@kimd_op2[0]);
+	brc		(1,"$ip-4");					# pay attention to "partial completion"
+	j		(LABEL("EXIT_gcm_gmult_4bit"));
+ALIGN(32);
+LABEL("Lsoft_gmult:");
+}
+	&{$z? \&stmg:\&stm}	("%r6","%r14","6*$SIZE_T($sp)") if ($flavour =~ /linux/);
+	aghi	($Xi,-1);
+	lghi	($len,1);
+	lghi	($x78,0x78);
+	larl	($rem_4bit,LABEL("rem_4bit"));
+	lg		($Zlo,"8+1($Xi)");		# Xi
+	j		(LABEL("Lgmult_shortcut"));
+# Note this generates strange and unused code because of the jump out to common code
+FUNCTION_END("gcm_gmult_4bit",$rv);
+
+#
+# void gcm_ghash(u64 Xi[2], const u128 Htable[16], const u8 *inp, size_t len);
+#
+FUNCTION_BEGIN("gcm_ghash_4bit",4,"true","stor6");
+#jpf don't think we need a stack for zos, but do need to get $len param
+if(!$softonly) {
+	GET_EXTERN($xcap,"OPENSSL_s390xcap_P");	# before r5 is corrupted
+	lg		($wr0,"CS390X_KIMD+8($xcap)");	# load second word of kimd capabilities
+											#  vector
+	tmhh	($wr0,0x4000);					# check for function 65
+	jz		(LABEL("Lsoft_ghash"));
+
+if ($flavour !~ /linux/) {
+	&{$z? \&lgr:\&lr}	(@kimd_op2[0],$inp);		# Move inp into even reg
+	&{$z? \&lg:\&l} ("R9","$DSA_OFF(R4)");		# Get DSA address
+	&{$z? \&lg:\&l} (@kimd_op2[1],"$PARMS_OFF+$SIZE_T*3(R9)");	# Get len address
+}
+	lghi	($wr0,"CS390X_GHASH");	# function 65
+	la		($wr1,"0($Xi)") if ($flavour =~ /linux/);	# H lies right after Xi in gcm128_context - z/OS already has Xi in r1
+	kimd	($wr0,@kimd_op2[0]);	#	.long	0xb93e0004
+	brc		(1,"$ip-4");			# pay attention to "partial completion"
+	j		(LABEL("EXIT_gcm_ghash_4bit"));
+ALIGN(32);
+LABEL("Lsoft_ghash:");
+}
+if ($flavour =~ /linux/) {
+	llgfr	($len,$len) if ($flavour =~ /3[12]/);
+	&{$z? \&stmg:\&stm}	("%r6","%r14","6*$SIZE_T($sp)");
+} else {
+	&{$z? \&lg:\&l} ("R9","$DSA_OFF(R4)");				# Get DSA address
+	&{$z? \&lg:\&llgf} ($len,"$PARMS_OFF+$SIZE_T*3(R9)");	# Get len address
+}
+
+	aghi	($Xi,-1);
+	srlg	($len,$len,4);
+	lghi	($x78,0x78);
+	larl	($rem_4bit,LABEL("rem_4bit"));
+
+	lg		($Zlo,"8+1($Xi)");		# Xi
+	lg		($Zhi,"0+1($Xi)");
+	lghi	($tmp,0);
+LABEL("Louter:");
+	xg		($Zhi,"0($inp)");		# Xi ^= inp
+	xg		($Zlo,"8($inp)");
+	xgr		($Zhi,$tmp);
+	stg		($Zlo,"8+1($Xi)");
+	stg		($Zhi,"0+1($Xi)");
+LABEL("Lgmult_shortcut:");
+	lghi	($tmp,0xf0);
+	sllg	($nlo,$Zlo,4);
+	srlg	($xi,$Zlo,8);		# extract second byte
+	ngr		($nlo,$tmp);
+	lgr		($nhi,$Zlo);
+	lghi	($cnt,14);
+	ngr		($nhi,$tmp);
+
+	lg		($Zlo,"8($nlo,$Htbl)");
+	lg		($Zhi,"0($nlo,$Htbl)");
+
+	sllg	($nlo,$xi,4);
+	sllg	($rem0,$Zlo,3);
+	ngr		($nlo,$tmp);
+	ngr		($rem0,$x78);
+	ngr		($xi,$tmp);
+
+	sllg	($tmp,$Zhi,60);
+	srlg	($Zlo,$Zlo,4);
+	srlg	($Zhi,$Zhi,4);
+	xg		($Zlo,"8($nhi,$Htbl)");
+	xg		($Zhi,"0($nhi,$Htbl)");
+	lgr		($nhi,$xi);
+	sllg	($rem1,$Zlo,3);
+	xgr		($Zlo,$tmp);
+	ngr		($rem1,$x78);
+	sllg	($tmp,$Zhi,60);
+	j		(LABEL("Lghash_inner"));
+ALIGN(16);
+LABEL("Lghash_inner:");
+	srlg	($Zlo,$Zlo,4);
+	srlg	($Zhi,$Zhi,4);
+	xg		($Zlo,"8($nlo,$Htbl)");
+	llgc	($xi,"0($cnt,$Xi)");
+	xg		($Zhi,"0($nlo,$Htbl)");
+	sllg	($nlo,$xi,4);
+	xg		($Zhi,"0($rem0,$rem_4bit)");
+	nill	($nlo,0xf0);
+	sllg	($rem0,$Zlo,3);
+	xgr		($Zlo,$tmp);
+	ngr		($rem0,$x78);
+	nill	($xi,0xf0);
+
+	sllg	($tmp,$Zhi,60);
+	srlg	($Zlo,$Zlo,4);
+	srlg	($Zhi,$Zhi,4);
+	xg		($Zlo,"8($nhi,$Htbl)");
+	xg		($Zhi,"0($nhi,$Htbl)");
+	lgr		($nhi,$xi);
+	xg		($Zhi,"0($rem1,$rem_4bit)");
+	sllg	($rem1,$Zlo,3);
+	xgr		($Zlo,$tmp);
+	ngr		($rem1,$x78);
+	sllg	($tmp,$Zhi,60);
+	brct	($cnt,LABEL("Lghash_inner"));
+
+	srlg	($Zlo,$Zlo,4);
+	srlg	($Zhi,$Zhi,4);
+	xg		($Zlo,"8($nlo,$Htbl)");
+	xg		($Zhi,"0($nlo,$Htbl)");
+	sllg	($xi,$Zlo,3);
+	xg		($Zhi,"0($rem0,$rem_4bit)");
+	xgr		($Zlo,$tmp);
+	ngr		($xi,$x78);
+
+	sllg	($tmp,$Zhi,60);
+	srlg	($Zlo,$Zlo,4);
+	srlg	($Zhi,$Zhi,4);
+	xg		($Zlo,"8($nhi,$Htbl)");
+	xg		($Zhi,"0($nhi,$Htbl)");
+	xgr		($Zlo,$tmp);
+	xg		($Zhi,"0($rem1,$rem_4bit)");
+
+	lg		($tmp,"0($xi,$rem_4bit)");
+	la		($inp,"16($inp)");
+	sllg	($tmp,$tmp,4);		# correct last rem_4bit[rem]
+	brctg	($len,LABEL("Louter"));
+
+	xgr		($Zhi,$tmp);
+	stg		($Zlo,"8+1($Xi)");
+	stg		($Zhi,"0+1($Xi)");
+	&{$z? \&lmg:\&lm}	("%r6","%r14","6*$SIZE_T($sp)") if ($flavour =~ /linux/);
+FUNCTION_END("gcm_ghash_4bit",$rv);
+
+
+
+OBJECT_BEGIN("rem_4bit",64);
+	LONG(	0x00000000,0x00000000,0x01c20000,0x00000000);
+	LONG(	0x03840000,0x00000000,0x02460000,0x00000000);
+	LONG(	0x07080000,0x00000000,0x06ca0000,0x00000000);
+	LONG(	0x048c0000,0x00000000,0x054e0000,0x00000000);
+	LONG(	0x0e100000,0x00000000,0x0fd20000,0x00000000);
+	LONG(	0x0d940000,0x00000000,0x0c560000,0x00000000);
+	LONG(	0x09180000,0x00000000,0x08da0000,0x00000000);
+	LONG(	0x0a9c0000,0x00000000,0x0b5e0000,0x00000000);
+
+OBJECT_END("rem_4bit");
+ASCIZ	("GHASH for s390x, CRYPTOGAMS by <appro\@openssl.org>");
+
+
+$output =~ s/\`([^\`]*)\`/eval $1/gem;
+
+LOCAL_VARS_BEGIN();
+	ds		("STACKSPACE","200F");
+    ds		("STACK", "0F");
+    ds      ("SAVEAREA","32F");
+LOCAL_VARS_END();
+
+PERLASM_END();
+
diff --git a/crypto/modes/build.info b/crypto/modes/build.info
index 821340e..26ffa4e 100644
--- a/crypto/modes/build.info
+++ b/crypto/modes/build.info
@@ -21,6 +21,7 @@ INCLUDE[ghash-armv4.o]=..
 GENERATE[ghashv8-armx.S]=asm/ghashv8-armx.pl $(PERLASM_SCHEME)
 INCLUDE[ghashv8-armx.o]=..
 GENERATE[ghash-s390x.S]=asm/ghash-s390x.pl $(PERLASM_SCHEME)
+GENERATE[ghash-s390x.s]=asm/ghash-s390x.pl $(PERLASM_SCHEME)
 INCLUDE[ghash-s390x.o]=..

 BEGINRAW[Makefile]
diff --git a/crypto/modes/modes_local.h b/crypto/modes/modes_local.h
index 8881416..b6f273f 100644
--- a/crypto/modes/modes_local.h
+++ b/crypto/modes/modes_local.h
@@ -32,7 +32,7 @@ typedef unsigned char u8;
      defined(__x86_64)  || defined(__x86_64__)  || \
      defined(_M_IX86)   || defined(_M_AMD64)    || defined(_M_X64) || \
      defined(__aarch64__)                       || \
-     defined(__s390__)  || defined(__s390x__)
+     defined(__s390__)  || defined(__s390x__) || defined(__MVS__)
 #  undef STRICT_ALIGNMENT
 # endif
 #endif
diff --git a/crypto/o_str.c b/crypto/o_str.c
index eb9f21c..70c3195 100644
--- a/crypto/o_str.c
+++ b/crypto/o_str.c
@@ -100,10 +100,7 @@ size_t OPENSSL_strlcat(char *dst, const char *src, size_t size)

 int OPENSSL_hexchar2int(unsigned char c)
 {
-#ifdef CHARSET_EBCDIC
-    c = os_toebcdic[c];
-#endif
-
+    /* Conversion from EDCDIC isn't needed here, this is char set neutral (PTW) */
     switch (c) {
     case '0':
         return 0;
diff --git a/crypto/perlasm/s390x.pm b/crypto/perlasm/s390x.pm
index 7fb55c7..8a68756 100644
--- a/crypto/perlasm/s390x.pm
+++ b/crypto/perlasm/s390x.pm
@@ -7,7 +7,39 @@
 # https://www.openssl.org/source/license.html

 # Copyright IBM Corp. 2018-2019
-# Author: Patrick Steuer <patrick.steuer@de.ibm.com>
+# Authors: Patrick Steuer <patrick.steuer@de.ibm.com>
+#          z/OS
+#	   Jonathan Furminger <furming@us.ibm.com>
+#	   Peter Waltenberg <pwalten@au1.ibm.com>
+#
+# Comments on z/OS
+# z/OS is more formal and has a line length limitation dating back to the punch card era.
+# One exit point as z/OS function exit is macro based. Hence the EXIT_(function) added by
+# the FUNCTION_END() macro. That does eat some performance, but mostly on unusual paths.
+# z/OS has less registers available than Linux (ouch)
+#
+# Some of the more important z/OS issues:
+#
+# Largest alignment that's viable is 16 byte. You CAN use sectalign on the command line but that appears
+# to consume some z/OS resource that needs increasing before the code will run. Running by default
+# was considered a desirable outcome.
+#
+# Access to global variables didn't always work and sometimes resulted in register corruption.
+# No idea why and in some cases we just worked around that (SHA256/512) by passing OPENSSL_s390xcap_P as a
+# parameter.
+#
+# Link semantics are xplink. We'd like to have supported both semantics but this file is enough of a mess now,
+# probably doable, probably not worth doing as zOS will thunk between ABI's for you and that's probably easier.
+#
+# 32 bit mode is untested at this point and needs a new stanza in Configurations/10-main.conf.
+#
+# zOS generates internal symbols which can conflict with symbols in the code. data,code, object names all share
+# the same namespace.
+#
+# This module does MOST of the heavy lifting but you do still have to be aware of the ABI
+# differences. The payoff for Linux is the handling of new instructions which the Linux
+# compilers are slow to pick up.
+#

 package perlasm::s390x;

@@ -16,12 +48,176 @@ use warnings;
 use bigint;
 use Carp qw(confess);
 use Exporter qw(import);
+use Text::Tabs;
+
+# Flag to change the generated asssembler
+# If we have a current enough compiler, just emit the instructions for the assembler.
+# By default translate direct to byte stream
+
+my $modern = 0;
+# z/OS uses a macro for function exit so we add a label EXIT_$local_function
+# at function exit and change all br(cond) %r14's to j(cond) EXIT_$local_function
+
+my $local_function;
+my @externNames;
+my @externNamesEmitted;
+my $entryMacro;
+my $exitMacro;
+
+# Basic remapping of registers from  Linux to zOS xplink usage
+# This isn't enough on it's own.
+# %r15 -> R4 (sp), %r14->R7 Return address, %r2 -> R3 simple return codes
+# Note in Perl we do this in two hits otherwise the optimized regex will
+# pick off %r15 as %r1 and ends up back as R15. Very annoying.
+#
+# Note: This is fallback code. We recommend using symbols for registers in
+#       the asm routines instead in which case this code is never activated.
+#
+
+my %regmap2 = (
+            "%r15" => "R4",
+            "%r14" => "R7",
+            "%r13" => "R13",
+            "%r12" => "R12",
+            "%r11" => "R11",
+            "%r10" => "R10",
+            "%R15" => "R4",
+            "%R14" => "R7",
+            "%R13" => "R13",
+            "%R12" => "R12",
+            "%R11" => "R11",
+            "%R10" => "R10",
+				"%f15" => "F15",
+				"%f14" => "F14",
+				"%f13" => "F13",
+				"%f12" => "F12",
+				"%f11" => "F11",
+				"%f10" => "F10",
+				"%F15" => "F15",
+				"%F14" => "F14",
+				"%F13" => "F13",
+				"%F12" => "F12",
+				"%F11" => "F11",
+				"%F10" => "F10",
+				"%v31"  => "V31",
+				"%v30"  => "V30",
+				"%v29"  => "V29",
+				"%v28"  => "V28",
+				"%v27"  => "V27",
+				"%v26"  => "V26",
+				"%v25"  => "V25",
+				"%v24"  => "V24",
+				"%v23"  => "V23",
+				"%v22"  => "V22",
+				"%v21"  => "V21",
+				"%v20"  => "V20",
+				"%v19"  => "V19",
+				"%v18"  => "V18",
+				"%v17"  => "V17",
+				"%v16"  => "V16",
+				"%v15"  => "V15",
+				"%v14"  => "V14",
+				"%v13"  => "V13",
+				"%v12"  => "V12",
+				"%v11"  => "V11",
+				"%v10"  => "V10",
+				"%V31"  => "V31",
+				"%V30"  => "V30",
+				"%V29"  => "V29",
+				"%V28"  => "V28",
+				"%V27"  => "V27",
+				"%V26"  => "V26",
+				"%V25"  => "V25",
+				"%V24"  => "V24",
+				"%V23"  => "V23",
+				"%V22"  => "V22",
+				"%V21"  => "V21",
+				"%V20"  => "V20",
+				"%V19"  => "V19",
+				"%V18"  => "V18",
+				"%V17"  => "V17",
+				"%V16"  => "V16",
+				"%V15"  => "V15",
+				"%V14"  => "V14",
+				"%V13"  => "V13",
+				"%V12"  => "V12",
+				"%V11"  => "V11",
+				"%V10"  => "V10"
+           );
+
+my %regmap1 = (
+            "%r9" => "R9",
+            "%r8" => "R8",
+            "%r7" => "R14",
+            "%r6" => "R6",
+            "%r5" => "R5",
+            "%r4" => "R15",
+            "%r3" => "R2",
+            "%r2" => "R3",
+            "%r1" => "R1",
+            "%r0" => "R0",
+            "%R9" => "R9",
+            "%R8" => "R8",
+            "%R7" => "R14",
+            "%R6" => "R6",
+            "%R5" => "R5",
+            "%R4" => "R15",
+            "%R3" => "R2",
+            "%R2" => "R3",
+            "%R1" => "R1",
+            "%R0" => "R0",
+				"%f9" => "F9",
+				"%f8" => "F8",
+				"%f7" => "F7",
+				"%f6" => "F6",
+				"%f5" => "F5",
+				"%f4" => "F4",
+				"%f3" => "F3",
+				"%f2" => "F2",
+				"%f1" => "F1",
+				"%f0" => "F0",
+				"%F9" => "F9",
+				"%F8" => "F8",
+				"%F7" => "F7",
+				"%F6" => "F6",
+				"%F5" => "F5",
+				"%F4" => "F4",
+				"%F3" => "F3",
+				"%F2" => "F2",
+				"%F1" => "F1",
+				"%F0" => "F0",
+				"%v9"  => "V9",
+				"%v8"  => "V8",
+				"%v7"  => "V7",
+				"%v6"  => "V6",
+				"%v5"  => "V5",
+				"%v4"  => "V4",
+				"%v3"  => "V3",
+				"%v2"  => "V2",
+				"%v1"  => "V1",
+				"%v0"  => "V0",
+				"%V9"  => "V9",
+				"%V8"  => "V8",
+				"%V7"  => "V7",
+				"%V6"  => "V6",
+				"%V5"  => "V5",
+				"%V4"  => "V4",
+				"%V3"  => "V3",
+				"%V2"  => "V2",
+				"%V1"  => "V1",
+				"%V0"  => "V0",
+             );
+
+my $regkeys2 = qr/@{[join '|', map { quotemeta($_) } keys %regmap2]}/;
+my $regkeys1 = qr/@{[join '|', map { quotemeta($_) } keys %regmap1]}/;
+
+

 our @EXPORT=qw(PERLASM_BEGIN PERLASM_END);
-our @EXPORT_OK=qw(AUTOLOAD LABEL INCLUDE stfle);
+our @EXPORT_OK=qw(AUTOLOAD LABEL INCLUDE stfle BR_EXIT FUNCTION_BEGIN LOCAL_FUNCTION LOCAL_FUNCTION_END FUNCTION_END FUNCTION_CALL ALIGN OBJECT_BEGIN OBJECT_END GET_OBJECT BYTE LONG QUAD ASCIZ TEXT GET_EXTERN LOCAL_VARS_BEGIN LOCAL_VARS_END ds );
 our %EXPORT_TAGS=(
 	# long-displacement facility
-	LD => [qw(clgfi)],
+	LD => [qw(clgfi clfi)],
 	# general-instruction-extension facility
 	GE => [qw(risbg)],
 	# extended-immediate facility
@@ -109,14 +305,151 @@ our $AUTOLOAD;
 my $GR='(?:%r)?([0-9]|1[0-5])';
 my $VR='(?:%v)?([0-9]|1[0-9]|2[0-9]|3[0-1])';

-my ($file,$out);
+my ($flavour,$file,$out);

+sub zRegs
+{
+	my $i;
+	for($i = 0; $i < 16; $i++) {
+		$out.= "R$i\tEQU\t$i\n";
+	}
+	$out.="\n";
+	for($i= 0 ; $i < 16; $i++) {
+		$out.= "F$i\tEQU\t$i\n";
+	}
+	$out.="\n";
+	for($i = 0 ; $i < 32; $i++) {
+		$out.= "V$i\tEQU\t$i\n";
+	}
+	$out.="\n";
+}
+
+# Find next #endif
+# used by equ() below.
+sub findEndif
+{
+   my $fh = shift;
+   my $line = "";
+   LINE: while ($line = <$fh> ) {
+      if($line =~ /"#endif"/  || $line =~/#\s+endif/) {
+         last;
+      }
+   }
+}
+
+# equ ( <path to file> ) - parse the named c header file
+# and convert #define SYMBOL value
+# to SYMBOL EQU value for assembler
+# Note the use of #ifndef __ASSEMBLER__ to handle
+# defines that this parser can't handle.
+# All we are after is manifest constants
+# in the headers so these don't need to be in two places.
+# i.e. #define FRED 2 as the asm phase can't really handle complex anyway
+#
+sub equ
+{
+   my $file1=shift;
+   my $line = "";
+   my $output = "";
+   open (my $fh, "<",$file1) or die "Can't open include file $file1: $!";
+   LINE: while (my $line = <$fh>) {
+      chomp $line;
+		next LINE if ($line !~ /^#/);
+      #     print "$line\n";
+      if ($line =~ /ifndef/ && $line =~ /__ASSEMBLER__/) {
+      #   print "Found no-asm block\n";
+			findEndif($fh);
+			next LINE;
+		}
+      # now look for #define SYMBOL VALUE #other rubbish
+      if($line =~ /#define/ || $line =~ /#\s+define/ ) {
+         # print "Found #define\n";
+         my $idx = index($line,"define");
+         $idx += 6; #skip past define
+         $line = substr($line,$idx);
+         $line =~ s/^\s+//; # Trim leading whitespace
+         my @words = split(/\s+/,$line);
+         my $n = scalar(@words);
+         # print "words = $n line = [$line]\n";
+         if($n >= 2) {
+            if($words[1] =~ /0x/) {
+               $words[1] = substr $words[1],2;
+               $output .= "$words[0]   EQU X'$words[1]'\n";
+            } else {
+               $output .= "$words[0]   EQU $words[1]\n";
+            }
+         }
+      }
+   }
+	close($file1);
+   return $output;
+}
+#
+# Setup phase for converting the .pl file to .s
+# Params are (in order)
+# flavour - linux[31|32|64] or ZOS[31|32|64]
+# file    - input file (.pl)
+# out     - output file (.s)
+#
+# global .modern. By default we convert "new" instructions to bytes directly
+#                 As the compiler/asm improves this may not be needed in which case
+#                 we can also emit the correct opcodes.
+#         Also potentially useful for debug on linux as you can at least read the code
+#         with modern=1 where .long 0x..... is fairly hard to understand
+#
 sub PERLASM_BEGIN
 {
-	($file,$out)=(shift,"");
+	($flavour,$file,$out)=(shift,shift,"");
+	if ( $flavour =~ /linux/ ) {
+		$modern = 0;
+	} else {
+		$modern = 1;
+		$GR='(?:R)?([0-9]|1[0-5])'; # Normal registers R0->R15 on z/OS
+		$VR='(?:V)?([0-9]|1[0-9]|2[0-9]|3[0-1])'; # Vector registers V0->V31 on z/OS
+	}
+	if ($flavour =~ /3[12]/) {
+		$entryMacro = "EDCXPRLG";	# 31/32 bit mode
+		$exitMacro = "EDCXEPLG";
+	} else {
+		$entryMacro = "CELQPRLG";	# 64 bit mode
+		$exitMacro = "CELQEPLG";
+	}
 }
+#
+# Finalization phase for the .pl to .s process.
+#	At this point we have a multiline perl string in memory
+#  do any last gasp fixups and write the output
+#
 sub PERLASM_END
 {
+	# finally, translate zLInux resgister usage to zOS usage
+	# if we are emitting code for z/OS
+	# Done late because the %r of the zLinux form makes it
+	# easy to distinguish opcodes from say r in a comment
+	# NOTE: It's better to use symbols in the source and avoid
+	#        the automatic register mapping
+	# Also fix any residual 0x constants that slipped through here
+	#
+	if( $flavour !~/linux/) {
+
+		$out=~ s/($regkeys2)/$regmap2{$1}/g;
+		$out=~ s/($regkeys1)/$regmap1{$1}/g;
+
+		$out=~ s/0x([0-9a-fA-F][0-9a-fA-F][0-9a-fA-F][0-9a-fA-F])\(/X'$1'\(/g;
+		$out=~ s/0x([0-9a-fA-F][0-9a-fA-F][0-9a-fA-F][0-9a-fA-F]) /X'$1' /g;
+		$out=~ s/0x([0-9a-fA-F][0-9a-fA-F])\(/X'$1'\(/g;
+		$out=~ s/0x([0-9a-fA-F][0-9a-fA-F]) /X'$1' /g;
+
+	   # $out=~ s/\`([^\`]*)\`/eval $1/gem; # Evaluate any quoted ` ` maths
+		zRegs();
+	   # if Text::tabs is unacceptable
+		# $out.= s/\t/    /g; works but produces ugly output.
+		# It's not human maintained at that point, so maybe we don't care.
+		my @lst = split(/\n/,$out);
+		@lst = expand(@lst);
+		$out = join("\n",@lst);
+		$out.="\n    END\n";
+	}
 	if (defined($file)) {
 		open(my $fd,'>',$file)||die("can't open $file: $!");
 		print({$fd}$out);
@@ -131,35 +464,557 @@ sub AUTOLOAD {
 	my $token;
 	for ($AUTOLOAD) {
 		$token=".$1" if (/^.*::([A-Z_]+)$/);	# uppercase: directive
-		$token="\t$1" if (/^.*::([a-z]+)$/);	# lowercase: mnemonic
+		if ( $flavour =~/linux/) {
+			$token="\t$1" if (/^.*::([a-z]+)$/);	# lowercase: mnemonic
+		} else {
+			$token="    $1" if (/^.*::([a-z]+)$/);	# lowercase: mnemonic
+		}
 		confess(err("PARSE")) if (!defined($token));
 	}
-	$token.="\t" if ($#_>=0);
-	$out.=$token.join(',',@_)."\n";
+	if ( $flavour =~/linux/) {
+		$token.="\t" if ($#_>=0);
+
+		$out.=$token.join(',',@_)."\n";
+	} else {
+		$token.="    " if ($#_>=0);
+		$out.=$token;
+
+		my $operands = '';
+		foreach (@_) {
+			$token = $_;
+				$token =~ s/0x([0-9a-fA-F]*)/X'$1'/ if ($token =~ /(0x[0-9a-fA-F]+$)/);
+			if ($operands eq '') {
+			   $operands=$token;
+			} else {
+			   $operands.=','.$token;
+			}
+		}
+		$out.=$operands."\n";
+	}
 }

-sub LABEL {						# label directive
-	confess(err("ARGNUM")) if ($#_!=0);
+#
+# LABEL( <label>[:]);
+# If the optional ":" is included then a LABEL declaration will be emitted,
+# otherwise a correctly formated label useful for branching to will be returned.
+#
+sub LABEL {
+    confess(err("ARGNUM")) if ($#_!=0);
 	my ($label)=@_;
-	$out.="$label:\n";
+    if (substr($label,-1) eq ':') {
+	if($flavour =~/linux/) {
+	  $out.=".$label\n";
+	} else {
+	  $out.= substr($label,0,-1)."    DS 0h\n";
+        }
+    } else {
+        $label=".$label" if($flavour =~/linux/);
+        return $label;
+   }
+}
+
+
+#
+# Byte (1 byte) constant
+# Note that this has a potential bug and MAY need to be fixed to
+# cope with long lines at some point.
+#
+sub BYTE {
+	my $i = @_;
+	my $data;
+	if($flavour =~/linux/) {
+		$out.= ".byte\t";
+		for( ; $i > 0 ; $i--) {
+			$data = shift;
+			$out.= sprintf("0x%02x",$data);
+			if ($i != 1) {
+				$out.=", ";
+			}	else {
+				$out.="\n";
+			}
+		}
+	} else {
+		$out.= "        DC    ";
+		for( ; $i > 0 ; $i--) {
+			$data = shift;
+			if ($i != 1) {
+				$out.= sprintf("X'%02X',",$data);
+			} else {
+				$out.= sprintf("X'%02X'",$data);
+
+			}
+		}
+		$out.="\n";
+	}
+}
+#
+# Long (4 byte) constants
+#
+sub LONG {
+	my $i = @_;
+	my $data;
+	if($flavour =~/linux/) {
+		$out.= ".long\t";
+		for( ; $i > 0 ; $i--) {
+			$data = shift;
+			$out.= sprintf("0x%08lx",$data);
+			if($i != 1) {
+				$out.=",";
+			}	else {
+				$out.="\n";
+			}
+		}
+	} else {
+            my $tmp.= "        DC    ";
+	    for( ; $i > 0 ; $i--) {
+		$data = shift;
+		        if ($i != 1) {
+                     $tmp.= sprintf("XL4'%0x',",$data);
+                } else {
+                     $tmp.= sprintf("XL4'%0x'",$data);
+                }
+            }
+            # If the declaration is longer than 70 chars try to do just per line
+            if (length($tmp) > 70) {
+		        for( ; $i > 0 ; $i--) {
+			        $data = shift;
+			        $out.= sprintf("        DC    XL4'%0x'\n",$data);
+                }
+            } else {
+                $out.= $tmp."\n";
+	    }
+	}
+}
+#
+# Quadword (8 byte) constants
+#
+sub QUAD {
+	my $i = @_;
+	my $data;
+	if($flavour =~ /linux/) {
+		$out.= ".quad\t";
+		for( ; $i > 0 ; $i--) {
+			$data = shift;
+			$out.= sprintf("0x%016s",$data);
+			if($i != 1) {
+				$out.=",\t";
+			}	else {
+				$out.="\n";
+			}
+		}
+	} else {
+		for( ; $i > 0 ; $i--) {
+			$data = shift;
+			$out.= sprintf("\tDC\tXL8'%016s'\n",$data);
+		}
+	}
+}
+#
+# Program text
+#
+sub TEXT {
+	if($flavour =~ /linux/) {
+		$out .= ".text\n";
+	}
+}
+#
+# ASCIZ  ascii NULL terminated string
+#
+sub ASCIZ {
+	my $data = shift;
+	if($flavour =~ /linux/) {
+		$out .= ".asciz \"$data\"\n";
+	} else {
+	    # Needs to split the data if we'd run over the line limit (50 chars)
+		my $len = length($data);
+		if ($len > 50) {
+		    my $pos = 0;
+			while ($pos < $len) {
+				$out.= "\tDC\tCA'".substr($data,$pos,50)."'\n";
+				$pos+=50;
+			}
+		} else {
+			$out.= "\tDC\tCA'$data'\n";
+		}
+	}
 }

+#
+# ALIGN( <number> ) - align statements
+# Needs work on z/OS because this only works for up to 16
+# - getting data on cacheline boundaries also matters and sometimes
+#  tricks are used to fetch specially aligned constants
+#
+sub ALIGN {
+	my $align = shift;
+	if($flavour =~ /linux/) {
+		$out.= ".align\t$align\n";
+	} else {
+		if ($align > 16) {
+			# SECTALIGN() assembler option must be used to enable sizes larger than 8
+			$out.= "                 ORG  *,$align\n"; # Needed for vector register alignment ?
+		} elsif ($align == 16) {
+			$out.= "        DS 0Q\n"; # Quadword
+		} elsif ($align == 8) {
+			$out.= "        DS 0D\n"; # Doubleword
+		} elsif ($align == 4) {
+			$out.= "        DS 0F\n"; #Fullword
+		}	elsif ($align == 2) {
+			$out.= "        DS 0H"    #Halfword
+		}
+	}
+}
+
+#
+# INCLUDE( <filename>, <execute directory> ) - include the named c header file
+#    Note:
+#    Linux uses C as a preprocessor
+#    z/OS does it's best to turn this into EQU statements the assembler can handle.
+#
+#
 sub INCLUDE {
-	confess(err("ARGNUM")) if ($#_!=0);
-	my ($file)=@_;
-	$out.="#include \"$file\"\n";
+#	confess(err("ARGNUM")) if ($#_!=0);
+	my ($file)=shift;
+	my $Bin = shift;
+	if($flavour =~ /linux/) {
+		$out.="#include \"$Bin$file\"\n";
+	} else {
+      $out.= equ("$Bin$file");
+      $out.="\n";
+	}
+}
+#
+# LOCAL_FUNCTION( <function name> ) - Local Function entry
+#
+# Somewhat more complex on z/OS - No saving or restoring of registers is done.
+#
+sub LOCAL_FUNCTION {
+   confess(err("ARGNUM")) if ($#_!=0);
+   my $func = shift;
+	$local_function = $func;
+   my $tmp = "";
+    if( $flavour =~ /linux/) {
+		$out.= ".type $func,\@function\n.align 32\n$func:\n";
+    } else {
+			$out.= "$func DS    0h\n"
+    }
+}
+
+#
+# Function entry
+#
+# Somewhat more complex on z/OS
+#   and complicated by lines over the 71 char limit.
+# FUNCTION_BEGIN( <function name>, <# of parms>, <LOCAL_VARS>, <PSECT name>, <BIG STACK> )
+#
+sub FUNCTION_BEGIN {
+   confess(err("ARGNUM")) if ($#_ < 1);
+   my $func = shift;
+	$local_function = $func;
+   my $tmp = "";
+#       $out.= sprintf("#function_begin(%s)\n",$func);
+   if( $flavour =~ /linux/) {
+		$out.= ".GLOBL $func\n.type $func,\@function\n.align 32\n$func:\n";
+   } else {
+		my $parms = shift;
+		my $localVars = shift;
+		my $psect = shift;
+		my $bigStack = shift;
+		$tmp= $func." ".$entryMacro;
+		$tmp.= sprintf(" ENTNAME=%s,BASEREG=12,PARMWRDS=%d",$func,$parms);
+		if (defined $localVars && $localVars ne '' ) {
+			$tmp.=sprintf(",DSASIZE=DYNSTOR_LEN");
+		}
+		if (defined $psect && $psect ne '' ) {
+			$tmp.= sprintf(",PSECT=%s",$psect);
+		}
+		if (defined $bigStack && $bigStack ne '' ) {
+			$tmp.= sprintf(",GT2KSTK=YES\n");
+		} else {
+			$tmp.= sprintf("\n");
+		}
+
+		my $strlen=length($tmp);  # zero based value
+
+		if ($strlen>70) {
+		# find the last parameter before column 71
+			my $break = rindex($tmp,",");
+			while ($break>70) {
+				$break = rindex($tmp,",", $break-1);
+			}
+			#$out.=sprintf("strlen=%d break=%d\n",$strlen,$break);
+			my $out1 = substr $tmp, 0, $break+1;
+			my $continuationChar = "X";
+			my $pad = "";
+			if ($break ne 70) {
+				$pad = substr "                                                                       ", 0, 71-$break-1;
+			}
+			my $out2 = substr $tmp, $break+1;
+			$out.= "$out1$pad$continuationChar\n               $out2\n"
+		} else {
+		$out.= $tmp;
+		}
+		if (defined $localVars && $localVars ne '' && $localVars eq "true") {
+			$out.= sprintf("    USING    DYNSTOR,R4\n");
+		}
+# And make the exported symbol case sensitive.
+# Still needs care with conflicts with INTERNAL symbols
+		$out.=sprintf("%s   ALIAS C'%s'\n",uc $func,$func);
+   }
+}
+#
+# FUNCTION_CALL( <function name> )
+#
+sub FUNCTION_CALL {
+	my $func = shift;
+	if ( $flavour =~ /linux/) {
+		$out.= "\tbras\t$func\n";
+	} else {
+		$out.= "    EDCXCALL    $func,WORKREG=10\n";
+	}
+}
+#
+# Local Function exit code
+#
+sub LOCAL_FUNCTION_END {
+    my $func = shift;
+#       $out.= sprintf("#function_end(%s)\n",$func);
+    LABEL("EXIT_".$func.":"); # Always emit the label
+    if ( $flavour =~ /linux/) {
+# Later, needs other changes
+        $out.= "\tbr\t%r14\n";
+        $out.= ".size $func,.-$func\n";
+    } else {
+        $out.= "    br    r7\n";
+        $out.= "* $func end\n";
+	}
+   $out.= "\n";
+}
+
+#
+# FUNCTION_END( <function name>, [return code reg])
+#    Note: Because z/OS uses a macro for function exit/returns we
+#          always need to branch to function exit on z/OS
+#          so we always stick a label at the end as a potential
+#          branch target
+#
+sub FUNCTION_END {
+#	confess(err("ARGNUM")) if ($#_ < 1); Seems utterly pointless ?
+	my $func = shift;
+	my $rv = shift;
+
+#       $out.= sprintf("#function_end(%s)\n",$func);
+	LABEL("EXIT_$local_function:"); # Always emit the label
+	if( $flavour =~ /linux/) {
+# Later, needs other changes
+		$out.= "\tlr\t%r2,$rv\n"	if (lc $rv ne "%r2");
+		$out.= "\tbr\t%r14\n";
+		$out.= ".size $func,.-$func\n";
+	} else {
+		$out.= "\tlr\tR3,$rv\n"		if (defined($rv) && $rv ne "R3");
+		$out.= "    ".$exitMacro."\n";
+		my $externName;
+		while ($externName = pop @externNames) {
+			$out.= "    CEEPDDA ".$externName.",SCOPE=IMPORT\n";
+			push @externNamesEmitted, $externName;
+		}
+   }
+   $out.= "\n";
+}
+#
+# OBJECT_BEGIN( <object name>, <alignment> )
+#
+# Data objects
+#
+sub OBJECT_BEGIN {
+   confess(err("ARGNUM")) if ($#_ < 1);
+   my $objectName = shift;
+   my $align = shift;
+   if( $flavour =~ /linux/) {
+		$out.= ".type .$objectName,\@object\n.align $align\n.$objectName:\n";
+   } else {
+#		$out.= sprintf("    CEEPDDA %s,SCOPE=LOCAL\n",$objectName);
+		$out.= sprintf("%s  DS 0F\n",$objectName);
+   }
+}
+
+# OBJECT_END( <object name> )
+sub OBJECT_END {
+#	confess(err("ARGNUM")) if ($#_ < 1); Seems utterly pointless ?
+   my $objectName = shift;
+   if( $flavour =~ /linux/) {
+		$out.= ".size .$objectName,.-.$objectName\n";
+#   } else {
+#		$out.= "    CEEPDDA END\n";
+   }
+   $out.= "\n";
+}
+# LOCAL_VARS_BEGIN(void)
+sub LOCAL_VARS_BEGIN() {
+	if( $flavour !~ /linux/) {
+		$out.= sprintf("DYNSTOR CEEDSA SECTYPE=XPLINK\n");
+	}
+}
+
+# ds(<var name>, <type>);
+sub ds {
+	my $varName = shift;
+	my $varType = shift;
+
+	if( $flavour !~ /linux/) {
+		$out.= sprintf("%s  DS    %s\n",$varName,$varType);
+	}
+}
+
+# LOCAL_VARS_END(void)
+sub LOCAL_VARS_END() {
+	if( $flavour !~ /linux/) {
+		$out.= sprintf("DYNSTOR_LEN EQU    *-CEEDSAHP_FIXED\n*\n");
+	}
+}
+# GET_EXTERN( <object name>, <target register> )
+sub GET_EXTERN {
+   my $targetReg = shift;
+   my $externName = shift;
+   if( $flavour =~ /linux/) {
+		$out.= "\tlarl\t$targetReg,$externName\n";
+   } else {
+		if ( !grep( /^$externName$/, @externNamesEmitted) ) {
+			push(@externNames, $externName);
+		}
+		$out.= "    CEEPLDA    $externName,REG=$targetReg\n";
+   }
+}
+
+# GET_OBJECT( <object name>, <target register> )
+sub GET_OBJECT {
+   #my $func = shift;
+   my $targetReg = shift;
+   my $externName = shift;
+   if( $flavour =~ /linux/) {
+		$out.= "\tlarl\t$targetReg,$externName\n";
+   } else {
+		$out.= "    CEEPLDA    $externName,REG=$targetReg\n";
+   }
+}
+#
+# Used where an opcode has to be handled as binary data or a series of binary data
+# .word on linux DC X'   ' on z/OS
+#
+sub opprefix {
+  if($flavour =~ /linux/) {
+    $out.= "\t.word\t";
+  } else {
+    $out.= "\tDC\t";
+  }
+}
+
+#
+# Used where an opcode has to be handled as binary data as a single long
+# .word on linux DC XL12'   ' on z/OS (Define constant ?)
+#
+sub opprefixl {
+  if($flavour =~ /linux/) {
+    $out.= "\t.long\t";
+  } else {
+    $out.= "\tDC\t";
+  }
+}
+
+#
+# Opcodes decribed as a set of .word statements
+#
+
+sub op {
+  my $opcode = shift;
+  my $tmp = "";
+
+  if($flavour =~ /linux/) {
+	$tmp = sprintf("0x%#06x",$opcode);
+		$tmp =~ s/0x0x/0x/g;
+	$out.= $tmp;
+   } else {
+     $out.= sprintf("XL4'%06x'",$opcode);
+   }
+}
+
+#
+# insert ".long" in the output stream
+#
+sub oprefix () {
+    $out.="\t.long\t";
+}
+#
+# opcodes described as a .long
+#
+sub opl {
+  my $opcode = shift;
+
+  if($flavour =~ /linux/) {
+#     $out.= sprintf("%#012x",$opcode); Left padding with zeros can result in 0c1 ABENDs
+     $out.= sprintf("0x%x",$opcode);
+   } else {
+     $out.= sprintf("XL12'%012x'",$opcode);
+   }
+}
+#
+# Emit a comment, different for zOS and Linux because we want the instructions to have correct syntax/registers
+#
+sub comment {
+  my $com = shift;
+  my $s = "\%";
+  if($flavour =~ /linux/) {
+    $out.="\t# $com\n";
+  } else {
+# 0xXX => X'XX'
+    $com =~ s/0x([0-9a-fA-F][0-9a-fA-F])/X'$1'/g;
+    $out.="  $com\n";
+  }
+}
+#
+# Emit instructions for more modern compilers
+#
+sub emitreal {
+  my $instr = shift;
+  my $s = "\%";
+  if($flavour =~ /linux/) {
+    $out.="\t$instr\n";
+  } else {
+    $instr =~ s/0x([0-9a-fA-F][0-9a-fA-F])/X'$1'/g;
+    $out.="    $instr\n";
+  }
 }

 #
 # Mnemonics
 #
+#
+# So we can fix exits. For zLinux br %r14 works
+# z/OS uses a macro to restore registers etc
+# so we jump to EXIT_$local_function instead and
+# wear the couple of extra cycles
+#
+# BR_EXIT( [condition] )
+sub BR_EXIT {
+	my $condition = shift;
+	$condition = "" if (!defined $condition);
+	if($flavour =~ /linux/) {
+		$out .= sprintf("\tb%sr\t%%r14\t# exit\n", $condition);
+	} else {
+		$out .= sprintf("    j%s EXIT_$local_function\n",$condition);

+	}
+}
+# MISC
 sub stfle {
 	confess(err("ARGNUM")) if ($#_!=0);
 	S(0xb2b0,@_);
 }

-# MISC
+sub clfi {
+	confess(err("ARGNUM")) if ($#_!=1);
+	RILa(0xc2f,@_);
+}

 sub clgfi {
 	confess(err("ARGNUM")) if ($#_!=1);
@@ -2532,12 +3387,17 @@ sub RIEf {
 	my ($opcode,$r1,$r2,$i3,$i4,$i5)=(shift,get_R(shift),get_R(shift),
 					  get_I(shift,8),get_I(shift,8),
 					  get_I(shift,8));
-
-	$out.="\t.word\t";
-	$out.=sprintf("%#06x",(($opcode>>8)<<8|$r1<<4|$r2)).",";
-	$out.=sprintf("%#06x",($i3<<8)|$i4).",";
-	$out.=sprintf("%#06x",($i5<<8)|($opcode&0xff));
-	$out.="\t# $memn\t$ops\n"
+	if($modern) {
+	  emitreal("$memn    $ops");
+	} else {
+	  opprefix();
+	  op(($opcode>>8)<<8|$r1<<4|$r2);
+	  $out.=",";
+	  op(($i3<<8)|$i4);
+	  $out.=",";
+	  op(($i5<<8)|($opcode&0xff));
+	  comment("$memn    $ops");
+   }
 }

 sub RILa {
@@ -2546,12 +3406,17 @@ sub RILa {
 	my $memn=(caller(1))[3];
 	$memn=~s/^.*:://;
 	my ($opcode,$r1,$i2)=(shift,get_R(shift),get_I(shift,32));
-
-	$out.="\t.word\t";
-	$out.=sprintf("%#06x",(($opcode>>4)<<8|$r1<<4|($opcode&0xf))).",";
-	$out.=sprintf("%#06x",($i2>>16)).",";
-	$out.=sprintf("%#06x",($i2&0xffff));
-	$out.="\t# $memn\t$ops\n"
+	if($modern) {
+	  emitreal("$memn\t$ops");
+	} else {
+	  opprefix();
+	  op(($opcode>>4)<<8|$r1<<4|($opcode&0xf));
+	  $out.=",";
+	  op($i2>>16);
+	  $out.=",";
+	  op($i2&0xffff);
+	  comment("$memn\t$ops");
+   }
 }

 sub RRE {
@@ -2559,10 +3424,14 @@ sub RRE {
 	my $ops=join(',',@_[1..$#_]);
 	my $memn=(caller(1))[3];
 	$memn=~s/^.*:://;
-	my ($opcode,$r1,$r2)=(shift,get_R(shift),get_R(shift));
-
-	$out.="\t.long\t".sprintf("%#010x",($opcode<<16|$r1<<4|$r2));
-	$out.="\t# $memn\t$ops\n"
+	if($modern) {
+		emitreal("$memn    $ops");
+	} else {
+		my ($opcode,$r1,$r2)=(shift,get_R(shift),get_R(shift));
+		opprefixl();
+		opl(($opcode<<16|$r1<<4|$r2));
+      comment("$memn    $ops");
+	}
 }

 sub RRFb {
@@ -2572,10 +3441,13 @@ sub RRFb {
 	$memn=~s/^.*:://;
 	my ($opcode,$r1,$r3,$r2,$m4)=(shift,get_R(shift),get_R(shift)
 	    ,get_R(shift),get_M(shift));
-
-	$out.="\t.long\t"
-	    .sprintf("%#010x",($opcode<<16|$r3<<12|$m4<<8|$r1<<4|$r2));
-	$out.="\t# $memn\t$ops\n"
+	if($modern) {
+		emitreal("$memn    $ops");
+	} else {
+		opprefixl();
+		opl(($opcode<<16|$r3<<12|$m4<<8|$r1<<4|$r2));
+      comment("$memn    $ops");
+	}
 }

 sub RXYa {
@@ -2584,12 +3456,17 @@ sub RXYa {
 	my $memn=(caller(1))[3];
 	$memn=~s/^.*:://;
 	my ($opcode,$r1,$d2,$x2,$b2)=(shift,get_R(shift),get_DXB(shift));
-
-	$out.="\t.word\t";
-	$out.=sprintf("%#06x",(($opcode>>8)<<8|$r1<<4|$x2)).",";
-	$out.=sprintf("%#06x",($b2<<12|($d2&0xfff))).",";
-	$out.=sprintf("%#06x",(($d2>>12)<<8|$opcode&0xff));
-	$out.="\t# $memn\t$ops\n"
+	if($modern) {
+		emitreal("$memn\t$ops");
+	} else {
+		opprefix();
+		op((($opcode>>8)<<8)|($r1<<4)|$x2);
+      $out.=",";
+      op(($b2<<12)|($d2&0xfff));
+      $out.=",";
+		op(($d2>>12)<<8|$opcode&0xff);
+		comment("$memn\t$ops");
+	}
 }

 sub S {
@@ -2598,9 +3475,13 @@ sub S {
 	my $memn=(caller(1))[3];
 	$memn=~s/^.*:://;
 	my ($opcode,$d2,$b2)=(shift,get_DB(shift));
-
-	$out.="\t.long\t".sprintf("%#010x",($opcode<<16|$b2<<12|$d2));
-	$out.="\t# $memn\t$ops\n"
+	if($modern) {
+		emitreal("$memn\t$ops");
+	} else {
+		opprefixl();
+		opl(($opcode<<16|$b2<<12|$d2));
+		comment("$memn\t$ops");
+	}
 }

 sub VRIa {
@@ -2610,12 +3491,17 @@ sub VRIa {
 	$memn=~s/^.*:://;
 	my ($opcode,$v1,$i2,$m3)=(shift,get_V(shift),get_I(shift,16),
 	    get_M(shift));
-
-	$out.="\t.word\t";
-	$out.=sprintf("%#06x",($opcode&0xff00|($v1&0xf)<<4)).",";
-	$out.=sprintf("%#06x",$i2).",";
-	$out.=sprintf("%#06x",($m3<<12|RXB($v1)<<8|$opcode&0xff));
-	$out.="\t# $memn\t$ops\n"
+	if($modern) {
+		emitreal("$memn\t$ops");
+	} else {
+		opprefix();
+		op(($opcode&0xff00|($v1&0xf)<<4));
+		$out.=",";
+		op($i2);
+		$out.=",";
+		op($m3<<12|RXB($v1)<<8|$opcode&0xff);
+		comment("$memn\t$ops");
+	}
 }

 sub VRIb {
@@ -2625,12 +3511,17 @@ sub VRIb {
 	$memn=~s/^.*:://;
 	my ($opcode,$v1,$i2,$i3,$m4)=(shift,get_V(shift),get_I(shift,8),
 	    ,get_I(shift,8),get_M(shift));
-
-	$out.="\t.word\t";
-	$out.=sprintf("%#06x",($opcode&0xff00|($v1&0xf)<<4)).",";
-	$out.=sprintf("%#06x",($i2<<8|$i3)).",";
-	$out.=sprintf("%#06x",($m4<<12|RXB($v1)<<8|$opcode&0xff));
-	$out.="\t# $memn\t$ops\n"
+	if($modern) {
+		emitreal("$memn\t$ops");
+	} else {
+		opprefix();
+		op($opcode&0xff00|($v1&0xf)<<4);
+		$out.=",";
+		op($i2<<8|$i3);
+      $out.=",";
+      op($m4<<12|RXB($v1)<<8|$opcode&0xff);
+		comment("$memn\t$ops");
+	}
 }

 sub VRIc {
@@ -2640,12 +3531,17 @@ sub VRIc {
 	$memn=~s/^.*:://;
 	my ($opcode,$v1,$v3,$i2,$m4)=(shift,get_V(shift),get_V(shift),
 	    ,get_I(shift,16),get_M(shift));
-
-	$out.="\t.word\t";
-	$out.=sprintf("%#06x",($opcode&0xff00|($v1&0xf)<<4)|($v3&0xf)).",";
-	$out.=sprintf("%#06x",$i2).",";
-	$out.=sprintf("%#06x",($m4<<12|RXB($v1,$v3)<<8|$opcode&0xff));
-	$out.="\t# $memn\t$ops\n"
+	if($modern) {
+		emitreal("$memn\t$ops");
+	} else {
+		opprefix();
+		op(($opcode&0xff00|($v1&0xf)<<4)|($v3&0xf));
+      $out.=",";
+      op($i2);
+      $out.=",";
+      op($m4<<12|RXB($v1,$v3)<<8|$opcode&0xff);
+		comment("$memn\t$ops");
+	}
 }

 sub VRId {
@@ -2655,12 +3551,17 @@ sub VRId {
 	$memn=~s/^.*:://;
 	my ($opcode,$v1,$v2,$v3,$i4,$m5)=(shift,get_V(shift),get_V(shift),
 	    ,get_V(shift),get_I(shift,8),get_M(shift));
-
-	$out.="\t.word\t";
-	$out.=sprintf("%#06x",($opcode&0xff00|($v1&0xf)<<4)|($v2&0xf)).",";
-	$out.=sprintf("%#06x",(($v3&0xf)<<12|$i4)).",";
-	$out.=sprintf("%#06x",($m5<<12|RXB($v1,$v2,$v3)<<8|$opcode&0xff));
-	$out.="\t# $memn\t$ops\n"
+	if($modern) {
+		emitreal("$memn\t$ops");
+	} else {
+		opprefix();
+		op(($opcode&0xff00|($v1&0xf)<<4)|($v2&0xf));
+      $out.=",";
+      op(($v3&0xf)<<12|$i4);
+      $out.=",";
+      op($m5<<12|RXB($v1,$v2,$v3)<<8|$opcode&0xff);
+		comment("$memn\t$ops");
+	}
 }

 sub VRIe {
@@ -2670,12 +3571,17 @@ sub VRIe {
 	$memn=~s/^.*:://;
 	my ($opcode,$v1,$v2,$i3,$m4,$m5)=(shift,get_V(shift),get_V(shift),
 	    ,get_I(shift,12),get_M(shift),get_M(shift));
-
-	$out.="\t.word\t";
-	$out.=sprintf("%#06x",($opcode&0xff00|($v1&0xf)<<4)|($v2&0xf)).",";
-	$out.=sprintf("%#06x",($i3<<4|$m5)).",";
-	$out.=sprintf("%#06x",($m4<<12|RXB($v1,$v2)<<8|$opcode&0xff));
-	$out.="\t# $memn\t$ops\n"
+	if($modern) {
+		emitreal("$memn\t$ops");
+	} else {
+		opprefix();
+		op(($opcode&0xff00|($v1&0xf)<<4)|($v2&0xf));
+      $out.=",";
+      op($i3<<4|$m5);
+      $out.=",";
+      op($m4<<12|RXB($v1,$v2)<<8|$opcode&0xff);
+		comment("$memn\t$ops");
+	}
 }

 sub VRIf {
@@ -2685,12 +3591,17 @@ sub VRIf {
 	$memn=~s/^.*:://;
 	my ($opcode,$v1,$v2,$v3,$i4,$m5)=(shift,get_V(shift),get_V(shift),
 	    ,get_V(shift),get_I(shift,8),get_M(shift));
-
-	$out.="\t.word\t";
-	$out.=sprintf("%#06x",($opcode&0xff00|($v1&0xf)<<4)|($v2&0xf)).",";
-	$out.=sprintf("%#06x",(($v3&0xf)<<12|$m5<<4)|$i4>>4).",";
-	$out.=sprintf("%#06x",(($i4&0xf)<<12|RXB($v1,$v2,$v3)<<8|$opcode&0xff));
-	$out.="\t# $memn\t$ops\n"
+	if($modern) {
+		emitreal("$memn\t$ops");
+	} else {
+		opprefix();
+		op(($opcode&0xff00|($v1&0xf)<<4)|($v2&0xf));
+		$out.=",";
+      op((($v3&0xf)<<12|$m5<<4)|$i4>>4);
+      $out .= ",";
+      op(($i4&0xf)<<12|RXB($v1,$v2,$v3)<<8|($opcode&0xff));
+		comment("$memn\t$ops");
+	}
 }

 sub VRIg {
@@ -2700,12 +3611,17 @@ sub VRIg {
 	$memn=~s/^.*:://;
 	my ($opcode,$v1,$v2,$i3,$i4,$m5)=(shift,get_V(shift),get_V(shift),
 	    ,get_I(shift,8),get_I(shift,8),get_M(shift));
-
-	$out.="\t.word\t";
-	$out.=sprintf("%#06x",($opcode&0xff00|($v1&0xf)<<4)|($v2&0xf)).",";
-	$out.=sprintf("%#06x",($i4<<8|$m5<<4|$i3>>4)).",";
-	$out.=sprintf("%#06x",(($i3&0xf)<<12|RXB($v1,$v2)<<8|$opcode&0xff));
-	$out.="\t# $memn\t$ops\n"
+	if($modern) {
+		emitreal("$memn\t$ops");
+	} else {
+		opprefix();
+		op(($opcode&0xff00|($v1&0xf)<<4)|($v2&0xf));
+		$out.=",";
+      op(($i4<<8|$m5<<4|$i3>>4));
+		$out.=",";
+		op((($i3&0xf)<<12|RXB($v1,$v2)<<8|$opcode&0xff));
+		comment("$memn\t$ops");
+	}
 }

 sub VRIh {
@@ -2715,12 +3631,17 @@ sub VRIh {
 	$memn=~s/^.*:://;
 	my ($opcode,$v1,$i2,$i3)=(shift,get_V(shift),get_I(shift,16),
 	    get_I(shift,4));
-
-	$out.="\t.word\t";
-	$out.=sprintf("%#06x",($opcode&0xff00|($v1&0xf)<<4)).",";
-	$out.=sprintf("%#06x",$i2).",";
-	$out.=sprintf("%#06x",($i3<<12|RXB($v1)<<8|$opcode&0xff));
-	$out.="\t# $memn\t$ops\n"
+	if($modern) {
+		emitreal("$memn\t$ops");
+	} else {
+		opprefix();
+		op(($opcode&0xff00|($v1&0xf)<<4));
+		$out.=",";
+		op($i2);
+		$out.=",";
+		op(($i3<<12|RXB($v1)<<8|$opcode&0xff));
+		comment("$memn\t$ops");
+	}
 }

 sub VRIi {
@@ -2730,12 +3651,17 @@ sub VRIi {
 	$memn=~s/^.*:://;
 	my ($opcode,$v1,$r2,$i3,$m4)=(shift,get_V(shift),get_R(shift),
 	    ,get_I(shift,8),get_M(shift));
-
-	$out.="\t.word\t";
-	$out.=sprintf("%#06x",($opcode&0xff00|($v1&0xf)<<4)|$r2).",";
-	$out.=sprintf("%#06x",($m4<<4|$i3>>4)).",";
-	$out.=sprintf("%#06x",(($i3&0xf)<<12|RXB($v1)<<8|$opcode&0xff));
-	$out.="\t# $memn\t$ops\n"
+	if($modern) {
+		emitreal("$memn\t$ops");
+	} else {
+		opprefix();
+		op(($opcode&0xff00|($v1&0xf)<<4)|$r2);
+		$out.=",";
+		op(($m4<<4|$i3>>4));
+		$out.=",";
+		op((($i3&0xf)<<12|RXB($v1)<<8|$opcode&0xff));
+		comment("$memn\t$ops");
+	}
 }

 sub VRRa {
@@ -2745,12 +3671,17 @@ sub VRRa {
 	$memn=~s/^.*:://;
 	my ($opcode,$v1,$v2,$m3,$m4,$m5)=(shift,get_V(shift),get_V(shift),
 	    get_M(shift),get_M(shift),get_M(shift));
-
-	$out.="\t.word\t";
-	$out.=sprintf("%#06x",($opcode&0xff00|($v1&0xf)<<4|($v2&0xf))).",";
-	$out.=sprintf("%#06x",($m5<<4|$m4)).",";
-	$out.=sprintf("%#06x",($m3<<12|RXB($v1,$v2)<<8|$opcode&0xff));
-	$out.="\t# $memn\t$ops\n"
+	if($modern) {
+		emitreal("$memn\t$ops");
+	} else {
+		opprefix();
+		op(($opcode&0xff00|($v1&0xf)<<4|($v2&0xf)));
+		$out.=",";
+		op(($m5<<4|$m4));
+		$out.=",";
+		op(($m3<<12|RXB($v1,$v2)<<8|$opcode&0xff));
+		comment("$memn\t$ops");
+	}
 }

 sub VRRb {
@@ -2760,12 +3691,17 @@ sub VRRb {
 	$memn=~s/^.*:://;
 	my ($opcode,$v1,$v2,$v3,$m4,$m5)=(shift,get_V(shift),get_V(shift),
 	    get_V(shift),get_M(shift),get_M(shift));
-
-	$out.="\t.word\t";
-	$out.=sprintf("%#06x",($opcode&0xff00|($v1&0xf)<<4|($v2&0xf))).",";
-	$out.=sprintf("%#06x",(($v3&0xf)<<12|$m5<<4)).",";
-	$out.=sprintf("%#06x",($m4<<12|RXB($v1,$v2,$v3)<<8|$opcode&0xff));
-	$out.="\t# $memn\t$ops\n"
+	if($modern) {
+		emitreal("$memn\t$ops");
+	} else {
+		opprefix();
+		op(($opcode&0xff00|($v1&0xf)<<4|($v2&0xf)));
+		$out.=",";
+		op(($v3&0xf)<<12|$m5<<4);
+		$out.=",";
+		op(($m4<<12|RXB($v1,$v2,$v3)<<8|$opcode&0xff));
+		comment("$memn\t$ops");
+	}
 }

 sub VRRc {
@@ -2775,12 +3711,17 @@ sub VRRc {
 	$memn=~s/^.*:://;
 	my ($opcode,$v1,$v2,$v3,$m4,$m5,$m6)=(shift,get_V(shift),get_V(shift),
 	    get_V(shift),get_M(shift),get_M(shift),get_M(shift));
-
-	$out.="\t.word\t";
-	$out.=sprintf("%#06x",($opcode&0xff00|($v1&0xf)<<4|($v2&0xf))).",";
-	$out.=sprintf("%#06x",(($v3&0xf)<<12|$m6<<4|$m5)).",";
-	$out.=sprintf("%#06x",($m4<<12|RXB($v1,$v2,$v3)<<8|$opcode&0xff));
-	$out.="\t# $memn\t$ops\n"
+	if($modern) {
+		emitreal("$memn\t$ops");
+	} else {
+		opprefix();
+		op(($opcode&0xff00|($v1&0xf)<<4|($v2&0xf)));
+		$out.=",";
+		op((($v3&0xf)<<12|$m6<<4|$m5));
+		$out.=",";
+		op(($m4<<12|RXB($v1,$v2,$v3)<<8|$opcode&0xff));
+		comment("$memn\t$ops");
+	}
 }

 sub VRRd {
@@ -2790,12 +3731,17 @@ sub VRRd {
 	$memn=~s/^.*:://;
 	my ($opcode,$v1,$v2,$v3,$v4,$m5,$m6)=(shift,get_V(shift),get_V(shift),
 	    get_V(shift),get_V(shift),get_M(shift),get_M(shift));
-
-	$out.="\t.word\t";
-	$out.=sprintf("%#06x",($opcode&0xff00|($v1&0xf)<<4|($v2&0xf))).",";
-	$out.=sprintf("%#06x",(($v3&0xf)<<12|$m5<<8|$m6<<4)).",";
-	$out.=sprintf("%#06x",(($v4&0xf)<<12|RXB($v1,$v2,$v3,$v4)<<8|$opcode&0xff));
-	$out.="\t# $memn\t$ops\n"
+	if($modern) {
+		emitreal("$memn\t$ops");
+	} else {
+		opprefix();
+		op(($opcode&0xff00|($v1&0xf)<<4|($v2&0xf)));
+		$out.=",";
+		op(($v3&0xf)<<12|$m5<<8|$m6<<4);
+		$out.=",";
+		op((($v4&0xf)<<12|RXB($v1,$v2,$v3,$v4)<<8|$opcode&0xff));
+		comment("$memn\t$ops");
+	}
 }

 sub VRRe {
@@ -2805,12 +3751,17 @@ sub VRRe {
 	$memn=~s/^.*:://;
 	my ($opcode,$v1,$v2,$v3,$v4,$m5,$m6)=(shift,get_V(shift),get_V(shift),
 	    get_V(shift),get_V(shift),get_M(shift),get_M(shift));
-
-	$out.="\t.word\t";
-	$out.=sprintf("%#06x",($opcode&0xff00|($v1&0xf)<<4|($v2&0xf))).",";
-	$out.=sprintf("%#06x",(($v3&0xf)<<12|$m6<<8|$m5)).",";
-	$out.=sprintf("%#06x",(($v4&0xf)<<12|RXB($v1,$v2,$v3,$v4)<<8|$opcode&0xff));
-	$out.="\t# $memn\t$ops\n"
+	if($modern) {
+		emitreal("$memn\t$ops");
+	} else {
+		opprefix();
+		op(($opcode&0xff00|($v1&0xf)<<4|($v2&0xf)));
+		$out.=",";
+		op((($v3&0xf)<<12|$m6<<8|$m5));
+		$out.=",";
+		op((($v4&0xf)<<12|RXB($v1,$v2,$v3,$v4)<<8|$opcode&0xff));
+		comment("$memn\t$ops");
+	}
 }

 sub VRRf {
@@ -2820,12 +3771,17 @@ sub VRRf {
 	$memn=~s/^.*:://;
 	my ($opcode,$v1,$r2,$r3)=(shift,get_V(shift),get_R(shift),
 	    get_R(shift));
-
-	$out.="\t.word\t";
-	$out.=sprintf("%#06x",($opcode&0xff00|($v1&0xf)<<4|$r2)).",";
-	$out.=sprintf("%#06x",($r3<<12)).",";
-	$out.=sprintf("%#06x",(RXB($v1)<<8|$opcode&0xff));
-	$out.="\t# $memn\t$ops\n"
+	if($modern) {
+		emitreal("$memn\t$ops");
+	} else {
+		opprefix();
+		op(($opcode&0xff00|($v1&0xf)<<4|$r2));
+		$out.=",";
+		op($r3<<12);
+		$out.=",";
+		op((RXB($v1)<<8|$opcode&0xff));
+		comment("$memn\t$ops");
+	}
 }

 sub VRRg {
@@ -2834,12 +3790,17 @@ sub VRRg {
 	my $memn=(caller(1))[3];
 	$memn=~s/^.*:://;
 	my ($opcode,$v1)=(shift,get_V(shift));
-
-	$out.="\t.word\t";
-	$out.=sprintf("%#06x",($opcode&0xff00|($v1&0xf))).",";
-	$out.=sprintf("%#06x",0x0000).",";
-	$out.=sprintf("%#06x",(RXB(0,$v1)<<8|$opcode&0xff));
-	$out.="\t# $memn\t$ops\n"
+	if($modern) {
+		emitreal("$memn\t$ops");
+	} else {
+		opprefix();
+		op(($opcode&0xff00|($v1&0xf)));
+		$out.=",";
+		op(0);
+		$out.=",";
+		op((RXB(0,$v1)<<8|$opcode&0xff));
+		comment("$memn\t$ops");
+	}
 }

 sub VRRh {
@@ -2849,12 +3810,17 @@ sub VRRh {
 	$memn=~s/^.*:://;
 	my ($opcode,$v1,$v2,$m3)=(shift,get_V(shift),get_V(shift),
 	    get_M(shift));
-
-	$out.="\t.word\t";
-	$out.=sprintf("%#06x",($opcode&0xff00|($v1&0xf))).",";
-	$out.=sprintf("%#06x",(($v2&0xf)<<12|$m3<<4)).",";
-	$out.=sprintf("%#06x",(RXB(0,$v1,$v2)<<8|$opcode&0xff));
-	$out.="\t# $memn\t$ops\n"
+	if($modern) {
+		emitreal("$memn\t$ops");
+	} else {
+		opprefix();
+		op(($opcode&0xff00|($v1&0xf)));
+		$out.=",";
+		op((($v2&0xf)<<12|$m3<<4));
+		$out.=",";
+		op((RXB(0,$v1,$v2)<<8|$opcode&0xff));
+		comment("$memn\t$ops");
+	}
 }

 sub VRRi {
@@ -2864,12 +3830,17 @@ sub VRRi {
 	$memn=~s/^.*:://;
 	my ($opcode,$r1,$v2,$m3)=(shift,get_R(shift),get_V(shift),
 	    get_M(shift));
-
-	$out.="\t.word\t";
-	$out.=sprintf("%#06x",($opcode&0xff00|$r1<<4|($v2&0xf))).",";
-	$out.=sprintf("%#06x",($m3<<4))."\,";
-	$out.=sprintf("%#06x",(RXB(0,$v2)<<8|$opcode&0xff));
-	$out.="\t# $memn\t$ops\n"
+	if($modern) {
+		emitreal("$memn\t$ops");
+	} else {
+		opprefix();
+		op(($opcode&0xff00|$r1<<4|($v2&0xf)));
+		$out.=",";
+		op($m3<<4);
+		$out.=",";
+		op((RXB(0,$v2)<<8|$opcode&0xff));
+		comment("$memn\t$ops");
+	}
 }

 sub VRSa {
@@ -2879,12 +3850,17 @@ sub VRSa {
 	$memn=~s/^.*:://;
 	my ($opcode,$v1,$v3,$d2,$b2,$m4)=(shift,get_V(shift),get_V(shift),
 	    get_DB(shift),get_M(shift));
-
-	$out.="\t.word\t";
-	$out.=sprintf("%#06x",($opcode&0xff00|($v1&0xf)<<4|($v3&0xf))).",";
-	$out.=sprintf("%#06x",($b2<<12|$d2)).",";
-	$out.=sprintf("%#06x",($m4<<12|RXB($v1,$v3)<<8|$opcode&0xff));
-	$out.="\t# $memn\t$ops\n"
+	if($modern) {
+		emitreal("$memn\t$ops");
+	} else {
+		opprefix();
+		op(($opcode&0xff00|($v1&0xf)<<4|($v3&0xf)));
+		$out.=",";
+		op($b2<<12|$d2);
+		$out.=",";
+		op(($m4<<12|RXB($v1,$v3)<<8|$opcode&0xff));
+		comment("$memn\t$ops");
+	}
 }

 sub VRSb {
@@ -2894,12 +3870,17 @@ sub VRSb {
 	$memn=~s/^.*:://;
 	my ($opcode,$v1,$r3,$d2,$b2,$m4)=(shift,get_V(shift),get_R(shift),
 	    get_DB(shift),get_M(shift));
-
-	$out.="\t.word\t";
-	$out.=sprintf("%#06x",($opcode&0xff00|($v1&0xf)<<4|$r3)).",";
-	$out.=sprintf("%#06x",($b2<<12|$d2)).",";
-	$out.=sprintf("%#06x",($m4<<12|RXB($v1)<<8|$opcode&0xff));
-	$out.="\t# $memn\t$ops\n"
+	if($modern) {
+		emitreal("$memn\t$ops");
+	} else {
+		opprefix();
+		op(($opcode&0xff00|($v1&0xf)<<4|$r3));
+		$out.=",";
+		op(($b2<<12|$d2));
+		$out.=",";
+		op(($m4<<12|RXB($v1)<<8|$opcode&0xff));
+		comment("$memn\t$ops");
+	}
 }

 sub VRSc {
@@ -2909,12 +3890,17 @@ sub VRSc {
 	$memn=~s/^.*:://;
 	my ($opcode,$r1,$v3,$d2,$b2,$m4)=(shift,get_R(shift),get_V(shift),
 	    get_DB(shift),get_M(shift));
-
-	$out.="\t.word\t";
-	$out.=sprintf("%#06x",($opcode&0xff00|$r1<<4|($v3&0xf))).",";
-	$out.=sprintf("%#06x",($b2<<12|$d2)).",";
-	$out.=sprintf("%#06x",($m4<<12|RXB(0,$v3)<<8|$opcode&0xff));
-	$out.="\t# $memn\t$ops\n"
+	if($modern) {
+		emitreal("$memn\t$ops");
+	} else {
+		opprefix();
+		op(($opcode&0xff00|$r1<<4|($v3&0xf)));
+		$out.=",";
+		op(($b2<<12|$d2));
+		$out.=",";
+		op(($m4<<12|RXB(0,$v3)<<8|$opcode&0xff));
+		comment("$memn\t$ops");
+	}
 }

 sub VRSd {
@@ -2924,12 +3910,17 @@ sub VRSd {
 	$memn=~s/^.*:://;
 	my ($opcode,$v1,$r3,$d2,$b2)=(shift,get_V(shift),get_R(shift),
 	    get_DB(shift));
-
-	$out.="\t.word\t";
-	$out.=sprintf("%#06x",($opcode&0xff00|$r3)).",";
-	$out.=sprintf("%#06x",($b2<<12|$d2)).",";
-	$out.=sprintf("%#06x",(($v1&0xf)<<12|RXB(0,0,0,$v1)<<8|$opcode&0xff));
-	$out.="\t# $memn\t$ops\n"
+	if($modern) {
+		emitreal("$memn\t$ops");
+	} else {
+		opprefix();
+		op(($opcode&0xff00|$r3));
+		$out.=",";
+		op(($b2<<12|$d2));
+		$out.=",";
+		op((($v1&0xf)<<12|RXB(0,0,0,$v1)<<8|$opcode&0xff));
+		comment("$memn\t$ops");
+	}
 }

 sub VRV {
@@ -2939,12 +3930,17 @@ sub VRV {
 	$memn=~s/^.*:://;
 	my ($opcode,$v1,$d2,$v2,$b2,$m3)=(shift,get_V(shift),get_DVB(shift),
 	    get_M(shift));
-
-	$out.="\t.word\t";
-	$out.=sprintf("%#06x",($opcode&0xff00|($v1&0xf)<<4|($v2&0xf))).",";
-	$out.=sprintf("%#06x",($b2<<12|$d2)).",";
-	$out.=sprintf("%#06x",($m3<<12|RXB($v1,$v2)<<8|$opcode&0xff));
-	$out.="\t# $memn\t$ops\n"
+	if($modern) {
+		emitreal("$memn\t$ops");
+	} else {
+		opprefix();
+		op(($opcode&0xff00|($v1&0xf)<<4|($v2&0xf)));
+		$out.=",";
+		op(($b2<<12|$d2));
+		$out.=",";
+		op(($m3<<12|RXB($v1,$v2)<<8|$opcode&0xff));
+		comment("$memn\t$ops");
+	}
 }

 sub VRX {
@@ -2954,12 +3950,17 @@ sub VRX {
 	$memn=~s/^.*:://;
 	my ($opcode,$v1,$d2,$x2,$b2,$m3)=(shift,get_V(shift),get_DXB(shift),
 	    get_M(shift));
-
-	$out.="\t.word\t";
-	$out.=sprintf("%#06x",($opcode&0xff00|($v1&0xf)<<4|($x2))).",";
-	$out.=sprintf("%#06x",($b2<<12|$d2)).",";
-	$out.=sprintf("%#06x",($m3<<12|RXB($v1)<<8|$opcode&0xff));
-	$out.="\t# $memn\t$ops\n"
+	if($modern) {
+		emitreal("$memn\t$ops");
+	} else {
+		opprefix();
+		op(($opcode&0xff00|($v1&0xf)<<4|($x2)));
+		$out.=",";
+		op(($b2<<12|$d2));
+		$out.=",";
+		op(($m3<<12|RXB($v1)<<8|$opcode&0xff));
+		comment("$memn\t$ops");
+	}
 }

 sub VSI {
@@ -2969,12 +3970,17 @@ sub VSI {
 	$memn=~s/^.*:://;
 	my ($opcode,$v1,$d2,$b2,$i3)=(shift,get_V(shift),get_DB(shift),
 	    get_I(shift,8));
-
-	$out.="\t.word\t";
-	$out.=sprintf("%#06x",($opcode&0xff00|$i3)).",";
-	$out.=sprintf("%#06x",($b2<<12|$d2)).",";
-	$out.=sprintf("%#06x",(($v1&0xf)<<12|RXB(0,0,0,$v1)<<8|$opcode&0xff));
-	$out.="\t# $memn\t$ops\n"
+	if($modern) {
+		emitreal("$memn\t$ops");
+	} else {
+		opprefix();
+		op(($opcode&0xff00|$i3));
+		$out.=",";
+		op(($b2<<12|$d2));
+		$out.=",";
+		op((($v1&0xf)<<12|RXB(0,0,0,$v1)<<8|$opcode&0xff));
+		comment("$memn\t$ops");
+	}
 }

 #
diff --git a/crypto/poly1305/asm/poly1305-s390x.pl b/crypto/poly1305/asm/poly1305-s390x.pl
index bcc8fd3..34c39a4 100755
--- a/crypto/poly1305/asm/poly1305-s390x.pl
+++ b/crypto/poly1305/asm/poly1305-s390x.pl
@@ -1,5 +1,5 @@
 #! /usr/bin/env perl
-# Copyright 2016-2020 The OpenSSL Project Authors. All Rights Reserved.
+# Copyright 2016 The OpenSSL Project Authors. All Rights Reserved.
 #
 # Licensed under the OpenSSL license (the "License").  You may not use
 # this file except in compliance with the License.  You can obtain a copy
@@ -24,204 +24,301 @@
 #
 # On side note, z13 enables vector base 2^26 implementation...

-$flavour = shift;
+use strict;
+use FindBin qw($Bin);
+use lib "$Bin/../..";
+use perlasm::s390x qw(:DEFAULT :LD :GE :EI :MI1 :VX AUTOLOAD LABEL INCLUDE LONG FUNCTION_BEGIN LOCAL_FUNCTION FUNCTION_END LOCAL_FUNCTION_END OBJECT_BEGIN OBJECT_END ALIGN ASCIZ TEXT GET_EXTERN LOCAL_VARS_BEGIN LOCAL_VARS_END BR_EXIT ds);

+my $flavour = shift;
+
+my ($z,$DSA_OFF,$PARMS_OFF,$SIZE_T);
+$DSA_OFF=2048;
 if ($flavour =~ /3[12]/) {
-	$SIZE_T=4;
-	$g="";
+        $z=0;   # 31/32 bit ABI
+        $SIZE_T=4;
+        $PARMS_OFF=2112;
 } else {
-	$SIZE_T=8;
-	$g="g";
+        $z=1;   # 64 bit ABI
+        $SIZE_T=8;
+        $PARMS_OFF=2176;
 }

+my $output;
 while (($output=shift) && ($output!~/\w[\w\-]*\.\w+$/)) {}
-open STDOUT,">$output";

-$sp="%r15";
+my $stdframe=16*$SIZE_T+4*8;
+my ($r0,$r1,$r10,$r15);
+my ($sp,$ra,$rv);
+
+my ($ctx,$inp,$len,$padbit);
+if ($flavour =~ /linux/) {
+        ($ctx,$inp,$len,$padbit) = map("%r$_",(2..5));
+
+        ($r0,$r1,$r10,$r15) = map("%r$_",(0..1,10,15));
+        $ra="%r14";
+        $sp="%r15";
+        $rv = "%r2";
+} else {
+        ($ctx,$inp,$len,$padbit) = map("R$_",(2..5));
+
+        ($r0,$r1,$r10,$r15) = map("R$_",(0..1,10,15));
+        $ra="R14";
+        $sp="R15";
+        $rv="R2";
+}
+
+PERLASM_BEGIN($flavour,$output);
+
+INCLUDE ("s390x_arch.h","crypto/");
+TEXT    ();
+
+{
+my ($ctx,$inp,$rv);
+my ($wr1,$wr2,$wr3);
+
+if ($flavour =~ /linux/) {
+        $ctx="%r2";
+        $inp="%r3";
+
+        ($wr1,$wr2,$wr3) = map("%r$_",(1,4,5));
+        $rv="%r2";
+} else {
+        $ctx="R1";
+        $inp="R2";
+
+        ($wr1,$wr2,$wr3) = map("R$_",(7..9));
+        $rv="R3";
+}
+

-my ($ctx,$inp,$len,$padbit) = map("%r$_",(2..5));
+# int poly1305_init(void *ctx, const unsigned char key[16]);

-$code.=<<___;
-.text
+FUNCTION_BEGIN("poly1305_init",2);   # 2 parms, no local storage
+	lghi	($r0,0);
+	lghi	($wr1,-1);
+	stg	($r0,"0($ctx)");		# zero hash value
+	stg	($r0,"8($ctx)");
+	stg	($r0,"16($ctx)");

-.globl	poly1305_init
-.type	poly1305_init,\@function
-.align	16
-poly1305_init:
-	lghi	%r0,0
-	lghi	%r1,-1
-	stg	%r0,0($ctx)		# zero hash value
-	stg	%r0,8($ctx)
-	stg	%r0,16($ctx)
+	&{$z? \&clgr :\&clr}  ($inp,$r0);

-	cl${g}r	$inp,%r0
-	je	.Lno_key
+	je		(LABEL("Lno_key"));

-	lrvg	%r4,0($inp)		# load little-endian key
-	lrvg	%r5,8($inp)
+	lrvg	($wr2,"0($inp)");		# load little-endian key
+	lrvg	($wr3,"8($inp)");

-	nihl	%r1,0xffc0		# 0xffffffc0ffffffff
-	srlg	%r0,%r1,4		# 0x0ffffffc0fffffff
-	srlg	%r1,%r1,4
-	nill	%r1,0xfffc		# 0x0ffffffc0ffffffc
+	nihl	($wr1,0xffc0);		# 0xffffffc0ffffffff
+	srlg	($r0,$wr1,4);		# 0x0ffffffc0fffffff
+	srlg	($wr1,$wr1,4);
+	nill	($wr1,0xfffc);		# 0x0ffffffc0ffffffc

-	ngr	%r4,%r0
-	ngr	%r5,%r1
+	ngr	($wr2,$r0);
+	ngr	($wr3,$wr1);

-	stg	%r4,32($ctx)
-	stg	%r5,40($ctx)
+	stg	($wr2,"32($ctx)");
+	stg	($wr3,"40($ctx)");
+
+LABEL("Lno_key:");
+	lghi	($rv,0);
+FUNCTION_END("poly1305_init",$rv);
+}

-.Lno_key:
-	lghi	%r2,0
-	br	%r14
-.size	poly1305_init,.-poly1305_init
-___
 {
-my ($d0hi,$d0lo,$d1hi,$d1lo,$t0,$h0,$t1,$h1,$h2) = map("%r$_",(6..14));
-my ($r0,$r1,$s1) = map("%r$_",(0..2));
-
-$code.=<<___;
-.globl	poly1305_blocks
-.type	poly1305_blocks,\@function
-.align	16
-poly1305_blocks:
-	srl${g}	$len,4			# fixed-up in 64-bit build
-	lghi	%r0,0
-	cl${g}r	$len,%r0
-	je	.Lno_data
-
-	stm${g}	%r6,%r14,`6*$SIZE_T`($sp)
-
-	llgfr   $padbit,$padbit		# clear upper half, much needed with
-					# non-64-bit ABI
-	lg	$r0,32($ctx)		# load key
-	lg	$r1,40($ctx)
-
-	lg	$h0,0($ctx)		# load hash value
-	lg	$h1,8($ctx)
-	lg	$h2,16($ctx)
-
-	st$g	$ctx,`2*$SIZE_T`($sp)	# off-load $ctx
-	srlg	$s1,$r1,2
-	algr	$s1,$r1			# s1 = r1 + r1>>2
-	j	.Loop
-
-.align	16
-.Loop:
-	lrvg	$d0lo,0($inp)		# load little-endian input
-	lrvg	$d1lo,8($inp)
-	la	$inp,16($inp)
-
-	algr	$d0lo,$h0		# accumulate input
-	alcgr	$d1lo,$h1
-
-	lgr	$h0,$d0lo
-	mlgr	$d0hi,$r0		# h0*r0	  -> $d0hi:$d0lo
-	lgr	$h1,$d1lo
-	mlgr	$d1hi,$s1		# h1*5*r1 -> $d1hi:$d1lo
-
-	mlgr	$t0,$r1			# h0*r1   -> $t0:$h0
-	mlgr	$t1,$r0			# h1*r0   -> $t1:$h1
-	alcgr	$h2,$padbit
-
-	algr	$d0lo,$d1lo
-	lgr	$d1lo,$h2
-	alcgr	$d0hi,$d1hi
-	lghi	$d1hi,0
-
-	algr	$h1,$h0
-	alcgr	$t1,$t0
-
-	msgr	$d1lo,$s1		# h2*s1
-	msgr	$h2,$r0			# h2*r0
-
-	algr	$h1,$d1lo
-	alcgr	$t1,$d1hi		# $d1hi is zero
-
-	algr	$h1,$d0hi
-	alcgr	$h2,$t1
-
-	lghi	$h0,-4			# final reduction step
-	ngr	$h0,$h2
-	srlg	$t0,$h2,2
-	algr	$h0,$t0
-	lghi	$t1,3
-	ngr	$h2,$t1
-
-	algr	$h0,$d0lo
-	alcgr	$h1,$d1hi		# $d1hi is still zero
-	alcgr	$h2,$d1hi		# $d1hi is still zero
-
-	brct$g	$len,.Loop
-
-	l$g	$ctx,`2*$SIZE_T`($sp)	# restore $ctx
-
-	stg	$h0,0($ctx)		# store hash value
-	stg	$h1,8($ctx)
-	stg	$h2,16($ctx)
-
-	lm${g}	%r6,%r14,`6*$SIZE_T`($sp)
-.Lno_data:
-	br	%r14
-.size	poly1305_blocks,.-poly1305_blocks
-___
+# static void poly1305_blocks(void *ctx, const unsigned char *inp,
+#                             size_t len, u32 padbit)
+
+my ($d0hi,$d0lo,$d1hi,$d1lo,$t0,$h0,$t1,$h1,$h2);
+my $s1;
+if ($flavour =~/linux/) {
+	($d0hi,$d0lo,$d1hi,$d1lo,$t0,$h0,$t1,$h1,$h2) = map("%r$_",(6..14));
+	$s1 = "%r2";
+} else {
+	($d0hi,$d0lo,$d1hi,$d1lo,$t0,$h0,$t1,$h1,$h2) = map("R$_",(6..14));
+	$s1 = "R2";
+}
+
+
+FUNCTION_BEGIN("poly1305_blocks",4,"true");		# 4 params, Local storage
+if ($flavour =~ /linux/) {
+	if ($z) {
+		srlg ($len, $len,4);
+	} else {
+		srl ($len,4);
+	}
+
+	lghi	($r0,0);
+	&{$z? \&clgr :\&clr}	($len,$r0);
+	je		(LABEL("Lno_data"));
+
+	&{$z? \&stmg:\&stm} ("%r6","%r14","6*$SIZE_T($sp)");
+} else {
+	# len is in R3 on z/OS will move into R4 after test, stack is setup and R4 (DSA ptr) is saved.
+	if ($z) {
+		srlg ("R3","R3",4);
+	} else {
+		srl ("R3",4);
+	}
+
+	lghi	($r0,0);
+	&{$z? \&clgr :\&clr}	("R3",$r0);
+	je		(LABEL("Lno_data"));
+
+	# z/OS: establish stack, move parms to appropriate regs
+	la      ($sp,"STACK");
+	&{$z? \&stg:\&st}	("R4","4*$SIZE_T($sp)"); # Store R4 before it is corrupted
+	&{$z? \&lg:\&l}	("R9","$DSA_OFF(R4)");      # Get DSA address, before corrupting R4
+	lgr		($len,"R3");
+	lgr		($inp,"R2");
+	lgr		($ctx,"R1");
+	&{$z? \&lg:\&l}	($padbit,"$PARMS_OFF+$SIZE_T*3(R9)"); # Get padbit from DSA
+}
+
+	llgfr   ($padbit,$padbit);		# clear upper half, much needed with non-64-bit ABI
+	lg		($r0,"32($ctx)");		# load key
+	lg		($r1,"40($ctx)");
+
+	lg		($h0,"0($ctx)");		# load hash value
+	lg		($h1,"8($ctx)");
+	lg		($h2,"16($ctx)");
+
+	&{$z ? \&stg : \&st } ($ctx,"2*$SIZE_T($sp)");
+
+	srlg	($s1,$r1,2);
+	algr	($s1,$r1);			# s1 = r1 + r1>>2
+	j		(LABEL("Loop"));
+
+ALIGN(16);
+LABEL("Loop:");
+	lrvg	($d0lo,"0($inp)");		# load little-endian input
+	lrvg	($d1lo,"8($inp)");
+	la		($inp,"16($inp)");
+
+	algr	($d0lo,$h0);		# accumulate input
+	alcgr	($d1lo,$h1);
+
+	lgr	($h0,$d0lo);
+	mlgr	($d0hi,$r0);		# h0*r0	  -> $d0hi:$d0lo
+	lgr	($h1,$d1lo);
+	mlgr	($d1hi,$s1);		# h1*5*r1 -> $d1hi:$d1lo
+
+	mlgr	($t0,$r1);			# h0*r1   -> $t0:$h0
+	mlgr	($t1,$r0);			# h1*r0   -> $t1:$h1
+	alcgr	($h2,$padbit);
+
+	algr	($d0lo,$d1lo);
+	lgr	($d1lo,$h2);
+	alcgr	($d0hi,$d1hi);
+	lghi	($d1hi,0);
+
+	algr	($h1,$h0);
+	alcgr	($t1,$t0);
+
+	msgr	($d1lo,$s1);		# h2*s1
+	msgr	($h2,$r0);			# h2*r0
+
+	algr	($h1,$d1lo);
+	alcgr	($t1,$d1hi);		# $d1hi is zero
+
+	algr	($h1,$d0hi);
+	alcgr	($h2,$t1);
+
+	lghi	($h0,-4);			# final reduction step
+	ngr	($h0,$h2);
+	srlg	($t0,$h2,2);
+	algr	($h0,$t0);
+	lghi	($t1,3);
+	ngr	($h2,$t1);
+
+	algr	($h0,$d0lo);
+	alcgr	($h1,$d1hi);		# $d1hi is still zero
+	alcgr	($h2,$d1hi);		# $d1hi is still zero
+
+	&{$z ? \&brctg : \&brct} ($len,LABEL("Loop"));
+	&{$z ? \&lg : \&l } ($ctx,"2*$SIZE_T($sp)");
+
+
+	stg	($h0,"0($ctx)");		# store hash value
+	stg	($h1,"8($ctx)");
+	stg	($h2,"16($ctx)");
+
+if ($flavour =~/linux/) {
+	&{$z? \&lmg:\&lm}	("%r6","%r14","6*$SIZE_T($sp)");
+} else {
+	&{$z? \&lg:\&l}		("R4","4*$SIZE_T($sp)"); # Restore R4 so DSA can be accessed
+}
+LABEL("Lno_data:");
+FUNCTION_END("poly1305_blocks",$rv);
 }
+
+
 {
-my ($mac,$nonce)=($inp,$len);
-my ($h0,$h1,$h2,$d0,$d1)=map("%r$_",(5..9));
-
-$code.=<<___;
-.globl	poly1305_emit
-.type	poly1305_emit,\@function
-.align	16
-poly1305_emit:
-	stm${g}	%r6,%r9,`6*$SIZE_T`($sp)
-
-	lg	$h0,0($ctx)
-	lg	$h1,8($ctx)
-	lg	$h2,16($ctx)
-
-	lghi	%r0,5
-	lghi	%r1,0
-	lgr	$d0,$h0
-	lgr	$d1,$h1
-
-	algr	$h0,%r0			# compare to modulus
-	alcgr	$h1,%r1
-	alcgr	$h2,%r1
-
-	srlg	$h2,$h2,2		# did it borrow/carry?
-	slgr	%r1,$h2			# 0-$h2>>2
-	lg	$h2,0($nonce)		# load nonce
-	lghi	%r0,-1
-	lg	$ctx,8($nonce)
-	xgr	%r0,%r1			# ~%r1
-
-	ngr	$h0,%r1
-	ngr	$d0,%r0
-	ngr	$h1,%r1
-	ngr	$d1,%r0
-	ogr	$h0,$d0
-	rllg	$d0,$h2,32		# flip nonce words
-	ogr	$h1,$d1
-	rllg	$d1,$ctx,32
-
-	algr	$h0,$d0			# accumulate nonce
-	alcgr	$h1,$d1
-
-	strvg	$h0,0($mac)		# write little-endian result
-	strvg	$h1,8($mac)
-
-	lm${g}	%r6,%r9,`6*$SIZE_T`($sp)
-	br	%r14
-.size	poly1305_emit,.-poly1305_emit
-
-.string	"Poly1305 for s390x, CRYPTOGAMS by <appro\@openssl.org>"
-___
+################
+# static void poly1305_emit(void *ctx, unsigned char mac[16],
+#                           const u32 nonce[4])
+
+my ($ctx,$mac,$nonce);
+my ($h0,$h1,$h2,$d0,$d1);
+my $wr1;
+if ($flavour =~ /linux/) {
+	($ctx,$mac,$nonce)=map("%r$_",(2..4));
+	($h0,$h1,$h2,$d0,$d1)=map("%r$_",(5..9));
+	$wr1="%r1";
+} else {
+	($ctx,$mac,$nonce)=map("R$_",(1..3));
+	($h0,$h1,$h2,$d0,$d1)=map("R$_",(5..9));
+	$wr1="R11";		# ctx is in r1, use r11 instead
+}
+
+FUNCTION_BEGIN("poly1305_emit",3);
+	&{$z ? \&stmg : \&stm}	("%r6","%r9","6*$SIZE_T($sp)") if ($flavour =~ /linux/);
+
+
+	lg		($h0,"0($ctx)");
+	lg		($h1,"8($ctx)");
+	lg		($h2,"16($ctx)");
+
+	lghi	($r0,5);
+	lghi	($wr1,0);
+	lgr	($d0,$h0);
+	lgr	($d1,$h1);
+
+	algr	($h0,$r0);			# compare to modulus
+	alcgr	($h1,$wr1);
+	alcgr	($h2,$wr1);
+
+	srlg	($h2,$h2,2);		# did it borrow/carry?
+	slgr	($wr1,$h2);			# 0-$h2>>2
+	lg		($h2,"0($nonce)");		# load nonce
+	lghi	($r0,-1);
+	lg		($ctx,"8($nonce)");
+	xgr	($r0,$wr1);			# ~%r1
+
+	ngr	($h0,$wr1);
+	ngr	($d0,$r0);
+	ngr	($h1,$wr1);
+	ngr	($d1,$r0);
+	ogr	($h0,$d0);
+	rllg	($d0,$h2,32);		# flip nonce words
+	ogr	($h1,$d1);
+	rllg	($d1,$ctx,32);
+
+	algr	($h0,$d0);			# accumulate nonce
+	alcgr	($h1,$d1);
+
+	strvg	($h0,"0($mac)");		# write little-endian result
+	strvg	($h1,"8($mac)");
+	&{$z ? \&lmg : \&lm} ("%r6","%r9","6*$SIZE_T($sp)") if ($flavour =~ /linux/);
+
+FUNCTION_END("poly1305_emit",$rv);
 }

-$code =~ s/\`([^\`]*)\`/eval $1/gem;
-$code =~ s/\b(srlg\s+)(%r[0-9]+\s*,)\s*([0-9]+)/$1$2$2$3/gm;
+ASCIZ("Poly1305 for s390x, CRYPTOGAMS by <appro\@openssl.org>");
+
+LOCAL_VARS_BEGIN();
+   ds		("STACKSPACE","178F");
+   ds		("STACK", "0F");
+   ds		("SAVEAREA","32F");
+LOCAL_VARS_END();
+
+PERLASM_END();

-print $code;
-close STDOUT or die "error closing STDOUT: $!";
diff --git a/crypto/poly1305/build.info b/crypto/poly1305/build.info
index 4e4dcca..f74ef8a 100644
--- a/crypto/poly1305/build.info
+++ b/crypto/poly1305/build.info
@@ -18,6 +18,7 @@ INCLUDE[poly1305-armv8.o]=..
 GENERATE[poly1305-mips.S]=asm/poly1305-mips.pl $(PERLASM_SCHEME)
 INCLUDE[poly1305-mips.o]=..
 GENERATE[poly1305-s390x.S]=asm/poly1305-s390x.pl $(PERLASM_SCHEME)
+GENERATE[poly1305-s390x.s]=asm/poly1305-s390x.pl $(PERLASM_SCHEME)

 BEGINRAW[Makefile(unix)]
 {- $builddir -}/poly1305-%.S:	{- $sourcedir -}/asm/poly1305-%.pl
diff --git a/crypto/rc4/asm/rc4-s390x.pl b/crypto/rc4/asm/rc4-s390x.pl
index dded0b7..f35e36a 100644
--- a/crypto/rc4/asm/rc4-s390x.pl
+++ b/crypto/rc4/asm/rc4-s390x.pl
@@ -1,5 +1,5 @@
 #! /usr/bin/env perl
-# Copyright 2009-2020 The OpenSSL Project Authors. All Rights Reserved.
+# Copyright 2009-2016 The OpenSSL Project Authors. All Rights Reserved.
 #
 # Licensed under the OpenSSL license (the "License").  You may not use
 # this file except in compliance with the License.  You can obtain a copy
@@ -30,212 +30,272 @@
 # remains z/Architecture specific. On z990 it was measured to perform
 # 50% better than code generated by gcc 4.3.

-$flavour = shift;
+#
+# 2019 Ported to support dual ABI (zLinux/zOS) conventions
+# Peter Waltenberg (pwalten@au1.ibm.com), Jonathon Furminger <furming@us.ibm.com>
+#
+
+use strict;
+use FindBin qw($Bin);
+use lib "$Bin/../..";
+use perlasm::s390x qw(:MSA :DEFAULT :VX :LD AUTOLOAD LABEL INCLUDE FUNCTION_BEGIN FUNCTION_END OBJECT_BEGIN OBJECT_END BYTE LONG ALIGN ASCIZ TEXT GET_EXTERN LOCAL_VARS_BEGIN LOCAL_VARS_END ds );
+
+
+my $flavour = shift;
+my $output;
+my ($z,$SIZE_T,$g,$PARMS_OFF,$DSA_OFF);
+my($rv,$rp,$sp);
+my ($acc,$cnt,$key,$len,$inp,$out,@XX,@TX,$YY,$TY);
+my ($i,$idx,$dat,$ikey,$iinp);
+my ($wr0,$wr6,$wr8,$wr11);
+
+$DSA_OFF=2048;

 if ($flavour =~ /3[12]/) {
+	$z=0;	# S/390 ABI
 	$SIZE_T=4;
-	$g="";
+	$PARMS_OFF=2112
 } else {
+	$z=1;	# zSeries/zOS  ABI
 	$SIZE_T=8;
-	$g="g";
+	$PARMS_OFF=2176
 }

 while (($output=shift) && ($output!~/\w[\w\-]*\.\w+$/)) {}
 open STDOUT,">$output";

-$rp="%r14";
-$sp="%r15";
-$code=<<___;
-.text
+if($flavour =~ /linux/) {
+	$rv = "%r2";
+	$rp = "%r14";
+	$sp = "%r15";
+} else {
+	$rv = "r3";
+	$rp = "r7";
+	$sp = "r4";
+}

-___
+PERLASM_BEGIN($flavour,$output);

 # void RC4(RC4_KEY *key,size_t len,const void *inp,void *out)
-{
-$acc="%r0";
-$cnt="%r1";
-$key="%r2";
-$len="%r3";
-$inp="%r4";
-$out="%r5";
-
-@XX=("%r6","%r7");
-@TX=("%r8","%r9");
-$YY="%r10";
-$TY="%r11";
-
-$code.=<<___;
-.globl	RC4
-.type	RC4,\@function
-.align	64
-RC4:
-	stm${g}	%r6,%r11,6*$SIZE_T($sp)
-___
-$code.=<<___ if ($flavour =~ /3[12]/);
-	llgfr	$len,$len
-___
-$code.=<<___;
-	llgc	$XX[0],0($key)
-	llgc	$YY,1($key)
-	la	$XX[0],1($XX[0])
-	nill	$XX[0],0xff
-	srlg	$cnt,$len,3
-	ltgr	$cnt,$cnt
-	llgc	$TX[0],2($XX[0],$key)
-	jz	.Lshort
-	j	.Loop8
-
-.align	64
-.Loop8:
-___
+
+
+	if($flavour =~ /linux/) {
+		$acc="%r0";
+		$cnt="%r1";
+		$key="%r2";
+		$len="%r3";
+		$inp="%r4";
+		$out="%r5";
+
+		@XX=("%r6","%r7");
+		@TX=("%r8","%r9");
+		$YY="%r10";
+		$TY="%r11";
+		$rv = "%r2";
+		$wr6 = "%r6";
+		$wr8 = "%r8";
+	} else {
+		$acc="r0";
+		$cnt="r5";
+		$key="r1";
+		$len="r2";
+		$inp="r3";
+		$out="r7";  # return address gets restored by EDCXEPLG
+
+		@XX=("r6","r13");
+		@TX=("r8","r9");
+		$YY="r10";
+		$TY="r11";
+      $wr6="r6";
+		$rv = "r3";
+	}
+
+TEXT();
+#void RC4(RC4_KEY *key, size_t len, const unsigned char *indata,unsigned char *outdata)
+
+FUNCTION_BEGIN("RC4",4,"");
+	if($flavour =~ /3[12]/) {
+		stm	("%r6","%r11","6*$SIZE_T($sp)") if ($flavour =~ /linux/);
+		llgfr	($len,$len);
+	} else {
+		stmg	("%r6","%r11","6*$SIZE_T($sp)") if ($flavour =~ /linux/);
+	}
+
+        if ($flavour !~ /linux/) {
+            &{$z? \&lg:\&l} ("r9","$DSA_OFF(r4)");      # Get DSA address
+            &{$z? \&lg:\&l} ($out,"$PARMS_OFF+$SIZE_T*3(r9)"); # Get out address
+        }
+
+	llgc	($XX[0],"0($key)");
+	llgc	($YY,"1($key)");
+	la		($XX[0],"1($XX[0])");
+	nill	($XX[0],0xff);
+	srlg	($cnt,$len,3);
+	ltgr	($cnt,$cnt);
+	llgc	($TX[0],"2($XX[0],$key)");
+	jz		(LABEL("Lshort"));
+	j		(LABEL("Loop8"));
+
+ALIGN(64);
+LABEL("Loop8:");
 for ($i=0;$i<8;$i++) {
-$code.=<<___;
-	la	$YY,0($YY,$TX[0])	# $i
-	nill	$YY,255
-	la	$XX[1],1($XX[0])
-	nill	$XX[1],255
-___
-$code.=<<___ if ($i==1);
-	llgc	$acc,2($TY,$key)
-___
-$code.=<<___ if ($i>1);
-	sllg	$acc,$acc,8
-	ic	$acc,2($TY,$key)
-___
-$code.=<<___;
-	llgc	$TY,2($YY,$key)
-	stc	$TX[0],2($YY,$key)
-	llgc	$TX[1],2($XX[1],$key)
-	stc	$TY,2($XX[0],$key)
-	cr	$XX[1],$YY
-	jne	.Lcmov$i
-	la	$TX[1],0($TX[0])
-.Lcmov$i:
-	la	$TY,0($TY,$TX[0])
-	nill	$TY,255
-___
-push(@TX,shift(@TX)); push(@XX,shift(@XX));     # "rotate" registers
-}
+	la		($YY,"0($YY,$TX[0])");	# $i
+	nill	($YY,255);
+	la		($XX[1],"1($XX[0])");
+	nill	($XX[1],255);
+
+	if ($i==1) {
+		llgc	($acc,"2($TY,$key)");
+	}
+	if ($i>1) {
+		sllg	($acc,$acc,8);
+		ic	($acc,"2($TY,$key)");
+	}
+
+	llgc	($TY,"2($YY,$key)");
+	stc	($TX[0],"2($YY,$key)");
+	llgc	($TX[1],"2($XX[1],$key)");
+	stc	($TY,"2($XX[0],$key)");
+	cr		($XX[1],$YY);
+	jne	(LABEL("Lcmov$i"));
+	la		($TX[1],"0($TX[0])");
+LABEL("Lcmov$i:");
+	la		($TY,"0($TY,$TX[0])");
+	nill	($TY,255);

-$code.=<<___;
-	lg	$TX[1],0($inp)
-	sllg	$acc,$acc,8
-	la	$inp,8($inp)
-	ic	$acc,2($TY,$key)
-	xgr	$acc,$TX[1]
-	stg	$acc,0($out)
-	la	$out,8($out)
-	brctg	$cnt,.Loop8
-
-.Lshort:
-	lghi	$acc,7
-	ngr	$len,$acc
-	jz	.Lexit
-	j	.Loop1
-
-.align	16
-.Loop1:
-	la	$YY,0($YY,$TX[0])
-	nill	$YY,255
-	llgc	$TY,2($YY,$key)
-	stc	$TX[0],2($YY,$key)
-	stc	$TY,2($XX[0],$key)
-	ar	$TY,$TX[0]
-	ahi	$XX[0],1
-	nill	$TY,255
-	nill	$XX[0],255
-	llgc	$acc,0($inp)
-	la	$inp,1($inp)
-	llgc	$TY,2($TY,$key)
-	llgc	$TX[0],2($XX[0],$key)
-	xr	$acc,$TY
-	stc	$acc,0($out)
-	la	$out,1($out)
-	brct	$len,.Loop1
-
-.Lexit:
-	ahi	$XX[0],-1
-	stc	$XX[0],0($key)
-	stc	$YY,1($key)
-	lm${g}	%r6,%r11,6*$SIZE_T($sp)
-	br	$rp
-.size	RC4,.-RC4
-.string	"RC4 for s390x, CRYPTOGAMS by <appro\@openssl.org>"
-
-___
+	push(@TX,shift(@TX)); push(@XX,shift(@XX));     # "rotate" registers
 }
+	lg		($TX[1],"0($inp)");
+	sllg	($acc,$acc,8);
+	la		($inp,"8($inp)");
+	ic		($acc,"2($TY,$key)");
+	xgr	($acc,$TX[1]);
+	stg	($acc,"0($out)");
+	la		($out,"8($out)");
+	brctg	($cnt,LABEL("Loop8"));
+LABEL("Lshort:");
+	lghi	($acc,7);
+	ngr	($len,$acc);
+	jz		(LABEL("Lexit"));
+	j		(LABEL("Loop1"));
+
+ALIGN(16);
+LABEL("Loop1:");
+	la		($YY,"0($YY,$TX[0])");
+	nill	($YY,255);
+	llgc	($TY,"2($YY,$key)");
+	stc	($TX[0],"2($YY,$key)");
+	stc	($TY,"2($XX[0],$key)");
+	ar		($TY,$TX[0]);
+	ahi	($XX[0],1);
+	nill	($TY,255);
+	nill	($XX[0],255);
+	llgc	($acc,"0($inp)");
+	la		($inp,"1($inp)");
+	llgc	($TY,"2($TY,$key)");
+	llgc	($TX[0],"2($XX[0],$key)");
+	xr		($acc,$TY);
+	stc	($acc,"0($out)");
+	la		($out,"1($out)");
+	brct	($len,LABEL("Loop1"));
+
+LABEL("Lexit:");
+	ahi	($XX[0],-1);
+	stc	($XX[0],"0($key)");
+	stc	($YY,"1($key)");
+	if( $flavour =~ /3[12]/) {
+		lm	("%r6","%r11","6*$SIZE_T($sp)") if ($flavour =~ /linux/);
+	} else {
+		lmg ("%r6","%r11","6*$SIZE_T($sp)") if ($flavour =~ /linux/);
+	}
+FUNCTION_END("RC4",$rv);
+
+ASCIZ ("RC4 for s390x, CRYPTOGAMS by <appro\@openssl.org>");
+
+
+

 # void RC4_set_key(RC4_KEY *key,unsigned int len,const void *inp)
-{
-$cnt="%r0";
-$idx="%r1";
-$key="%r2";
-$len="%r3";
-$inp="%r4";
-$acc="%r5";
-$dat="%r6";
-$ikey="%r7";
-$iinp="%r8";
-
-$code.=<<___;
-.globl	RC4_set_key
-.type	RC4_set_key,\@function
-.align	64
-RC4_set_key:
-	stm${g}	%r6,%r8,6*$SIZE_T($sp)
-	lhi	$cnt,256
-	la	$idx,0
-	sth	$idx,0($key)
-.align	4
-.L1stloop:
-	stc	$idx,2($idx,$key)
-	la	$idx,1($idx)
-	brct	$cnt,.L1stloop
-
-	lghi	$ikey,-256
-	lr	$cnt,$len
-	la	$iinp,0
-	la	$idx,0
-.align	16
-.L2ndloop:
-	llgc	$acc,2+256($ikey,$key)
-	llgc	$dat,0($iinp,$inp)
-	la	$idx,0($idx,$acc)
-	la	$ikey,1($ikey)
-	la	$idx,0($idx,$dat)
-	nill	$idx,255
-	la	$iinp,1($iinp)
-	tml	$ikey,255
-	llgc	$dat,2($idx,$key)
-	stc	$dat,2+256-1($ikey,$key)
-	stc	$acc,2($idx,$key)
-	jz	.Ldone
-	brct	$cnt,.L2ndloop
-	lr	$cnt,$len
-	la	$iinp,0
-	j	.L2ndloop
-.Ldone:
-	lm${g}	%r6,%r8,6*$SIZE_T($sp)
-	br	$rp
-.size	RC4_set_key,.-RC4_set_key
-
-___
-}
+
+	if($flavour =~ /linux/) {
+		$cnt="%r0";
+		$idx="%r1";
+		$key="%r2";
+		$len="%r3";
+		$inp="%r4";
+		$acc="%r5";
+		$dat="%r6";
+		$ikey="%r7";
+		$iinp="%r8";
+      $wr0="%r0";
+		$rv = "%r2";
+	} else {
+		$cnt="r0";
+		$idx="r9";
+		$key="r1";
+		$len="r2";
+		$inp="r3";
+		$acc="r5";
+		$dat="r6";
+		$ikey="r10";
+		$iinp="r8";
+      $wr0="r0";
+		$rv = "r3";
+	}
+# void RC4_set_key(RC4_KEY *key, int len, const unsigned char *data)
+FUNCTION_BEGIN("RC4_set_key",3,"");
+	if($flavour =~ /3[12]/) {
+		stm	($dat,$iinp,"6*$SIZE_T($sp)") if ($flavour =~ /linux/);
+	} else {
+		stmg	($dat,$iinp,"6*$SIZE_T($sp)") if ($flavour =~ /linux/);
+	}
+	lhi	($cnt,256);
+	la		($idx,"0($cnt)");
+	sth	($idx,"0($key)");
+ALIGN(4) if ($flavour =~ /linux/);
+LABEL("L1stloop:");
+	stc	($idx,"2($idx,$key)");
+	la		($idx,"1($idx)");
+	brct	($cnt,LABEL("L1stloop"));
+	lghi	($ikey,-256);
+	lr		($cnt,$len);
+	la		($iinp,"0($wr0)");
+	la		($idx,"0($wr0)");
+ALIGN(16) if ($flavour =~ /linux/);
+LABEL("L2ndloop:");
+	llgc	($acc,"2+256($ikey,$key)");
+	llgc	($dat,"0($iinp,$inp)");
+	la		($idx,"0($idx,$acc)");
+	la		($ikey,"1($ikey)");
+	la		($idx,"0($idx,$dat)");
+	nill	($idx,255);
+	la		($iinp,"1($iinp)");
+	tml	($ikey,255);
+	llgc	($dat,"2($idx,$key)");
+	stc	($dat,"2+256-1($ikey,$key)");
+	stc	($acc,"2($idx,$key)");
+	jz		(LABEL("Ldone"));
+	brct	($cnt,LABEL("L2ndloop"));
+	lr		($cnt,$len);
+	la		($iinp,"0($wr0)");
+	j		(LABEL("L2ndloop"));
+LABEL("Ldone:");
+	if($flavour =~ /3[12]/) {
+		lm	($wr6,$wr8,"6*$SIZE_T($sp)") if ($flavour =~ /linux/);
+	} else {
+		lmg	($wr6,$wr8,"6*$SIZE_T($sp)") if ($flavour =~ /linux/);
+	}
+FUNCTION_END("RC4_set_key",$rv);
+
+

 # const char *RC4_options()
-$code.=<<___;
-.globl	RC4_options
-.type	RC4_options,\@function
-.align	16
-RC4_options:
-	larl	%r2,.Loptions
-	br	%r14
-.size	RC4_options,.-RC4_options
-.section	.rodata
-.Loptions:
-.align	8
-.string	"rc4(8x,char)"
-___
-
-print $code;
-close STDOUT or die "error closing STDOUT: $!";	# force flush
+FUNCTION_BEGIN("RC4_options",0);
+	larl	($rv,LABEL("Loptions"));
+FUNCTION_END("RC4_options",$rv);
+OBJECT_BEGIN("Loptions",8);
+	ASCIZ	("rc4(8x,char)");
+OBJECT_END("Loptions");
+
+PERLASM_END();
+
diff --git a/crypto/s390x_arch.h b/crypto/s390x_arch.h
index 13626df..96cf894 100644
--- a/crypto/s390x_arch.h
+++ b/crypto/s390x_arch.h
@@ -11,6 +11,15 @@
 # define OSSL_CRYPTO_S390X_ARCH_H

 # ifndef __ASSEMBLER__
+/*
+   Note. zOS which also uses these definitions is case insensitive, so we can't have
+   a function S390X_kimd and a constant S390X_KIMD
+   Worked around that by prefixing the constants with C so
+   S390X_KIMD -> CS390X_KIMD
+   We converted all the constants that conflicted this way rather than the
+   minimal set as it's easier to read.
+
+*/

 void s390x_kimd(const unsigned char *in, size_t len, unsigned int fc,
                 void *param);
@@ -66,91 +75,96 @@ extern struct OPENSSL_s390xcap_st OPENSSL_s390xcap_P;
 # endif

 /* OPENSSL_s390xcap_P offsets [bytes] */
-# define S390X_STFLE		0x00
-# define S390X_KIMD		0x20
-# define S390X_KLMD		0x30
-# define S390X_KM		0x40
-# define S390X_KMC		0x50
-# define S390X_KMAC		0x60
-# define S390X_KMCTR		0x70
-# define S390X_KMO		0x80
-# define S390X_KMF		0x90
-# define S390X_PRNO		0xa0
-# define S390X_KMA		0xb0
-# define S390X_PCC		0xc0
-# define S390X_KDSA		0xd0
+# define CS390X_STFLE		0x00
+# define CS390X_KIMD		0x20
+# define CS390X_KLMD		0x30
+# define CS390X_KM		0x40
+# define CS390X_KMC		0x50
+# define CS390X_KMAC		0x60
+# define CS390X_KMCTR		0x70
+# define CS390X_KMO		0x80
+# define CS390X_KMF		0x90
+# define CS390X_PRNO		0xa0
+# define CS390X_KMA		0xb0
+# define CS390X_PCC		0xc0
+# define CS390X_KDSA		0xd0

 /* Facility Bit Numbers */
-# define S390X_MSA		17	/* message-security-assist */
-# define S390X_STCKF		25	/* store-clock-fast */
-# define S390X_MSA5		57	/* message-security-assist-ext. 5 */
-# define S390X_MSA3		76	/* message-security-assist-ext. 3 */
-# define S390X_MSA4		77	/* message-security-assist-ext. 4 */
-# define S390X_VX		129	/* vector */
-# define S390X_VXD		134	/* vector packed decimal */
-# define S390X_VXE		135	/* vector enhancements 1 */
-# define S390X_MSA8		146	/* message-security-assist-ext. 8 */
-# define S390X_MSA9		155	/* message-security-assist-ext. 9 */
+# define CS390X_MSA		17	/* message-security-assist */
+# define CS390X_STCKF		25	/* store-clock-fast */
+# define CS390X_MSA5		57	/* message-security-assist-ext. 5 */
+# define CS390X_MSA3		76	/* message-security-assist-ext. 3 */
+# define CS390X_MSA4		77	/* message-security-assist-ext. 4 */
+# define CS390X_VX		129	/* vector */
+# define CS390X_VXD		134	/* vector packed decimal */
+# define CS390X_VXE		135	/* vector enhancements 1 */
+# define CS390X_MSA8		146	/* message-security-assist-ext. 8 */
+# define CS390X_MSA9		155	/* message-security-assist-ext. 9 */

-/* Facility Bit Numbers */
-# define S390X_VX		129
-# define S390X_VXD		134
-# define S390X_VXE		135

 /* Function Codes */

 /* all instructions */
-# define S390X_QUERY		0
+# define CS390X_QUERY		0

 /* kimd/klmd */
-# define S390X_SHA_1		1
-# define S390X_SHA_256		2
-# define S390X_SHA_512		3
-# define S390X_SHA3_224		32
-# define S390X_SHA3_256		33
-# define S390X_SHA3_384		34
-# define S390X_SHA3_512		35
-# define S390X_SHAKE_128	36
-# define S390X_SHAKE_256	37
-# define S390X_GHASH		65
+# define CS390X_SHA_1		1
+# define CS390X_SHA_256		2
+# define CS390X_SHA_512		3
+# define CS390X_SHA3_224		32
+# define CS390X_SHA3_256		33
+# define CS390X_SHA3_384		34
+# define CS390X_SHA3_512		35
+# define CS390X_SHAKE_128	36
+# define CS390X_SHAKE_256	37
+# define CS390X_GHASH		65

 /* km/kmc/kmac/kmctr/kmo/kmf/kma */
-# define S390X_AES_128		18
-# define S390X_AES_192		19
-# define S390X_AES_256		20
+# define CS390X_AES_128		18
+# define CS390X_AES_192		19
+# define CS390X_AES_256		20

 /* km */
-# define S390X_XTS_AES_128	50
-# define S390X_XTS_AES_256	52
+# define CS390X_XTS_AES_128	50
+# define CS390X_XTS_AES_256	52

 /* prno */
-# define S390X_SHA_512_DRNG	3
-# define S390X_TRNG		114
+# define CS390X_SHA_512_DRNG	3
+# define CS390X_TRNG		114

 /* pcc */
-# define S390X_SCALAR_MULTIPLY_P256	64
-# define S390X_SCALAR_MULTIPLY_P384	65
-# define S390X_SCALAR_MULTIPLY_P521	66
+# define CS390X_SCALAR_MULTIPLY_P256	64
+# define CS390X_SCALAR_MULTIPLY_P384	65
+# define CS390X_SCALAR_MULTIPLY_P521	66
+# define CS390X_SCALAR_MULTIPLY_ED25519  72
+# define CS390X_SCALAR_MULTIPLY_ED448    73
+# define CS390X_SCALAR_MULTIPLY_X25519   80
+# define CS390X_SCALAR_MULTIPLY_X448     81
+

 /* kdsa */
-# define S390X_ECDSA_VERIFY_P256	1
-# define S390X_ECDSA_VERIFY_P384	2
-# define S390X_ECDSA_VERIFY_P521	3
-# define S390X_ECDSA_SIGN_P256		9
-# define S390X_ECDSA_SIGN_P384		10
-# define S390X_ECDSA_SIGN_P521		11
+# define CS390X_ECDSA_VERIFY_P256	1
+# define CS390X_ECDSA_VERIFY_P384	2
+# define CS390X_ECDSA_VERIFY_P521	3
+# define CS390X_ECDSA_SIGN_P256		9
+# define CS390X_ECDSA_SIGN_P384		10
+# define CS390X_ECDSA_SIGN_P521		11
+# define CS390X_EDDSA_VERIFY_ED25519     32
+# define CS390X_EDDSA_VERIFY_ED448       36
+# define CS390X_EDDSA_SIGN_ED25519       40
+# define CS390X_EDDSA_SIGN_ED448         44

 /* Register 0 Flags */
-# define S390X_DECRYPT		0x80
-# define S390X_KMA_LPC		0x100
-# define S390X_KMA_LAAD		0x200
-# define S390X_KMA_HS		0x400
-# define S390X_KDSA_D		0x80
+# define CS390X_DECRYPT		0x80
+# define CS390X_KMA_LPC		0x100
+# define CS390X_KMA_LAAD	0x200
+# define CS390X_KMA_HS		0x400
+# define CS390X_KDSA_D		0x80

 /* Bits for ICC's CPUID function, compressing the mess down to 64 bits
    There are assumptions here i.e. that we won't lose partial function
    These are used to mask out function for testing/bug suppression
-   and the lower level capability tests in OpenSSL do full detail
+   The lower level capability tests in OpenSSL still do full detail
 */

 /* kimd/klmd */
diff --git a/crypto/s390xcap.c b/crypto/s390xcap.c
index d81b188..00acba9 100644
--- a/crypto/s390xcap.c
+++ b/crypto/s390xcap.c
@@ -102,13 +102,13 @@ void OPENSSL_cpuid_setup(void)
         OPENSSL_s390xcap_P.stfle[2] &= cap.stfle[2];
     }
     /* protection against disabled vector facility */
-    if ((OPENSSL_s390xcap_P.stfle[2] & S390X_CAPBIT(S390X_VX))
+    if ((OPENSSL_s390xcap_P.stfle[2] & S390X_CAPBIT(CS390X_VX))
         && (sigsetjmp(ill_jmp, 1) == 0)) {
         OPENSSL_vx_probe();
     } else {
-        OPENSSL_s390xcap_P.stfle[2] &= ~(S390X_CAPBIT(S390X_VX)
-                                         | S390X_CAPBIT(S390X_VXD)
-                                         | S390X_CAPBIT(S390X_VXE));
+        OPENSSL_s390xcap_P.stfle[2] &= ~(  S390X_CAPBIT(CS390X_VX)
+                                         | S390X_CAPBIT(CS390X_VXD)
+                                         | S390X_CAPBIT(CS390X_VXE));
     }

     sigaction(SIGFPE, &oact_fpe, NULL);
@@ -176,19 +176,19 @@ static int parse_env(struct OPENSSL_s390xcap_st *cap)
      * Implements MSA. Facility detection would fail on real hw (no STFLE).
      */
     static const struct OPENSSL_s390xcap_st z990 = {
-        /*.stfle  = */{S390X_CAPBIT(S390X_MSA),
+        /*.stfle  = */{S390X_CAPBIT(CS390X_MSA),
                        0ULL, 0ULL, 0ULL},
-        /*.kimd   = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_SHA_1),
+        /*.kimd   = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_SHA_1),
                        0ULL},
-        /*.klmd   = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_SHA_1),
+        /*.klmd   = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_SHA_1),
                        0ULL},
-        /*.km     = */{S390X_CAPBIT(S390X_QUERY),
+        /*.km     = */{S390X_CAPBIT(CS390X_QUERY),
                        0ULL},
-        /*.kmc    = */{S390X_CAPBIT(S390X_QUERY),
+        /*.kmc    = */{S390X_CAPBIT(CS390X_QUERY),
                        0ULL},
-        /*.kmac   = */{S390X_CAPBIT(S390X_QUERY),
+        /*.kmac   = */{S390X_CAPBIT(CS390X_QUERY),
                        0ULL},
         /*.kmctr  = */{0ULL, 0ULL},
         /*.kmo    = */{0ULL, 0ULL},
@@ -204,24 +204,24 @@ static int parse_env(struct OPENSSL_s390xcap_st *cap)
      * Implements MSA and MSA1.
      */
     static const struct OPENSSL_s390xcap_st z9 = {
-        /*.stfle  = */{S390X_CAPBIT(S390X_MSA)
-                       | S390X_CAPBIT(S390X_STCKF),
+        /*.stfle  = */{S390X_CAPBIT(CS390X_MSA)
+                       | S390X_CAPBIT(CS390X_STCKF),
                        0ULL, 0ULL, 0ULL},
-        /*.kimd   = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_SHA_1)
-                       | S390X_CAPBIT(S390X_SHA_256),
+        /*.kimd   = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_SHA_1)
+                       | S390X_CAPBIT(CS390X_SHA_256),
                        0ULL},
-        /*.klmd   = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_SHA_1)
-                       | S390X_CAPBIT(S390X_SHA_256),
+        /*.klmd   = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_SHA_1)
+                       | S390X_CAPBIT(CS390X_SHA_256),
                        0ULL},
-        /*.km     = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_AES_128),
+        /*.km     = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_AES_128),
                        0ULL},
-        /*.kmc    = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_AES_128),
+        /*.kmc    = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_AES_128),
                        0ULL},
-        /*.kmac   = */{S390X_CAPBIT(S390X_QUERY),
+        /*.kmac   = */{S390X_CAPBIT(CS390X_QUERY),
                        0ULL},
         /*.kmctr  = */{0ULL, 0ULL},
         /*.kmo    = */{0ULL, 0ULL},
@@ -237,30 +237,30 @@ static int parse_env(struct OPENSSL_s390xcap_st *cap)
      * Implements MSA and MSA1-2.
      */
     static const struct OPENSSL_s390xcap_st z10 = {
-        /*.stfle  = */{S390X_CAPBIT(S390X_MSA)
-                       | S390X_CAPBIT(S390X_STCKF),
+        /*.stfle  = */{S390X_CAPBIT(CS390X_MSA)
+                       | S390X_CAPBIT(CS390X_STCKF),
                        0ULL, 0ULL, 0ULL},
-        /*.kimd   = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_SHA_1)
-                       | S390X_CAPBIT(S390X_SHA_256)
-                       | S390X_CAPBIT(S390X_SHA_512),
+        /*.kimd   = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_SHA_1)
+                       | S390X_CAPBIT(CS390X_SHA_256)
+                       | S390X_CAPBIT(CS390X_SHA_512),
                        0ULL},
-        /*.klmd   = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_SHA_1)
-                       | S390X_CAPBIT(S390X_SHA_256)
-                       | S390X_CAPBIT(S390X_SHA_512),
+        /*.klmd   = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_SHA_1)
+                       | S390X_CAPBIT(CS390X_SHA_256)
+                       | S390X_CAPBIT(CS390X_SHA_512),
                        0ULL},
-        /*.km     = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_AES_128)
-                       | S390X_CAPBIT(S390X_AES_192)
-                       | S390X_CAPBIT(S390X_AES_256),
+        /*.km     = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_AES_128)
+                       | S390X_CAPBIT(CS390X_AES_192)
+                       | S390X_CAPBIT(CS390X_AES_256),
                        0ULL},
-        /*.kmc    = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_AES_128)
-                       | S390X_CAPBIT(S390X_AES_192)
-                       | S390X_CAPBIT(S390X_AES_256),
+        /*.kmc    = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_AES_128)
+                       | S390X_CAPBIT(CS390X_AES_192)
+                       | S390X_CAPBIT(CS390X_AES_256),
                        0ULL},
-        /*.kmac   = */{S390X_CAPBIT(S390X_QUERY),
+        /*.kmac   = */{S390X_CAPBIT(CS390X_QUERY),
                        0ULL},
         /*.kmctr  = */{0ULL, 0ULL},
         /*.kmo    = */{0ULL, 0ULL},
@@ -276,56 +276,56 @@ static int parse_env(struct OPENSSL_s390xcap_st *cap)
      * Implements MSA and MSA1-4.
      */
     static const struct OPENSSL_s390xcap_st z196 = {
-        /*.stfle  = */{S390X_CAPBIT(S390X_MSA)
-                       | S390X_CAPBIT(S390X_STCKF),
-                       S390X_CAPBIT(S390X_MSA3)
-                       | S390X_CAPBIT(S390X_MSA4),
+        /*.stfle  = */{S390X_CAPBIT(CS390X_MSA)
+                       | S390X_CAPBIT(CS390X_STCKF),
+                       S390X_CAPBIT(CS390X_MSA3)
+                       | S390X_CAPBIT(CS390X_MSA4),
                        0ULL, 0ULL},
-        /*.kimd   = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_SHA_1)
-                       | S390X_CAPBIT(S390X_SHA_256)
-                       | S390X_CAPBIT(S390X_SHA_512),
-                       S390X_CAPBIT(S390X_GHASH)},
-        /*.klmd   = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_SHA_1)
-                       | S390X_CAPBIT(S390X_SHA_256)
-                       | S390X_CAPBIT(S390X_SHA_512),
-                       0ULL},
-        /*.km     = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_AES_128)
-                       | S390X_CAPBIT(S390X_AES_192)
-                       | S390X_CAPBIT(S390X_AES_256)
-                       | S390X_CAPBIT(S390X_XTS_AES_128)
-                       | S390X_CAPBIT(S390X_XTS_AES_256),
-                       0ULL},
-        /*.kmc    = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_AES_128)
-                       | S390X_CAPBIT(S390X_AES_192)
-                       | S390X_CAPBIT(S390X_AES_256),
-                       0ULL},
-        /*.kmac   = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_AES_128)
-                       | S390X_CAPBIT(S390X_AES_192)
-                       | S390X_CAPBIT(S390X_AES_256),
-                       0ULL},
-        /*.kmctr  = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_AES_128)
-                       | S390X_CAPBIT(S390X_AES_192)
-                       | S390X_CAPBIT(S390X_AES_256),
-                       0ULL},
-        /*.kmo    = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_AES_128)
-                       | S390X_CAPBIT(S390X_AES_192)
-                       | S390X_CAPBIT(S390X_AES_256),
-                       0ULL},
-        /*.kmf    = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_AES_128)
-                       | S390X_CAPBIT(S390X_AES_192)
-                       | S390X_CAPBIT(S390X_AES_256),
+        /*.kimd   = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_SHA_1)
+                       | S390X_CAPBIT(CS390X_SHA_256)
+                       | S390X_CAPBIT(CS390X_SHA_512),
+                       S390X_CAPBIT(CS390X_GHASH)},
+        /*.klmd   = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_SHA_1)
+                       | S390X_CAPBIT(CS390X_SHA_256)
+                       | S390X_CAPBIT(CS390X_SHA_512),
+                       0ULL},
+        /*.km     = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_AES_128)
+                       | S390X_CAPBIT(CS390X_AES_192)
+                       | S390X_CAPBIT(CS390X_AES_256)
+                       | S390X_CAPBIT(CS390X_XTS_AES_128)
+                       | S390X_CAPBIT(CS390X_XTS_AES_256),
+                       0ULL},
+        /*.kmc    = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_AES_128)
+                       | S390X_CAPBIT(CS390X_AES_192)
+                       | S390X_CAPBIT(CS390X_AES_256),
+                       0ULL},
+        /*.kmac   = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_AES_128)
+                       | S390X_CAPBIT(CS390X_AES_192)
+                       | S390X_CAPBIT(CS390X_AES_256),
+                       0ULL},
+        /*.kmctr  = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_AES_128)
+                       | S390X_CAPBIT(CS390X_AES_192)
+                       | S390X_CAPBIT(CS390X_AES_256),
+                       0ULL},
+        /*.kmo    = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_AES_128)
+                       | S390X_CAPBIT(CS390X_AES_192)
+                       | S390X_CAPBIT(CS390X_AES_256),
+                       0ULL},
+        /*.kmf    = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_AES_128)
+                       | S390X_CAPBIT(CS390X_AES_192)
+                       | S390X_CAPBIT(CS390X_AES_256),
                        0ULL},
         /*.prno   = */{0ULL, 0ULL},
         /*.kma    = */{0ULL, 0ULL},
-        /*.pcc    = */{S390X_CAPBIT(S390X_QUERY),
+        /*.pcc    = */{S390X_CAPBIT(CS390X_QUERY),
                        0ULL},
         /*.kdsa   = */{0ULL, 0ULL},
     };
@@ -335,56 +335,56 @@ static int parse_env(struct OPENSSL_s390xcap_st *cap)
      * Implements MSA and MSA1-4.
      */
     static const struct OPENSSL_s390xcap_st zEC12 = {
-        /*.stfle  = */{S390X_CAPBIT(S390X_MSA)
-                       | S390X_CAPBIT(S390X_STCKF),
-                       S390X_CAPBIT(S390X_MSA3)
-                       | S390X_CAPBIT(S390X_MSA4),
+        /*.stfle  = */{S390X_CAPBIT(CS390X_MSA)
+                       | S390X_CAPBIT(CS390X_STCKF),
+                       S390X_CAPBIT(CS390X_MSA3)
+                       | S390X_CAPBIT(CS390X_MSA4),
                        0ULL, 0ULL},
-        /*.kimd   = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_SHA_1)
-                       | S390X_CAPBIT(S390X_SHA_256)
-                       | S390X_CAPBIT(S390X_SHA_512),
-                   S390X_CAPBIT(S390X_GHASH)},
-        /*.klmd   = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_SHA_1)
-                       | S390X_CAPBIT(S390X_SHA_256)
-                       | S390X_CAPBIT(S390X_SHA_512),
-                       0ULL},
-        /*.km     = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_AES_128)
-                       | S390X_CAPBIT(S390X_AES_192)
-                       | S390X_CAPBIT(S390X_AES_256)
-                       | S390X_CAPBIT(S390X_XTS_AES_128)
-                       | S390X_CAPBIT(S390X_XTS_AES_256),
-                       0ULL},
-        /*.kmc    = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_AES_128)
-                       | S390X_CAPBIT(S390X_AES_192)
-                       | S390X_CAPBIT(S390X_AES_256),
-                       0ULL},
-        /*.kmac   = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_AES_128)
-                       | S390X_CAPBIT(S390X_AES_192)
-                       | S390X_CAPBIT(S390X_AES_256),
-                       0ULL},
-        /*.kmctr  = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_AES_128)
-                       | S390X_CAPBIT(S390X_AES_192)
-                       | S390X_CAPBIT(S390X_AES_256),
-                       0ULL},
-        /*.kmo    = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_AES_128)
-                       | S390X_CAPBIT(S390X_AES_192)
-                       | S390X_CAPBIT(S390X_AES_256),
-                       0ULL},
-        /*.kmf    = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_AES_128)
-                       | S390X_CAPBIT(S390X_AES_192)
-                       | S390X_CAPBIT(S390X_AES_256),
+        /*.kimd   = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_SHA_1)
+                       | S390X_CAPBIT(CS390X_SHA_256)
+                       | S390X_CAPBIT(CS390X_SHA_512),
+                   S390X_CAPBIT(CS390X_GHASH)},
+        /*.klmd   = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_SHA_1)
+                       | S390X_CAPBIT(CS390X_SHA_256)
+                       | S390X_CAPBIT(CS390X_SHA_512),
+                       0ULL},
+        /*.km     = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_AES_128)
+                       | S390X_CAPBIT(CS390X_AES_192)
+                       | S390X_CAPBIT(CS390X_AES_256)
+                       | S390X_CAPBIT(CS390X_XTS_AES_128)
+                       | S390X_CAPBIT(CS390X_XTS_AES_256),
+                       0ULL},
+        /*.kmc    = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_AES_128)
+                       | S390X_CAPBIT(CS390X_AES_192)
+                       | S390X_CAPBIT(CS390X_AES_256),
+                       0ULL},
+        /*.kmac   = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_AES_128)
+                       | S390X_CAPBIT(CS390X_AES_192)
+                       | S390X_CAPBIT(CS390X_AES_256),
+                       0ULL},
+        /*.kmctr  = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_AES_128)
+                       | S390X_CAPBIT(CS390X_AES_192)
+                       | S390X_CAPBIT(CS390X_AES_256),
+                       0ULL},
+        /*.kmo    = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_AES_128)
+                       | S390X_CAPBIT(CS390X_AES_192)
+                       | S390X_CAPBIT(CS390X_AES_256),
+                       0ULL},
+        /*.kmf    = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_AES_128)
+                       | S390X_CAPBIT(CS390X_AES_192)
+                       | S390X_CAPBIT(CS390X_AES_256),
                        0ULL},
         /*.prno   = */{0ULL, 0ULL},
         /*.kma    = */{0ULL, 0ULL},
-        /*.pcc    = */{S390X_CAPBIT(S390X_QUERY),
+        /*.pcc    = */{S390X_CAPBIT(CS390X_QUERY),
                        0ULL},
         /*.kdsa   = */{0ULL, 0ULL},
     };
@@ -394,60 +394,60 @@ static int parse_env(struct OPENSSL_s390xcap_st *cap)
      * Implements MSA and MSA1-5.
      */
     static const struct OPENSSL_s390xcap_st z13 = {
-        /*.stfle  = */{S390X_CAPBIT(S390X_MSA)
-                       | S390X_CAPBIT(S390X_STCKF)
-                       | S390X_CAPBIT(S390X_MSA5),
-                       S390X_CAPBIT(S390X_MSA3)
-                       | S390X_CAPBIT(S390X_MSA4),
-                       S390X_CAPBIT(S390X_VX),
-                       0ULL},
-        /*.kimd   = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_SHA_1)
-                       | S390X_CAPBIT(S390X_SHA_256)
-                       | S390X_CAPBIT(S390X_SHA_512),
-                       S390X_CAPBIT(S390X_GHASH)},
-        /*.klmd   = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_SHA_1)
-                       | S390X_CAPBIT(S390X_SHA_256)
-                       | S390X_CAPBIT(S390X_SHA_512),
-                       0ULL},
-        /*.km     = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_AES_128)
-                       | S390X_CAPBIT(S390X_AES_192)
-                       | S390X_CAPBIT(S390X_AES_256)
-                       | S390X_CAPBIT(S390X_XTS_AES_128)
-                       | S390X_CAPBIT(S390X_XTS_AES_256),
-                       0ULL},
-        /*.kmc    = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_AES_128)
-                       | S390X_CAPBIT(S390X_AES_192)
-                       | S390X_CAPBIT(S390X_AES_256),
-                       0ULL},
-        /*.kmac   = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_AES_128)
-                       | S390X_CAPBIT(S390X_AES_192)
-                       | S390X_CAPBIT(S390X_AES_256),
-                       0ULL},
-        /*.kmctr  = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_AES_128)
-                       | S390X_CAPBIT(S390X_AES_192)
-                       | S390X_CAPBIT(S390X_AES_256),
-                       0ULL},
-        /*.kmo    = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_AES_128)
-                       | S390X_CAPBIT(S390X_AES_192)
-                       | S390X_CAPBIT(S390X_AES_256),
-                       0ULL},
-        /*.kmf    = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_AES_128)
-                       | S390X_CAPBIT(S390X_AES_192)
-                       | S390X_CAPBIT(S390X_AES_256),
-                       0ULL},
-        /*.prno   = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_SHA_512_DRNG),
+        /*.stfle  = */{S390X_CAPBIT(CS390X_MSA)
+                       | S390X_CAPBIT(CS390X_STCKF)
+                       | S390X_CAPBIT(CS390X_MSA5),
+                       S390X_CAPBIT(CS390X_MSA3)
+                       | S390X_CAPBIT(CS390X_MSA4),
+                       S390X_CAPBIT(CS390X_VX),
+                       0ULL},
+        /*.kimd   = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_SHA_1)
+                       | S390X_CAPBIT(CS390X_SHA_256)
+                       | S390X_CAPBIT(CS390X_SHA_512),
+                       S390X_CAPBIT(CS390X_GHASH)},
+        /*.klmd   = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_SHA_1)
+                       | S390X_CAPBIT(CS390X_SHA_256)
+                       | S390X_CAPBIT(CS390X_SHA_512),
+                       0ULL},
+        /*.km     = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_AES_128)
+                       | S390X_CAPBIT(CS390X_AES_192)
+                       | S390X_CAPBIT(CS390X_AES_256)
+                       | S390X_CAPBIT(CS390X_XTS_AES_128)
+                       | S390X_CAPBIT(CS390X_XTS_AES_256),
+                       0ULL},
+        /*.kmc    = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_AES_128)
+                       | S390X_CAPBIT(CS390X_AES_192)
+                       | S390X_CAPBIT(CS390X_AES_256),
+                       0ULL},
+        /*.kmac   = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_AES_128)
+                       | S390X_CAPBIT(CS390X_AES_192)
+                       | S390X_CAPBIT(CS390X_AES_256),
+                       0ULL},
+        /*.kmctr  = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_AES_128)
+                       | S390X_CAPBIT(CS390X_AES_192)
+                       | S390X_CAPBIT(CS390X_AES_256),
+                       0ULL},
+        /*.kmo    = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_AES_128)
+                       | S390X_CAPBIT(CS390X_AES_192)
+                       | S390X_CAPBIT(CS390X_AES_256),
+                       0ULL},
+        /*.kmf    = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_AES_128)
+                       | S390X_CAPBIT(CS390X_AES_192)
+                       | S390X_CAPBIT(CS390X_AES_256),
+                       0ULL},
+        /*.prno   = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_SHA_512_DRNG),
                        0ULL},
         /*.kma    = */{0ULL, 0ULL},
-        /*.pcc    = */{S390X_CAPBIT(S390X_QUERY),
+        /*.pcc    = */{S390X_CAPBIT(CS390X_QUERY),
                        0ULL},
         /*.kdsa   = */{0ULL, 0ULL},
     };
@@ -457,79 +457,79 @@ static int parse_env(struct OPENSSL_s390xcap_st *cap)
      * Implements MSA and MSA1-8.
      */
     static const struct OPENSSL_s390xcap_st z14 = {
-        /*.stfle  = */{S390X_CAPBIT(S390X_MSA)
-                       | S390X_CAPBIT(S390X_STCKF)
-                       | S390X_CAPBIT(S390X_MSA5),
-                       S390X_CAPBIT(S390X_MSA3)
-                       | S390X_CAPBIT(S390X_MSA4),
-                       S390X_CAPBIT(S390X_VX)
-                       | S390X_CAPBIT(S390X_VXD)
-                       | S390X_CAPBIT(S390X_VXE)
-                       | S390X_CAPBIT(S390X_MSA8),
-                       0ULL},
-        /*.kimd   = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_SHA_1)
-                       | S390X_CAPBIT(S390X_SHA_256)
-                       | S390X_CAPBIT(S390X_SHA_512)
-                       | S390X_CAPBIT(S390X_SHA3_224)
-                       | S390X_CAPBIT(S390X_SHA3_256)
-                       | S390X_CAPBIT(S390X_SHA3_384)
-                       | S390X_CAPBIT(S390X_SHA3_512)
-                       | S390X_CAPBIT(S390X_SHAKE_128)
-                       | S390X_CAPBIT(S390X_SHAKE_256),
-                       S390X_CAPBIT(S390X_GHASH)},
-        /*.klmd   = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_SHA_1)
-                       | S390X_CAPBIT(S390X_SHA_256)
-                       | S390X_CAPBIT(S390X_SHA_512)
-                       | S390X_CAPBIT(S390X_SHA3_224)
-                       | S390X_CAPBIT(S390X_SHA3_256)
-                       | S390X_CAPBIT(S390X_SHA3_384)
-                       | S390X_CAPBIT(S390X_SHA3_512)
-                       | S390X_CAPBIT(S390X_SHAKE_128)
-                       | S390X_CAPBIT(S390X_SHAKE_256),
-                       0ULL},
-        /*.km     = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_AES_128)
-                       | S390X_CAPBIT(S390X_AES_192)
-                       | S390X_CAPBIT(S390X_AES_256)
-                       | S390X_CAPBIT(S390X_XTS_AES_128)
-                       | S390X_CAPBIT(S390X_XTS_AES_256),
-                       0ULL},
-        /*.kmc    = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_AES_128)
-                       | S390X_CAPBIT(S390X_AES_192)
-                       | S390X_CAPBIT(S390X_AES_256),
-                       0ULL},
-        /*.kmac   = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_AES_128)
-                       | S390X_CAPBIT(S390X_AES_192)
-                       | S390X_CAPBIT(S390X_AES_256),
-                       0ULL},
-        /*.kmctr  = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_AES_128)
-                       | S390X_CAPBIT(S390X_AES_192)
-                       | S390X_CAPBIT(S390X_AES_256),
-                       0ULL},
-        /*.kmo    = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_AES_128)
-                       | S390X_CAPBIT(S390X_AES_192)
-                       | S390X_CAPBIT(S390X_AES_256),
-                       0ULL},
-        /*.kmf    = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_AES_128)
-                       | S390X_CAPBIT(S390X_AES_192)
-                       | S390X_CAPBIT(S390X_AES_256),
-                       0ULL},
-        /*.prno   = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_SHA_512_DRNG),
-                       S390X_CAPBIT(S390X_TRNG)},
-        /*.kma    = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_AES_128)
-                       | S390X_CAPBIT(S390X_AES_192)
-                       | S390X_CAPBIT(S390X_AES_256),
-                       0ULL},
-        /*.pcc    = */{S390X_CAPBIT(S390X_QUERY),
+        /*.stfle  = */{S390X_CAPBIT(CS390X_MSA)
+                       | S390X_CAPBIT(CS390X_STCKF)
+                       | S390X_CAPBIT(CS390X_MSA5),
+                       S390X_CAPBIT(CS390X_MSA3)
+                       | S390X_CAPBIT(CS390X_MSA4),
+                       S390X_CAPBIT(CS390X_VX)
+                       | S390X_CAPBIT(CS390X_VXD)
+                       | S390X_CAPBIT(CS390X_VXE)
+                       | S390X_CAPBIT(CS390X_MSA8),
+                       0ULL},
+        /*.kimd   = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_SHA_1)
+                       | S390X_CAPBIT(CS390X_SHA_256)
+                       | S390X_CAPBIT(CS390X_SHA_512)
+                       | S390X_CAPBIT(CS390X_SHA3_224)
+                       | S390X_CAPBIT(CS390X_SHA3_256)
+                       | S390X_CAPBIT(CS390X_SHA3_384)
+                       | S390X_CAPBIT(CS390X_SHA3_512)
+                       | S390X_CAPBIT(CS390X_SHAKE_128)
+                       | S390X_CAPBIT(CS390X_SHAKE_256),
+                       S390X_CAPBIT(CS390X_GHASH)},
+        /*.klmd   = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_SHA_1)
+                       | S390X_CAPBIT(CS390X_SHA_256)
+                       | S390X_CAPBIT(CS390X_SHA_512)
+                       | S390X_CAPBIT(CS390X_SHA3_224)
+                       | S390X_CAPBIT(CS390X_SHA3_256)
+                       | S390X_CAPBIT(CS390X_SHA3_384)
+                       | S390X_CAPBIT(CS390X_SHA3_512)
+                       | S390X_CAPBIT(CS390X_SHAKE_128)
+                       | S390X_CAPBIT(CS390X_SHAKE_256),
+                       0ULL},
+        /*.km     = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_AES_128)
+                       | S390X_CAPBIT(CS390X_AES_192)
+                       | S390X_CAPBIT(CS390X_AES_256)
+                       | S390X_CAPBIT(CS390X_XTS_AES_128)
+                       | S390X_CAPBIT(CS390X_XTS_AES_256),
+                       0ULL},
+        /*.kmc    = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_AES_128)
+                       | S390X_CAPBIT(CS390X_AES_192)
+                       | S390X_CAPBIT(CS390X_AES_256),
+                       0ULL},
+        /*.kmac   = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_AES_128)
+                       | S390X_CAPBIT(CS390X_AES_192)
+                       | S390X_CAPBIT(CS390X_AES_256),
+                       0ULL},
+        /*.kmctr  = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_AES_128)
+                       | S390X_CAPBIT(CS390X_AES_192)
+                       | S390X_CAPBIT(CS390X_AES_256),
+                       0ULL},
+        /*.kmo    = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_AES_128)
+                       | S390X_CAPBIT(CS390X_AES_192)
+                       | S390X_CAPBIT(CS390X_AES_256),
+                       0ULL},
+        /*.kmf    = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_AES_128)
+                       | S390X_CAPBIT(CS390X_AES_192)
+                       | S390X_CAPBIT(CS390X_AES_256),
+                       0ULL},
+        /*.prno   = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_SHA_512_DRNG),
+                       S390X_CAPBIT(CS390X_TRNG)},
+        /*.kma    = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_AES_128)
+                       | S390X_CAPBIT(CS390X_AES_192)
+                       | S390X_CAPBIT(CS390X_AES_256),
+                       0ULL},
+        /*.pcc    = */{S390X_CAPBIT(CS390X_QUERY),
                        0ULL},
         /*.kdsa   = */{0ULL, 0ULL},
     };
@@ -539,90 +539,98 @@ static int parse_env(struct OPENSSL_s390xcap_st *cap)
      * Implements MSA and MSA1-9.
      */
     static const struct OPENSSL_s390xcap_st z15 = {
-        /*.stfle  = */{S390X_CAPBIT(S390X_MSA)
-                       | S390X_CAPBIT(S390X_STCKF)
-                       | S390X_CAPBIT(S390X_MSA5),
-                       S390X_CAPBIT(S390X_MSA3)
-                       | S390X_CAPBIT(S390X_MSA4),
-                       S390X_CAPBIT(S390X_VX)
-                       | S390X_CAPBIT(S390X_VXD)
-                       | S390X_CAPBIT(S390X_VXE)
-                       | S390X_CAPBIT(S390X_MSA8),
-                       0ULL},
-        /*.kimd   = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_SHA_1)
-                       | S390X_CAPBIT(S390X_SHA_256)
-                       | S390X_CAPBIT(S390X_SHA_512)
-                       | S390X_CAPBIT(S390X_SHA3_224)
-                       | S390X_CAPBIT(S390X_SHA3_256)
-                       | S390X_CAPBIT(S390X_SHA3_384)
-                       | S390X_CAPBIT(S390X_SHA3_512)
-                       | S390X_CAPBIT(S390X_SHAKE_128)
-                       | S390X_CAPBIT(S390X_SHAKE_256),
-                       S390X_CAPBIT(S390X_GHASH)},
-        /*.klmd   = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_SHA_1)
-                       | S390X_CAPBIT(S390X_SHA_256)
-                       | S390X_CAPBIT(S390X_SHA_512)
-                       | S390X_CAPBIT(S390X_SHA3_224)
-                       | S390X_CAPBIT(S390X_SHA3_256)
-                       | S390X_CAPBIT(S390X_SHA3_384)
-                       | S390X_CAPBIT(S390X_SHA3_512)
-                       | S390X_CAPBIT(S390X_SHAKE_128)
-                       | S390X_CAPBIT(S390X_SHAKE_256),
-                       0ULL},
-        /*.km     = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_AES_128)
-                       | S390X_CAPBIT(S390X_AES_192)
-                       | S390X_CAPBIT(S390X_AES_256)
-                       | S390X_CAPBIT(S390X_XTS_AES_128)
-                       | S390X_CAPBIT(S390X_XTS_AES_256),
-                       0ULL},
-        /*.kmc    = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_AES_128)
-                       | S390X_CAPBIT(S390X_AES_192)
-                       | S390X_CAPBIT(S390X_AES_256),
-                       0ULL},
-        /*.kmac   = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_AES_128)
-                       | S390X_CAPBIT(S390X_AES_192)
-                       | S390X_CAPBIT(S390X_AES_256),
-                       0ULL},
-        /*.kmctr  = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_AES_128)
-                       | S390X_CAPBIT(S390X_AES_192)
-                       | S390X_CAPBIT(S390X_AES_256),
-                       0ULL},
-        /*.kmo    = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_AES_128)
-                       | S390X_CAPBIT(S390X_AES_192)
-                       | S390X_CAPBIT(S390X_AES_256),
-                       0ULL},
-        /*.kmf    = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_AES_128)
-                       | S390X_CAPBIT(S390X_AES_192)
-                       | S390X_CAPBIT(S390X_AES_256),
-                       0ULL},
-        /*.prno   = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_SHA_512_DRNG),
-                       S390X_CAPBIT(S390X_TRNG)},
-        /*.kma    = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_AES_128)
-                       | S390X_CAPBIT(S390X_AES_192)
-                       | S390X_CAPBIT(S390X_AES_256),
-                       0ULL},
-        /*.pcc    = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_SCALAR_MULTIPLY_P256)
-                       | S390X_CAPBIT(S390X_SCALAR_MULTIPLY_P384)
-                       | S390X_CAPBIT(S390X_SCALAR_MULTIPLY_P521),
-                       0ULL},
-        /*.kdsa   = */{S390X_CAPBIT(S390X_QUERY)
-                       | S390X_CAPBIT(S390X_ECDSA_VERIFY_P256)
-                       | S390X_CAPBIT(S390X_ECDSA_VERIFY_P384)
-                       | S390X_CAPBIT(S390X_ECDSA_VERIFY_P521)
-                       | S390X_CAPBIT(S390X_ECDSA_SIGN_P256)
-                       | S390X_CAPBIT(S390X_ECDSA_SIGN_P384)
-                       | S390X_CAPBIT(S390X_ECDSA_SIGN_P521),
+        /*.stfle  = */{S390X_CAPBIT(CS390X_MSA)
+                       | S390X_CAPBIT(CS390X_STCKF)
+                       | S390X_CAPBIT(CS390X_MSA5),
+                       S390X_CAPBIT(CS390X_MSA3)
+                       | S390X_CAPBIT(CS390X_MSA4),
+                       S390X_CAPBIT(CS390X_VX)
+                       | S390X_CAPBIT(CS390X_VXD)
+                       | S390X_CAPBIT(CS390X_VXE)
+                       | S390X_CAPBIT(CS390X_MSA8),
+                       0ULL},
+        /*.kimd   = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_SHA_1)
+                       | S390X_CAPBIT(CS390X_SHA_256)
+                       | S390X_CAPBIT(CS390X_SHA_512)
+                       | S390X_CAPBIT(CS390X_SHA3_224)
+                       | S390X_CAPBIT(CS390X_SHA3_256)
+                       | S390X_CAPBIT(CS390X_SHA3_384)
+                       | S390X_CAPBIT(CS390X_SHA3_512)
+                       | S390X_CAPBIT(CS390X_SHAKE_128)
+                       | S390X_CAPBIT(CS390X_SHAKE_256),
+                       S390X_CAPBIT(CS390X_GHASH)},
+        /*.klmd   = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_SHA_1)
+                       | S390X_CAPBIT(CS390X_SHA_256)
+                       | S390X_CAPBIT(CS390X_SHA_512)
+                       | S390X_CAPBIT(CS390X_SHA3_224)
+                       | S390X_CAPBIT(CS390X_SHA3_256)
+                       | S390X_CAPBIT(CS390X_SHA3_384)
+                       | S390X_CAPBIT(CS390X_SHA3_512)
+                       | S390X_CAPBIT(CS390X_SHAKE_128)
+                       | S390X_CAPBIT(CS390X_SHAKE_256),
+                       0ULL},
+        /*.km     = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_AES_128)
+                       | S390X_CAPBIT(CS390X_AES_192)
+                       | S390X_CAPBIT(CS390X_AES_256)
+                       | S390X_CAPBIT(CS390X_XTS_AES_128)
+                       | S390X_CAPBIT(CS390X_XTS_AES_256),
+                       0ULL},
+        /*.kmc    = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_AES_128)
+                       | S390X_CAPBIT(CS390X_AES_192)
+                       | S390X_CAPBIT(CS390X_AES_256),
+                       0ULL},
+        /*.kmac   = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_AES_128)
+                       | S390X_CAPBIT(CS390X_AES_192)
+                       | S390X_CAPBIT(CS390X_AES_256),
+                       0ULL},
+        /*.kmctr  = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_AES_128)
+                       | S390X_CAPBIT(CS390X_AES_192)
+                       | S390X_CAPBIT(CS390X_AES_256),
+                       0ULL},
+        /*.kmo    = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_AES_128)
+                       | S390X_CAPBIT(CS390X_AES_192)
+                       | S390X_CAPBIT(CS390X_AES_256),
+                       0ULL},
+        /*.kmf    = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_AES_128)
+                       | S390X_CAPBIT(CS390X_AES_192)
+                       | S390X_CAPBIT(CS390X_AES_256),
+                       0ULL},
+        /*.prno   = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_SHA_512_DRNG),
+                       S390X_CAPBIT(CS390X_TRNG)},
+        /*.kma    = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_AES_128)
+                       | S390X_CAPBIT(CS390X_AES_192)
+                       | S390X_CAPBIT(CS390X_AES_256),
+                       0ULL},
+        /*.pcc    = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_SCALAR_MULTIPLY_P256)
+                       | S390X_CAPBIT(CS390X_SCALAR_MULTIPLY_P384)
+                       | S390X_CAPBIT(CS390X_SCALAR_MULTIPLY_P521)
+                       | S390X_CAPBIT(CS390X_SCALAR_MULTIPLY_ED25519)
+                       | S390X_CAPBIT(CS390X_SCALAR_MULTIPLY_ED448)
+                       | S390X_CAPBIT(CS390X_SCALAR_MULTIPLY_X25519)
+		       | S390X_CAPBIT(CS390X_SCALAR_MULTIPLY_X448),
+                       0ULL},
+        /*.kdsa   = */{S390X_CAPBIT(CS390X_QUERY)
+                       | S390X_CAPBIT(CS390X_ECDSA_VERIFY_P256)
+                       | S390X_CAPBIT(CS390X_ECDSA_VERIFY_P384)
+                       | S390X_CAPBIT(CS390X_ECDSA_VERIFY_P521)
+                       | S390X_CAPBIT(CS390X_ECDSA_SIGN_P256)
+                       | S390X_CAPBIT(CS390X_ECDSA_SIGN_P384)
+                       | S390X_CAPBIT(CS390X_ECDSA_SIGN_P521)
+                       | S390X_CAPBIT(CS390X_EDDSA_VERIFY_ED25519)
+                       | S390X_CAPBIT(CS390X_EDDSA_VERIFY_ED448)
+                       | S390X_CAPBIT(CS390X_EDDSA_SIGN_ED25519)
+                       | S390X_CAPBIT(CS390X_EDDSA_SIGN_ED448),
                        0ULL},
     };

@@ -701,13 +709,13 @@ ret:
 }


-#define ALL_AES ( S390X_CAPBIT(S390X_AES_128) | S390X_CAPBIT(S390X_AES_192) | S390X_CAPBIT(S390X_AES_256) )
+#define ALL_AES ( S390X_CAPBIT(CS390X_AES_128) | S390X_CAPBIT(CS390X_AES_192) | S390X_CAPBIT(CS390X_AES_256) )
 /* EC scalar multiply */
-#define ALL_PCC ( S390X_CAPBIT(S390X_SCALAR_MULTIPLY_P256) | S390X_CAPBIT(S390X_SCALAR_MULTIPLY_P384) | S390X_CAPBIT(S390X_SCALAR_MULTIPLY_P521))
+#define ALL_PCC ( S390X_CAPBIT(CS390X_SCALAR_MULTIPLY_P256) | S390X_CAPBIT(CS390X_SCALAR_MULTIPLY_P384) | S390X_CAPBIT(CS390X_SCALAR_MULTIPLY_P521))
 /* kdsa verify */
-#define ALL_ECV ( S390X_CAPBIT(S390X_ECDSA_VERIFY_P256) | S390X_CAPBIT(S390X_ECDSA_VERIFY_P384) | S390X_CAPBIT(S390X_ECDSA_VERIFY_P521))
+#define ALL_ECV ( S390X_CAPBIT(CS390X_ECDSA_VERIFY_P256) | S390X_CAPBIT(CS390X_ECDSA_VERIFY_P384) | S390X_CAPBIT(CS390X_ECDSA_VERIFY_P521))
 /* kdsa sign */
-#define ALL_ECS ( S390X_CAPBIT(S390X_ECDSA_SIGN_P256) | S390X_CAPBIT(S390X_ECDSA_SIGN_P384) | S390X_CAPBIT(S390X_ECDSA_SIGN_P521) )
+#define ALL_ECS ( S390X_CAPBIT(CS390X_ECDSA_SIGN_P256) | S390X_CAPBIT(CS390X_ECDSA_SIGN_P384) | S390X_CAPBIT(CS390X_ECDSA_SIGN_P521) )
 /* kdsa, done like this simply to keep the macros sane */
 #define ALL_KDSA (ALL_ECV | ALL_ECS)

@@ -718,35 +726,35 @@ static unsigned long long OSSL_2ICC()
 {
   unsigned long long cap = 0;

-  if((OPENSSL_s390xcap_P.kimd[0] & S390X_CAPBIT(S390X_SHA3_224)) &&  \
-     (OPENSSL_s390xcap_P.klmd[0] & S390X_CAPBIT(S390X_SHA3_224))
+  if((OPENSSL_s390xcap_P.kimd[0] & S390X_CAPBIT(CS390X_SHA3_224)) &&  \
+     (OPENSSL_s390xcap_P.klmd[0] & S390X_CAPBIT(CS390X_SHA3_224))
      )  cap |= I_S390X_SHA3_224;

-  if((OPENSSL_s390xcap_P.kimd[0] & S390X_CAPBIT(S390X_SHA3_256)) &&  \
-     (OPENSSL_s390xcap_P.klmd[0] & S390X_CAPBIT(S390X_SHA3_256))
+  if((OPENSSL_s390xcap_P.kimd[0] & S390X_CAPBIT(CS390X_SHA3_256)) &&  \
+     (OPENSSL_s390xcap_P.klmd[0] & S390X_CAPBIT(CS390X_SHA3_256))
      )  cap |= I_S390X_SHA3_256;

-  if((OPENSSL_s390xcap_P.kimd[0] & S390X_CAPBIT(S390X_SHA3_384)) &&  \
-    (OPENSSL_s390xcap_P.klmd[0] & S390X_CAPBIT(S390X_SHA3_384))
+  if((OPENSSL_s390xcap_P.kimd[0] & S390X_CAPBIT(CS390X_SHA3_384)) &&  \
+    (OPENSSL_s390xcap_P.klmd[0] & S390X_CAPBIT(CS390X_SHA3_384))
      )   cap |= I_S390X_SHA3_384;

-  if((OPENSSL_s390xcap_P.kimd[0] & S390X_CAPBIT(S390X_SHA3_512)) &&  \
-     (OPENSSL_s390xcap_P.klmd[0] & S390X_CAPBIT(S390X_SHA3_512))
+  if((OPENSSL_s390xcap_P.kimd[0] & S390X_CAPBIT(CS390X_SHA3_512)) &&  \
+     (OPENSSL_s390xcap_P.klmd[0] & S390X_CAPBIT(CS390X_SHA3_512))
      )  cap |= I_S390X_SHA3_512;

-  if((OPENSSL_s390xcap_P.kimd[0] & S390X_CAPBIT(S390X_SHAKE_128)) &&  \
-     (OPENSSL_s390xcap_P.klmd[0] & S390X_CAPBIT(S390X_SHAKE_128))
+  if((OPENSSL_s390xcap_P.kimd[0] & S390X_CAPBIT(CS390X_SHAKE_128)) &&  \
+     (OPENSSL_s390xcap_P.klmd[0] & S390X_CAPBIT(CS390X_SHAKE_128))
      ) cap |= I_S390X_SHAKE_128;

-  if((OPENSSL_s390xcap_P.kimd[0] & S390X_CAPBIT(S390X_SHAKE_256)) &&  \
-     (OPENSSL_s390xcap_P.klmd[0] & S390X_CAPBIT(S390X_SHAKE_256))
+  if((OPENSSL_s390xcap_P.kimd[0] & S390X_CAPBIT(CS390X_SHAKE_256)) &&  \
+     (OPENSSL_s390xcap_P.klmd[0] & S390X_CAPBIT(CS390X_SHAKE_256))
      ) cap |= I_S390X_SHAKE_256;

-  if((OPENSSL_s390xcap_P.kimd[1] & S390X_CAPBIT(S390X_GHASH)) !=0)     cap |= I_S390X_GHASH;
-  if((OPENSSL_s390xcap_P.km[0] & S390X_CAPBIT(S390X_AES_128)) !=0)     cap |= I_S390X_AES_128;
-  if((OPENSSL_s390xcap_P.km[0] & S390X_CAPBIT(S390X_AES_192)) !=0)     cap |= I_S390X_AES_192;
-  if((OPENSSL_s390xcap_P.km[0] & S390X_CAPBIT(S390X_AES_256)) !=0)     cap |= I_S390X_AES_256;
-  if((OPENSSL_s390xcap_P.prno[1] & S390X_CAPBIT(S390X_TRNG))  !=0)     cap |= I_S390X_TRNG;
+  if((OPENSSL_s390xcap_P.kimd[1] & S390X_CAPBIT(CS390X_GHASH)) !=0)     cap |= I_S390X_GHASH;
+  if((OPENSSL_s390xcap_P.km[0] & S390X_CAPBIT(CS390X_AES_128)) !=0)     cap |= I_S390X_AES_128;
+  if((OPENSSL_s390xcap_P.km[0] & S390X_CAPBIT(CS390X_AES_192)) !=0)     cap |= I_S390X_AES_192;
+  if((OPENSSL_s390xcap_P.km[0] & S390X_CAPBIT(CS390X_AES_256)) !=0)     cap |= I_S390X_AES_256;
+  if((OPENSSL_s390xcap_P.prno[1] & S390X_CAPBIT(CS390X_TRNG))  !=0)     cap |= I_S390X_TRNG;
   if((OPENSSL_s390xcap_P.kma[0] & ALL_AES ) == ALL_AES )         cap |= I_S390X_KMA_GCM;
   if((OPENSSL_s390xcap_P.pcc[0] & ALL_PCC ) == ALL_PCC )         cap |= I_S390X_PCC;
   if((OPENSSL_s390xcap_P.kdsa[0] & ALL_KDSA ) == ALL_KDSA )      cap |= I_S390X_KDSA;
@@ -757,43 +765,43 @@ static unsigned long long OSSL_2ICC()
 static void ICC_2OSSL(unsigned long long capbits)
 {
   if( 0 == (capbits & I_S390X_SHA3_224) ) {
-    OPENSSL_s390xcap_P.kimd[0] &= ~S390X_CAPBIT(S390X_SHA3_224);
-    OPENSSL_s390xcap_P.klmd[0] &= ~S390X_CAPBIT(S390X_SHA3_224);
+    OPENSSL_s390xcap_P.kimd[0] &= ~S390X_CAPBIT(CS390X_SHA3_224);
+    OPENSSL_s390xcap_P.klmd[0] &= ~S390X_CAPBIT(CS390X_SHA3_224);
   }
   if( 0 == (capbits & I_S390X_SHA3_256) ) {
-    OPENSSL_s390xcap_P.kimd[0] &= ~S390X_CAPBIT(S390X_SHA3_256);
-    OPENSSL_s390xcap_P.klmd[0] &= ~S390X_CAPBIT(S390X_SHA3_256);
+    OPENSSL_s390xcap_P.kimd[0] &= ~S390X_CAPBIT(CS390X_SHA3_256);
+    OPENSSL_s390xcap_P.klmd[0] &= ~S390X_CAPBIT(CS390X_SHA3_256);
   }
   if( 0 == (capbits & I_S390X_SHA3_384) ) {
-    OPENSSL_s390xcap_P.kimd[0] &= ~S390X_CAPBIT(S390X_SHA3_384);
-    OPENSSL_s390xcap_P.klmd[0] &= ~S390X_CAPBIT(S390X_SHA3_384);
+    OPENSSL_s390xcap_P.kimd[0] &= ~S390X_CAPBIT(CS390X_SHA3_384);
+    OPENSSL_s390xcap_P.klmd[0] &= ~S390X_CAPBIT(CS390X_SHA3_384);
   }
   if( 0 == (capbits & I_S390X_SHA3_512) ) {
-    OPENSSL_s390xcap_P.kimd[0] &= ~S390X_CAPBIT(S390X_SHA3_512);
-    OPENSSL_s390xcap_P.klmd[0] &= ~S390X_CAPBIT(S390X_SHA3_512);
+    OPENSSL_s390xcap_P.kimd[0] &= ~S390X_CAPBIT(CS390X_SHA3_512);
+    OPENSSL_s390xcap_P.klmd[0] &= ~S390X_CAPBIT(CS390X_SHA3_512);
   }
   if( 0 == (capbits & I_S390X_SHAKE_128) ) {
-    OPENSSL_s390xcap_P.kimd[0] &= ~S390X_CAPBIT(S390X_SHAKE_128);
-    OPENSSL_s390xcap_P.klmd[0] &= ~S390X_CAPBIT(S390X_SHAKE_128);
+    OPENSSL_s390xcap_P.kimd[0] &= ~S390X_CAPBIT(CS390X_SHAKE_128);
+    OPENSSL_s390xcap_P.klmd[0] &= ~S390X_CAPBIT(CS390X_SHAKE_128);
   }
   if( 0 == (capbits & I_S390X_SHAKE_256) ) {
-    OPENSSL_s390xcap_P.kimd[0] &= ~S390X_CAPBIT(S390X_SHAKE_256);
-    OPENSSL_s390xcap_P.klmd[0] &= ~S390X_CAPBIT(S390X_SHAKE_256);
+    OPENSSL_s390xcap_P.kimd[0] &= ~S390X_CAPBIT(CS390X_SHAKE_256);
+    OPENSSL_s390xcap_P.klmd[0] &= ~S390X_CAPBIT(CS390X_SHAKE_256);
   }
   if( 0 == (capbits & I_S390X_GHASH) ) {
-    OPENSSL_s390xcap_P.kimd[1] &= ~S390X_CAPBIT(S390X_GHASH);
+    OPENSSL_s390xcap_P.kimd[1] &= ~S390X_CAPBIT(CS390X_GHASH);
   }
   if( 0 == (capbits & I_S390X_AES_128) ) {
-    OPENSSL_s390xcap_P.km[0] &= ~S390X_CAPBIT(S390X_AES_128);
+    OPENSSL_s390xcap_P.km[0] &= ~S390X_CAPBIT(CS390X_AES_128);
   }
   if( 0 == (capbits & I_S390X_AES_192) ) {
-    OPENSSL_s390xcap_P.km[0] &= ~S390X_CAPBIT(S390X_AES_192);
+    OPENSSL_s390xcap_P.km[0] &= ~S390X_CAPBIT(CS390X_AES_192);
   }
   if( 0 == (capbits & I_S390X_AES_256) ) {
-    OPENSSL_s390xcap_P.km[0] &= ~S390X_CAPBIT(S390X_AES_256);
+    OPENSSL_s390xcap_P.km[0] &= ~S390X_CAPBIT(CS390X_AES_256);
   }
   if( 0 == (capbits & I_S390X_TRNG) ) {
-    OPENSSL_s390xcap_P.prno[1] &= ~S390X_CAPBIT(S390X_TRNG);
+    OPENSSL_s390xcap_P.prno[1] &= ~S390X_CAPBIT(CS390X_TRNG);
   }
   if( 0 == (capbits & I_S390X_KMA_GCM) ) {
     OPENSSL_s390xcap_P.kma[0] &= ~(ALL_AES);
diff --git a/crypto/s390xcpuid.pl b/crypto/s390xcpuid.pl
index 3fdeb12..623fde1 100755
--- a/crypto/s390xcpuid.pl
+++ b/crypto/s390xcpuid.pl
@@ -1,423 +1,737 @@
 #! /usr/bin/env perl
-# Copyright 2009-2020 The OpenSSL Project Authors. All Rights Reserved.
+# Copyright 2009-2018 The OpenSSL Project Authors. All Rights Reserved.
 #
-# Licensed under the Apache License 2.0 (the "License").  You may not use
+# Licensed under the OpenSSL license (the "License").  You may not use
 # this file except in compliance with the License.  You can obtain a copy
 # in the file LICENSE in the source distribution or at
 # https://www.openssl.org/source/license.html

-$flavour = shift;

+#
+# Note to Jon. You need to update s390xcap.c s390x_arch.h to pick up the changes to  OPENSSL_s390xcap_P to cater for the longer
+# capability vector and the split into facilities/functions
+#
+use strict;
+use FindBin qw($Bin);
+use lib "$Bin/../..";
+use lib "$Bin/";
+use perlasm::s390x qw(:DEFAULT :VX :LD :MSA :MSA4 :MSA5 :MSA8 stfle AUTOLOAD LABEL INCLUDE FUNCTION_BEGIN FUNCTION_END LONG ALIGN ASCIZ TEXT GET_EXTERN LOCAL_VARS_BEGIN LOCAL_VARS_END ds);
+
+my $flavour = shift;
+my ($z,$DSA_OFF,$PARMS_OFF,$SIZE_T);
+my ($alwaysr0,$alwaysr1);
+my ($fr0,$fr1,$fr2,$fr3,$fr4,$fr5,$fr6,$fr7,$ip,$ra,$sp,$v0,$wr0,$wr1,$wr2,$wr3,$wr4,$wr5,$wr6,$inp,$len,$rv);
+
+$DSA_OFF=2048;
 if ($flavour =~ /3[12]/) {
-	$SIZE_T=4;
-	$g="";
+        $z=0;	# 31/32 bit ABI
+		$SIZE_T=4;
+        $PARMS_OFF=2112
+} else {
+        $z=1;	# 64 bit ABI
+		$SIZE_T=8;
+        $PARMS_OFF=2176
+}
+
+if ($flavour =~ /linux/) {
+        $alwaysr0="%r0";
+        $alwaysr1="%r1";
+        $inp="%r2";
+        $len="%r4";
+
+        $fr0="%f0";
+        $fr1="%f1";
+        $fr2="%f2";
+        $fr3="%f3";
+        $fr4="%f4";
+        $fr5="%f5";
+        $fr6="%f6";
+        $fr7="%f7";
+
+        $v0="%v0";
+
+        $wr0="%r0";
+        $wr1="%r1";
+        $wr2="%r2";
+        $wr3="%r3";
+        $wr4="%r4";
+        $wr5="%r5";
+        $wr6="%r6";
+
+        $sp="%r15";
+        $rv="%r2";
+        $ra="%r14";
+        $ip=".";
 } else {
-	$SIZE_T=8;
-	$g="g";
+        $alwaysr0="R0";
+        $alwaysr1="R1";
+
+        $inp="R1";
+        $len="R2";
+
+        $fr0="f0";
+        $fr1="f1";
+        $fr2="f2";
+        $fr3="f3";
+        $fr4="f4";
+        $fr5="f5";
+        $fr6="f6";
+        $fr7="f7";
+
+        $v0="0";
+
+        $wr0="R6";
+        $wr1="R7";
+        $wr2="R8";
+        $wr3="R9";
+        $wr4="R10";
+        $wr5="R11";
+        $wr6="R14";
+
+        $sp="R4";
+        $rv="R3";
+        $ra="R7";
+
+        $ip="*";
 }

+my $output;
 while (($output=shift) && ($output!~/\w[\w\-]*\.\w+$/)) {}
 open STDOUT,">$output";

-$ra="%r14";
-$sp="%r15";
-$stdframe=16*$SIZE_T+4*8;
+my $stdframe=16*$SIZE_T+4*8;
+
+#my $code=<<___;

-$code=<<___;
+PERLASM_BEGIN($flavour,$output);
+
+INCLUDE	("s390x_arch.h", "crypto/");
+TEXT	();
 #include "s390x_arch.h"

-.text
-
-.globl	OPENSSL_s390x_facilities
-.type	OPENSSL_s390x_facilities,\@function
-.align	16
-OPENSSL_s390x_facilities:
-	lghi	%r0,0
-	larl	%r4,OPENSSL_s390xcap_P
-
-	stg	%r0,S390X_STFLE+8(%r4)	# wipe capability vectors
-	stg	%r0,S390X_STFLE+16(%r4)
-	stg	%r0,S390X_STFLE+24(%r4)
-
-	.long	0xb2b04000		# stfle	0(%r4)
-	brc	8,.Ldone
-	lghi	%r0,1
-	.long	0xb2b04000		# stfle 0(%r4)
-	brc	8,.Ldone
-	lghi	%r0,2
-	.long	0xb2b04000		# stfle 0(%r4)
-.Ldone:
-	br	$ra
-.size	OPENSSL_s390x_facilities,.-OPENSSL_s390x_facilities
-
-.globl	OPENSSL_s390x_functions
-.type	OPENSSL_s390x_functions,\@function
-.align	16
-OPENSSL_s390x_functions:
-	lghi	%r0,0
-	larl	%r4,OPENSSL_s390xcap_P
-
-	stg	%r0,S390X_KIMD(%r4)	# wipe capability vectors
-	stg	%r0,S390X_KIMD+8(%r4)
-	stg	%r0,S390X_KLMD(%r4)
-	stg	%r0,S390X_KLMD+8(%r4)
-	stg	%r0,S390X_KM(%r4)
-	stg	%r0,S390X_KM+8(%r4)
-	stg	%r0,S390X_KMC(%r4)
-	stg	%r0,S390X_KMC+8(%r4)
-	stg	%r0,S390X_KMAC(%r4)
-	stg	%r0,S390X_KMAC+8(%r4)
-	stg	%r0,S390X_KMCTR(%r4)
-	stg	%r0,S390X_KMCTR+8(%r4)
-	stg	%r0,S390X_KMO(%r4)
-	stg	%r0,S390X_KMO+8(%r4)
-	stg	%r0,S390X_KMF(%r4)
-	stg	%r0,S390X_KMF+8(%r4)
-	stg	%r0,S390X_PRNO(%r4)
-	stg	%r0,S390X_PRNO+8(%r4)
-	stg	%r0,S390X_KMA(%r4)
-	stg	%r0,S390X_KMA+8(%r4)
-	stg	%r0,S390X_PCC(%r4)
-	stg	%r0,S390X_PCC+8(%r4)
-	stg	%r0,S390X_KDSA(%r4)
-	stg	%r0,S390X_KDSA+8(%r4)
-
-	lmg	%r2,%r3,S390X_STFLE(%r4)
-
-	tmhl	%r2,0x4000		# check for message-security-assist
-	jz	.Lret
-
-	lghi	%r0,S390X_QUERY		# query kimd capabilities
-	la	%r1,S390X_KIMD(%r4)
-	.long	0xb93e0002		# kimd %r0,%r2
-
-	lghi	%r0,S390X_QUERY		# query klmd capabilities
-	la	%r1,S390X_KLMD(%r4)
-	.long	0xb93f0002		# klmd %r0,%r2
-
-	lghi	%r0,S390X_QUERY		# query km capability vector
-	la	%r1,S390X_KM(%r4)
-	.long	0xb92e0042		# km %r4,%r2
-
-	lghi	%r0,S390X_QUERY		# query kmc capability vector
-	la	%r1,S390X_KMC(%r4)
-	.long	0xb92f0042		# kmc %r4,%r2
-
-	lghi	%r0,S390X_QUERY		# query kmac capability vector
-	la	%r1,S390X_KMAC(%r4)
-	.long	0xb91e0042		# kmac %r4,%r2
-
-	tmhh	%r3,0x0008		# check for message-security-assist-3
-	jz	.Lret
-
-	lghi	%r0,S390X_QUERY		# query pcc capability vector
-	la	%r1,S390X_PCC(%r4)
-	.long	0xb92c0000		# pcc
-
-	tmhh	%r3,0x0004		# check for message-security-assist-4
-	jz	.Lret
-
-	lghi	%r0,S390X_QUERY		# query kmctr capability vector
-	la	%r1,S390X_KMCTR(%r4)
-	.long	0xb92d2042		# kmctr %r4,%r2,%r2
-
-	lghi	%r0,S390X_QUERY		# query kmo capability vector
-	la	%r1,S390X_KMO(%r4)
-	.long	0xb92b0042		# kmo %r4,%r2
-
-	lghi	%r0,S390X_QUERY		# query kmf capability vector
-	la	%r1,S390X_KMF(%r4)
-	.long	0xb92a0042		# kmf %r4,%r2
-
-	tml	%r2,0x40		# check for message-security-assist-5
-	jz	.Lret
-
-	lghi	%r0,S390X_QUERY		# query prno capability vector
-	la	%r1,S390X_PRNO(%r4)
-	.long	0xb93c0042		# prno %r4,%r2
-
-	lg	%r2,S390X_STFLE+16(%r4)
-
-	tmhl	%r2,0x2000		# check for message-security-assist-8
-	jz	.Lret
-
-	lghi	%r0,S390X_QUERY		# query kma capability vector
-	la	%r1,S390X_KMA(%r4)
-	.long	0xb9294022		# kma %r2,%r4,%r2
-
-	lg	%r2,S390X_STFLE+16(%r4) # Not so confident that r2 isn't clobbered by the kma probe
-	tmhl	%r2,0x0010		# check for message-security-assist-9
-	jz	.Lret
-
-	lghi	%r0,S390X_QUERY		# query kdsa capability vector
-	la	%r1,S390X_KDSA(%r4)
-	.long	0xb93a0002		# kdsa %r0,%r2
-
-.Lret:
-	br	$ra
-.size	OPENSSL_s390x_functions,.-OPENSSL_s390x_functions
-
-.globl	OPENSSL_rdtsc
-.type	OPENSSL_rdtsc,\@function
-.align	16
-OPENSSL_rdtsc:
-	larl	%r4,OPENSSL_s390xcap_P
-	tm	S390X_STFLE+3(%r4),0x40	# check for store-clock-fast facility
-	jz	.Lstck
-
-	.long	0xb27cf010	# stckf 16($sp)
-	lg	%r2,16($sp)
-	br	$ra
-.Lstck:
-	stck	16($sp)
-	lg	%r2,16($sp)
-	br	$ra
-.size	OPENSSL_rdtsc,.-OPENSSL_rdtsc
-
-.globl	OPENSSL_atomic_add
-.type	OPENSSL_atomic_add,\@function
-.align	16
-OPENSSL_atomic_add:
-	l	%r1,0(%r2)
-.Lspin:	lr	%r0,%r1
-	ar	%r0,%r3
-	cs	%r1,%r0,0(%r2)
-	brc	4,.Lspin
-	lgfr	%r2,%r0		# OpenSSL expects the new value
-	br	$ra
-.size	OPENSSL_atomic_add,.-OPENSSL_atomic_add
-
-.globl	OPENSSL_wipe_cpu
-.type	OPENSSL_wipe_cpu,\@function
-.align	16
-OPENSSL_wipe_cpu:
-	xgr	%r0,%r0
-	xgr	%r1,%r1
-	lgr	%r2,$sp
-	xgr	%r3,%r3
-	xgr	%r4,%r4
-	lzdr	%f0
-	lzdr	%f1
-	lzdr	%f2
-	lzdr	%f3
-	lzdr	%f4
-	lzdr	%f5
-	lzdr	%f6
-	lzdr	%f7
-	br	$ra
-.size	OPENSSL_wipe_cpu,.-OPENSSL_wipe_cpu
-
-.globl	OPENSSL_cleanse
-.type	OPENSSL_cleanse,\@function
-.align	16
-OPENSSL_cleanse:
-#if !defined(__s390x__) && !defined(__s390x)
-	llgfr	%r3,%r3
-#endif
-	lghi	%r4,15
-	lghi	%r0,0
-	clgr	%r3,%r4
-	jh	.Lot
-	clgr	%r3,%r0
-	bcr	8,%r14
-.Little:
-	stc	%r0,0(%r2)
-	la	%r2,1(%r2)
-	brctg	%r3,.Little
-	br	%r14
-.align	4
-.Lot:	tmll	%r2,7
-	jz	.Laligned
-	stc	%r0,0(%r2)
-	la	%r2,1(%r2)
-	brctg	%r3,.Lot
-.Laligned:
-	srlg	%r4,%r3,3
-.Loop:	stg	%r0,0(%r2)
-	la	%r2,8(%r2)
-	brctg	%r4,.Loop
-	lghi	%r4,7
-	ngr	%r3,%r4
-	jnz	.Little
-	br	$ra
-.size	OPENSSL_cleanse,.-OPENSSL_cleanse
-
-.globl	CRYPTO_memcmp
-.type	CRYPTO_memcmp,\@function
-.align	16
-CRYPTO_memcmp:
+################
+# void OPENSSL_s390x_facilities(void)
+{
+#.text
+#.globl	OPENSSL_s390x_facilities
+#.type	OPENSSL_s390x_facilities,\@function
+#.align	16
+FUNCTION_BEGIN("OPENSSL_s390x_facilities",0,"","stor2");
+	xgr	($alwaysr0,$alwaysr0);
+	GET_EXTERN($wr4,"OPENSSL_s390xcap_P");
+
+	stg	($alwaysr0,"CS390X_STFLE+8($wr4)");	# wipe capability vectors
+	stg	($alwaysr0,"CS390X_STFLE+16($wr4)");
+	stg	($alwaysr0,"CS390X_STFLE+24($wr4)");
+	stfle	("0($wr4)");
+	brc	(8,LABEL("Ldone"));
+	lghi	($alwaysr0,"1");
+	stfle	("0($wr4)");
+	brc	(8,LABEL("Ldone"));
+	lghi	($alwaysr0,"2");
+	stfle	("0($wr4)");
+LABEL   ("Ldone:");
+FUNCTION_END("OPENSSL_s390x_facilities",$rv);
+}
+{
+FUNCTION_BEGIN("OPENSSL_s390x_functions",0,"","stor2");
+	lghi	($alwaysr0,0);
+	GET_EXTERN($wr4,"OPENSSL_s390xcap_P");
+
+	stg	($alwaysr0,"CS390X_KIMD($wr4)");
+	stg	($alwaysr0,"CS390X_KIMD+8($wr4)");
+	stg	($alwaysr0,"CS390X_KLMD($wr4)");
+	stg	($alwaysr0,"CS390X_KLMD+8($wr4)");
+	stg	($alwaysr0,"CS390X_KM($wr4)");
+	stg	($alwaysr0,"CS390X_KM+8($wr4)");
+	stg	($alwaysr0,"CS390X_KMC($wr4)");
+	stg	($alwaysr0,"CS390X_KMC+8($wr4)");
+	stg	($alwaysr0,"CS390X_KMAC($wr4)");
+	stg	($alwaysr0,"CS390X_KMAC+8($wr4)");
+	stg	($alwaysr0,"CS390X_KMCTR($wr4)");
+	stg	($alwaysr0,"CS390X_KMCTR+8($wr4)");
+	stg	($alwaysr0,"CS390X_KMO($wr4)");
+	stg	($alwaysr0,"CS390X_KMO+8($wr4)");
+	stg	($alwaysr0,"CS390X_KMF($wr4)");
+	stg	($alwaysr0,"CS390X_KMF+8($wr4)");
+	stg	($alwaysr0,"CS390X_PRNO($wr4)");
+	stg	($alwaysr0,"CS390X_PRNO+8($wr4)");
+	stg	($alwaysr0,"CS390X_KMA($wr4)");
+	stg	($alwaysr0,"CS390X_KMA+8($wr4)");
+	stg ($alwaysr0,"CS390X_PCC($wr4)");
+	stg	($alwaysr0,"CS390X_PCC+8($wr4)");
+	stg	($alwaysr0,"CS390X_KDSA($wr4)");
+	stg	($alwaysr0,"CS390X_KDSA+8($wr4)");
+
+
+
+	lmg	    ($wr2,$wr3,"CS390X_STFLE($wr4)");
+	tmhl	($wr2,"0x4000");	# check for message-security-assist
+	jz	    (LABEL("Lret"));
+
+	lghi	($alwaysr0,"CS390X_QUERY");	# query kimd capabilities
+	la	    ($alwaysr1,"CS390X_KIMD($wr4)");
+	kimd    ($alwaysr0,$wr2);
+
+	lghi	($alwaysr0,"CS390X_QUERY");	# query klmd capabilities
+	la	    ($alwaysr1,"CS390X_KLMD($wr4)");
+	klmd    ($alwaysr0,$wr2);
+
+	lghi	($alwaysr0,"CS390X_QUERY");	# query km capability vector
+	la	    ($alwaysr1,"CS390X_KM($wr4)");
+	km      ($wr4,$wr2);
+
+	lghi	($alwaysr0,"CS390X_QUERY");	# query kmc capability vector
+	la	    ($alwaysr1,"CS390X_KMC($wr4)");
+	kmc     ($wr4,$wr2);
+
+	lghi	($alwaysr0,"CS390X_QUERY");	# query kmac capability vector
+	la	    ($alwaysr1,"CS390X_KMAC($wr4)");
+	kmac    ($wr4,$wr2);
+
+	tmhh	($wr3,0x0008);		# check for message-security-assist-3
+	jz	    (LABEL("Lret"));
+
+	lghi	($alwaysr0,"CS390X_QUERY");		# query pcc capability vector
+	la	    ($alwaysr1,"CS390X_PCC($wr4)");
+    LONG(0xb92c0000);
+#	pcc     ($alwaysr0,$wr2);    #.long	0xb92c0000	(Unsure of this one)
+
+	tmhh	($wr3,"0x0004");	# check for message-security-assist-4
+	jz	    (LABEL("Lret"));
+
+	lghi	($alwaysr0,"CS390X_QUERY");	# query kmctr capability vector
+	la	    ($alwaysr1,"CS390X_KMCTR($wr4)");
+	kmctr   ($wr4,$wr2,$wr2);
+
+	lghi	($alwaysr0,"CS390X_QUERY");	# query kmo capability vector
+	la	    ($alwaysr1,"CS390X_KMO($wr4)");
+	kmo     ($wr4,$wr2);
+
+	lghi	($alwaysr0,"CS390X_QUERY");	# query kmf capability vector
+	la	    ($alwaysr1,"CS390X_KMF($wr4)");
+	kmf     ($wr4,$wr2);
+
+	tml	    ($wr2,"0x40");		# check for message-security-assist-5
+	jz	    (LABEL("Lret"));
+
+	lghi	($alwaysr0,"CS390X_QUERY");	# query prno capability vector
+	la	    ($alwaysr1,"CS390X_PRNO($wr4)");
+	prno    ($wr4,$wr2);
+
+	lg	    ($wr2,"CS390X_STFLE+16($wr4)");
+	tmhl	($wr2,"0x2000");	# check for message-security-assist-8
+	jz	    (LABEL("Lret"));
+
+	lghi	($alwaysr0,"CS390X_QUERY");	# query kma capability vector
+	la	    ( $alwaysr1,"CS390X_KMA($wr4)");
+	kma     ($wr2,$wr4,$wr2);
+
+	tmhl	($wr2,0x0010);		# check for message-security-assist-9
+	jz	    (LABEL("Lret"));
+
+	lghi	($alwaysr0,"CS390X_QUERY");		# query kdsa capability vector
+	la	    ($alwaysr1,"CS390X_KDSA($wr4)");
+	LONG	(0xb93a0002);					# kdsa    ($alwaysr0,$wr2);
+LABEL   ("Lret:");
+#	br	($ra);
+#.size	OPENSSL_s390x_facilities,.-OPENSSL_s390x_facilities
+FUNCTION_END("OPENSSL_s390x_functions",$rv);
+}
+
+################
+# unsigned long OPENSSL_rdtsc(void)
+# We can do this (better) in C on z/OS, so this is zLinux only
+if ($flavour =~ /linux/)
+{
+my $clock;
+if ($flavour =~ /linux/) {
+    $clock="16($sp)";
+} else {
+    $clock="CLOCK";
+}
+#.globl	OPENSSL_rdtsc
+#.type	OPENSSL_rdtsc,\@function
+#.align	16
+FUNCTION_BEGIN("OPENSSL_rdtsc",0,"true","stor2");
+	GET_EXTERN($wr4,"OPENSSL_s390xcap_P");
+	tm	("CS390X_STFLE+3($wr4)","0x40");	# check for store-clock-fast facility
+	jz	(LABEL("Lstck"));
+    if($flavour =~ /linux/) {
+        LONG(0xb27cf010);
+    } else {
+	    stckf   ("$clock");
+    }
+	lg	($rv,"$clock");
+	j	(LABEL("EXIT_OPENSSL_rdtsc"));
+LABEL   ("Lstck:");
+	stck	("$clock");
+	lg	($rv,"$clock");
+#.size	OPENSSL_rdtsc,.-OPENSSL_rdtsc
+FUNCTION_END("OPENSSL_rdtsc",$rv);
+LOCAL_VARS_BEGIN();
+	ds	("CLOCK", "XL16");
+LOCAL_VARS_END();
+}
+
+################
+# unsigned long OPENSSL_atomic_add(ulong *currentValue,ulong addend) <===best guess
+{
+my ($inp,$addend);
+if ($flavour =~ /linux/) {
+    $inp="%r2";
+    $addend="%r3";
+} else {
+    $inp="r1";
+    $addend="r2";
+}
+#.globl	OPENSSL_atomic_add
+#.type	OPENSSL_atomic_add,\@function
+#.align	16
+FUNCTION_BEGIN("OPENSSL_atomic_add",0);
+        l	($wr1,"0($inp)");
+LABEL   ("Lspin:");
+	lr	($wr0,$wr1);
+	ar	($wr0,$addend);
+	cs	($wr1,$wr0,"0($inp)");
+	brc	(4,LABEL("Lspin"));
+	lgfr	($rv,$wr0);	# OpenSSL expects the new value
+#.size	OPENSSL_atomic_add,.-OPENSSL_atomic_add
+FUNCTION_END("OPENSSL_atomic_add",$rv);
+}
+
+################
+# void OPENSSL_wipe_cpu(void)
+{
+#.globl	OPENSSL_wipe_cpu
+#.type	OPENSSL_wipe_cpu,\@function
+#.align	16
+FUNCTION_BEGIN("OPENSSL_wipe_cpu",0);
+	xgr	($wr0,$wr0);
+	xgr	($wr1,$wr1);
+	lgr	($wr2,$sp);
+	xgr	($wr3,$wr3);
+	xgr	($wr4,$wr4);
+	lzdr	($fr0);
+	lzdr	($fr1);
+	lzdr	($fr2);
+	lzdr	($fr3);
+	lzdr	($fr4);
+	lzdr	($fr5);
+	lzdr	($fr6);
+	lzdr	($fr7);
+#.size	OPENSSL_wipe_cpu,.-OPENSSL_wipe_cpu
+    FUNCTION_END("OPENSSL_wipe_cpu",$rv);
+}
+
+################
+# void OPENSSL_cleanse(void *ptr, size_t len);
+{
+my ($inp,$len);
+if ($flavour =~ /linux/) {
+    $inp="%r2";
+    $len="%r3";
+} else {
+    $inp="r1";
+    $len="r2";
+}
+#.globl	OPENSSL_cleanse
+#.type	OPENSSL_cleanse,\@function
+#.align	16
+FUNCTION_BEGIN("OPENSSL_cleanse",2);
+&{$z? \&lgr:\&lr}    ($wr0,$inp);      # Move stor addr to MVCL target
+&{$z? \&lgr:\&lr}    ($wr1,$len);      # Move stor len to MVCL target len
+#&{$z? \&xgr:\&xr}    ($w2,$wr2);       # Set MVCL source to 0 (not needed)
+&{$z? \&xgr:\&xr}    ($wr3,$wr3);      # Set MVCL source pad and len to 0
+        mvcl  ($wr0,$wr2);      # source pad and len 0, so storage cleared
+##if !defined(__s390x__) && !defined(__s390x)
+#	llgfr	($len,$len);
+##endif
+#	lghi	($wr4,15);
+#	lghi	($wr0,0);
+#	clgr	($len,$wr4);
+#	jh	("Lot");
+#	clgr	($len,$wr0);
+#	bcr	(8,"EXIT_OPENSSL_cleanse");
+#LABEL("Little");
+#	stc	($wr0,"0($inp)");
+#	la	($inp,"1($inp)");
+#	brctg	($wr3,"Little");
+#	br	("EXIT_OPENSSL_cleanse");
+#ALIGN(4);
+#LABEL("Lot");
+#	tmll	($inp,7);
+#	jz	("Laligned");
+#	stc	($wr0,"0($inp)");
+#	la	($inp,"1($inp)");
+#	brctg	($len,"Lot");
+#LABEL("Laligned");
+#	srlg	($wr4,$wr3,3);
+#LABEL("Loop");
+#	stg	($wr0,"0($inp)");
+#	la	($inp,"8($inp)");
+#	brctg	($wr4,"Loop");
+#	lghi	($wr4,7);
+#	ngr	($len,$wr4);
+#	jnz	("Little");
+#	br	($ra);
+#.size	OPENSSL_cleanse,.-OPENSSL_cleanse
+        FUNCTION_END("OPENSSL_cleanse",$rv);
+}
+
+################
+# int CRYPTO_memcmp(const void * in_a, const void * in_b, size_t len);
+{
+my ($inpa,$inpb,$len);
+if ($flavour =~ /linux/) {
+    $inpa="%r2";
+    $inpb="%r3";
+    $len="%r4";
+} else {
+    $inpa="r1";
+    $inpb="r2";
+    $len="r3";
+}
+#.globl	CRYPTO_memcmp
+#.type	CRYPTO_memcmp,\@function
+#.align	16
+FUNCTION_BEGIN("CRYPTO_memcmp",3);
 #if !defined(__s390x__) && !defined(__s390x)
-	llgfr	%r4,%r4
+	llgfr	($len,$len);
 #endif
-	lghi	%r5,0
-	clgr	%r4,%r5
-	je	.Lno_data
-
-.Loop_cmp:
-	llgc	%r0,0(%r2)
-	la	%r2,1(%r2)
-	llgc	%r1,0(%r3)
-	la	%r3,1(%r3)
-	xr	%r1,%r0
-	or	%r5,%r1
-	brctg	%r4,.Loop_cmp
-
-	lnr	%r5,%r5
-	srl	%r5,31
-.Lno_data:
-	lgr	%r2,%r5
-	br	$ra
-.size	CRYPTO_memcmp,.-CRYPTO_memcmp
-
-.globl	OPENSSL_instrument_bus
-.type	OPENSSL_instrument_bus,\@function
-.align	16
-OPENSSL_instrument_bus:
-	lghi	%r2,0
-	br	%r14
-.size	OPENSSL_instrument_bus,.-OPENSSL_instrument_bus
-
-.globl	OPENSSL_instrument_bus2
-.type	OPENSSL_instrument_bus2,\@function
-.align	16
-OPENSSL_instrument_bus2:
-	lghi	%r2,0
-	br	$ra
-.size	OPENSSL_instrument_bus2,.-OPENSSL_instrument_bus2
-
-.globl	OPENSSL_vx_probe
-.type	OPENSSL_vx_probe,\@function
-.align	16
-OPENSSL_vx_probe:
-	.word	0xe700,0x0000,0x0044	# vzero %v0
-	br	$ra
-.size	OPENSSL_vx_probe,.-OPENSSL_vx_probe
-___
+	lghi	($wr5,0);
+	clgr	($len,$wr5);
+	je	(LABEL("Lno_data"));
+
+LABEL("Loop_cmp:");
+	llgc	($wr0,"0($inpa)");
+	la	($inpa,"1($inpa)");
+	llgc	($wr1,"0($inpb)");
+	la	($inpb,"1($inpb)");
+	xr	($wr1,$wr0);
+	&or	($wr5,$wr1);
+	brctg	($len,LABEL("Loop_cmp"));
+
+	lnr	($wr5,$wr5);
+	srl	($wr5,31);
+LABEL("Lno_data:");
+	lgr	($rv,$wr5);
+#.size	CRYPTO_memcmp,.-CRYPTO_memcmp
+    FUNCTION_END("OPENSSL_cleanse",$rv);
+}
+
+################
+# size_t OPENSSL_instrument_bus(unsigned int *, size_t);
+{
+my ($inp,$len);
+if ($flavour =~ /linux/) {
+    $inp="%r2";
+    $len="%r4";
+} else {
+    $inp="r1";
+    $len="r2";
+}
+#
+#.globl	OPENSSL_instrument_bus
+#.type	OPENSSL_instrument_bus,\@function
+#.align	16
+FUNCTION_BEGIN("OPENSSL_instrument_bus",2);
+	lghi	($rv,0);
+#.size	OPENSSL_instrument_bus,.-OPENSSL_instrument_bus
+FUNCTION_END("OPENSSL_instrument_bus",$rv);
+}

+################
+# size_t OPENSSL_instrument_bus2(unsigned int *, size_t, size_t);
+{
+my ($inp,$len);
+if ($flavour =~ /linux/) {
+    $inp="%r2";
+    $len="%r4";
+} else {
+    $inp="r1";
+    $len="r2";
+}
+#
+#.globl	OPENSSL_instrument_bus2
+#.type	OPENSSL_instrument_bus2,\@function
+#.align	16
+FUNCTION_BEGIN("OPENSSL_instrument_bus2",3);
+	lghi	($rv,0);
+#.size	OPENSSL_instrument_bus2,.-OPENSSL_instrument_bus2
+FUNCTION_END("OPENSSL_instrument_bus2",$rv);
+}
+
+################
+# void OPENSSL_vx_probe(void);
 {
+#
+#.globl	OPENSSL_vx_probe
+#.type	OPENSSL_vx_probe,\@function
+#.align	16
+FUNCTION_BEGIN("OPENSSL_vx_probe",0);
+        vzero ($v0);
+#.size	OPENSSL_vx_probe,.-OPENSSL_vx_probe
+FUNCTION_END("OPENSSL_vx_probe",$rv);
+}
+
 ################
 # void s390x_kimd(const unsigned char *in, size_t len, unsigned int fc,
 #                 void *param)
-my ($in,$len,$fc,$param) = map("%r$_",(2..5));
-$code.=<<___;
-.globl	s390x_kimd
-.type	s390x_kimd,\@function
-.align	16
-s390x_kimd:
-	llgfr	%r0,$fc
-	lgr	%r1,$param
+{
+my ($inp,$len,$fc,$param);
+if ($flavour =~ /linux/) {
+    $inp="%r2";
+    $len="%r3";
+    $fc="%r4";
+    $param="%r5";
+} else {
+    $inp="r1";
+    $len="r2";
+    $fc="r3";
+}
+#.globl	s390x_kimd
+#.type	s390x_kimd,\@function
+#.align	16
+FUNCTION_BEGIN("s390x_kimd",4);
+	llgfr	($alwaysr0,$fc);
+if ($flavour =~ /linux/) {
+	lgr	($wr1,$param);
+} else {
+    # inp is in r1 - len is in r2 - fc is in r3
+    # param is in DSA
+&{$z? \&lgr:\&lr}	($wr2,$inp);             # Move inp to source register
+&{$z? \&lgr:\&lr}	($wr3,$len);             # Move len to source register
+&{$z? \&lg:\&l} ($wr6,"$DSA_OFF($sp)");      # Get DSA address
+&{$z? \&lg:\&l}	("r1","$PARMS_OFF+$SIZE_T*3($wr6)"); # Get param CB
+}

-	.long	0xb93e0002	# kimd %r0,%r2
-	brc	1,.-4		# pay attention to "partial completion"
+	kimd    ($alwaysr0,$wr2);
+	brc	(1,"$ip-4");	# pay attention to "partial completion"

-	br	$ra
-.size	s390x_kimd,.-s390x_kimd
-___
+#.size	s390x_kimd,.-s390x_kimd
+FUNCTION_END("s390x_kimd",$rv);
 }

+
 {
 ################
 # void s390x_klmd(const unsigned char *in, size_t inlen, unsigned char *out,
 #                 size_t outlen, unsigned int fc, void *param)
-my ($in,$inlen,$out,$outlen,$fc) = map("%r$_",(2..6));
-$code.=<<___;
-.globl	s390x_klmd
-.type	s390x_klmd,\@function
-.align	32
-s390x_klmd:
-	llgfr	%r0,$fc
-	l${g}	%r1,$stdframe($sp)
+my ($inp,$inlen,$outp,$outlen,$fc,$param);
+if ($flavour =~ /linux/) {
+    $inp="%r2";
+    $inlen="%r3";
+    $outp="%r4";
+    $outlen="%r5";
+    $fc="%r6";
+    $param="%r7";
+} else {
+    $inp="r1";
+    $inlen="r2";
+    $outp="r3";
+}
+#$code.=<<___;
+#.globl	s390x_klmd
+#.type	s390x_klmd,\@function
+#.align	32
+FUNCTION_BEGIN("s390x_klmd",6);
+
+if ($flavour =~ /linux/) {
+    llgfr	("%r0",$fc);
+&{$z? \&lg:\&l} ("%r1","$stdframe($sp)");
+} else {

-	.long	0xb93f0042	# klmd %r4,%r2
-	brc	1,.-4		# pay attention to "partial completion"
+    # inp is in r1 - inlen is in r2 - out is in r3
+    # outlen, fc and param are in DSA
+&{$z? \&lgr:\&lr}	($wr2,$inp);             # Move inp to source register
+&{$z? \&lgr:\&lr}	($wr3,$inlen);           # Move inlen to source register
+&{$z? \&lgr:\&lr}	($wr4,$outp);            # Move out to target register
+&{$z? \&lg:\&l} ($wr6,"$DSA_OFF($sp)");      # Get DSA address
+&{$z? \&lg:\&l}	($wr5,"$PARMS_OFF+$SIZE_T*3($wr6)"); # Get out length
+&{$z? \&lg:\&l} ("r0","$PARMS_OFF+$SIZE_T*4($wr6)"); # Get function code
+&{$z? \&lg:\&l}	("r1","$PARMS_OFF+$SIZE_T*5($wr6)"); # Get param CB
+}
+	klmd    ($wr4,$wr2);
+	brc	(1,"$ip-4");	# pay attention to "partial completion"

-	br	$ra
-.size	s390x_klmd,.-s390x_klmd
-___
+#.size	s390x_klmd,.-s390x_klmd
+FUNCTION_END("s390x_klmd",$rv);
+#___
 }

 ################
 # void s390x_km(const unsigned char *in, size_t len, unsigned char *out,
 #               unsigned int fc, void *param)
 {
-my ($in,$len,$out,$fc,$param) = map("%r$_",(2..6));
-$code.=<<___;
-.globl	s390x_km
-.type	s390x_km,\@function
-.align	16
-s390x_km:
-	lr	%r0,$fc
-	l${g}r	%r1,$param
+my ($inp,$len,$outp,$fc,$param);
+if ($flavour =~ /linux/) {
+    $inp="%r2";
+    $len="%r3";
+    $outp="%r4";
+    $fc="%r5";
+    $param="%r6";
+} else {
+    $inp="r1";
+    $len="r2";
+    $outp="r3";
+}
+#$code.=<<___;
+#.globl	s390x_km
+#.type	s390x_km,\@function
+#.align	16
+FUNCTION_BEGIN("s390x_km",5);
+if ($flavour =~ /linux/) {
+	lr	("%r0",$fc);
+&{$z? \&lgr:\&lr} ("%r1",$param);
+
+} else {
+    # inp is in r1 - len is in r2 - out is in r3
+    # fc and param are in DSA
+&{$z? \&lgr:\&lr}	($wr2,$inp);             # Move inp to source register
+&{$z? \&lgr:\&lr}	($wr3,$len);             # Move len to source register
+&{$z? \&lgr:\&lr}	($wr4,$outp);            # Move out to target register
+&{$z? \&lg:\&l} ($wr6,"$DSA_OFF($sp)");      # Get DSA address
+&{$z? \&lg:\&l} ("r0","$PARMS_OFF+$SIZE_T*3($wr6)"); # Get function code
+&{$z? \&lg:\&l}	("r1","$PARMS_OFF+$SIZE_T*4($wr6)"); # Get param CB
+}

-	.long	0xb92e0042	# km $out,$in
-	brc	1,.-4		# pay attention to "partial completion"
+	km      ($wr4,$wr2);
+	brc	(1,"$ip-4");	# pay attention to "partial completion"

-	br	$ra
-.size	s390x_km,.-s390x_km
-___
+#.size	s390x_km,.-s390x_km
+FUNCTION_END("s390x_km",$rv);
+#___
 }

 ################
 # void s390x_kmac(const unsigned char *in, size_t len, unsigned int fc,
 #                 void *param)
 {
-my ($in,$len,$fc,$param) = map("%r$_",(2..5));
-$code.=<<___;
-.globl	s390x_kmac
-.type	s390x_kmac,\@function
-.align	16
-s390x_kmac:
-	lr	%r0,$fc
-	l${g}r	%r1,$param
+my ($inp,$len,$fc,$param);
+if ($flavour =~ /linux/) {
+    $inp="%r2";
+    $len="%r3";
+    $fc="%r4";
+    $param="%r5";
+} else {
+    $inp="r1";
+    $len="r2";
+    $fc="r3";
+}
+#$code.=<<___;
+#.globl	s390x_kmac
+#.type	s390x_kmac,\@function
+#.align	16
+FUNCTION_BEGIN("s390x_kmac",4);
+LABEL("s390x_kmac_A:");
+        lr	($alwaysr0,$fc); # Get function code
+if ($flavour =~ /linux/) {
+&{$z? \&lgr:\&lr} ("%r1",$param);
+
+} else {
+    # inp is in r1 - len is in r2 - fc is in r3
+    # param is in DSA
+&{$z? \&lgr:\&lr}	($wr2,$inp);             # Move inp to source register
+&{$z? \&lgr:\&lr}	($wr3,$len);             # Move len to source register
+&{$z? \&lg:\&l} ($wr6,"$DSA_OFF($sp)");      # Get DSA address
+&{$z? \&lg:\&l}	("r1","$PARMS_OFF+$SIZE_T*3($wr6)"); # Get param CB
+}

-	.long	0xb91e0002	# kmac %r0,$in
-	brc	1,.-4		# pay attention to "partial completion"
+	kmac    ($alwaysr0,$wr2);
+	brc	(1,"$ip-4");	# pay attention to "partial completion"

-	br	$ra
-.size	s390x_kmac,.-s390x_kmac
-___
+#.size	s390x_kmac,.-s390x_kmac
+FUNCTION_END("s390x_kmac",$rv);
+#___
 }

 ################
 # void s390x_kmo(const unsigned char *in, size_t len, unsigned char *out,
 #                unsigned int fc, void *param)
 {
-my ($in,$len,$out,$fc,$param) = map("%r$_",(2..6));
-$code.=<<___;
-.globl	s390x_kmo
-.type	s390x_kmo,\@function
-.align	16
-s390x_kmo:
-	lr	%r0,$fc
-	l${g}r	%r1,$param
+my ($inp,$len,$outp,$fc,$param);
+if ($flavour =~ /linux/) {
+    $inp="%r2";
+    $len="%r3";
+    $outp="%r4";
+    $fc="%r5";
+    $param="%r6";
+} else {
+    $inp="r1";
+    $len="r2";
+    $outp="r3";
+}
+#$code.=<<___;
+#.globl	s390x_kmo
+#.type	s390x_kmo,\@function
+#.align	16
+FUNCTION_BEGIN("s390x_kmo",5);
+if ($flavour =~ /linux/) {
+	lr	("%r0",$fc);
+&{$z? \&lgr:\&lr} ("%r1",$param);

-	.long	0xb92b0042	# kmo $out,$in
-	brc	1,.-4		# pay attention to "partial completion"
+} else {
+    # inp is in r1 - len is in r2 - out is in r3
+    # fc and param are in DSA
+&{$z? \&lgr:\&lr}	($wr2,$inp);             # Move inp to source register
+&{$z? \&lgr:\&lr}	($wr3,$len);             # Move len to source register
+&{$z? \&lgr:\&lr}	($wr4,$outp);            # Move out to target register
+&{$z? \&lg:\&l} ($wr6,"$DSA_OFF($sp)");      # Get DSA address
+&{$z? \&lg:\&l}	("r0","$PARMS_OFF+$SIZE_T*3($wr6)"); # Get function code
+&{$z? \&lg:\&l}	("r1","$PARMS_OFF+$SIZE_T*4($wr6)"); # Get param CB
+}

-	br	$ra
-.size	s390x_kmo,.-s390x_kmo
-___
+	kmo     ($wr4,$wr2);
+	brc	(1,"$ip-4");	# pay attention to "partial completion"
+
+#.size	s390x_kmo,.-s390x_kmo
+FUNCTION_END("s390x_kmo",$rv);
+#___
 }

 ################
 # void s390x_kmf(const unsigned char *in, size_t len, unsigned char *out,
 #                unsigned int fc, void *param)
 {
-my ($in,$len,$out,$fc,$param) = map("%r$_",(2..6));
-$code.=<<___;
-.globl	s390x_kmf
-.type	s390x_kmf,\@function
-.align	16
-s390x_kmf:
-	lr	%r0,$fc
-	l${g}r	%r1,$param
+my ($inp,$len,$outp,$fc,$param);
+if ($flavour =~ /linux/) {
+    $inp="%r2";
+    $len="%r3";
+    $outp="%r4";
+    $fc="%r5";
+    $param="%r6";
+} else {
+    $inp="r1";
+    $len="r2";
+    $outp="r3";
+}
+#$code.=<<___;
+#.globl	s390x_kmf
+#.type	s390x_kmf,\@function
+#.align	16
+FUNCTION_BEGIN("s390x_kmf",5);
+
+if ($flavour =~ /linux/) {
+	lr	("%r0",$fc);
+&{$z? \&lgr:\&lr} ("%r1",$param);

-	.long	0xb92a0042	# kmf $out,$in
-	brc	1,.-4		# pay attention to "partial completion"
+} else {
+    # inp is in r1 - len is in r2 - out is in r3
+    # fc and param are in DSA
+&{$z? \&lgr:\&lr}	($wr2,$inp);             # Move inp to source register
+&{$z? \&lgr:\&lr}	($wr3,$len);             # Move len to source register
+&{$z? \&lgr:\&lr}	($wr4,$outp);            # Move out to target register
+&{$z? \&lg:\&l} ($wr6,"$DSA_OFF($sp)");      # Get DSA address
+&{$z? \&lg:\&l} ("r0","$PARMS_OFF+$SIZE_T*3($wr6)"); # Get function code
+&{$z? \&lg:\&l}	("r1","$PARMS_OFF+$SIZE_T*4($wr6)"); # Get param CB
+}
+	kmf     ($wr4,$wr2);
+	brc	(1,"$ip-4");	# pay attention to "partial completion"

-	br	$ra
-.size	s390x_kmf,.-s390x_kmf
-___
+#.size	s390x_kmf,.-s390x_kmf
+FUNCTION_END("s390x_kmf",$rv);
+#___
 }

 ################
@@ -425,112 +739,202 @@ ___
 #                const unsigned char *in, size_t len,
 #                unsigned char *out, unsigned int fc, void *param)
 {
-my ($aad,$alen,$in,$len,$out) = map("%r$_",(2..6));
-$code.=<<___;
-.globl	s390x_kma
-.type	s390x_kma,\@function
-.align	16
-s390x_kma:
-	st${g}	$out,6*$SIZE_T($sp)
-	lm${g}	%r0,%r1,$stdframe($sp)
+my ($aad,$alen,$inp,$len,$outp);
+if ($flavour =~ /linux/) {
+    $aad="%r2";
+    $alen="%r3";
+    $inp="%r4";
+    $len="%r5";
+    $outp="%r6";
+} else {
+    $aad="r1";
+    $alen="r2";
+    $inp="r3";
+}
+#$code.=<<___;
+#.globl	s390x_kma
+#.type	s390x_kma,\@function
+#.align	16
+FUNCTION_BEGIN("s390x_kma",7);
+
+if ($flavour =~ /linux/) {
+
+&{$z? \&stg:\&st} ($outp,"6*$SIZE_T($sp)");
+&{$z? \&lmg:\&lm} ("%r0","%r1","$stdframe($sp)");
+	kma     ($outp,$aad,$inp);
+	brc	(1,"$ip-4");    # pay attention to "partial completion"

-	.long	0xb9292064	# kma $out,$aad,$in
-	brc	1,.-4		# pay attention to "partial completion"
+&{$z? \&lg:\&l}	($outp,"6*$SIZE_T($sp)");

-	l${g}	$out,6*$SIZE_T($sp)
-	br	$ra
-.size	s390x_kma,.-s390x_kma
-___
+} else {
+    # aad is in r1, alen is in r2, inp is in r3
+    # len, out, fc and param are in DSA
+&{$z? \&lgr:\&lr}	($wr0,$aad);             # Move aad
+&{$z? \&lgr:\&lr}	($wr1,$alen);            # Move alen
+&{$z? \&lgr:\&lr}	($wr2,$inp);             # Move inp to source register
+&{$z? \&lg:\&l} ($wr6,"$DSA_OFF($sp)");      # Get DSA address
+&{$z? \&lg:\&l}	($wr3,"$PARMS_OFF+$SIZE_T*3($wr6)"); # Move len to source register
+&{$z? \&lg:\&l}	($wr4,"$PARMS_OFF+$SIZE_T*4($wr6)"); # Move out to target register
+&{$z? \&lg:\&l}	("r0","$PARMS_OFF+$SIZE_T*5($wr6)"); # Get function code
+&{$z? \&lg:\&l}	("r1","$PARMS_OFF+$SIZE_T*6($wr6)"); # Get param CB
+	kma     ($wr4,$wr0,$wr2);
+	brc	(1,"$ip-4");    # pay attention to "partial completion"
+}
+
+#.size	s390x_kma,.-s390x_kma
+FUNCTION_END("s390x_kma",$rv);
+
+#___
 }

-################
-# int s390x_pcc(unsigned int fc, void *param)
 {
-my ($fc,$param) = map("%r$_",(2..3));
-$code.=<<___;
-.globl	s390x_pcc
-.type	s390x_pcc,\@function
-.align	16
-s390x_pcc:
-	lr	%r0,$fc
-	l${g}r	%r1,$param
-	lhi	%r2,0
-
-	.long	0xb92c0000	# pcc
-	brc	1,.-4		# pay attention to "partial completion"
-	brc	7,.Lpcc_err	# if CC==0 return 0, else return 1
-.Lpcc_out:
-	br	$ra
-.Lpcc_err:
-	lhi	%r2,1
-	j	.Lpcc_out
-.size	s390x_pcc,.-s390x_pcc
-___
+###############
+# int s390x_pcc(unsigned int fc, void *param)
+my ($fc,$param);
+if ($flavour =~ /linux/) {
+    $fc="%r2";
+    $param="%r3";
+} else {
+    $fc="r1";
+    $param="r2";
+}
+
+
+FUNCTION_BEGIN("s390x_pcc",2);
+	lr	    ($alwaysr0,$fc);
+	&{$z? \&lgr:\&lr}	($alwaysr1,$param); # inplicitly used by pcc
+	lhi	    ($rv,0);
+	LONG	(0xb92c0000);	# pcc
+	brc	    (1,"$ip-4");		# pay attention to "partial completion"
+	brc	    (7,LABEL("Lpcc_err"));	# if CC==0 return 0, else return 1
+    j       (LABEL("EXIT_s390x_pcc"));
+LABEL("Lpcc_err:");
+	lhi	    ($rv,1);
+FUNCTION_END("s390x_pcc",$rv);
+
 }

 ################
-# int s390x_kdsa(unsigned int fc, void *param,
-#                 const unsigned char *in, size_t len)
+# int s390x_kdsa(unsigned int fc, void *param, const unsigned char *in, size_t len)
 {
-my ($fc,$param,$in,$len) = map("%r$_",(2..5));
-$code.=<<___;
-.globl	s390x_kdsa
-.type	s390x_kdsa,\@function
-.align	16
-s390x_kdsa:
-	lr	%r0,$fc
-	l${g}r	%r1,$param
-	lhi	%r2,0
-
-	.long	0xb93a0004	# kdsa %r0,$in
-	brc	1,.-4		# pay attention to "partial completion"
-	brc	7,.Lkdsa_err	# if CC==0 return 0, else return 1
-.Lkdsa_out:
-	br	$ra
-.Lkdsa_err:
-	lhi	%r2,1
-	j	.Lkdsa_out
-.size	s390x_kdsa,.-s390x_kdsa
-___
-}
-
-$code.=<<___;
-.globl s390x_trng
-.type  s390x_trng,\@function
-.align 16
-s390x_trng:
-       lghi    %r5,0
-       lghi    %r0,114         # prno capability vector checked by caller
-       .long   0xb93c0042      # prno %r4,%r2
-       brc     1,.-4           # pay attention to "partial completion"
-       br      %r14
-.size  s390x_trng,.-s390x_trng
-
-
-.globl s390x_drng
-.type  s390x_drng,\@function
-
-.align 16
-s390x_drng:
-#if !defined(__s390x__) && !defined(__s390x)
-       l       %r1,96(%r15)
-#else
-       lg      %r1,160(%r15)
-#endif
-       lr      %r0,%r6         # prno capability vector checked by caller
-       .long   0xb93c0024      # prno %r2,%r4
-       brc     1,.-4           # pay attention to "partial completion"
-       br      %r14
-.size  s390x_drng,.-s390x_drng
-___
-
-$code.=<<___;
-.section	.init
-	brasl	$ra,OPENSSL_cpuid_setup
-___
+    my ($fc,$param,$in,$len);
+    if ($flavour =~ /linux/) {
+        $fc="%r2";
+        $param="%r3";
+        $in="%r4";
+        $len="%r5";
+    } else {
+        $fc="r1";
+        $param="r2";
+        $in = "r3";
+        # Other arguments on the stack on zOS
+    }
+#
+# int s390x_kdsa(unsigned int fc, void *param, const unsigned char *in, size_t len);
+#
+FUNCTION_BEGIN("s390x_kdsa",4);
+
+	lr	    ($alwaysr0,"$fc");
+    &{$z?   \&lgr:\&lr}	($alwaysr1,$param); # implicitly used by the kdsa instruction
+	lhi	    ($rv,0);		# use xgr($rv,$rv) instead, is faster
+if ($flavour =~ /linux/) {
+	LONG	(0xb93a0004);		# kdsa    ($wr0,$in);
+} else {
+    &{$z? \&lgr:\&lr}	("R2","R3");		# Move $inp into even-odd reg pair
+	&{$z? \&lg:\&l} ($wr6,"$DSA_OFF($sp)");      # Get DSA address
+	&{$z? \&lg:\&l}	($wr3,"$PARMS_OFF+$SIZE_T*3($wr6)"); # Get len
+	LONG	(0xb93a0002);		# kdsa    ($wr0,$in);
+}
+	brc	    (1,"$ip-4");		# pay attention to "partial completion"
+	brc	    (7,LABEL("Lkdsa_err"));	# if CC==0 return 0, else return 1
+    j       (LABEL("EXIT_s390x_kdsa"));
+LABEL("Lkdsa_err:");
+	lhi	    ($rv,1);      # Increment instead ?
+FUNCTION_END("s390x_kdsa",$rv);
+}
+################
+# void s390x_trng(unsigned long long *	x,int i);
+{
+my ($inp,$len);
+if ($flavour =~ /linux/) {
+    $inp="%r2";
+    $len="%r3";
+} else {
+    $inp="r1";
+    $len="r2";
+}
+#$code.=<<___;
+#.globl s390x_trng
+#.type  s390x_trng,\@function
+#.align 16
+FUNCTION_BEGIN("s390x_trng",2);
+if ($flavour !~ /linux/) {
+&{$z? \&lgr:\&lr}	($wr2,$inp);  # Move inp to source
+&{$z? \&lgr:\&lr}	($wr3,$len);  # Move len to source
+}
+       xgr     ($wr5,$wr5);       # Set length of output to 0, output addr not used
+       lghi    ($alwaysr0,114);      # prno capability vector checked by caller
+       prno    ($wr4,$wr2);
+       brc     (1,"$ip-4");    # pay attention to "partial completion"
+#.size  s390x_trng,.-s390x_trng
+FUNCTION_END("s390x_trng",$rv);
+}

+################
+# void s390x_drng( 6 parms? - in?, inlen?, out?, outlen?, unsigned int fc, void *param);
+{
+my ($outp,$outlen,$inp,$inlen,$fc);
+if ($flavour =~ /linux/) {
+    $outp="%r2";
+    $outlen="%r3";
+    $inp="%r4";
+    $inlen="%r5";
+    $fc="%r6";
+} else {
+    $outp="r1";
+    $outlen="r2";
+    $inp="r3";
+}
+#
+#.globl s390x_drng
+#.type  s390x_drng,\@function
+#.align 16
+FUNCTION_BEGIN("s390x_drng",2);
+##if !defined(__s390x__) && !defined(__s390x)
+#       l       %r1,96(%r15)
+##else
+#       lg      %r1,160(%r15)
+##endif
+
+if ($flavour =~ /linux/) {
+&{$z? \&lg:\&l}	("%r1","$stdframe(%r15)");
+       lr      ("%r0","%r6");   # prno capability vector checked by caller

+} else {
+    # outp is in r1 - outlen is in r2 - inp is in r3
+    # inlen, fc and param are in DSA
+&{$z? \&lgr:\&lr}	($wr2,$outp);            # Move outp to target register
+&{$z? \&lgr:\&lr}	($wr3,$len);             # Move outlen to target register
+&{$z? \&lgr:\&lr}	($wr4,$inp);             # Move inp to source register
+&{$z? \&lg:\&l} ($wr6,"$DSA_OFF($sp)");      # Get DSA address
+&{$z? \&lg:\&l}	($wr5,"$PARMS_OFF+$SIZE_T*3($wr6)"); # Get inlen
+&{$z? \&lg:\&l}	("r0","$PARMS_OFF+$SIZE_T*4($wr6)"); # Get function code
+&{$z? \&lg:\&l}	("r1","$PARMS_OFF+$SIZE_T*5($wr6)"); # Get param CB
+}

-$code =~ s/\`([^\`]*)\`/eval $1/gem;
-print $code;
-close STDOUT or die "error closing STDOUT: $!";	# force flush
+       prno    ($wr2,$wr4);
+       brc     (1,"$ip-4");     # pay attention to "partial completion"
+#.size  s390x_drng,.-s390x_drng
+FUNCTION_END("s390x_drng",$rv);
+}
+#
+#
+#
+#.section	.init
+#	brasl	$ra,OPENSSL_cpuid_setup
+#___
+#
+#$code =~ s/\`([^\`]*)\`/eval $1/gem;
+#print $code;
+#close STDOUT;	# force flush
+PERLASM_END();
diff --git a/crypto/sha/asm/keccak1600-s390x.pl b/crypto/sha/asm/keccak1600-s390x.pl
index a7d819a..5006b4d 100755
--- a/crypto/sha/asm/keccak1600-s390x.pl
+++ b/crypto/sha/asm/keccak1600-s390x.pl
@@ -1,5 +1,5 @@
 #!/usr/bin/env perl
-# Copyright 2017-2020 The OpenSSL Project Authors. All Rights Reserved.
+# Copyright 2017-2018 The OpenSSL Project Authors. All Rights Reserved.
 #
 # Licensed under the OpenSSL license (the "License").  You may not use
 # this file except in compliance with the License.  You can obtain a copy
@@ -29,27 +29,58 @@
 # cycles. At least the result is consistent with estimate based on
 # amount of instruction and assumed instruction issue rate. It's ~2.5x
 # faster than compiler-generated code.
-
-$flavour = shift;
-
+use strict;
+use FindBin qw($Bin);
+use lib "$Bin/../..";
+use perlasm::s390x qw(:MSA :DEFAULT :VX :LD AUTOLOAD LABEL INCLUDE FUNCTION_BEGIN LOCAL_FUNCTION FUNCTION_END LOCAL_FUNCTION_END OBJECT_BEGIN OBJECT_END BYTE LONG QUAD ALIGN ASCIZ TEXT GET_EXTERN LOCAL_VARS_BEGIN LOCAL_VARS_END ds);
+
+
+my $output;
+my ($z,$SIZE_T,$DSA_OFF,$PARMS_OFF,$g);
+my ($ra,$rv,$sp);
+my ($acc,$cnt,$key,$len,$inp,$out,@XX,@TX,$YY,$TY);
+my ($i,$idx,$dat,$ikey,$iinp,$src,$dst,$iotas);
+my (@A,@C,@D,@T,$sp,$stdframe,$frame);
+my ($wr0,$wr1,$wr6,$wr14,$wr15);				# work registers
+my $flavour = shift;
+
+$DSA_OFF=2048;
 if ($flavour =~ /3[12]/) {
 	$SIZE_T=4;
-	$g="";
+	$z = 0;  # 31/32 bit ABI
+	$PARMS_OFF=2112;
 } else {
 	$SIZE_T=8;
-	$g="g";
+	$z=1;    # 64 bit ABI
+	$PARMS_OFF=2176;
 }

 while (($output=shift) && ($output!~/\w[\w\-]*\.\w+$/)) {}
 open STDOUT,">$output";

-my @A = map([ 8*$_, 8*($_+1), 8*($_+2), 8*($_+3), 8*($_+4) ], (0,5,10,15,20));
-
-my @C = map("%r$_",(0,1,5..7));
-my @D = map("%r$_",(8..12));
-my @T = map("%r$_",(13..14));
-my ($src,$dst,$iotas) = map("%r$_",(2..4));
-my $sp = "%r15";
+PERLASM_BEGIN($flavour,$output);
+
+if($flavour =~ /linux/) {
+	@A = map([ 8*$_, 8*($_+1), 8*($_+2), 8*($_+3), 8*($_+4) ], (0,5,10,15,20));
+	@C = map("%r$_",(0,1,5..7));
+	@D = map("%r$_",(8..12));
+	@T = map("%r$_",(13..14));
+	($src,$dst,$iotas) = map("%r$_",(2..4));
+	($wr0,$wr1,$wr6,$wr14,$wr15) = map("%r$_",(0..1,6,14,15));
+	$rv = "%r2";
+	$ra = "%r14";
+	$sp = "%r15";
+} else {
+	@A = map([ 8*$_, 8*($_+1), 8*($_+2), 8*($_+3), 8*($_+4) ], (0,5,10,15,20));
+	@C = map("R$_",(0,1,5..7));
+	@D = map("R$_",(8..12));
+	@T = map("R$_",(13..14));
+	($src,$dst,$iotas) = map("R$_",(2..4));
+	($wr0,$wr1,$wr6,$wr14,$wr15) = map("R$_",(0..1,6,14,15));
+	$rv = "R3";
+	$ra = "R7";
+	$sp = "R15";
+}

 $stdframe=16*$SIZE_T+4*8;
 $frame=$stdframe+25*8;
@@ -60,501 +91,563 @@ my @rhotates = ([  0,  1, 62, 28, 27 ],
                 [ 41, 45, 15, 21,  8 ],
                 [ 18,  2, 61, 56, 14 ]);

-{ my @C = @C;	# copy, because we mess them up...
-  my @D = @D;
-
-$code.=<<___;
-.text
-
-.type	__KeccakF1600,\@function
-.align	32
-__KeccakF1600:
-	st${g}	%r14,$SIZE_T*14($sp)
-	lg	@C[0],$A[4][0]($src)
-	lg	@C[1],$A[4][1]($src)
-	lg	@C[2],$A[4][2]($src)
-	lg	@C[3],$A[4][3]($src)
-	lg	@C[4],$A[4][4]($src)
-	larl	$iotas,iotas
-	j	.Loop
-
-.align	16
-.Loop:
-	lg	@D[0],$A[0][0]($src)
-	lg	@D[1],$A[1][1]($src)
-	lg	@D[2],$A[2][2]($src)
-	lg	@D[3],$A[3][3]($src)
-
-	xgr	@C[0],@D[0]
-	xg	@C[1],$A[0][1]($src)
-	xg	@C[2],$A[0][2]($src)
-	xg	@C[3],$A[0][3]($src)
-	lgr	@D[4],@C[4]
-	xg	@C[4],$A[0][4]($src)
-
-	xg	@C[0],$A[1][0]($src)
-	xgr	@C[1],@D[1]
-	xg	@C[2],$A[1][2]($src)
-	xg	@C[3],$A[1][3]($src)
-	xg	@C[4],$A[1][4]($src)
-
-	xg	@C[0],$A[2][0]($src)
-	xg	@C[1],$A[2][1]($src)
-	xgr	@C[2],@D[2]
-	xg	@C[3],$A[2][3]($src)
-	xg	@C[4],$A[2][4]($src)
-
-	xg	@C[0],$A[3][0]($src)
-	xg	@C[1],$A[3][1]($src)
-	xg	@C[2],$A[3][2]($src)
-	xgr	@C[3],@D[3]
-	xg	@C[4],$A[3][4]($src)
-
-	lgr	@T[0],@C[2]
-	rllg	@C[2],@C[2],1
-	xgr	@C[2],@C[0]		# D[1] = ROL64(C[2], 1) ^ C[0]
-
-	rllg	@C[0],@C[0],1
-	xgr	@C[0],@C[3]		# D[4] = ROL64(C[0], 1) ^ C[3]
-
-	rllg	@C[3],@C[3],1
-	xgr	@C[3],@C[1]		# D[2] = ROL64(C[3], 1) ^ C[1]
-
-	rllg	@C[1],@C[1],1
-	xgr	@C[1],@C[4]		# D[0] = ROL64(C[1], 1) ^ C[4]
-
-	rllg	@C[4],@C[4],1
-	xgr	@C[4],@T[0]		# D[3] = ROL64(C[4], 1) ^ C[2]
-___
+
+
+{
+	my @C = @C;	# copy, because we mess them up...
+	my @D = @D;
+
+
+TEXT();
+# void __KeccakF1600(uint64_t A[5][5]) ;
+
+LOCAL_FUNCTION("__KeccakF1600");
+
+&{$z? \&stg:\&st}	($ra,"$SIZE_T*14($sp)");
+	lg		(@C[0],"$A[4][0]($src)");
+	lg		(@C[1],"$A[4][1]($src)");
+	lg		(@C[2],"$A[4][2]($src)");
+	lg		(@C[3],"$A[4][3]($src)");
+	lg		(@C[4],"$A[4][4]($src)");
+	larl	($iotas,LABEL("iotas"));
+	j		(LABEL("Loop"));
+
+	ALIGN(16);
+	LABEL("Loop:");
+	lg		(@D[0],"$A[0][0]($src)");
+	lg		(@D[1],"$A[1][1]($src)");
+	lg		(@D[2],"$A[2][2]($src)");
+	lg		(@D[3],"$A[3][3]($src)");
+
+	xgr		(@C[0],@D[0]);
+	xg		(@C[1],"$A[0][1]($src)");
+	xg		(@C[2],"$A[0][2]($src)");
+	xg		(@C[3],"$A[0][3]($src)");
+	lgr		(@D[4],@C[4]);
+	xg		(@C[4],"$A[0][4]($src)");
+
+	xg		(@C[0],"$A[1][0]($src)");
+	xgr		(@C[1],@D[1]);
+	xg		(@C[2],"$A[1][2]($src)");
+	xg		(@C[3],"$A[1][3]($src)");
+	xg		(@C[4],"$A[1][4]($src)");
+
+	xg		(@C[0],"$A[2][0]($src)");
+	xg		(@C[1],"$A[2][1]($src)");
+	xgr		(@C[2],@D[2]);
+	xg		(@C[3],"$A[2][3]($src)");
+	xg		(@C[4],"$A[2][4]($src)");
+
+	xg		(@C[0],"$A[3][0]($src)");
+	xg		(@C[1],"$A[3][1]($src)");
+	xg		(@C[2],"$A[3][2]($src)");
+	xgr		(@C[3],@D[3]);
+	xg		(@C[4],"$A[3][4]($src)");
+
+	lgr		(@T[0],@C[2]);
+	rllg	(@C[2],@C[2],1);
+	xgr		(@C[2],@C[0]);		# D[1] = ROL64(C[2], 1) ^ C[0]
+
+	rllg	(@C[0],@C[0],1);
+	xgr		(@C[0],@C[3]);		# D[4] = ROL64(C[0], 1) ^ C[3]
+
+	rllg	(@C[3],@C[3],1);
+	xgr		(@C[3],@C[1]);		# D[2] = ROL64(C[3], 1) ^ C[1]
+
+	rllg	(@C[1],@C[1],1);
+	xgr		(@C[1],@C[4]);		# D[0] = ROL64(C[1], 1) ^ C[4]
+
+	rllg	(@C[4],@C[4],1);
+	xgr		(@C[4],@T[0]);		# Ddir[3] = ROL64(C[4], 1) ^ C[2]
+
 	(@D[0..4], @C) = (@C[1..4,0], @D);
-$code.=<<___;
-	xgr	@C[1],@D[1]
-	xgr	@C[2],@D[2]
-	xgr	@C[3],@D[3]
-	 rllg	@C[1],@C[1],$rhotates[1][1]
-	xgr	@C[4],@D[4]
-	 rllg	@C[2],@C[2],$rhotates[2][2]
-	xgr	@C[0],@D[0]
-
-	lgr	@T[0],@C[1]
-	ogr	@C[1],@C[2]
-	 rllg	@C[3],@C[3],$rhotates[3][3]
-	xgr	@C[1],@C[0]		#	    C[0] ^ ( C[1] | C[2])
-	 rllg	@C[4],@C[4],$rhotates[4][4]
-	xg	@C[1],0($iotas)
-	la	$iotas,8($iotas)
-	stg	@C[1],$A[0][0]($dst)	# R[0][0] = C[0] ^ ( C[1] | C[2]) ^ iotas[i]
-
-	lgr	@T[1],@C[4]
-	ngr	@C[4],@C[3]
-	 lghi	@C[1],-1		# no 'not' instruction :-(
-	xgr	@C[4],@C[2]		#	    C[2] ^ ( C[4] & C[3])
-	 xgr	@C[2],@C[1]		# not	@C[2]
-	stg	@C[4],$A[0][2]($dst)	# R[0][2] = C[2] ^ ( C[4] & C[3])
-	 ogr	@C[2],@C[3]
-	 xgr	@C[2],@T[0]		#	    C[1] ^ (~C[2] | C[3])
-
-	ngr	@T[0],@C[0]
-	 stg	@C[2],$A[0][1]($dst)	# R[0][1] = C[1] ^ (~C[2] | C[3])
-	xgr	@T[0],@T[1]		#	    C[4] ^ ( C[1] & C[0])
-	 ogr	@T[1],@C[0]
-	stg	@T[0],$A[0][4]($dst)	# R[0][4] = C[4] ^ ( C[1] & C[0])
-	 xgr	@T[1],@C[3]		#	    C[3] ^ ( C[4] | C[0])
-	 stg	@T[1],$A[0][3]($dst)	# R[0][3] = C[3] ^ ( C[4] | C[0])
-
-
-	lg	@C[0],$A[0][3]($src)
-	lg	@C[4],$A[4][2]($src)
-	lg	@C[3],$A[3][1]($src)
-	lg	@C[1],$A[1][4]($src)
-	lg	@C[2],$A[2][0]($src)
-
-	xgr	@C[0],@D[3]
-	xgr	@C[4],@D[2]
-	 rllg	@C[0],@C[0],$rhotates[0][3]
-	xgr	@C[3],@D[1]
-	 rllg	@C[4],@C[4],$rhotates[4][2]
-	xgr	@C[1],@D[4]
-	 rllg	@C[3],@C[3],$rhotates[3][1]
-	xgr	@C[2],@D[0]
-
-	lgr	@T[0],@C[0]
-	ogr	@C[0],@C[4]
-	 rllg	@C[1],@C[1],$rhotates[1][4]
-	xgr	@C[0],@C[3]		#	    C[3] ^ (C[0] |  C[4])
-	 rllg	@C[2],@C[2],$rhotates[2][0]
-	stg	@C[0],$A[1][3]($dst)	# R[1][3] = C[3] ^ (C[0] |  C[4])
-
-	lgr	@T[1],@C[1]
-	ngr	@C[1],@T[0]
-	 lghi	@C[0],-1		# no 'not' instruction :-(
-	xgr	@C[1],@C[4]		#	    C[4] ^ (C[1] &  C[0])
-	 xgr	@C[4],@C[0]		# not	@C[4]
-	stg	@C[1],$A[1][4]($dst)	# R[1][4] = C[4] ^ (C[1] &  C[0])
-
-	 ogr	@C[4],@C[3]
-	 xgr	@C[4],@C[2]		#	    C[2] ^ (~C[4] | C[3])
-
-	ngr	@C[3],@C[2]
-	 stg	@C[4],$A[1][2]($dst)	# R[1][2] = C[2] ^ (~C[4] | C[3])
-	xgr	@C[3],@T[1]		#	    C[1] ^ (C[3] &  C[2])
-	 ogr	@T[1],@C[2]
-	stg	@C[3],$A[1][1]($dst)	# R[1][1] = C[1] ^ (C[3] &  C[2])
-	 xgr	@T[1],@T[0]		#	    C[0] ^ (C[1] |  C[2])
-	 stg	@T[1],$A[1][0]($dst)	# R[1][0] = C[0] ^ (C[1] |  C[2])
-
-
-	lg	@C[2],$A[2][3]($src)
-	lg	@C[3],$A[3][4]($src)
-	lg	@C[1],$A[1][2]($src)
-	lg	@C[4],$A[4][0]($src)
-	lg	@C[0],$A[0][1]($src)
-
-	xgr	@C[2],@D[3]
-	xgr	@C[3],@D[4]
-	 rllg	@C[2],@C[2],$rhotates[2][3]
-	xgr	@C[1],@D[2]
-	 rllg	@C[3],@C[3],$rhotates[3][4]
-	xgr	@C[4],@D[0]
-	 rllg	@C[1],@C[1],$rhotates[1][2]
-	xgr	@C[0],@D[1]
-
-	lgr	@T[0],@C[2]
-	ngr	@C[2],@C[3]
-	 rllg	@C[4],@C[4],$rhotates[4][0]
-	xgr	@C[2],@C[1]		#	     C[1] ^ ( C[2] & C[3])
-	lghi	@T[1],-1		# no 'not' instruction :-(
-	stg	@C[2],$A[2][1]($dst)	# R[2][1] =  C[1] ^ ( C[2] & C[3])
-
-	xgr	@C[3],@T[1]		# not	@C[3]
-	lgr	@T[1],@C[4]
-	ngr	@C[4],@C[3]
-	 rllg	@C[0],@C[0],$rhotates[0][1]
-	xgr	@C[4],@T[0]		#	     C[2] ^ ( C[4] & ~C[3])
-	 ogr	@T[0],@C[1]
-	stg	@C[4],$A[2][2]($dst)	# R[2][2] =  C[2] ^ ( C[4] & ~C[3])
-	 xgr	@T[0],@C[0]		#	     C[0] ^ ( C[2] | C[1])
-
-	ngr	@C[1],@C[0]
-	 stg	@T[0],$A[2][0]($dst)	# R[2][0] =  C[0] ^ ( C[2] | C[1])
-	xgr	@C[1],@T[1]		#	     C[4] ^ ( C[1] & C[0])
-	 ogr	@C[0],@T[1]
-	stg	@C[1],$A[2][4]($dst)	# R[2][4] =  C[4] ^ ( C[1] & C[0])
-	 xgr	@C[0],@C[3]		#	    ~C[3] ^ ( C[0] | C[4])
-	 stg	@C[0],$A[2][3]($dst)	# R[2][3] = ~C[3] ^ ( C[0] | C[4])
-
-
-	lg	@C[2],$A[2][1]($src)
-	lg	@C[3],$A[3][2]($src)
-	lg	@C[1],$A[1][0]($src)
-	lg	@C[4],$A[4][3]($src)
-	lg	@C[0],$A[0][4]($src)
-
-	xgr	@C[2],@D[1]
-	xgr	@C[3],@D[2]
-	 rllg	@C[2],@C[2],$rhotates[2][1]
-	xgr	@C[1],@D[0]
-	 rllg	@C[3],@C[3],$rhotates[3][2]
-	xgr	@C[4],@D[3]
-	 rllg	@C[1],@C[1],$rhotates[1][0]
-	xgr	@C[0],@D[4]
-	 rllg	@C[4],@C[4],$rhotates[4][3]
-
-	lgr	@T[0],@C[2]
-	ogr	@C[2],@C[3]
-	lghi	@T[1],-1		# no 'not' instruction :-(
-	xgr	@C[2],@C[1]		#	     C[1] ^ ( C[2] | C[3])
-	xgr	@C[3],@T[1]		# not	@C[3]
-	stg	@C[2],$A[3][1]($dst)	# R[3][1] =  C[1] ^ ( C[2] | C[3])
-
-	lgr	@T[1],@C[4]
-	ogr	@C[4],@C[3]
-	 rllg	@C[0],@C[0],$rhotates[0][4]
-	xgr	@C[4],@T[0]		#	     C[2] ^ ( C[4] | ~C[3])
-	 ngr	@T[0],@C[1]
-	stg	@C[4],$A[3][2]($dst)	# R[3][2] =  C[2] ^ ( C[4] | ~C[3])
-	 xgr	@T[0],@C[0]		#	     C[0] ^ ( C[2] & C[1])
-
-	ogr	@C[1],@C[0]
-	 stg	@T[0],$A[3][0]($dst)	# R[3][0] =  C[0] ^ ( C[2] & C[1])
-	xgr	@C[1],@T[1]		#	     C[4] ^ ( C[1] | C[0])
-	 ngr	@C[0],@T[1]
-	stg	@C[1],$A[3][4]($dst)	# R[3][4] =  C[4] ^ ( C[1] | C[0])
-	 xgr	@C[0],@C[3]		#	    ~C[3] ^ ( C[0] & C[4])
-	 stg	@C[0],$A[3][3]($dst)	# R[3][3] = ~C[3] ^ ( C[0] & C[4])
-
-
-	xg	@D[2],$A[0][2]($src)
-	xg	@D[3],$A[1][3]($src)
-	xg	@D[1],$A[4][1]($src)
-	xg	@D[4],$A[2][4]($src)
-	xgr	$dst,$src		# xchg	$dst,$src
-	 rllg	@D[2],@D[2],$rhotates[0][2]
-	xg	@D[0],$A[3][0]($src)
-	 rllg	@D[3],@D[3],$rhotates[1][3]
-	xgr	$src,$dst
-	 rllg	@D[1],@D[1],$rhotates[4][1]
-	xgr	$dst,$src
-	 rllg	@D[4],@D[4],$rhotates[2][4]
-___
+
+	xgr		(@C[1],@D[1]);
+	xgr		(@C[2],@D[2]);
+	xgr		(@C[3],@D[3]);
+	rllg	(@C[1],@C[1],"$rhotates[1][1]");
+	xgr		(@C[4],@D[4]);
+	rllg	(@C[2],@C[2],"$rhotates[2][2]");
+	xgr		(@C[0],@D[0]);
+
+	lgr		(@T[0],@C[1]);
+	ogr		(@C[1],@C[2]);
+	rllg	(@C[3],@C[3],"$rhotates[3][3]");
+	xgr		(@C[1],@C[0]);		#	    C[0] ^ ( C[1] | C[2])
+	rllg	(@C[4],@C[4],"$rhotates[4][4]");
+	xg		(@C[1],"0($iotas)");
+	la		($iotas,"8($iotas)");
+	stg		(@C[1],"$A[0][0]($dst)");	# R[0][0] = C[0] ^ ( C[1] | C[2]) ^ iotas[i]
+
+	lgr		(@T[1],@C[4]);
+	ngr		(@C[4],@C[3]);
+	lghi	(@C[1],-1);		# no 'not' instruction :-(
+	xgr		(@C[4],@C[2]);		#	    C[2] ^ ( C[4] & C[3])
+	xgr		(@C[2],@C[1]);		# not	@C[2]
+	stg		(@C[4],"$A[0][2]($dst)");	# R[0][2] = C[2] ^ ( C[4] & C[3])
+	ogr		(@C[2],@C[3]);
+	xgr		(@C[2],@T[0]);		#	    C[1] ^ (~C[2] | C[3])
+
+	ngr		(@T[0],@C[0]);
+	stg		(@C[2],"$A[0][1]($dst)");	# R[0][1] = C[1] ^ (~C[2] | C[3])
+	xgr		(@T[0],@T[1]);		#	    C[4] ^ ( C[1] & C[0])
+	ogr		(@T[1],@C[0]);
+	stg		(@T[0],"$A[0][4]($dst)");	# R[0][4] = C[4] ^ ( C[1] & C[0])
+	xgr		(@T[1],@C[3]);		#	    C[3] ^ ( C[4] | C[0])
+	stg		(@T[1],"$A[0][3]($dst)");	# R[0][3] = C[3] ^ ( C[4] | C[0])
+
+
+	lg		(@C[0],"$A[0][3]($src)");
+	lg		(@C[4],"$A[4][2]($src)");
+	lg		(@C[3],"$A[3][1]($src)");
+	lg		(@C[1],"$A[1][4]($src)");
+	lg		(@C[2],"$A[2][0]($src)");
+
+	xgr		(@C[0],@D[3]);
+	xgr		(@C[4],@D[2]);
+	rllg	(@C[0],@C[0],"$rhotates[0][3]");
+	xgr		(@C[3],@D[1]);
+	rllg	(@C[4],@C[4],"$rhotates[4][2]");
+	xgr		(@C[1],@D[4]);
+	rllg	(@C[3],@C[3],"$rhotates[3][1]");
+	xgr		(@C[2],@D[0]);
+
+	lgr		(@T[0],@C[0]);
+	ogr		(@C[0],@C[4]);
+	rllg	(@C[1],@C[1],"$rhotates[1][4]");
+	xgr		(@C[0],@C[3]);		#	    C[3] ^ (C[0] |  C[4])
+	rllg	(@C[2],@C[2],"$rhotates[2][0]");
+	stg		(@C[0],"$A[1][3]($dst)");	# R[1][3] = C[3] ^ (C[0] |  C[4])
+
+	lgr		(@T[1],@C[1]);
+	ngr		(@C[1],@T[0]);
+	lghi	(@C[0],-1);		# no 'not' instruction :-(
+	xgr		(@C[1],@C[4]);		#	    C[4] ^ (C[1] &  C[0])
+	xgr		(@C[4],@C[0]);		# not	@C[4]
+	stg		(@C[1],"$A[1][4]($dst)");	# R[1][4] = C[4] ^ (C[1] &  C[0])
+
+	ogr		(@C[4],@C[3]);
+	xgr		(@C[4],@C[2]);		#	    C[2] ^ (~C[4] | C[3])
+
+	ngr		(@C[3],@C[2]);
+	stg		(@C[4],"$A[1][2]($dst)");	# R[1][2] = C[2] ^ (~C[4] | C[3])
+	xgr		(@C[3],@T[1]);		#	    C[1] ^ (C[3] &  C[2])
+	ogr		(@T[1],@C[2]);
+	stg		(@C[3],"$A[1][1]($dst)");	# R[1][1] = C[1] ^ (C[3] &  C[2])
+	xgr		(@T[1],@T[0]);		#	    C[0] ^ (C[1] |  C[2])
+	stg		(@T[1],"$A[1][0]($dst)");	# R[1][0] = C[0] ^ (C[1] |  C[2])
+
+
+	lg		(@C[2],"$A[2][3]($src)");
+	lg		(@C[3],"$A[3][4]($src)");
+	lg		(@C[1],"$A[1][2]($src)");
+	lg		(@C[4],"$A[4][0]($src)");
+	lg		(@C[0],"$A[0][1]($src)");
+
+	xgr		(@C[2],@D[3]);
+	xgr		(@C[3],@D[4]);
+	rllg	(@C[2],@C[2],"$rhotates[2][3]");
+	xgr		(@C[1],@D[2]);
+	rllg	(@C[3],@C[3],"$rhotates[3][4]");
+	xgr		(@C[4],@D[0]);
+	rllg	(@C[1],@C[1],"$rhotates[1][2]");
+	xgr		(@C[0],@D[1]);
+
+	lgr		(@T[0],@C[2]);
+	ngr		(@C[2],@C[3]);
+	rllg	(@C[4],@C[4],"$rhotates[4][0]");
+	xgr		(@C[2],@C[1]);		#	     C[1] ^ ( C[2] & C[3])
+	lghi	(@T[1],-1);	# no 'not' instruction :-(
+	stg		(@C[2],"$A[2][1]($dst)");	# R[2][1] =  C[1] ^ ( C[2] & C[3])
+
+	xgr		(@C[3],@T[1]);		# not	@C[3]
+	lgr		(@T[1],@C[4]);
+	ngr		(@C[4],@C[3]);
+	rllg	(@C[0],@C[0],"$rhotates[0][1]");
+	xgr		(@C[4],@T[0]);		#	     C[2] ^ ( C[4] & ~C[3])
+	ogr		(@T[0],@C[1]);
+	stg		(@C[4],"$A[2][2]($dst)");	# R[2][2] =  C[2] ^ ( C[4] & ~C[3])
+	xgr		(@T[0],@C[0]);		#	     C[0] ^ ( C[2] | C[1])
+
+	ngr		(@C[1],@C[0]);
+	stg		(@T[0],"$A[2][0]($dst)");	# R[2][0] =  C[0] ^ ( C[2] | C[1])
+	xgr		(@C[1],@T[1]);		#	     C[4] ^ ( C[1] & C[0])
+	ogr		(@C[0],@T[1]);
+	stg		(@C[1],"$A[2][4]($dst)");	# R[2][4] =  C[4] ^ ( C[1] & C[0])
+	xgr		(@C[0],@C[3]);		#	    ~C[3] ^ ( C[0] | C[4])
+	stg		(@C[0],"$A[2][3]($dst)");	# R[2][3] = ~C[3] ^ ( C[0] | C[4])
+
+
+	lg		(@C[2],"$A[2][1]($src)");
+	lg		(@C[3],"$A[3][2]($src)");
+	lg		(@C[1],"$A[1][0]($src)");
+	lg		(@C[4],"$A[4][3]($src)");
+	lg		(@C[0],"$A[0][4]($src)");
+
+	xgr		(@C[2],@D[1]);
+	xgr		(@C[3],@D[2]);
+	rllg	(@C[2],@C[2],"$rhotates[2][1]");
+	xgr		(@C[1],@D[0]);
+	rllg	(@C[3],@C[3],"$rhotates[3][2]");
+	xgr		(@C[4],@D[3]);
+	rllg	(@C[1],@C[1],"$rhotates[1][0]");
+	xgr		(@C[0],@D[4]);
+	rllg	(@C[4],@C[4],"$rhotates[4][3]");
+
+	lgr		(@T[0],@C[2]);
+	ogr		(@C[2],@C[3]);
+	lghi	(@T[1],-1);			# no 'not' instruction :-(
+	xgr		(@C[2],@C[1]);		#	     C[1] ^ ( C[2] | C[3])
+	xgr		(@C[3],@T[1]);		# not	@C[3]
+	stg		(@C[2],"$A[3][1]($dst)");	# R[3][1] =  C[1] ^ ( C[2] | C[3])
+
+	lgr		(@T[1],@C[4]);
+	ogr		(@C[4],@C[3]);
+	rllg	(@C[0],@C[0],"$rhotates[0][4]");
+	xgr		(@C[4],@T[0]);				#	     C[2] ^ ( C[4] | ~C[3])
+	ngr		(@T[0],@C[1]);
+	stg		(@C[4],"$A[3][2]($dst)");	# R[3][2] =  C[2] ^ ( C[4] | ~C[3])
+	xgr		(@T[0],@C[0]);				#	     C[0] ^ ( C[2] & C[1])
+
+	ogr		(@C[1],@C[0]);
+	stg		(@T[0],"$A[3][0]($dst)");	# R[3][0] =  C[0] ^ ( C[2] & C[1])
+	xgr		(@C[1],@T[1]);				#	     C[4] ^ ( C[1] | C[0])
+	ngr		(@C[0],@T[1]);
+	stg		(@C[1],"$A[3][4]($dst)");	# R[3][4] =  C[4] ^ ( C[1] | C[0])
+	xgr		(@C[0],@C[3]);				#	    ~C[3] ^ ( C[0] & C[4])
+	stg		(@C[0],"$A[3][3]($dst)");	# R[3][3] = ~C[3] ^ ( C[0] & C[4])
+
+
+	xg		(@D[2],"$A[0][2]($src)");
+	xg		(@D[3],"$A[1][3]($src)");
+	xg		(@D[1],"$A[4][1]($src)");
+	xg		(@D[4],"$A[2][4]($src)");
+	xgr		($dst,$src);		# xchg	$dst,$src
+	rllg	(@D[2],@D[2],"$rhotates[0][2]");
+	xg		(@D[0],"$A[3][0]($src)");
+	rllg	(@D[3],@D[3],"$rhotates[1][3]");
+	xgr		($src,$dst);
+	rllg	(@D[1],@D[1],"$rhotates[4][1]");
+	xgr		($dst,$src);
+	rllg	(@D[4],@D[4],"$rhotates[2][4]");
+
 	@C = @D[2..4,0,1];
-$code.=<<___;
-	lgr	@T[0],@C[0]
-	ngr	@C[0],@C[1]
-	lghi	@T[1],-1		# no 'not' instruction :-(
-	xgr	@C[0],@C[4]		#	     C[4] ^ ( C[0] & C[1])
-	xgr	@C[1],@T[1]		# not	@C[1]
-	stg	@C[0],$A[4][4]($src)	# R[4][4] =  C[4] ^ ( C[0] & C[1])
-
-	lgr	@T[1],@C[2]
-	ngr	@C[2],@C[1]
-	 rllg	@D[0],@D[0],$rhotates[3][0]
-	xgr	@C[2],@T[0]		#	     C[0] ^ ( C[2] & ~C[1])
-	 ogr	@T[0],@C[4]
-	stg	@C[2],$A[4][0]($src)	# R[4][0] =  C[0] ^ ( C[2] & ~C[1])
-	 xgr	@T[0],@C[3]		#	     C[3] ^ ( C[0] | C[4])
-
-	ngr	@C[4],@C[3]
-	 stg	@T[0],$A[4][3]($src)	# R[4][3] =  C[3] ^ ( C[0] | C[4])
-	xgr	@C[4],@T[1]		#	     C[2] ^ ( C[4] & C[3])
-	 ogr	@C[3],@T[1]
-	stg	@C[4],$A[4][2]($src)	# R[4][2] =  C[2] ^ ( C[4] & C[3])
-	 xgr	@C[3],@C[1]		#	    ~C[1] ^ ( C[2] | C[3])
-
-	lgr	@C[1],@C[0]		# harmonize with the loop top
-	lgr	@C[0],@T[0]
-	 stg	@C[3],$A[4][1]($src)	# R[4][1] = ~C[1] ^ ( C[2] | C[3])
-
-	tmll	$iotas,255
-	jnz	.Loop
-
-	l${g}	%r14,$SIZE_T*14($sp)
-	br	%r14
-.size	__KeccakF1600,.-__KeccakF1600
-___
+
+	lgr		(@T[0],@C[0]);
+	ngr		(@C[0],@C[1]);
+	lghi	(@T[1],-1);		# no 'not' instruction :-(
+	xgr		(@C[0],@C[4]);		#	     C[4] ^ ( C[0] & C[1])
+	xgr		(@C[1],@T[1]);		# not	@C[1]
+	stg		(@C[0],"$A[4][4]($src)");	# R[4][4] =  C[4] ^ ( C[0] & C[1])
+
+	lgr		(@T[1],@C[2]);
+	ngr		(@C[2],@C[1]);
+	rllg	(@D[0],@D[0],"$rhotates[3][0]");
+	xgr		(@C[2],@T[0]);		#	     C[0] ^ ( C[2] & ~C[1])
+	ogr		(@T[0],@C[4]);
+	stg		(@C[2],"$A[4][0]($src)");	# R[4][0] =  C[0] ^ ( C[2] & ~C[1])
+	xgr		(@T[0],@C[3]);		#	     C[3] ^ ( C[0] | C[4])
+
+	ngr		(@C[4],@C[3]);
+	stg		(@T[0],"$A[4][3]($src)");	# R[4][3] =  C[3] ^ ( C[0] | C[4])
+	xgr		(@C[4],@T[1]);		#	     C[2] ^ ( C[4] & C[3])
+	ogr		(@C[3],@T[1]);
+	stg		(@C[4],"$A[4][2]($src)");	# R[4][2] =  C[2] ^ ( C[4] & C[3])
+	xgr		(@C[3],@C[1]);		#	    ~C[1] ^ ( C[2] | C[3])
+
+	lgr		(@C[1],@C[0]);		# harmonize with the loop top
+	lgr		(@C[0],@T[0]);
+	stg		(@C[3],"$A[4][1]($src)");	# R[4][1] = ~C[1] ^ ( C[2] | C[3])
+
+	tmll	($iotas,255);
+	jnz		(LABEL("Loop"));
+&{$z? \&lg:\&l}	($ra,"$SIZE_T*14($sp)");
+	LOCAL_FUNCTION_END("__KeccakF1600");
 }
+
+#
+# static void KeccakF1600(uint64_t A[5][5])
+#
 {
-$code.=<<___;
-.type	KeccakF1600,\@function
-.align	32
-KeccakF1600:
-.LKeccakF1600:
-	lghi	%r1,-$frame
-	stm${g}	%r6,%r15,$SIZE_T*6($sp)
-	lgr	%r0,$sp
-	la	$sp,0(%r1,$sp)
-	st${g}	%r0,0($sp)
-
-	lghi	@D[0],-1		# no 'not' instruction :-(
-	lghi	@D[1],-1
-	lghi	@D[2],-1
-	lghi	@D[3],-1
-	lghi	@D[4],-1
-	lghi	@T[0],-1
-	xg	@D[0],$A[0][1]($src)
-	xg	@D[1],$A[0][2]($src)
-	xg	@D[2],$A[1][3]($src)
-	xg	@D[3],$A[2][2]($src)
-	xg	@D[4],$A[3][2]($src)
-	xg	@T[0],$A[4][0]($src)
-	stmg	@D[0],@D[1],$A[0][1]($src)
-	stg	@D[2],$A[1][3]($src)
-	stg	@D[3],$A[2][2]($src)
-	stg	@D[4],$A[3][2]($src)
-	stg	@T[0],$A[4][0]($src)
-
-	la	$dst,$stdframe($sp)
-
-	bras	%r14,__KeccakF1600
-
-	lghi	@D[0],-1		# no 'not' instruction :-(
-	lghi	@D[1],-1
-	lghi	@D[2],-1
-	lghi	@D[3],-1
-	lghi	@D[4],-1
-	lghi	@T[0],-1
-	xg	@D[0],$A[0][1]($src)
-	xg	@D[1],$A[0][2]($src)
-	xg	@D[2],$A[1][3]($src)
-	xg	@D[3],$A[2][2]($src)
-	xg	@D[4],$A[3][2]($src)
-	xg	@T[0],$A[4][0]($src)
-	stmg	@D[0],@D[1],$A[0][1]($src)
-	stg	@D[2],$A[1][3]($src)
-	stg	@D[3],$A[2][2]($src)
-	stg	@D[4],$A[3][2]($src)
-	stg	@T[0],$A[4][0]($src)
-
-	lm${g}	%r6,%r15,$frame+6*$SIZE_T($sp)
-	br	%r14
-.size	KeccakF1600,.-KeccakF1600
-___
+LOCAL_FUNCTION("KeccakF1600");
+LABEL("LKeccakF1600:");
+	lghi	($wr1,-$frame);
+&{$z? \&stmg:\&stm}	($wr6,$wr15,"$SIZE_T*6($sp)");
+	lgr		($wr0,$sp);
+	la		($sp,"0($wr1,$sp)");
+&{$z? \&stg:\&st}	($wr0,"0($sp)");
+
+	lghi	(@D[0],-1);		# no 'not' instruction :-(
+	lghi	(@D[1],-1);
+	lghi	(@D[2],-1);
+	lghi	(@D[3],-1);
+	lghi	(@D[4],-1);
+	lghi	(@T[0],-1);
+	xg		(@D[0],"$A[0][1]($src)");
+	xg		(@D[1],"$A[0][2]($src)");
+	xg		(@D[2],"$A[1][3]($src)");
+	xg		(@D[3],"$A[2][2]($src)");
+	xg		(@D[4],"$A[3][2]($src)");
+	xg		(@T[0],"$A[4][0]($src)");
+	stmg	(@D[0],@D[1],"$A[0][1]($src)");
+	stg		(@D[2],"$A[1][3]($src)");
+	stg		(@D[3],"$A[2][2]($src)");
+	stg		(@D[4],"$A[3][2]($src)");
+	stg		(@T[0],"$A[4][0]($src)");
+
+	la		($dst,"$stdframe($sp)");
+
+	bras	($ra,"__KeccakF1600");
+
+	lghi	(@D[0],-1);		# no 'not' instruction :-(
+	lghi	(@D[1],-1);
+	lghi	(@D[2],-1);
+	lghi	(@D[3],-1);
+	lghi	(@D[4],-1);
+	lghi	(@T[0],-1);
+	xg		(@D[0],"$A[0][1]($src)");
+	xg		(@D[1],"$A[0][2]($src)");
+	xg		(@D[2],"$A[1][3]($src)");
+	xg		(@D[3],"$A[2][2]($src)");
+	xg		(@D[4],"$A[3][2]($src)");
+	xg		(@T[0],"$A[4][0]($src)");
+	stmg	(@D[0],@D[1],"$A[0][1]($src)");
+	stg		(@D[2],"$A[1][3]($src)");
+	stg		(@D[3],"$A[2][2]($src)");
+	stg		(@D[4],"$A[3][2]($src)");
+	stg		(@T[0],"$A[4][0]($src)");
+&{$z? \&lmg:\&lm}	($wr6,$wr15,"$frame+6*$SIZE_T($sp)");
+LOCAL_FUNCTION_END("KeccakF1600");
 }
-{ my ($A_flat,$inp,$len,$bsz) = map("%r$_",(2..5));
-
-$code.=<<___;
-.globl	SHA3_absorb
-.type	SHA3_absorb,\@function
-.align	32
-SHA3_absorb:
-	lghi	%r1,-$frame
-	stm${g}	%r5,%r15,$SIZE_T*5($sp)
-	lgr	%r0,$sp
-	la	$sp,0(%r1,$sp)
-	st${g}	%r0,0($sp)
-
-	lghi	@D[0],-1		# no 'not' instruction :-(
-	lghi	@D[1],-1
-	lghi	@D[2],-1
-	lghi	@D[3],-1
-	lghi	@D[4],-1
-	lghi	@T[0],-1
-	xg	@D[0],$A[0][1]($src)
-	xg	@D[1],$A[0][2]($src)
-	xg	@D[2],$A[1][3]($src)
-	xg	@D[3],$A[2][2]($src)
-	xg	@D[4],$A[3][2]($src)
-	xg	@T[0],$A[4][0]($src)
-	stmg	@D[0],@D[1],$A[0][1]($src)
-	stg	@D[2],$A[1][3]($src)
-	stg	@D[3],$A[2][2]($src)
-	stg	@D[4],$A[3][2]($src)
-	stg	@T[0],$A[4][0]($src)
-
-.Loop_absorb:
-	cl${g}r	$len,$bsz
-	jl	.Ldone_absorb
-
-	srl${g}	$bsz,3
-	la	%r1,0($A_flat)
-
-.Lblock_absorb:
-	lrvg	%r0,0($inp)
-	la	$inp,8($inp)
-	xg	%r0,0(%r1)
-	a${g}hi	$len,-8
-	stg	%r0,0(%r1)
-	la	%r1,8(%r1)
-	brct	$bsz,.Lblock_absorb
-
-	stm${g}	$inp,$len,$frame+3*$SIZE_T($sp)
-	la	$dst,$stdframe($sp)
-	bras	%r14,__KeccakF1600
-	lm${g}	$inp,$bsz,$frame+3*$SIZE_T($sp)
-	j	.Loop_absorb
-
-.align	16
-.Ldone_absorb:
-	lghi	@D[0],-1		# no 'not' instruction :-(
-	lghi	@D[1],-1
-	lghi	@D[2],-1
-	lghi	@D[3],-1
-	lghi	@D[4],-1
-	lghi	@T[0],-1
-	xg	@D[0],$A[0][1]($src)
-	xg	@D[1],$A[0][2]($src)
-	xg	@D[2],$A[1][3]($src)
-	xg	@D[3],$A[2][2]($src)
-	xg	@D[4],$A[3][2]($src)
-	xg	@T[0],$A[4][0]($src)
-	stmg	@D[0],@D[1],$A[0][1]($src)
-	stg	@D[2],$A[1][3]($src)
-	stg	@D[3],$A[2][2]($src)
-	stg	@D[4],$A[3][2]($src)
-	stg	@T[0],$A[4][0]($src)
-
-	lgr	%r2,$len		# return value
-
-	lm${g}	%r6,%r15,$frame+6*$SIZE_T($sp)
-	br	%r14
-.size	SHA3_absorb,.-SHA3_absorb
-___
+
+
+#
+#size_t SHA3_absorb(uint64_t A[5][5], const unsigned char *inp, size_t len,size_t r);
+#
+{
+	FUNCTION_BEGIN("SHA3_absorb", 4, "true");
+	my ($A_flat,$inp,$len,$bsz);		# parm regs
+
+
+if ($flavour =~ /linux/) {
+	($A_flat,$inp,$len,$bsz) = map("%r$_",(2..5));
+
+} else {
+	($A_flat,$inp,$len,$bsz) = map("R$_",(2..5));
+
+	la      ($sp,"STACK");								# Setup stack for z/OS
+
+	&{$z? \&lg:\&l}   ("R9","$DSA_OFF(R4)");			# Get callers DSA address
+	&{$z? \&stg:\&st} ("R4","0*$SIZE_T($sp)");			# save DSA on stack
+
+	&{$z? \&lgr:\&lr} ($len,"R3");						# Move p3 into $len reg which is R4, the DSA reg, it is now corrupted and will have to be restored
+	&{$z? \&lgr:\&lr} ($inp,"R2");						# Move p2 into $out reg
+	&{$z? \&lgr:\&lr} ($A_flat,"R1");					# Move p1 into $A_flat reg
+
+	&{$z? \&lg:\&l}   ($bsz,"$PARMS_OFF+$SIZE_T*3(R9)");	# Get $bsz
 }
-{ my ($A_flat,$out,$len,$bsz) = map("%r$_",(2..5));
-
-$code.=<<___;
-.globl	SHA3_squeeze
-.type	SHA3_squeeze,\@function
-.align	32
-SHA3_squeeze:
-	srl${g}	$bsz,3
-	st${g}	%r14,2*$SIZE_T($sp)
-	lghi	%r14,8
-	st${g}	$bsz,5*$SIZE_T($sp)
-	la	%r1,0($A_flat)
-
-	j	.Loop_squeeze
-
-.align	16
-.Loop_squeeze:
-	cl${g}r $len,%r14
-	jl	.Ltail_squeeze
-
-	lrvg	%r0,0(%r1)
-	la	%r1,8(%r1)
-	stg	%r0,0($out)
-	la	$out,8($out)
-	a${g}hi	$len,-8			# len -= 8
-	jz	.Ldone_squeeze
-
-	brct	$bsz,.Loop_squeeze	# bsz--
-
-	stm${g}	$out,$len,3*$SIZE_T($sp)
-	bras	%r14,.LKeccakF1600
-	lm${g}	$out,$bsz,3*$SIZE_T($sp)
-	lghi	%r14,8
-	la	%r1,0($A_flat)
-	j	.Loop_squeeze
-
-.Ltail_squeeze:
-	lg	%r0,0(%r1)
-.Loop_tail_squeeze:
-	stc	%r0,0($out)
-	la	$out,1($out)
-	srlg	%r0,8
-	brct	$len,.Loop_tail_squeeze
-
-.Ldone_squeeze:
-	l${g}	%r14,2*$SIZE_T($sp)
-	br	%r14
-.size	SHA3_squeeze,.-SHA3_squeeze
-___
+
+
+	lghi	($wr1,-$frame);
+if ($flavour =~ /linux/) {
+	&{$z? \&stmg:\&stm}	("%r5","%r15","$SIZE_T*5($sp)");
+} else {
+	&{$z? \&stg:\&st}	("R5","$SIZE_T*5($sp)");
+}
+	lgr		($wr0,$sp);
+	la		($sp,"0($wr1,$sp)");
+&{$z? \&stg:\&st}	($wr0,"0($sp)");
+	lghi	(@D[0],-1);		# no 'not' instruction :-(
+	lghi	(@D[1],-1);
+	lghi	(@D[2],-1);
+	lghi	(@D[3],-1);
+	lghi	(@D[4],-1);
+	lghi	(@T[0],-1);
+	xg		(@D[0],"$A[0][1]($src)");
+	xg		(@D[1],"$A[0][2]($src)");
+	xg		(@D[2],"$A[1][3]($src)");
+	xg		(@D[3],"$A[2][2]($src)");
+	xg		(@D[4],"$A[3][2]($src)");
+	xg		(@T[0],"$A[4][0]($src)");
+	stmg	(@D[0],"@D[1]","$A[0][1]($src)");
+	stg		(@D[2],"$A[1][3]($src)");
+	stg		(@D[3],"$A[2][2]($src)");
+	stg		(@D[4],"$A[3][2]($src)");
+	stg		(@T[0],"$A[4][0]($src)");
+
+LABEL("Loop_absorb:");
+&{$z? \&clgr:\&clr}	($len,$bsz);
+	jl		(LABEL("Ldone_absorb"));
+	if ($flavour =~ /3[12]/) {
+		srl		($bsz,3);
+	} else {
+		srlg	($bsz,$bsz,3);
+	}
+	la		($wr1,"0($A_flat)");
+
+LABEL("Lblock_absorb:");
+	lrvg	($wr0,"0($inp)");
+	la		($inp,"8($inp)");
+	xg		($wr0,"0($wr1)");
+&{$z? \&aghi:\&ahi}	($len,-8);
+	stg		($wr0,"0($wr1)");
+	la		($wr1,"8($wr1)");
+	brct	($bsz,LABEL("Lblock_absorb"));
+
+&{$z? \&stmg:\&stm}	($inp,$len,"$frame+3*$SIZE_T($sp)");
+	la		($dst,"$stdframe($sp)");
+	bras	($ra,"__KeccakF1600"); # Fix for z/OS
+&{$z? \&lmg:\&lm}	($inp,$bsz,"$frame+3*$SIZE_T($sp)");
+	j	(LABEL("Loop_absorb"));
+
+	ALIGN(16);
+LABEL("Ldone_absorb:");
+	lghi	(@D[0],-1);		# no 'not' instruction :-(
+	lghi	(@D[1],-1);
+	lghi	(@D[2],-1);
+	lghi	(@D[3],-1);
+	lghi	(@D[4],-1);
+	lghi	(@T[0],-1);
+	xg		(@D[0],"$A[0][1]($src)");
+	xg		(@D[1],"$A[0][2]($src)");
+	xg		(@D[2],"$A[1][3]($src)");
+	xg		(@D[3],"$A[2][2]($src)");
+	xg		(@D[4],"$A[3][2]($src)");
+	xg		(@T[0],"$A[4][0]($src)");
+	stmg	(@D[0],@D[1],"$A[0][1]($src)");
+	stg		(@D[2],"$A[1][3]($src)");
+	stg		(@D[3],"$A[2][2]($src)");
+	stg		(@D[4],"$A[3][2]($src)");
+	stg		(@T[0],"$A[4][0]($src)");
+
+	lgr	($rv,$len);		# set return value
+if ($flavour =~ /linux/) {
+	&{$z? \&lmg:\&lm}	("%r6","%r15","$frame+6*$SIZE_T($sp)");
+} else {
+	#&{$z? \&lg:\&l} ("R15","0*$SIZE_T($sp)");			# get pointer to previous sp
+	#&{$z? \&lg:\&l} ("R4","0*$SIZE_T($sp)");			# get DSA off stack
+	&{$z? \&lg:\&l} ("R4","$frame+0*$SIZE_T($sp)");		# get DSA off stack
 }
-$code.=<<___;
-.align	256
-	.quad	0,0,0,0,0,0,0,0
-.type	iotas,\@object
-iotas:
-	.quad	0x0000000000000001
-	.quad	0x0000000000008082
-	.quad	0x800000000000808a
-	.quad	0x8000000080008000
-	.quad	0x000000000000808b
-	.quad	0x0000000080000001
-	.quad	0x8000000080008081
-	.quad	0x8000000000008009
-	.quad	0x000000000000008a
-	.quad	0x0000000000000088
-	.quad	0x0000000080008009
-	.quad	0x000000008000000a
-	.quad	0x000000008000808b
-	.quad	0x800000000000008b
-	.quad	0x8000000000008089
-	.quad	0x8000000000008003
-	.quad	0x8000000000008002
-	.quad	0x8000000000000080
-	.quad	0x000000000000800a
-	.quad	0x800000008000000a
-	.quad	0x8000000080008081
-	.quad	0x8000000000008080
-	.quad	0x0000000080000001
-	.quad	0x8000000080008008
-.size	iotas,.-iotas
-.asciz	"Keccak-1600 absorb and squeeze for s390x, CRYPTOGAMS by <appro\@openssl.org>"
-___
-
-# unlike 32-bit shift 64-bit one takes three arguments
-$code =~ s/(srlg\s+)(%r[0-9]+),/$1$2,$2,/gm;
-
-print $code;
-close STDOUT or die "error closing STDOUT: $!";
+	FUNCTION_END("SHA3_absorb",$rv);
+}
+
+
+#
+# void SHA3_squeeze(uint64_t A[5][5], unsigned char *out, size_t len, size_t r);
+#
+{
+	FUNCTION_BEGIN("SHA3_squeeze",4,"true");
+	my ($A_flat,$out,$len,$bsz);		# parm regs
+
+if ($flavour =~ /linux/) {
+	($A_flat,$out,$len,$bsz) = map("%r$_",(2..5));
+
+} else {
+	($A_flat,$out,$len,$bsz) = map("R$_",(2..5));
+
+	la      ($sp,"STACK");								# Setup stack for z/OS
+
+	&{$z? \&lg:\&l}   ("R9","$DSA_OFF(R4)");			# Get callers DSA address
+	&{$z? \&stg:\&st} ("R4","0*$SIZE_T($sp)");			# save DSA on stack
+
+	&{$z? \&lgr:\&lr} ($len,"R3");						# Move p3 into $len reg which is R4, the DSA reg, it is now corrupted and will have to be restored
+	&{$z? \&lgr:\&lr} ($out,"R2");						# Move p2 into $out reg
+	&{$z? \&lgr:\&lr} ($A_flat,"R1");					# Move p1 into $A_flat reg
+
+	&{$z? \&lg:\&l}   ($bsz,"$PARMS_OFF+$SIZE_T*3(R9)");	# Get $bsz
+}
+
+if ($flavour =~ /3[12]/) {
+	srl		($bsz,3);
+} else {
+	srlg	($bsz,$bsz,3);
+}
+&{$z? \&stg:\&st}	($wr14,"2*$SIZE_T($sp)") if ($flavour =~ /linux/);
+	lghi	($wr14,8);
+&{$z? \&stg:\&st}	($bsz,"5*$SIZE_T($sp)");
+
+	la		($wr1,"0($A_flat)");
+	j		(LABEL("Loop_squeeze"));
+
+	ALIGN(16);
+LABEL("Loop_squeeze:");
+&{$z? \&clgr:\&clr} ($len,$wr14);
+	jl		(LABEL("Ltail_squeeze"));
+
+	lrvg	($wr0,"0($wr1)");
+	la		($wr1,"8($wr1)");
+	stg		($wr0,"0($out)");
+	la		($out,"8($out)");
+&{$z? \&aghi:\&ahi}	($len,-8);			# len -= 8
+	jz		(LABEL("Ldone_squeeze"));
+
+	brct	($bsz,LABEL("Loop_squeeze"));	# bsz--
+&{$z? \&stmg:\&stm}	($out,$len,"3*$SIZE_T($sp)");
+	bras	($ra,"KeccakF1600");
+&{$z? \&lmg:\&lm}	($out,$bsz,"3*$SIZE_T($sp)");
+	lghi	($wr14,8);
+	la		($wr1,"0($A_flat)");
+	j		(LABEL("Loop_squeeze"));
+
+LABEL("Ltail_squeeze:");
+	lg		($wr0,"0($wr1)");
+LABEL("Loop_tail_squeeze:");
+	stc		($wr0,"0($out)");
+	la		($out,"1($out)");
+	srlg	($wr0,$wr0,8);
+	brct	($len,LABEL("Loop_tail_squeeze"));
+
+LABEL("Ldone_squeeze:");
+if ($flavour =~ /linux/) {
+	&{$z? \&lg:\&l}	($wr14,"2*$SIZE_T($sp)");
+} else {
+	&{$z? \&lg:\&l} ("R4","0*$SIZE_T($sp)");			# get DSA off stack
+}
+	FUNCTION_END("SHA3_squeeze",$rv);
+}
+
+ALIGN(256);
+
+	QUAD(	"0","0","0","0","0","0","0","0");
+	OBJECT_BEGIN("iotas",8);
+	QUAD(	"0000000000000001");
+	QUAD(	"0000000000008082");
+	QUAD(	"800000000000808a");
+	QUAD(	"8000000080008000");
+	QUAD(	"000000000000808b");
+	QUAD(	"0000000080000001");
+	QUAD(	"8000000080008081");
+	QUAD(	"8000000000008009");
+	QUAD(	"000000000000008a");
+	QUAD(	"0000000000000088");
+	QUAD(	"0000000080008009");
+	QUAD(	"000000008000000a");
+	QUAD(	"000000008000808b");
+	QUAD(	"800000000000008b");
+	QUAD(	"8000000000008089");
+	QUAD(	"8000000000008003");
+	QUAD(	"8000000000008002");
+	QUAD(	"8000000000000080");
+	QUAD(	"000000000000800a");
+	QUAD(	"800000008000000a");
+	QUAD(	"8000000080008081");
+	QUAD(	"8000000000008080");
+	QUAD(	"0000000080000001");
+	QUAD(	"8000000080008008");
+	OBJECT_END("iotas");
+	ASCIZ	("Keccak-1600 absorb and squeeze for s390x, CRYPTOGAMS by <appro\@openssl.org>");
+
+
+
+# unlike 32-bit shift 64-bit one takes three arguments - will need to revisit this
+# Fixed inline in the code. It's in if($flavour blocks now and done explicitly
+#$code =~ s/(srlg\s+)(%r[0-9]+),/$1$2,$2,/gm;
+
+LOCAL_VARS_BEGIN();
+	ds		("STACKSPACE","180F");
+    ds		("STACK", "0F");
+    ds      ("SAVEAREA","32F");
+LOCAL_VARS_END();
+
+PERLASM_END();
+
diff --git a/crypto/sha/asm/sha1-s390x.pl b/crypto/sha/asm/sha1-s390x.pl
index 653a6cb..ec79daa 100644
--- a/crypto/sha/asm/sha1-s390x.pl
+++ b/crypto/sha/asm/sha1-s390x.pl
@@ -1,5 +1,5 @@
 #! /usr/bin/env perl
-# Copyright 2007-2020 The OpenSSL Project Authors. All Rights Reserved.
+# Copyright 2007-2016 The OpenSSL Project Authors. All Rights Reserved.
 #
 # Licensed under the OpenSSL license (the "License").  You may not use
 # this file except in compliance with the License.  You can obtain a copy
@@ -38,67 +38,145 @@
 # remains z/Architecture specific. On z990 it was measured to perform
 # 23% better than code generated by gcc 4.3.

-$kimdfunc=1;	# magic function code for kimd instruction
+#
+# Converted to use s390x.pm & added zOS support
+#     Peter Waltenberg   <pwalten@au1.ibm.com>
+#     Jonathan Furminger <furming@us.ibm.com>
+#
+#
+
+
+use strict;
+use FindBin qw($Bin);
+use lib "$Bin/../..";
+use perlasm::s390x qw(:MSA :DEFAULT :VX :LD AUTOLOAD LABEL INCLUDE FUNCTION_BEGIN FUNCTION_END OBJECT_BEGIN OBJECT_END BYTE LONG ALIGN ASCIZ TEXT GET_EXTERN LOCAL_VARS_BEGIN LOCAL_VARS_END ds);
+
+

-$flavour = shift;
+my $kimdfunc=1;	# magic function code for kimd instruction
+
+my $flavour = shift;
+my $output;
+my ($z,$SIZE_T);

 if ($flavour =~ /3[12]/) {
+	$z=0;    # S/390 ABI
 	$SIZE_T=4;
-	$g="";
 } else {
+	$z=1;    # zSeries/zOS  ABI
 	$SIZE_T=8;
-	$g="g";
 }

 while (($output=shift) && ($output!~/\w[\w\-]*\.\w+$/)) {}
 open STDOUT,">$output";

-$K_00_39="%r0"; $K=$K_00_39;
-$K_40_79="%r1";
-$ctx="%r2";	$prefetch="%r2";
-$inp="%r3";
-$len="%r4";
-
-$A="%r5";
-$B="%r6";
-$C="%r7";
-$D="%r8";
-$E="%r9";	@V=($A,$B,$C,$D,$E);
-$t0="%r10";
-$t1="%r11";
-@X=("%r12","%r13","%r14");
-$sp="%r15";
-
-$stdframe=16*$SIZE_T+4*8;
-$frame=$stdframe+16*4;
+
+my ($K,$K_00_39,$K_40_79,$ctx,$prefetch,$inp,$len,$rv);
+my ($A,$B,$C,$D,$E,@V,$t0,$t1,@X,$i,$xcap);
+my ($sp,$stdframe,$frame,$ip);
+my ($k_func, $k_pb, $k_op1, @k_op2);
+my ($wr0,$wr8);
+
+if ($flavour =~ /linux/) {
+	$K_00_39="%r0";
+	$K=$K_00_39;
+	$K_40_79="%r1";
+	$ctx="%r2";
+	$prefetch="%r2";
+	$inp="%r3";
+	$len="%r4";
+
+	$xcap="%r1";
+	$k_func="%r0";
+	$k_pb="%r1";
+	$k_op1="%r0";
+	@k_op2=("%r2","%r3");
+
+	$wr0="%r0";
+	$wr8="%r8";
+
+	$A="%r5";
+	$B="%r6";
+	$C="%r7";
+	$D="%r8";
+	$E="%r9";
+	@V=($A,$B,$C,$D,$E);
+	$t0="%r10";
+	$t1="%r11";
+	@X=("%r12","%r13","%r14");
+	$sp="%r15";
+
+	$stdframe=16*$SIZE_T+4*8;
+	$frame=$stdframe+16*4;
+	$ip=".";
+	$rv = "%r2";
+} else {
+	$K_00_39="R0"; $K=$K_00_39;
+	$K_40_79="R1";
+	$ctx="R1";	$prefetch="R1";
+	$inp="R2";
+	$len="R3";
+
+	$k_func="R0";
+	$k_pb="R1";
+	$k_op1="%r0";
+	@k_op2=("R2","R3");
+	$xcap="R13";
+
+	$wr0="R0";
+	$wr8="R8";
+
+	$A="R5";
+	$B="R6";
+	$C="R7";
+	$D="R8";
+	$E="R9";
+	@V=($A,$B,$C,$D,$E);
+	$t0="R10";
+	$t1="R11";
+	@X=("R12","R13","R14");
+	$sp="R15";
+
+	$stdframe=16*$SIZE_T+4*8;
+	$frame=$stdframe+16*4;
+	$ip="*";
+	$rv = "r3";
+}
+PERLASM_BEGIN($flavour,$output);
+
+INCLUDE ("s390x_arch.h", "crypto/");

 sub Xupdate {
 my $i=shift;
-
-$code.=<<___ if ($i==15);
-	lg	$prefetch,$stdframe($sp)	### Xupdate(16) warm-up
-	lr	$X[0],$X[2]
-___
+### Xupdate(16) warm-up
+	if ($i==15) {
+		lg	("$prefetch","$stdframe($sp)");
+		lr	("$X[0]","$X[2]");
+	}
 return if ($i&1);	# Xupdate is vectorized and executed every 2nd cycle
-$code.=<<___ if ($i<16);
-	lg	$X[0],`$i*4`($inp)	### Xload($i)
-	rllg	$X[1],$X[0],32
-___
-$code.=<<___ if ($i>=16);
-	xgr	$X[0],$prefetch		### Xupdate($i)
-	lg	$prefetch,`$stdframe+4*(($i+2)%16)`($sp)
-	xg	$X[0],`$stdframe+4*(($i+8)%16)`($sp)
-	xgr	$X[0],$prefetch
-	rll	$X[0],$X[0],1
-	rllg	$X[1],$X[0],32
-	rll	$X[1],$X[1],1
-	rllg	$X[0],$X[1],32
-	lr	$X[2],$X[1]		# feedback
-___
-$code.=<<___ if ($i<=70);
-	stg	$X[0],`$stdframe+4*($i%16)`($sp)
-___
-unshift(@X,pop(@X));
+	if ($i<16) {
+		lg	("$X[0]","($i*4)($inp)");	### Xload($i)
+		rllg	("$X[1]","$X[0]",32);
+	}
+	my $offset;
+	if ($i>=16) {
+		xgr	("$X[0]","$prefetch");		### Xupdate($i)
+		$offset = ($i+2)%16;
+		lg		("$prefetch","($stdframe+4*$offset)($sp)");
+		$offset = ($i+8)%16;
+		xg		("$X[0]","($stdframe+4*$offset)($sp)");
+		xgr	("$X[0]","$prefetch");
+		rll	("$X[0]","$X[0]",1);
+		rllg	("$X[1]","$X[0]",32);
+		rll	("$X[1]","$X[1]",1);
+		rllg	("$X[0]","$X[1]",32);
+		lr		("$X[2]","$X[1]");		# feedback
+	}
+	if ($i<=70) {
+		$offset = $i%16;
+		stg	("$X[0]","($stdframe+4*$offset)($sp)");
+	}
+	unshift(@X,pop(@X));
 }

 sub BODY_00_19 {
@@ -106,18 +184,18 @@ my ($i,$a,$b,$c,$d,$e)=@_;
 my $xi=$X[1];

 	&Xupdate($i);
-$code.=<<___;
-	alr	$e,$K		### $i
-	rll	$t1,$a,5
-	lr	$t0,$d
-	xr	$t0,$c
-	alr	$e,$t1
-	nr	$t0,$b
-	alr	$e,$xi
-	xr	$t0,$d
-	rll	$b,$b,30
-	alr	$e,$t0
-___
+
+	alr	("$e","$K");		### $i
+	rll	("$t1","$a",5);
+	lr		("$t0","$d");
+	xr		("$t0","$c");
+	alr	("$e","$t1");
+	nr		("$t0","$b");
+	alr	("$e","$xi");
+	xr		("$t0","$d");
+	rll	("$b","$b",30);
+	alr	("$e","$t0");
+
 }

 sub BODY_20_39 {
@@ -125,17 +203,17 @@ my ($i,$a,$b,$c,$d,$e)=@_;
 my $xi=$X[1];

 	&Xupdate($i);
-$code.=<<___;
-	alr	$e,$K		### $i
-	rll	$t1,$a,5
-	lr	$t0,$b
-	alr	$e,$t1
-	xr	$t0,$c
-	alr	$e,$xi
-	xr	$t0,$d
-	rll	$b,$b,30
-	alr	$e,$t0
-___
+
+	alr	("$e","$K");		### $i
+	rll	("$t1","$a",5);
+	lr		("$t0","$b");
+	alr	("$e","$t1");
+	xr		("$t0","$c");
+	alr	("$e","$xi");
+	xr		("$t0","$d");
+	rll	("$b","$b",30);
+	alr	("$e","$t0");
+
 }

 sub BODY_40_59 {
@@ -143,107 +221,114 @@ my ($i,$a,$b,$c,$d,$e)=@_;
 my $xi=$X[1];

 	&Xupdate($i);
-$code.=<<___;
-	alr	$e,$K		### $i
-	rll	$t1,$a,5
-	lr	$t0,$b
-	alr	$e,$t1
-	or	$t0,$c
-	lr	$t1,$b
-	nr	$t0,$d
-	nr	$t1,$c
-	alr	$e,$xi
-	or	$t0,$t1
-	rll	$b,$b,30
-	alr	$e,$t0
-___
+
+	alr	("$e","$K");		### $i
+	rll	("$t1","$a",5);
+	lr		("$t0","$b");
+	alr	("$e","$t1");
+	&or	("$t0","$c");
+	lr		("$t1","$b");
+	nr		("$t0","$d");
+	nr		("$t1","$c");
+	alr	("$e","$xi");
+	&or	("$t0","$t1");
+	rll	("$b","$b",30);
+	alr	("$e","$t0");
+
+}
+
+
+
+TEXT();
+OBJECT_BEGIN("Ktable",64);
+	LONG( 0x5a827999,0x6ed9eba1,0x8f1bbcdc,0xca62c1d6);
+	LONG( 0,0,0,0);
+	LONG( 0,0,0,0);
+	LONG( 0,0,0,0);
+OBJECT_END("Ktable");
+# void sha1_block_data_order(SHA_CTX *c, const void *p, size_t num);
+FUNCTION_BEGIN("sha1_block_data_order",3,"true","stor4");
+
+if ($kimdfunc) {
+	GET_EXTERN($xcap,"OPENSSL_s390xcap_P");
+	lg		($wr0,"CS390X_KIMD($xcap)");	# check kimd capabilities
+	my $funcFlag = 0x8000>>$kimdfunc;
+	tmhh	($wr0,$funcFlag);
+	jz		(LABEL("Lsoftware"));
+	lghi	($k_func,$kimdfunc);
+  if ($flavour =~ /linux/) {	# z/OS passes ctx in r1, inp in r2, len in r3
+	lgr		($k_pb,$ctx);
+	lgr		(@k_op2[0],$inp);
+  }
+	sllg	(@k_op2[1],$len,6);
+	kimd	($k_op1,@k_op2[0]); # .long	0xb93e0002
+	brc		(1,"$ip-4");		# pay attention to "partial completion"
+	j	(LABEL("EXIT_sha1_block_data_order"));
 }

-$code.=<<___;
-#include "s390x_arch.h"
-
-.text
-.align	64
-.type	Ktable,\@object
-Ktable: .long	0x5a827999,0x6ed9eba1,0x8f1bbcdc,0xca62c1d6
-	.skip	48	#.long	0,0,0,0,0,0,0,0,0,0,0,0
-.size	Ktable,.-Ktable
-.globl	sha1_block_data_order
-.type	sha1_block_data_order,\@function
-sha1_block_data_order:
-___
-$code.=<<___ if ($kimdfunc);
-	larl	%r1,OPENSSL_s390xcap_P
-	lg	%r0,S390X_KIMD(%r1)	# check kimd capabilities
-	tmhh	%r0,`0x8000>>$kimdfunc`
-	jz	.Lsoftware
-	lghi	%r0,$kimdfunc
-	lgr	%r1,$ctx
-	lgr	%r2,$inp
-	sllg	%r3,$len,6
-	.long	0xb93e0002	# kimd %r0,%r2
-	brc	1,.-4		# pay attention to "partial completion"
-	br	%r14
-.align	16
-.Lsoftware:
-___
-$code.=<<___;
-	lghi	%r1,-$frame
-	st${g}	$ctx,`2*$SIZE_T`($sp)
-	stm${g}	%r6,%r15,`6*$SIZE_T`($sp)
-	lgr	%r0,$sp
-	la	$sp,0(%r1,$sp)
-	st${g}	%r0,0($sp)
-
-	larl	$t0,Ktable
-	llgf	$A,0($ctx)
-	llgf	$B,4($ctx)
-	llgf	$C,8($ctx)
-	llgf	$D,12($ctx)
-	llgf	$E,16($ctx)
-
-	lg	$K_00_39,0($t0)
-	lg	$K_40_79,8($t0)
-
-.Lloop:
-	rllg	$K_00_39,$K_00_39,32
-___
+LABEL("Lsoftware:");
+	lghi	($wr8,"-$frame");
+	la      ($sp,"STACK") if ($flavour !~ /linux/);	# set up stack for zos
+
+	&{$z? \&stg:\&st}	($ctx,"2*$SIZE_T($sp)");
+	&{$z? \&stmg:\&stm}	("%r6","%r15","6*$SIZE_T($sp)") if ($flavour =~ /linux/);
+	lgr		($wr0,$sp);
+	la		($sp,"0($wr8,$sp)");
+	&{$z? \&stg:\&st}	($wr0,"0($sp)");
+
+	larl	($t0,LABEL("Ktable"));
+	llgf	($A,"0($ctx)");
+	llgf	($B,"4($ctx)");
+	llgf	($C,"8($ctx)");
+	llgf	($D,"12($ctx)");
+	llgf	($E,"16($ctx)");
+
+	lg		($K_00_39,"0($t0)");
+	lg		($K_40_79,"8($t0)");
+
+LABEL("Lloop:");
+	rllg	($K_00_39,$K_00_39,32);
+
 for ($i=0;$i<20;$i++)	{ &BODY_00_19($i,@V); unshift(@V,pop(@V)); }
-$code.=<<___;
-	rllg	$K_00_39,$K_00_39,32
-___
+
+	rllg	($K_00_39,$K_00_39,32);
+
 for (;$i<40;$i++)	{ &BODY_20_39($i,@V); unshift(@V,pop(@V)); }
-$code.=<<___;	$K=$K_40_79;
-	rllg	$K_40_79,$K_40_79,32
-___
+
+	$K=$K_40_79;
+	rllg	($K_40_79,$K_40_79,32);
+
 for (;$i<60;$i++)	{ &BODY_40_59($i,@V); unshift(@V,pop(@V)); }
-$code.=<<___;
-	rllg	$K_40_79,$K_40_79,32
-___
+
+	rllg	($K_40_79,$K_40_79,32);
+
 for (;$i<80;$i++)	{ &BODY_20_39($i,@V); unshift(@V,pop(@V)); }
-$code.=<<___;
-
-	l${g}	$ctx,`$frame+2*$SIZE_T`($sp)
-	la	$inp,64($inp)
-	al	$A,0($ctx)
-	al	$B,4($ctx)
-	al	$C,8($ctx)
-	al	$D,12($ctx)
-	al	$E,16($ctx)
-	st	$A,0($ctx)
-	st	$B,4($ctx)
-	st	$C,8($ctx)
-	st	$D,12($ctx)
-	st	$E,16($ctx)
-	brct${g} $len,.Lloop
-
-	lm${g}	%r6,%r15,`$frame+6*$SIZE_T`($sp)
-	br	%r14
-.size	sha1_block_data_order,.-sha1_block_data_order
-.string	"SHA1 block transform for s390x, CRYPTOGAMS by <appro\@openssl.org>"
-___
-
-$code =~ s/\`([^\`]*)\`/eval $1/gem;
-
-print $code;
-close STDOUT or die "error closing STDOUT: $!";
+
+	&{$z? \&lg:\&l}	($ctx,"($frame+2*$SIZE_T)($sp)");
+	la		($inp,"64($inp)");
+	al		($A,"0($ctx)");
+	al		($B,"4($ctx)");
+	al		($C,"8($ctx)");
+	al		($D,"12($ctx)");
+	al		($E,"16($ctx)");
+	st		($A,"0($ctx)");
+	st		($B,"4($ctx)");
+	st		($C,"8($ctx)");
+	st		($D,"12($ctx)");
+	st		($E,"16($ctx)");
+	&{$z? \&brctg:\&brct}	($len,LABEL("Lloop"));
+	&{$z? \&lmg:\&lm}	("%r6","%r15","($frame+6*$SIZE_T)($sp)") if ($flavour =~ /linux/);
+
+FUNCTION_END("sha1_block_data_order",$rv);
+	ASCIZ	("SHA1 block transform for s390x, CRYPTOGAMS by <appro\@openssl.org>");
+
+
+# $code =~ s/\`([^\`]*)\`/eval $1/gem;
+
+LOCAL_VARS_BEGIN();
+	ds		("STACKSPACE","200F");
+    ds		("STACK", "0F");
+    ds      ("SAVEAREA","32F");
+LOCAL_VARS_END();
+
+	PERLASM_END();
diff --git a/crypto/sha/asm/sha512-s390x.pl b/crypto/sha/asm/sha512-s390x.pl
index 9752fed..a074cf7 100644
--- a/crypto/sha/asm/sha512-s390x.pl
+++ b/crypto/sha/asm/sha512-s390x.pl
@@ -1,5 +1,5 @@
 #! /usr/bin/env perl
-# Copyright 2007-2020 The OpenSSL Project Authors. All Rights Reserved.
+# Copyright 2007-2016 The OpenSSL Project Authors. All Rights Reserved.
 #
 # Licensed under the OpenSSL license (the "License").  You may not use
 # this file except in compliance with the License.  You can obtain a copy
@@ -43,45 +43,112 @@
 # remains z/Architecture specific. On z990 SHA256 was measured to
 # perform 2.4x and SHA512 - 13x better than code generated by gcc 4.3.

-$flavour = shift;
+# July 2019.
+# Converted to use s390x.pm & added zOS support
+#     Peter Waltenberg   <pwalten@au1.ibm.com>
+#     Jonathan Furminger <furming@us.ibm.com>
+#
+#
+
+
+use strict;
+use FindBin qw($Bin);
+use lib "$Bin/../..";
+use perlasm::s390x qw(:MSA :DEFAULT :VX :LD AUTOLOAD LABEL INCLUDE FUNCTION_BEGIN FUNCTION_END OBJECT_BEGIN OBJECT_END BYTE LONG QUAD ALIGN ASCIZ TEXT GET_EXTERN LOCAL_VARS_BEGIN LOCAL_VARS_END ds);
+
+
+
+my $flavour = shift;
+my $output;

-if ($flavour =~ /3[12]/) {
+my ($z,$DSA_OFF,$PARMS_OFF,$SIZE_T,$g,$t0,$t1,$ctx,$t2,$inp,$len,$i,$rv);
+my ($A,$B,$C,$D,$E,$F,$G,$H,@V,$tbl,$T1,$xcap);
+my ($label,$SZ);
+my (@Sigma0,@Sigma1,@sigma0,@sigma1,$rounds,$kimdfunc);
+my ($sp,$frame,$stdframe,$ip);
+my ($Func,$Table);
+my ($wr0,$wr2,$wr8);
+
+$DSA_OFF=2048;
+if ($flavour =~ /3[12]/) { # 31/32 bit ABI's
 	$SIZE_T=4;
-	$g="";
-} else {
+	$z = 0;
+	$PARMS_OFF=2112;
+} else {                 # 64 bit ABI
 	$SIZE_T=8;
-	$g="g";
+	$z = 1;
+	$PARMS_OFF=2176;
 }
+if($flavour =~ /linux/) {
+	$t0="%r0";
+	$t1="%r1";
+	$ctx="%r2";
+	$t2="%r2";
+	$inp="%r3";
+	$len="%r4";	# used as index in inner loop

-$t0="%r0";
-$t1="%r1";
-$ctx="%r2";	$t2="%r2";
-$inp="%r3";
-$len="%r4";	# used as index in inner loop
-
-$A="%r5";
-$B="%r6";
-$C="%r7";
-$D="%r8";
-$E="%r9";
-$F="%r10";
-$G="%r11";
-$H="%r12";	@V=($A,$B,$C,$D,$E,$F,$G,$H);
-$tbl="%r13";
-$T1="%r14";
-$sp="%r15";
+	$xcap="%r1";
+	$wr0="%r0";
+	$wr2="%r2";
+	$wr8="%r8";
+
+	$A="%r5";
+	$B="%r6";
+	$C="%r7";
+	$D="%r8";
+	$E="%r9";
+	$F="%r10";
+	$G="%r11";
+	$H="%r12";
+	@V=($A,$B,$C,$D,$E,$F,$G,$H);
+	$tbl="%r13";
+	$T1="%r14";
+	$sp="%r15";
+
+	$ip=".";
+	$rv = "%r2";
+} else {
+	$t0="R0";
+	$t1="R1";
+	$ctx="R2";
+	$t2="R2";
+	$inp="R3";
+	$len="R4";	# used as index in inner loop
+#	$ctx="R1";
+#	$inp="R2";
+#	$len="R3";	# used as index in inner loop
+
+	$xcap="R13";
+	$wr0="R0";
+	$wr2="R2";
+	$wr8="R8";
+
+	$A="R5";
+	$B="R6";
+	$C="R7";
+	$D="R8";
+	$E="R9";
+	$F="R10";
+	$G="R11";
+	$H="R12";
+	@V=($A,$B,$C,$D,$E,$F,$G,$H);
+	$tbl="R13";
+	$T1="R14";
+	$sp="R15";
+
+	$ip="*";
+	$rv = "r3";
+}

 while (($output=shift) && ($output!~/\w[\w\-]*\.\w+$/)) {}
 open STDOUT,">$output";

+PERLASM_BEGIN($flavour,$output);
+
+
 if ($output =~ /512/) {
 	$label="512";
-	$SZ=8;
-	$LD="lg";	# load from memory
-	$ST="stg";	# store to memory
-	$ADD="alg";	# add with memory operand
-	$ROT="rllg";	# rotate left
-	$SHR="srlg";	# logical right shift [see even at the end]
+	$SZ=8;   # Target hash size, NOT the same as SIZE_T which is machine arch
 	@Sigma0=(25,30,36);
 	@Sigma1=(23,46,50);
 	@sigma0=(56,63, 7);
@@ -91,234 +158,362 @@ if ($output =~ /512/) {
 } else {
 	$label="256";
 	$SZ=4;
-	$LD="llgf";	# load from memory
-	$ST="st";	# store to memory
-	$ADD="al";	# add with memory operand
-	$ROT="rll";	# rotate left
-	$SHR="srl";	# logical right shift
 	@Sigma0=(10,19,30);
 	@Sigma1=( 7,21,26);
 	@sigma0=(14,25, 3);
 	@sigma1=(13,15,10);
 	$rounds=64;
 	$kimdfunc=2;	# magic function code for kimd instruction
-}
-$Func="sha${label}_block_data_order";
-$Table="K${label}";
-$stdframe=16*$SIZE_T+4*8;
-$frame=$stdframe+16*$SZ;
+}

-sub BODY_00_15 {
-my ($i,$a,$b,$c,$d,$e,$f,$g,$h) = @_;
+my $Func="sha${label}_block_data_order";
+my $Table="K${label}";
+
+$stdframe=(16*$SIZE_T)+(4*8);
+$frame=$stdframe+(16*$SZ);

-$code.=<<___ if ($i<16);
-	$LD	$T1,`$i*$SZ`($inp)	### $i
-___
-$code.=<<___;
-	$ROT	$t0,$e,$Sigma1[0]
-	$ROT	$t1,$e,$Sigma1[1]
-	 lgr	$t2,$f
-	xgr	$t0,$t1
-	$ROT	$t1,$t1,`$Sigma1[2]-$Sigma1[1]`
-	 xgr	$t2,$g
-	$ST	$T1,`$stdframe+$SZ*($i%16)`($sp)
-	xgr	$t0,$t1			# Sigma1(e)
-	algr	$T1,$h			# T1+=h
-	 ngr	$t2,$e
-	 lgr	$t1,$a
-	algr	$T1,$t0			# T1+=Sigma1(e)
-	$ROT	$h,$a,$Sigma0[0]
-	 xgr	$t2,$g			# Ch(e,f,g)
-	$ADD	$T1,`$i*$SZ`($len,$tbl)	# T1+=K[i]
-	$ROT	$t0,$a,$Sigma0[1]
-	algr	$T1,$t2			# T1+=Ch(e,f,g)
-	 ogr	$t1,$b
-	xgr	$h,$t0
-	 lgr	$t2,$a
-	 ngr	$t1,$c
-	$ROT	$t0,$t0,`$Sigma0[2]-$Sigma0[1]`
-	xgr	$h,$t0			# h=Sigma0(a)
-	 ngr	$t2,$b
-	algr	$h,$T1			# h+=T1
-	 ogr	$t2,$t1			# Maj(a,b,c)
-	algr	$d,$T1			# d+=T1
-	algr	$h,$t2			# h+=Maj(a,b,c)
-___
+
+
+INCLUDE ("s390x_arch.h", "crypto/");
+#
+# This isn't as elegant as the original admitted
+# but perlasm does come with benefits
+#
+sub BODY_00_15 {
+	my ($i,$a,$b,$c,$d,$e,$f,$g,$h) = @_;
+	if ($SZ == 8) {
+		if ($i<16) {
+			lg	($T1,"($i*$SZ)($inp)");	### $i
+		}
+		rllg	($t0,$e,"$Sigma1[0]");
+		rllg	($t1,$e,"$Sigma1[1]");
+		lgr		($t2,$f);
+		xgr		($t0,$t1);
+		rllg	($t1,$t1,"$Sigma1[2]-$Sigma1[1]");
+		xgr		($t2,$g);
+		my $offset=$stdframe+$SZ*($i%16);
+		stg		($T1,"$offset($sp)");
+		xgr		($t0,$t1);			# Sigma1(e)
+		algr	($T1,$h);			# T1+=h
+		ngr		($t2,$e);
+		lgr		($t1,$a);
+		algr	($T1,$t0);			# T1+=Sigma1(e)
+		rllg	($h,$a,$Sigma0[0]);
+		xgr		($t2,$g);			# Ch(e,f,g)
+		alg		($T1,"$i*$SZ($len,$tbl)");	# T1+=K[i]
+		rllg	($t0,$a,$Sigma0[1]);
+		algr	($T1,$t2);			# T1+=Ch(e,f,g)
+		ogr		($t1,$b);
+		xgr		($h,$t0);
+		lgr		($t2,$a);
+		ngr		($t1,$c);
+		rllg	($t0,$t0,"$Sigma0[2]-$Sigma0[1]");
+		xgr		($h,$t0);			# h=Sigma0(a)
+		ngr		($t2,$b);
+		algr	($h,$T1);			# h+=T1
+		ogr		($t2,$t1);			# Maj(a,b,c)
+		algr	($d,$T1);			# d+=T1
+		algr	($h,$t2);			# h+=Maj(a,b,c)
+	} else {
+		if ($i<16) {
+			llgf	("$T1","($i*$SZ)($inp)");	### $i
+		}
+		rll		($t0,$e,$Sigma1[0]);
+		rll		($t1,$e,$Sigma1[1]);
+		lgr		($t2,$f);
+		xgr		($t0,$t1);
+		rll		($t1,$t1,"$Sigma1[2]-$Sigma1[1]");
+		xgr		($t2,$g);
+		my $offset=$stdframe+$SZ*($i%16);
+		st		($T1,"$offset($sp)");
+		xgr		($t0,$t1);			# Sigma1(e)
+		algr	($T1,$h);			# T1+=h
+		ngr		($t2,$e);
+		lgr		($t1,$a);
+		algr	($T1,$t0);			# T1+=Sigma1(e)
+		rll		($h,$a,$Sigma0[0]);
+		xgr		($t2,$g);			# Ch(e,f,g)
+		al		($T1,"$i*$SZ($len,$tbl)");	# T1+=K[i]
+		rll		($t0,$a,"$Sigma0[1]");
+		algr	($T1,$t2);			# T1+=Ch(e,f,g)
+		ogr		($t1,$b);
+		xgr		($h,$t0);
+		lgr		($t2,$a);
+		ngr		($t1,$c);
+		rll		($t0,$t0,"$Sigma0[2]-$Sigma0[1]");
+		xgr		($h,$t0);			# h=Sigma0(a)
+		ngr		($t2,$b);
+		algr	($h,$T1);			# h+=T1
+		ogr		($t2,$t1);			# Maj(a,b,c)
+		algr	($d,$T1);			# d+=T1
+		algr	($h,$t2);			# h+=Maj(a,b,c)
+	}
 }

 sub BODY_16_XX {
 my ($i,$a,$b,$c,$d,$e,$f,$g,$h) = @_;
-
-$code.=<<___;
-	$LD	$T1,`$stdframe+$SZ*(($i+1)%16)`($sp)	### $i
-	$LD	$t1,`$stdframe+$SZ*(($i+14)%16)`($sp)
-	$ROT	$t0,$T1,$sigma0[0]
-	$SHR	$T1,$sigma0[2]
-	$ROT	$t2,$t0,`$sigma0[1]-$sigma0[0]`
-	xgr	$T1,$t0
-	$ROT	$t0,$t1,$sigma1[0]
-	xgr	$T1,$t2					# sigma0(X[i+1])
-	$SHR	$t1,$sigma1[2]
-	$ADD	$T1,`$stdframe+$SZ*($i%16)`($sp)	# +=X[i]
-	xgr	$t1,$t0
-	$ROT	$t0,$t0,`$sigma1[1]-$sigma1[0]`
-	$ADD	$T1,`$stdframe+$SZ*(($i+9)%16)`($sp)	# +=X[i+9]
-	xgr	$t1,$t0				# sigma1(X[i+14])
-	algr	$T1,$t1				# +=sigma1(X[i+14])
-___
+my $offset;
+	if($SZ == 8) {
+		$offset=$stdframe+$SZ*(($i+1)%16);
+		lg			($T1,"$offset($sp)");	### $i
+		$offset=$stdframe+$SZ*(($i+14)%16);
+		lg			($t1,"$offset($sp)");
+		rllg		($t0,$T1,$sigma0[0]);
+		srlg		($T1,$T1,$sigma0[2]);
+		rllg		($t2,$t0,"$sigma0[1]-$sigma0[0]");
+		if($flavour =~ /linux/) {
+		  xgr	("%r14","%r0"); # Perlasm failure ?
+		} else {
+		xgr		($T1,$t0);
+		}
+		rllg		($t0,$t1,$sigma1[0]);
+		xgr		($T1,$t2);					# sigma0(X[i+1])
+		srlg		($t1,$t1,$sigma1[2]);
+		$offset=$stdframe+$SZ*($i%16);
+		alg		($T1,"$offset($sp)");	# +=X[i]
+		xgr		($t1,$t0);
+		rllg		($t0,$t0,"$sigma1[1]-$sigma1[0]");
+		$offset=$stdframe+$SZ*(($i+9)%16);
+		alg		($T1,"$offset($sp)");	# +=X[i+9]
+		xgr		($t1,$t0);				# sigma1(X[i+14])
+		algr		($T1,$t1);				# +=sigma1(X[i+14])
+	} else {
+		$offset=$stdframe+$SZ*(($i+1)%16);
+		llgf		($T1,"$offset($sp)");	### $i
+		$offset=$stdframe+$SZ*(($i+14)%16);
+		llgf		($t1,"$offset($sp)");
+		rll		($t0,$T1,$sigma0[0]);
+		srl		($t1,$sigma0[2]);
+		rll		($t2,$t0,"$sigma0[1]-$sigma0[0]");
+		xgr		($t1,$t0);
+		rll		($t0,$t1,$sigma1[0]);
+		xgr		($t1,$t2);					# sigma0(X[i+1])
+		srl		($t1,$sigma1[2]);
+		$offset=$stdframe+$SZ*($i%16);
+		al			($T1,"$offset($sp)");	# +=X[i]
+		xgr		($t1,$t0);
+		rll		($t0,$t0,"$sigma1[1]-$sigma1[0]");
+		$offset=$stdframe+$SZ*(($i+9)%16);
+		al			($T1,"$offset($sp)");	# +=X[i+9]
+		xgr		($t1,$t0);				# sigma1(X[i+14])
+		algr		($T1,$t1);				# +=sigma1(X[i+14])
+	}
 	&BODY_00_15(@_);
 }

-$code.=<<___;
-#include "s390x_arch.h"
-
-.text
-.align	64
-.type	$Table,\@object
-$Table:
-___
-$code.=<<___ if ($SZ==4);
-	.long	0x428a2f98,0x71374491,0xb5c0fbcf,0xe9b5dba5
-	.long	0x3956c25b,0x59f111f1,0x923f82a4,0xab1c5ed5
-	.long	0xd807aa98,0x12835b01,0x243185be,0x550c7dc3
-	.long	0x72be5d74,0x80deb1fe,0x9bdc06a7,0xc19bf174
-	.long	0xe49b69c1,0xefbe4786,0x0fc19dc6,0x240ca1cc
-	.long	0x2de92c6f,0x4a7484aa,0x5cb0a9dc,0x76f988da
-	.long	0x983e5152,0xa831c66d,0xb00327c8,0xbf597fc7
-	.long	0xc6e00bf3,0xd5a79147,0x06ca6351,0x14292967
-	.long	0x27b70a85,0x2e1b2138,0x4d2c6dfc,0x53380d13
-	.long	0x650a7354,0x766a0abb,0x81c2c92e,0x92722c85
-	.long	0xa2bfe8a1,0xa81a664b,0xc24b8b70,0xc76c51a3
-	.long	0xd192e819,0xd6990624,0xf40e3585,0x106aa070
-	.long	0x19a4c116,0x1e376c08,0x2748774c,0x34b0bcb5
-	.long	0x391c0cb3,0x4ed8aa4a,0x5b9cca4f,0x682e6ff3
-	.long	0x748f82ee,0x78a5636f,0x84c87814,0x8cc70208
-	.long	0x90befffa,0xa4506ceb,0xbef9a3f7,0xc67178f2
-___
-$code.=<<___ if ($SZ==8);
-	.quad	0x428a2f98d728ae22,0x7137449123ef65cd
-	.quad	0xb5c0fbcfec4d3b2f,0xe9b5dba58189dbbc
-	.quad	0x3956c25bf348b538,0x59f111f1b605d019
-	.quad	0x923f82a4af194f9b,0xab1c5ed5da6d8118
-	.quad	0xd807aa98a3030242,0x12835b0145706fbe
-	.quad	0x243185be4ee4b28c,0x550c7dc3d5ffb4e2
-	.quad	0x72be5d74f27b896f,0x80deb1fe3b1696b1
-	.quad	0x9bdc06a725c71235,0xc19bf174cf692694
-	.quad	0xe49b69c19ef14ad2,0xefbe4786384f25e3
-	.quad	0x0fc19dc68b8cd5b5,0x240ca1cc77ac9c65
-	.quad	0x2de92c6f592b0275,0x4a7484aa6ea6e483
-	.quad	0x5cb0a9dcbd41fbd4,0x76f988da831153b5
-	.quad	0x983e5152ee66dfab,0xa831c66d2db43210
-	.quad	0xb00327c898fb213f,0xbf597fc7beef0ee4
-	.quad	0xc6e00bf33da88fc2,0xd5a79147930aa725
-	.quad	0x06ca6351e003826f,0x142929670a0e6e70
-	.quad	0x27b70a8546d22ffc,0x2e1b21385c26c926
-	.quad	0x4d2c6dfc5ac42aed,0x53380d139d95b3df
-	.quad	0x650a73548baf63de,0x766a0abb3c77b2a8
-	.quad	0x81c2c92e47edaee6,0x92722c851482353b
-	.quad	0xa2bfe8a14cf10364,0xa81a664bbc423001
-	.quad	0xc24b8b70d0f89791,0xc76c51a30654be30
-	.quad	0xd192e819d6ef5218,0xd69906245565a910
-	.quad	0xf40e35855771202a,0x106aa07032bbd1b8
-	.quad	0x19a4c116b8d2d0c8,0x1e376c085141ab53
-	.quad	0x2748774cdf8eeb99,0x34b0bcb5e19b48a8
-	.quad	0x391c0cb3c5c95a63,0x4ed8aa4ae3418acb
-	.quad	0x5b9cca4f7763e373,0x682e6ff3d6b2b8a3
-	.quad	0x748f82ee5defb2fc,0x78a5636f43172f60
-	.quad	0x84c87814a1f0ab72,0x8cc702081a6439ec
-	.quad	0x90befffa23631e28,0xa4506cebde82bde9
-	.quad	0xbef9a3f7b2c67915,0xc67178f2e372532b
-	.quad	0xca273eceea26619c,0xd186b8c721c0c207
-	.quad	0xeada7dd6cde0eb1e,0xf57d4f7fee6ed178
-	.quad	0x06f067aa72176fba,0x0a637dc5a2c898a6
-	.quad	0x113f9804bef90dae,0x1b710b35131c471b
-	.quad	0x28db77f523047d84,0x32caab7b40c72493
-	.quad	0x3c9ebe0a15c9bebc,0x431d67c49c100d4c
-	.quad	0x4cc5d4becb3e42b6,0x597f299cfc657e2a
-	.quad	0x5fcb6fab3ad6faec,0x6c44198c4a475817
-___
-$code.=<<___;
-.size	$Table,.-$Table
-.globl	$Func
-.type	$Func,\@function
-$Func:
-	sllg	$len,$len,`log(16*$SZ)/log(2)`
-___
-$code.=<<___ if ($kimdfunc);
-	larl	%r1,OPENSSL_s390xcap_P
-	lg	%r0,S390X_KIMD(%r1)	# check kimd capabilities
-	tmhh	%r0,`0x8000>>$kimdfunc`
-	jz	.Lsoftware
-	lghi	%r0,$kimdfunc
-	lgr	%r1,$ctx
-	lgr	%r2,$inp
-	lgr	%r3,$len
-	.long	0xb93e0002	# kimd %r0,%r2
-	brc	1,.-4		# pay attention to "partial completion"
-	br	%r14
-.align	16
-.Lsoftware:
-___
-$code.=<<___;
-	lghi	%r1,-$frame
-	la	$len,0($len,$inp)
-	stm${g}	$ctx,%r15,`2*$SIZE_T`($sp)
-	lgr	%r0,$sp
-	la	$sp,0(%r1,$sp)
-	st${g}	%r0,0($sp)
-
-	larl	$tbl,$Table
-	$LD	$A,`0*$SZ`($ctx)
-	$LD	$B,`1*$SZ`($ctx)
-	$LD	$C,`2*$SZ`($ctx)
-	$LD	$D,`3*$SZ`($ctx)
-	$LD	$E,`4*$SZ`($ctx)
-	$LD	$F,`5*$SZ`($ctx)
-	$LD	$G,`6*$SZ`($ctx)
-	$LD	$H,`7*$SZ`($ctx)
-
-.Lloop:
-	lghi	$len,0
-___
-for ($i=0;$i<16;$i++)	{ &BODY_00_15($i,@V); unshift(@V,pop(@V)); }
-$code.=".Lrounds_16_xx:\n";
+
+
+TEXT();
+OBJECT_BEGIN("$Table",64);
+
+if ($SZ==4) {
+	LONG(	0x428a2f98,0x71374491,0xb5c0fbcf,0xe9b5dba5);
+	LONG(	0x3956c25b,0x59f111f1,0x923f82a4,0xab1c5ed5);
+	LONG(	0xd807aa98,0x12835b01,0x243185be,0x550c7dc3);
+	LONG(	0x72be5d74,0x80deb1fe,0x9bdc06a7,0xc19bf174);
+	LONG(	0xe49b69c1,0xefbe4786,0x0fc19dc6,0x240ca1cc);
+	LONG(	0x2de92c6f,0x4a7484aa,0x5cb0a9dc,0x76f988da);
+	LONG(	0x983e5152,0xa831c66d,0xb00327c8,0xbf597fc7);
+	LONG(	0xc6e00bf3,0xd5a79147,0x06ca6351,0x14292967);
+	LONG(	0x27b70a85,0x2e1b2138,0x4d2c6dfc,0x53380d13);
+	LONG(	0x650a7354,0x766a0abb,0x81c2c92e,0x92722c85);
+	LONG(	0xa2bfe8a1,0xa81a664b,0xc24b8b70,0xc76c51a3);
+	LONG(	0xd192e819,0xd6990624,0xf40e3585,0x106aa070);
+	LONG(	0x19a4c116,0x1e376c08,0x2748774c,0x34b0bcb5);
+	LONG(	0x391c0cb3,0x4ed8aa4a,0x5b9cca4f,0x682e6ff3);
+	LONG(	0x748f82ee,0x78a5636f,0x84c87814,0x8cc70208);
+	LONG(	0x90befffa,0xa4506ceb,0xbef9a3f7,0xc67178f2);
+} else {
+	QUAD(	"428a2f98d728ae22", "7137449123ef65cd");
+	QUAD(	"b5c0fbcfec4d3b2f", "e9b5dba58189dbbc");
+	QUAD(	"3956c25bf348b538", "59f111f1b605d019");
+	QUAD(	"923f82a4af194f9b", "ab1c5ed5da6d8118");
+	QUAD(	"d807aa98a3030242", "12835b0145706fbe");
+	QUAD(	"243185be4ee4b28c", "550c7dc3d5ffb4e2");
+	QUAD(	"72be5d74f27b896f", "80deb1fe3b1696b1");
+	QUAD(	"9bdc06a725c71235", "c19bf174cf692694");
+	QUAD(	"e49b69c19ef14ad2", "efbe4786384f25e3");
+	QUAD(	"0fc19dc68b8cd5b5", "240ca1cc77ac9c65");
+	QUAD(	"2de92c6f592b0275", "4a7484aa6ea6e483");
+	QUAD(	"5cb0a9dcbd41fbd4", "76f988da831153b5");
+	QUAD(	"983e5152ee66dfab", "a831c66d2db43210");
+	QUAD(	"b00327c898fb213f", "bf597fc7beef0ee4");
+	QUAD(	"c6e00bf33da88fc2", "d5a79147930aa725");
+	QUAD(	"06ca6351e003826f", "142929670a0e6e70");
+	QUAD(	"27b70a8546d22ffc", "2e1b21385c26c926");
+	QUAD(	"4d2c6dfc5ac42aed", "53380d139d95b3df");
+	QUAD(	"650a73548baf63de", "766a0abb3c77b2a8");
+	QUAD(	"81c2c92e47edaee6", "92722c851482353b");
+	QUAD(	"a2bfe8a14cf10364", "a81a664bbc423001");
+	QUAD(	"c24b8b70d0f89791", "c76c51a30654be30");
+	QUAD(	"d192e819d6ef5218", "d69906245565a910");
+	QUAD(	"f40e35855771202a", "106aa07032bbd1b8");
+	QUAD(	"19a4c116b8d2d0c8", "1e376c085141ab53");
+	QUAD(	"2748774cdf8eeb99", "34b0bcb5e19b48a8");
+	QUAD(	"391c0cb3c5c95a63", "4ed8aa4ae3418acb");
+	QUAD(	"5b9cca4f7763e373", "682e6ff3d6b2b8a3");
+	QUAD(	"748f82ee5defb2fc", "78a5636f43172f60");
+	QUAD(	"84c87814a1f0ab72", "8cc702081a6439ec");
+	QUAD(	"90befffa23631e28", "a4506cebde82bde9");
+	QUAD(	"bef9a3f7b2c67915", "c67178f2e372532b");
+	QUAD(	"ca273eceea26619c", "d186b8c721c0c207");
+	QUAD(	"eada7dd6cde0eb1e", "f57d4f7fee6ed178");
+	QUAD(	"06f067aa72176fba", "0a637dc5a2c898a6");
+	QUAD(	"113f9804bef90dae", "1b710b35131c471b");
+	QUAD(	"28db77f523047d84", "32caab7b40c72493");
+	QUAD(	"3c9ebe0a15c9bebc", "431d67c49c100d4c");
+	QUAD(	"4cc5d4becb3e42b6", "597f299cfc657e2a");
+	QUAD(	"5fcb6fab3ad6faec", "6c44198c4a475817");
+}
+
+OBJECT_END("$Table");
+# Linux void sha[256|512]_block_data_order(SHA[256|512]_CTX *ctx, const void *in, size_t num);
+# z/OS  void sha[256|512]_block_data_order(SHA[256|512]_CTX *ctx, const void *in, size_t num, OPENSSL_s390xcap_st *OPENSSL_s390xcap_P);
+#
+FUNCTION_BEGIN($Func,3,"true");
+if ($flavour =~ /linux/) {
+	sllg	($len,$len,eval "log(16*$SZ)/log(2)");
+} else {
+	sllg	("R3","R3",eval "log(16*$SZ)/log(2)");
+}
+
+	if ($kimdfunc) {
+#		GET_EXTERN($xcap,"OPENSSL_s390xcap_P");
+if ($flavour =~ /linux/) {
+	larl	($xcap,"OPENSSL_s390xcap_P");
+} else {
+	# Need to get OPENSSL_s390xcap_P out of DSA
+	&{$z? \&lg:\&l} ("R9","$DSA_OFF(R4)");      # Get DSA address
+	&{$z? \&lg:\&l} ($xcap,"$PARMS_OFF+$SIZE_T*3(R9)"); # Get OPENSSL_s390xcap_P pointer
+}
+		lg		($wr0,"CS390X_KIMD($xcap)");	# check kimd capabilities
+		my $funcFlag = 0x8000>>$kimdfunc;
+		tmhh	($wr0,$funcFlag);
+		jz		(LABEL("Lsoftware"));
+
+		lghi	($wr0,$kimdfunc);
+		if ($flavour =~ /linux/) { # z/OS passes ctx in r1, inp in r2, len in r3
+		  lgr		("%r1",$ctx);
+		  lgr		("%r2",$inp);
+		  lgr		("%r3",$len);
+		}
+		kimd	($wr0,$wr2);		#.long	0xb93e0002
+		brc		(1,"$ip-4");		# pay attention to "partial completion"
+		j		(LABEL("EXIT_$Func"));
+	}
+	ALIGN(16);
+LABEL("Lsoftware:");
+	if ($flavour =~ /linux/) {
+	        lghi	("%r1","-$frame");
+		la		($len,"0($len,$inp)");
+		&{$z? \&stmg:\&stm}	($ctx,"%r15","(2*$SIZE_T)($sp)");
+		lgr		($wr0,$sp);
+		la		($sp,"0(%r1,$sp)"); # Push the stack frame
+	} else {
+	        lghi	($wr8,"-$frame");
+	        la      ($sp,"STACK");
+		&{$z? \&stg:\&st} ("R4","0*$SIZE_T($sp)");		# Save DSA pointer
+		# Move parameters into expected regs for z/OS
+		la		($len,"0(R3,R2)");		# la	($len,"0($len,$inp)");
+		lgr		($inp,"R2");
+		lgr		($ctx,"R1");
+
+		&{$z? \&stmg:\&stm}	($ctx,$len,"2*$SIZE_T($sp)");	# Save params
+		lgr		($wr0,$sp);
+		la		($sp,"0($wr8,$sp)"); # Push the stack frame
+	}
+	&{$z? \&stg:\&st}	($wr0,"0($sp)");				# Store back chain
+
+	larl	($tbl,LABEL("$Table"));
+	if ($SZ == 8) {
+		lg	($A,"0*$SZ($ctx)");
+		lg	($B,"1*$SZ($ctx)");
+		lg	($C,"2*$SZ($ctx)");
+		lg	($D,"3*$SZ($ctx)");
+		lg	($E,"4*$SZ($ctx)");
+		lg	($F,"5*$SZ($ctx)");
+		lg	($G,"6*$SZ($ctx)");
+		lg	($H,"7*$SZ($ctx)");
+	} else {
+		llgf	($A,"0*$SZ($ctx)");
+		llgf	($B,"1*$SZ($ctx)");
+		llgf	($C,"2*$SZ($ctx)");
+		llgf	($D,"3*$SZ($ctx)");
+		llgf	($E,"4*$SZ($ctx)");
+		llgf	($F,"5*$SZ($ctx)");
+		llgf	($G,"6*$SZ($ctx)");
+		llgf	($H,"7*$SZ($ctx)");
+	}
+LABEL("Lloop:");
+	lghi	("$len",0);
+
+for ($i=0;$i<16;$i++)	{  &BODY_00_15($i,@V);  unshift(@V,pop(@V));  }
+
+LABEL("Lrounds_16_xx:");
+
 for (;$i<32;$i++)	{ &BODY_16_XX($i,@V); unshift(@V,pop(@V)); }
-$code.=<<___;
-	aghi	$len,`16*$SZ`
-	lghi	$t0,`($rounds-16)*$SZ`
-	clgr	$len,$t0
-	jne	.Lrounds_16_xx
-
-	l${g}	$ctx,`$frame+2*$SIZE_T`($sp)
-	la	$inp,`16*$SZ`($inp)
-	$ADD	$A,`0*$SZ`($ctx)
-	$ADD	$B,`1*$SZ`($ctx)
-	$ADD	$C,`2*$SZ`($ctx)
-	$ADD	$D,`3*$SZ`($ctx)
-	$ADD	$E,`4*$SZ`($ctx)
-	$ADD	$F,`5*$SZ`($ctx)
-	$ADD	$G,`6*$SZ`($ctx)
-	$ADD	$H,`7*$SZ`($ctx)
-	$ST	$A,`0*$SZ`($ctx)
-	$ST	$B,`1*$SZ`($ctx)
-	$ST	$C,`2*$SZ`($ctx)
-	$ST	$D,`3*$SZ`($ctx)
-	$ST	$E,`4*$SZ`($ctx)
-	$ST	$F,`5*$SZ`($ctx)
-	$ST	$G,`6*$SZ`($ctx)
-	$ST	$H,`7*$SZ`($ctx)
-	cl${g}	$inp,`$frame+4*$SIZE_T`($sp)
-	jne	.Lloop
-
-	lm${g}	%r6,%r15,`$frame+6*$SIZE_T`($sp)
-	br	%r14
-.size	$Func,.-$Func
-.string	"SHA${label} block transform for s390x, CRYPTOGAMS by <appro\@openssl.org>"
-___
-
-$code =~ s/\`([^\`]*)\`/eval $1/gem;
+
+	aghi	($len,"16*$SZ");
+	lghi	($t0,"($rounds-16)*$SZ");
+	clgr	($len,$t0);
+	jne		(LABEL("Lrounds_16_xx"));
+	&{$z? \&lg:\&l}	($ctx,"($frame+(2*$SIZE_T))($sp)");
+	la		($inp,"16*$SZ($inp)");
+	if ($SZ == 8) {
+		alg	($A,"0*$SZ($ctx)");
+		alg	($B,"1*$SZ($ctx)");
+		alg	($C,"2*$SZ($ctx)");
+		alg	($D,"3*$SZ($ctx)");
+		alg	($E,"4*$SZ($ctx)");
+		alg	($F,"5*$SZ($ctx)");
+		alg	($G,"6*$SZ($ctx)");
+		alg	($H,"7*$SZ($ctx)");
+		stg	($A,"0*$SZ($ctx)");
+		stg	($B,"1*$SZ($ctx)");
+		stg	($C,"2*$SZ($ctx)");
+		stg	($D,"3*$SZ($ctx)");
+		stg	($E,"4*$SZ($ctx)");
+		stg	($F,"5*$SZ($ctx)");
+		stg	($G,"6*$SZ($ctx)");
+		stg	($H,"7*$SZ($ctx)");
+	} else {
+		al	($A,"0*$SZ($ctx)");
+		al	($B,"1*$SZ($ctx)");
+		al	($C,"2*$SZ($ctx)");
+		al	($D,"3*$SZ($ctx)");
+		al	($E,"4*$SZ($ctx)");
+		al	($F,"5*$SZ($ctx)");
+		al	($G,"6*$SZ($ctx)");
+		al	($H,"7*$SZ($ctx)");
+		st	($A,"0*$SZ($ctx)");
+		st	($B,"1*$SZ($ctx)");
+		st	($C,"2*$SZ($ctx)");
+		st	($D,"3*$SZ($ctx)");
+		st	($E,"4*$SZ($ctx)");
+		st	($F,"5*$SZ($ctx)");
+		st	($G,"6*$SZ($ctx)");
+		st	($H,"7*$SZ($ctx)");
+	}
+	&{$z? \&clg:\&cl}	($inp,"($frame+(4*$SIZE_T))($sp)");
+	jne		(LABEL("Lloop"));
+if ($flavour =~ /linux/) {
+	&{$z? \&lmg:\&lm} ("%r6","%r15","($frame+(6*$SIZE_T))($sp)");
+} else {
+	&{$z? \&lg:\&l} ("R4","($frame+(0*$SIZE_T))($sp)");
+}
+FUNCTION_END("$Func",$rv);
+
+ASCIZ	("SHA${label} block transform for s390x, CRYPTOGAMS by <appro\@openssl.org>");
+
+#$code =~ s/\`([^\`]*)\`/eval $1/gem;
 # unlike 32-bit shift 64-bit one takes three arguments
-$code =~ s/(srlg\s+)(%r[0-9]+),/$1$2,$2,/gm;
+#$code =~ s/(srlg\s+)(%r[0-9]+),/$1$2,$2,/gm; fixed inline PTW
+
+LOCAL_VARS_BEGIN();
+	ds		("STACKSPACE","200F");
+    ds		("STACK", "0F");
+    ds      ("SAVEAREA","32F");
+LOCAL_VARS_END();
+
+PERLASM_END();

-print $code;
-close STDOUT or die "error closing STDOUT: $!";
diff --git a/crypto/sha/build.info b/crypto/sha/build.info
index 5dd5a99..d1a6a9c 100644
--- a/crypto/sha/build.info
+++ b/crypto/sha/build.info
@@ -68,12 +68,17 @@ GENERATE[sha512-armv8.S]=asm/sha512-armv8.pl $(PERLASM_SCHEME)
 INCLUDE[sha512-armv8.o]=..
 GENERATE[keccak1600-armv8.S]=asm/keccak1600-armv8.pl $(PERLASM_SCHEME)

+GENERATE[sha1-s390x.s]=asm/sha1-s390x.pl $(PERLASM_SCHEME)
 GENERATE[sha1-s390x.S]=asm/sha1-s390x.pl $(PERLASM_SCHEME)
 INCLUDE[sha1-s390x.o]=..
+GENERATE[sha256-s390x.s]=asm/sha512-s390x.pl $(PERLASM_SCHEME)
 GENERATE[sha256-s390x.S]=asm/sha512-s390x.pl $(PERLASM_SCHEME)
+
 INCLUDE[sha256-s390x.o]=..
+GENERATE[sha512-s390x.s]=asm/sha512-s390x.pl $(PERLASM_SCHEME)
 GENERATE[sha512-s390x.S]=asm/sha512-s390x.pl $(PERLASM_SCHEME)
 INCLUDE[sha512-s390x.o]=..
+GENERATE[keccak1600-s390x.s]=asm/keccak1600-s390x.pl $(PERLASM_SCHEME)
 GENERATE[keccak1600-s390x.S]=asm/keccak1600-s390x.pl $(PERLASM_SCHEME)

 BEGINRAW[Makefile(unix)]
diff --git a/crypto/sha/sha256.c b/crypto/sha/sha256.c
index 11050ba..b210693 100644
--- a/crypto/sha/sha256.c
+++ b/crypto/sha/sha256.c
@@ -122,11 +122,22 @@ int SHA224_Final(unsigned char *md, SHA256_CTX *c)
 #define HASH_UPDATE             SHA256_Update
 #define HASH_TRANSFORM          SHA256_Transform
 #define HASH_FINAL              SHA256_Final
-#define HASH_BLOCK_DATA_ORDER   sha256_block_data_order
+
 #ifndef SHA256_ASM
-static
+    #define HASH_BLOCK_DATA_ORDER   sha256_block_data_order
+    static void sha256_block_data_order(SHA256_CTX *ctx, const void *in, size_t num);
+#else
+#  ifdef __MVS__
+     #define HASH_BLOCK_DATA_ORDER(_c,_p,_n) sha256_block_data_order(_c, _p, _n, &OPENSSL_s390xcap_P)
+     void sha256_block_data_order(SHA256_CTX *ctx, const void *in, size_t num, void *OPENSSL_s390xcap_P);
+#  else
+     #define HASH_BLOCK_DATA_ORDER   sha256_block_data_order
+     void sha256_block_data_order(SHA256_CTX *ctx, const void *in, size_t num);
+#  endif
 #endif
-void sha256_block_data_order(SHA256_CTX *ctx, const void *in, size_t num);
+
+
+

 #include "crypto/md32_common.h"

diff --git a/crypto/sha/sha512.c b/crypto/sha/sha512.c
index ca1f387..684fb00 100644
--- a/crypto/sha/sha512.c
+++ b/crypto/sha/sha512.c
@@ -52,9 +52,16 @@
 #include "internal/cryptlib.h"
 #include "crypto/sha.h"

+#if defined(OPENSSL_CPUID_OBJ) && defined(__MVS__)
+/*
+ * IBM S390X support
+ */
+# include "crypto/s390x_arch.h"
+#endif
+
 #if defined(__i386) || defined(__i386__) || defined(_M_IX86) || \
     defined(__x86_64) || defined(_M_AMD64) || defined(_M_X64) || \
-    defined(__s390__) || defined(__s390x__) || \
+    defined(__s390__) || defined(__s390x__) || defined(__MVS__) || \
     defined(__aarch64__) || \
     defined(SHA512_ASM)
 # define SHA512_BLOCK_CAN_MANAGE_UNALIGNED_DATA
@@ -133,9 +140,17 @@ int SHA512_Init(SHA512_CTX *c)
 }

 #ifndef SHA512_ASM
-static
+    #define HASH_BLOCK_DATA_ORDER(_c,_p,_n) sha512_block_data_order(_c, _p, _n)
+    static void sha512_block_data_order(SHA512_CTX *ctx, const void *in, size_t num);
+#else
+#  ifdef __MVS__
+     #define HASH_BLOCK_DATA_ORDER(_c,_p,_n) sha512_block_data_order(_c, _p, _n, &OPENSSL_s390xcap_P)
+     void sha512_block_data_order(SHA512_CTX *ctx, const void *in, size_t num, void *OPENSSL_s390xcap_P);
+#  else
+     #define HASH_BLOCK_DATA_ORDER(_c,_p,_n) sha512_block_data_order(_c, _p, _n)
+     void sha512_block_data_order(SHA512_CTX *ctx, const void *in, size_t num);
+#  endif
 #endif
-void sha512_block_data_order(SHA512_CTX *ctx, const void *in, size_t num);

 int SHA512_Final(unsigned char *md, SHA512_CTX *c)
 {
@@ -147,7 +162,7 @@ int SHA512_Final(unsigned char *md, SHA512_CTX *c)
     if (n > (sizeof(c->u) - 16)) {
         memset(p + n, 0, sizeof(c->u) - n);
         n = 0;
-        sha512_block_data_order(c, p, 1);
+        HASH_BLOCK_DATA_ORDER(c, p, 1);
     }

     memset(p + n, 0, sizeof(c->u) - 16 - n);
@@ -173,7 +188,7 @@ int SHA512_Final(unsigned char *md, SHA512_CTX *c)
     p[sizeof(c->u) - 16] = (unsigned char)(c->Nh >> 56);
 #endif

-    sha512_block_data_order(c, p, 1);
+    HASH_BLOCK_DATA_ORDER(c, p, 1);

     if (md == 0)
         return 0;
@@ -286,7 +301,7 @@ int SHA512_Update(SHA512_CTX *c, const void *_data, size_t len)
         } else {
             memcpy(p + c->num, data, n), c->num = 0;
             len -= n, data += n;
-            sha512_block_data_order(c, p, 1);
+            HASH_BLOCK_DATA_ORDER(c, p, 1);
         }
     }

@@ -295,11 +310,11 @@ int SHA512_Update(SHA512_CTX *c, const void *_data, size_t len)
         if ((size_t)data % sizeof(c->u.d[0]) != 0)
             while (len >= sizeof(c->u))
                 memcpy(p, data, sizeof(c->u)),
-                sha512_block_data_order(c, p, 1),
+                HASH_BLOCK_DATA_ORDER(c, p, 1),
                 len -= sizeof(c->u), data += sizeof(c->u);
         else
 #endif
-            sha512_block_data_order(c, data, len / sizeof(c->u)),
+            HASH_BLOCK_DATA_ORDER(c, data, len / sizeof(c->u)),
             data += len, len %= sizeof(c->u), data -= len;
     }

@@ -320,7 +335,7 @@ void SHA512_Transform(SHA512_CTX *c, const unsigned char *data)
     if ((size_t)data % sizeof(c->u.d[0]) != 0)
         memcpy(c->u.p, data, sizeof(c->u.p)), data = c->u.p;
 #endif
-    sha512_block_data_order(c, data, 1);
+    HASH_BLOCK_DATA_ORDER(c, data, 1);
 }

 unsigned char *SHA384(const unsigned char *d, size_t n, unsigned char *md)
diff --git a/crypto/sha/sha_local.h b/crypto/sha/sha_local.h
index 6edb9ef..bfbe8a8 100644
--- a/crypto/sha/sha_local.h
+++ b/crypto/sha/sha_local.h
@@ -31,15 +31,22 @@
 #define HASH_TRANSFORM                  SHA1_Transform
 #define HASH_FINAL                      SHA1_Final
 #define HASH_INIT                       SHA1_Init
-#define HASH_BLOCK_DATA_ORDER           sha1_block_data_order
+/*#define HASH_BLOCK_DATA_ORDER           sha1_block_data_order */
 #define Xupdate(a,ix,ia,ib,ic,id)       ( (a)=(ia^ib^ic^id),    \
                                           ix=(a)=ROTATE((a),1)  \
                                         )

 #ifndef SHA1_ASM
-static void sha1_block_data_order(SHA_CTX *c, const void *p, size_t num);
+  #define HASH_BLOCK_DATA_ORDER           sha1_block_data_order
+  static void sha1_block_data_order(SHA_CTX *c, const void *p, size_t num);
 #else
-void sha1_block_data_order(SHA_CTX *c, const void *p, size_t num);
+  #ifdef __MVS__
+    #define HASH_BLOCK_DATA_ORDER(_c,_p,_n) sha1_block_data_order(_c, _p, _n, &OPENSSL_s390xcap_P)
+    void sha1_block_data_order(SHA_CTX *c, const void *p, size_t num, void *OPENSSL_s390xcap_P);
+  #else
+    #define HASH_BLOCK_DATA_ORDER           sha1_block_data_order
+    void sha1_block_data_order(SHA_CTX *c, const void *p, size_t num);
+  #endif
 #endif

 #include "crypto/md32_common.h"
diff --git a/crypto/threads_pthread.c b/crypto/threads_pthread.c
index ae39e23..6d9ede2 100644
--- a/crypto/threads_pthread.c
+++ b/crypto/threads_pthread.c
@@ -137,7 +137,13 @@ int CRYPTO_THREAD_init_local(CRYPTO_THREAD_LOCAL *key, void (*cleanup)(void *))

 void *CRYPTO_THREAD_get_local(CRYPTO_THREAD_LOCAL *key)
 {
+#if defined(__MVS__)
+    void *getvalue = NULL;
+    pthread_getspecific(*key,&getvalue);
+    return getvalue;
+#else
     return pthread_getspecific(*key);
+#endif
 }

 int CRYPTO_THREAD_set_local(CRYPTO_THREAD_LOCAL *key, void *val)
diff --git a/include/crypto/evp.h b/include/crypto/evp.h
index d86aed3..063391c 100644
--- a/include/crypto/evp.h
+++ b/include/crypto/evp.h
@@ -377,6 +377,7 @@ const EVP_CIPHER *EVP_##cname##_ecb(void) { return &cname##_ecb; }

 #define X25519_KEYLEN        32
 #define X448_KEYLEN          56
+#define ED25519_KEYLEN       32
 #define ED448_KEYLEN         57

 #define MAX_KEYLEN  ED448_KEYLEN
diff --git a/include/crypto/md32_common.h b/include/crypto/md32_common.h
index 1124e9c..39ee256 100644
--- a/include/crypto/md32_common.h
+++ b/include/crypto/md32_common.h
@@ -64,6 +64,13 @@
  */

 #include <openssl/crypto.h>
+#if defined(OPENSSL_CPUID_OBJ) && defined(__MVS__)
+/*
+ * IBM S390X support
+ */
+# include "crypto/s390x_arch.h"
+
+#endif

 #if !defined(DATA_ORDER_IS_BIG_ENDIAN) && !defined(DATA_ORDER_IS_LITTLE_ENDIAN)
 # error "DATA_ORDER must be defined!"
diff --git a/include/openssl/ecerr.h b/include/openssl/ecerr.h
index b6a5de0..cf88d07 100644
--- a/include/openssl/ecerr.h
+++ b/include/openssl/ecerr.h
@@ -206,8 +206,13 @@ int ERR_load_EC_strings(void);
 #  define EC_F_PKEY_EC_KEYGEN                              199
 #  define EC_F_PKEY_EC_PARAMGEN                            219
 #  define EC_F_PKEY_EC_SIGN                                218
-#  define EC_F_VALIDATE_ECX_DERIVE                         278
-
+#   define EC_F_S390X_PKEY_ECD_DIGESTSIGN25519             303
+#   define EC_F_S390X_PKEY_ECD_DIGESTSIGN448               304
+#   define EC_F_S390X_PKEY_ECD_KEYGEN25519                 305
+#   define EC_F_S390X_PKEY_ECD_KEYGEN448                   306
+#   define EC_F_S390X_PKEY_ECX_KEYGEN25519                 307
+#   define EC_F_S390X_PKEY_ECX_KEYGEN448                   308
+#  define EC_F_VALIDATE_ECX_DERIVE                         209
 /*
  * EC reason codes.
  */
diff --git a/test/build.info b/test/build.info
index 6357a7f..17148ee 100644
--- a/test/build.info
+++ b/test/build.info
@@ -47,8 +47,8 @@ INCLUDE_MAIN___test_libtestutil_OLB = /INCLUDE=MAIN
           pkey_meth_test pkey_meth_kdf_test uitest cipherbytes_test \
           asn1_encode_test asn1_decode_test asn1_string_table_test \
           x509_time_test x509_dup_cert_test x509_check_cert_pkey_test \
-          recordlentest drbgtest sslbuffertest \
-          recordlentest drbgtest drbg_cavs_test sslbuffertest \
+          sslbuffertest \
+          recordlentest sslbuffertest \
           time_offset_test pemtest ssl_cert_table_internal_test ciphername_test \
           servername_test ocspapitest rsa_mp_test fatalerrtest tls13ccstest \
           sysdefaulttest errtest ssl_ctx_test gosttest
diff --git a/tools/c99.sh b/tools/c99.sh
index 40b9d95..1caabbf 100644
--- a/tools/c99.sh
+++ b/tools/c99.sh
@@ -10,7 +10,30 @@ for arg in $* ; do
     -L*) lopts="$lopts $arg" ;;
     *) opts="$opts $arg" ;;
   esac
+  source=$arg;
 done

-c99 -Wl,dll $lopts $opts
-#c99 -DOPENSSL_THREADS -D_OPEN_THREADS -O -Wc,XPLINK -DB_ENDIAN -DCHARSET_EBCDIC -DNO_SYS_PARAM_H -D_ALL_SOURCE -qlongname -qlanglvl=extc99 $lopts $opts
+#echo "source=$source"
+filename=$(basename "$source")
+#echo "filename=$filename"
+extension="${filename##*.}"
+#echo "$extension"
+
+if [ "$filename" = "aes-s390x.s" ]; then
+  cmdline="-Wa,SECTALGN(256) $lopts $opts";
+elif [ "$filename" = "chacha-s390x.s" ]; then
+  cmdline="-Wa,SECTALGN(32) $lopts $opts";
+elif [ "$filename" = "ghash-s390x.s" ]; then
+  cmdline="-Wa,SECTALGN(32) $lopts $opts";
+elif [ "$filename" = "rc4-s390x.s" ]; then
+  cmdline="-Wa,SECTALGN(64) $lopts $opts";
+elif [ "$filename" = "keccak1600-s390x.s" ]; then
+  cmdline="-Wa,SECTALGN(256) $lopts $opts";
+else
+#  echo "Default"
+  cmdline="-Wl,dll $lopts $opts";
+fi
+
+#echo "c99 $cmdline"
+c99 $cmdline
+
